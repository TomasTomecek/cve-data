[
  {
    "patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex b4a9583364..ab7c0f755f 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -406,17 +406,41 @@ class MultipleHiddenInput(HiddenInput):\n \n \n class FileInput(Input):\n+    allow_multiple_selected = False\n     input_type = \"file\"\n     needs_multipart_form = True\n     template_name = \"django/forms/widgets/file.html\"\n \n+    def __init__(self, attrs=None):\n+        if (\n+            attrs is not None\n+            and not self.allow_multiple_selected\n+            and attrs.get(\"multiple\", False)\n+        ):\n+            raise ValueError(\n+                \"%s doesn't support uploading multiple files.\"\n+                % self.__class__.__qualname__\n+            )\n+        if self.allow_multiple_selected:\n+            if attrs is None:\n+                attrs = {\"multiple\": True}\n+            else:\n+                attrs.setdefault(\"multiple\", True)\n+        super().__init__(attrs)\n+\n     def format_value(self, value):\n         \"\"\"File input never renders a value.\"\"\"\n         return\n \n     def value_from_datadict(self, data, files, name):\n         \"File widgets take data from FILES, not POST\"\n-        return files.get(name)\n+        getter = files.get\n+        if self.allow_multiple_selected:\n+            try:\n+                getter = files.getlist\n+            except AttributeError:\n+                pass\n+        return getter(name)\n \n     def value_omitted_from_data(self, data, files, name):\n         return name not in files\n",
    "commit_message": "Fixed CVE-2023-31047, Fixed #31710 -- Prevented potential bypass of validation when uploading multiple files using one form field.\n\nThanks Moataz Al-Sharida and nawaik for reports.\n\nCo-authored-by: Shai Berger <shai@platonix.com>\nCo-authored-by: nessita <124304+nessita@users.noreply.github.com>\n\n",
    "code_before": "\"\"\"\nHTML Widget classes\n\"\"\"\n\nimport copy\nimport datetime\nimport warnings\nfrom collections import defaultdict\nfrom graphlib import CycleError, TopologicalSorter\nfrom itertools import chain\n\nfrom django.forms.utils import to_current_timezone\nfrom django.templatetags.static import static\nfrom django.utils import formats\nfrom django.utils.dates import MONTHS\nfrom django.utils.formats import get_format\nfrom django.utils.html import format_html, html_safe\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .renderers import get_default_renderer\n\n__all__ = (\n    \"Media\",\n    \"MediaDefiningClass\",\n    \"Widget\",\n    \"TextInput\",\n    \"NumberInput\",\n    \"EmailInput\",\n    \"URLInput\",\n    \"PasswordInput\",\n    \"HiddenInput\",\n    \"MultipleHiddenInput\",\n    \"FileInput\",\n    \"ClearableFileInput\",\n    \"Textarea\",\n    \"DateInput\",\n    \"DateTimeInput\",\n    \"TimeInput\",\n    \"CheckboxInput\",\n    \"Select\",\n    \"NullBooleanSelect\",\n    \"SelectMultiple\",\n    \"RadioSelect\",\n    \"CheckboxSelectMultiple\",\n    \"MultiWidget\",\n    \"SplitDateTimeWidget\",\n    \"SplitHiddenDateTimeWidget\",\n    \"SelectDateWidget\",\n)\n\nMEDIA_TYPES = (\"css\", \"js\")\n\n\nclass MediaOrderConflictWarning(RuntimeWarning):\n    pass\n\n\n@html_safe\nclass Media:\n    def __init__(self, media=None, css=None, js=None):\n        if media is not None:\n            css = getattr(media, \"css\", {})\n            js = getattr(media, \"js\", [])\n        else:\n            if css is None:\n                css = {}\n            if js is None:\n                js = []\n        self._css_lists = [css]\n        self._js_lists = [js]\n\n    def __repr__(self):\n        return \"Media(css=%r, js=%r)\" % (self._css, self._js)\n\n    def __str__(self):\n        return self.render()\n\n    @property\n    def _css(self):\n        css = defaultdict(list)\n        for css_list in self._css_lists:\n            for medium, sublist in css_list.items():\n                css[medium].append(sublist)\n        return {medium: self.merge(*lists) for medium, lists in css.items()}\n\n    @property\n    def _js(self):\n        return self.merge(*self._js_lists)\n\n    def render(self):\n        return mark_safe(\n            \"\\n\".join(\n                chain.from_iterable(\n                    getattr(self, \"render_\" + name)() for name in MEDIA_TYPES\n                )\n            )\n        )\n\n    def render_js(self):\n        return [\n            path.__html__()\n            if hasattr(path, \"__html__\")\n            else format_html('<script src=\"{}\"></script>', self.absolute_path(path))\n            for path in self._js\n        ]\n\n    def render_css(self):\n        # To keep rendering order consistent, we can't just iterate over items().\n        # We need to sort the keys, and iterate over the sorted list.\n        media = sorted(self._css)\n        return chain.from_iterable(\n            [\n                path.__html__()\n                if hasattr(path, \"__html__\")\n                else format_html(\n                    '<link href=\"{}\" media=\"{}\" rel=\"stylesheet\">',\n                    self.absolute_path(path),\n                    medium,\n                )\n                for path in self._css[medium]\n            ]\n            for medium in media\n        )\n\n    def absolute_path(self, path):\n        \"\"\"\n        Given a relative or absolute path to a static asset, return an absolute\n        path. An absolute path will be returned unchanged while a relative path\n        will be passed to django.templatetags.static.static().\n        \"\"\"\n        if path.startswith((\"http://\", \"https://\", \"/\")):\n            return path\n        return static(path)\n\n    def __getitem__(self, name):\n        \"\"\"Return a Media object that only contains media of the given type.\"\"\"\n        if name in MEDIA_TYPES:\n            return Media(**{str(name): getattr(self, \"_\" + name)})\n        raise KeyError('Unknown media type \"%s\"' % name)\n\n    @staticmethod\n    def merge(*lists):\n        \"\"\"\n        Merge lists while trying to keep the relative order of the elements.\n        Warn if the lists have the same elements in a different relative order.\n\n        For static assets it can be important to have them included in the DOM\n        in a certain order. In JavaScript you may not be able to reference a\n        global or in CSS you might want to override a style.\n        \"\"\"\n        ts = TopologicalSorter()\n        for head, *tail in filter(None, lists):\n            ts.add(head)  # Ensure that the first items are included.\n            for item in tail:\n                if head != item:  # Avoid circular dependency to self.\n                    ts.add(item, head)\n                head = item\n        try:\n            return list(ts.static_order())\n        except CycleError:\n            warnings.warn(\n                \"Detected duplicate Media files in an opposite order: {}\".format(\n                    \", \".join(repr(list_) for list_ in lists)\n                ),\n                MediaOrderConflictWarning,\n            )\n            return list(dict.fromkeys(chain.from_iterable(filter(None, lists))))\n\n    def __add__(self, other):\n        combined = Media()\n        combined._css_lists = self._css_lists[:]\n        combined._js_lists = self._js_lists[:]\n        for item in other._css_lists:\n            if item and item not in self._css_lists:\n                combined._css_lists.append(item)\n        for item in other._js_lists:\n            if item and item not in self._js_lists:\n                combined._js_lists.append(item)\n        return combined\n\n\ndef media_property(cls):\n    def _media(self):\n        # Get the media property of the superclass, if it exists\n        sup_cls = super(cls, self)\n        try:\n            base = sup_cls.media\n        except AttributeError:\n            base = Media()\n\n        # Get the media definition for this class\n        definition = getattr(cls, \"Media\", None)\n        if definition:\n            extend = getattr(definition, \"extend\", True)\n            if extend:\n                if extend is True:\n                    m = base\n                else:\n                    m = Media()\n                    for medium in extend:\n                        m += base[medium]\n                return m + Media(definition)\n            return Media(definition)\n        return base\n\n    return property(_media)\n\n\nclass MediaDefiningClass(type):\n    \"\"\"\n    Metaclass for classes that can have media definitions.\n    \"\"\"\n\n    def __new__(mcs, name, bases, attrs):\n        new_class = super().__new__(mcs, name, bases, attrs)\n\n        if \"media\" not in attrs:\n            new_class.media = media_property(new_class)\n\n        return new_class\n\n\nclass Widget(metaclass=MediaDefiningClass):\n    needs_multipart_form = False  # Determines does this widget need multipart form\n    is_localized = False\n    is_required = False\n    supports_microseconds = True\n    use_fieldset = False\n\n    def __init__(self, attrs=None):\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.attrs = self.attrs.copy()\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.input_type == \"hidden\" if hasattr(self, \"input_type\") else False\n\n    def subwidgets(self, name, value, attrs=None):\n        context = self.get_context(name, value, attrs)\n        yield context[\"widget\"]\n\n    def format_value(self, value):\n        \"\"\"\n        Return a value as it should appear when rendered in a template.\n        \"\"\"\n        if value == \"\" or value is None:\n            return None\n        if self.is_localized:\n            return formats.localize_input(value)\n        return str(value)\n\n    def get_context(self, name, value, attrs):\n        return {\n            \"widget\": {\n                \"name\": name,\n                \"is_hidden\": self.is_hidden,\n                \"required\": self.is_required,\n                \"value\": self.format_value(value),\n                \"attrs\": self.build_attrs(self.attrs, attrs),\n                \"template_name\": self.template_name,\n            },\n        }\n\n    def render(self, name, value, attrs=None, renderer=None):\n        \"\"\"Render the widget as an HTML string.\"\"\"\n        context = self.get_context(name, value, attrs)\n        return self._render(self.template_name, context, renderer)\n\n    def _render(self, template_name, context, renderer=None):\n        if renderer is None:\n            renderer = get_default_renderer()\n        return mark_safe(renderer.render(template_name, context))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"Build an attribute dictionary.\"\"\"\n        return {**base_attrs, **(extra_attrs or {})}\n\n    def value_from_datadict(self, data, files, name):\n        \"\"\"\n        Given a dictionary of data and this widget's name, return the value\n        of this widget or None if it's not provided.\n        \"\"\"\n        return data.get(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return name not in data\n\n    def id_for_label(self, id_):\n        \"\"\"\n        Return the HTML ID attribute of this Widget for use by a <label>, given\n        the ID of the field. Return an empty string if no ID is available.\n\n        This hook is necessary because some widgets have multiple HTML\n        elements and, thus, multiple IDs. In that case, this method should\n        return an ID value that corresponds to the first ID in the widget's\n        tags.\n        \"\"\"\n        return id_\n\n    def use_required_attribute(self, initial):\n        return not self.is_hidden\n\n\nclass Input(Widget):\n    \"\"\"\n    Base class for all <input> widgets.\n    \"\"\"\n\n    input_type = None  # Subclasses must define this.\n    template_name = \"django/forms/widgets/input.html\"\n\n    def __init__(self, attrs=None):\n        if attrs is not None:\n            attrs = attrs.copy()\n            self.input_type = attrs.pop(\"type\", self.input_type)\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context[\"widget\"][\"type\"] = self.input_type\n        return context\n\n\nclass TextInput(Input):\n    input_type = \"text\"\n    template_name = \"django/forms/widgets/text.html\"\n\n\nclass NumberInput(Input):\n    input_type = \"number\"\n    template_name = \"django/forms/widgets/number.html\"\n\n\nclass EmailInput(Input):\n    input_type = \"email\"\n    template_name = \"django/forms/widgets/email.html\"\n\n\nclass URLInput(Input):\n    input_type = \"url\"\n    template_name = \"django/forms/widgets/url.html\"\n\n\nclass PasswordInput(Input):\n    input_type = \"password\"\n    template_name = \"django/forms/widgets/password.html\"\n\n    def __init__(self, attrs=None, render_value=False):\n        super().__init__(attrs)\n        self.render_value = render_value\n\n    def get_context(self, name, value, attrs):\n        if not self.render_value:\n            value = None\n        return super().get_context(name, value, attrs)\n\n\nclass HiddenInput(Input):\n    input_type = \"hidden\"\n    template_name = \"django/forms/widgets/hidden.html\"\n\n\nclass MultipleHiddenInput(HiddenInput):\n    \"\"\"\n    Handle <input type=\"hidden\"> for fields that have a list\n    of values.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/multiple_hidden.html\"\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        final_attrs = context[\"widget\"][\"attrs\"]\n        id_ = context[\"widget\"][\"attrs\"].get(\"id\")\n\n        subwidgets = []\n        for index, value_ in enumerate(context[\"widget\"][\"value\"]):\n            widget_attrs = final_attrs.copy()\n            if id_:\n                # An ID attribute was given. Add a numeric index as a suffix\n                # so that the inputs don't all have the same ID attribute.\n                widget_attrs[\"id\"] = \"%s_%s\" % (id_, index)\n            widget = HiddenInput()\n            widget.is_required = self.is_required\n            subwidgets.append(widget.get_context(name, value_, widget_attrs)[\"widget\"])\n\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        try:\n            getter = data.getlist\n        except AttributeError:\n            getter = data.get\n        return getter(name)\n\n    def format_value(self, value):\n        return [] if value is None else value\n\n\nclass FileInput(Input):\n    input_type = \"file\"\n    needs_multipart_form = True\n    template_name = \"django/forms/widgets/file.html\"\n\n    def format_value(self, value):\n        \"\"\"File input never renders a value.\"\"\"\n        return\n\n    def value_from_datadict(self, data, files, name):\n        \"File widgets take data from FILES, not POST\"\n        return files.get(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return name not in files\n\n    def use_required_attribute(self, initial):\n        return super().use_required_attribute(initial) and not initial\n\n\nFILE_INPUT_CONTRADICTION = object()\n\n\nclass ClearableFileInput(FileInput):\n    clear_checkbox_label = _(\"Clear\")\n    initial_text = _(\"Currently\")\n    input_text = _(\"Change\")\n    template_name = \"django/forms/widgets/clearable_file_input.html\"\n    checked = False\n\n    def clear_checkbox_name(self, name):\n        \"\"\"\n        Given the name of the file input, return the name of the clear checkbox\n        input.\n        \"\"\"\n        return name + \"-clear\"\n\n    def clear_checkbox_id(self, name):\n        \"\"\"\n        Given the name of the clear checkbox input, return the HTML id for it.\n        \"\"\"\n        return name + \"_id\"\n\n    def is_initial(self, value):\n        \"\"\"\n        Return whether value is considered to be initial value.\n        \"\"\"\n        return bool(value and getattr(value, \"url\", False))\n\n    def format_value(self, value):\n        \"\"\"\n        Return the file object if it has a defined url attribute.\n        \"\"\"\n        if self.is_initial(value):\n            return value\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        checkbox_name = self.clear_checkbox_name(name)\n        checkbox_id = self.clear_checkbox_id(checkbox_name)\n        context[\"widget\"].update(\n            {\n                \"checkbox_name\": checkbox_name,\n                \"checkbox_id\": checkbox_id,\n                \"is_initial\": self.is_initial(value),\n                \"input_text\": self.input_text,\n                \"initial_text\": self.initial_text,\n                \"clear_checkbox_label\": self.clear_checkbox_label,\n            }\n        )\n        context[\"widget\"][\"attrs\"].setdefault(\"disabled\", False)\n        context[\"widget\"][\"attrs\"][\"checked\"] = self.checked\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        upload = super().value_from_datadict(data, files, name)\n        self.checked = self.clear_checkbox_name(name) in data\n        if not self.is_required and CheckboxInput().value_from_datadict(\n            data, files, self.clear_checkbox_name(name)\n        ):\n            if upload:\n                # If the user contradicts themselves (uploads a new file AND\n                # checks the \"clear\" checkbox), we return a unique marker\n                # object that FileField will turn into a ValidationError.\n                return FILE_INPUT_CONTRADICTION\n            # False signals to clear any existing value, as opposed to just None\n            return False\n        return upload\n\n    def value_omitted_from_data(self, data, files, name):\n        return (\n            super().value_omitted_from_data(data, files, name)\n            and self.clear_checkbox_name(name) not in data\n        )\n\n\nclass Textarea(Widget):\n    template_name = \"django/forms/widgets/textarea.html\"\n\n    def __init__(self, attrs=None):\n        # Use slightly better defaults than HTML's 20x2 box\n        default_attrs = {\"cols\": \"40\", \"rows\": \"10\"}\n        if attrs:\n            default_attrs.update(attrs)\n        super().__init__(default_attrs)\n\n\nclass DateTimeBaseInput(TextInput):\n    format_key = \"\"\n    supports_microseconds = False\n\n    def __init__(self, attrs=None, format=None):\n        super().__init__(attrs)\n        self.format = format or None\n\n    def format_value(self, value):\n        return formats.localize_input(\n            value, self.format or formats.get_format(self.format_key)[0]\n        )\n\n\nclass DateInput(DateTimeBaseInput):\n    format_key = \"DATE_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/date.html\"\n\n\nclass DateTimeInput(DateTimeBaseInput):\n    format_key = \"DATETIME_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/datetime.html\"\n\n\nclass TimeInput(DateTimeBaseInput):\n    format_key = \"TIME_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/time.html\"\n\n\n# Defined at module level so that CheckboxInput is picklable (#17976)\ndef boolean_check(v):\n    return not (v is False or v is None or v == \"\")\n\n\nclass CheckboxInput(Input):\n    input_type = \"checkbox\"\n    template_name = \"django/forms/widgets/checkbox.html\"\n\n    def __init__(self, attrs=None, check_test=None):\n        super().__init__(attrs)\n        # check_test is a callable that takes a value and returns True\n        # if the checkbox should be checked for that value.\n        self.check_test = boolean_check if check_test is None else check_test\n\n    def format_value(self, value):\n        \"\"\"Only return the 'value' attribute if value isn't empty.\"\"\"\n        if value is True or value is False or value is None or value == \"\":\n            return\n        return str(value)\n\n    def get_context(self, name, value, attrs):\n        if self.check_test(value):\n            attrs = {**(attrs or {}), \"checked\": True}\n        return super().get_context(name, value, attrs)\n\n    def value_from_datadict(self, data, files, name):\n        if name not in data:\n            # A missing value means False because HTML form submission does not\n            # send results for unselected checkboxes.\n            return False\n        value = data.get(name)\n        # Translate true and false strings to boolean values.\n        values = {\"true\": True, \"false\": False}\n        if isinstance(value, str):\n            value = values.get(value.lower(), value)\n        return bool(value)\n\n    def value_omitted_from_data(self, data, files, name):\n        # HTML checkboxes don't appear in POST data if not checked, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass ChoiceWidget(Widget):\n    allow_multiple_selected = False\n    input_type = None\n    template_name = None\n    option_template_name = None\n    add_id_index = True\n    checked_attribute = {\"checked\": True}\n    option_inherits_attrs = True\n\n    def __init__(self, attrs=None, choices=()):\n        super().__init__(attrs)\n        # choices can be any iterable, but we may need to render this widget\n        # multiple times. Thus, collapse it into a list so it can be consumed\n        # more than once.\n        self.choices = list(choices)\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.attrs = self.attrs.copy()\n        obj.choices = copy.copy(self.choices)\n        memo[id(self)] = obj\n        return obj\n\n    def subwidgets(self, name, value, attrs=None):\n        \"\"\"\n        Yield all \"subwidgets\" of this widget. Used to enable iterating\n        options from a BoundField for choice widgets.\n        \"\"\"\n        value = self.format_value(value)\n        yield from self.options(name, value, attrs)\n\n    def options(self, name, value, attrs=None):\n        \"\"\"Yield a flat list of options for this widget.\"\"\"\n        for group in self.optgroups(name, value, attrs):\n            yield from group[1]\n\n    def optgroups(self, name, value, attrs=None):\n        \"\"\"Return a list of optgroups for this widget.\"\"\"\n        groups = []\n        has_selected = False\n\n        for index, (option_value, option_label) in enumerate(self.choices):\n            if option_value is None:\n                option_value = \"\"\n\n            subgroup = []\n            if isinstance(option_label, (list, tuple)):\n                group_name = option_value\n                subindex = 0\n                choices = option_label\n            else:\n                group_name = None\n                subindex = None\n                choices = [(option_value, option_label)]\n            groups.append((group_name, subgroup, index))\n\n            for subvalue, sublabel in choices:\n                selected = (not has_selected or self.allow_multiple_selected) and str(\n                    subvalue\n                ) in value\n                has_selected |= selected\n                subgroup.append(\n                    self.create_option(\n                        name,\n                        subvalue,\n                        sublabel,\n                        selected,\n                        index,\n                        subindex=subindex,\n                        attrs=attrs,\n                    )\n                )\n                if subindex is not None:\n                    subindex += 1\n        return groups\n\n    def create_option(\n        self, name, value, label, selected, index, subindex=None, attrs=None\n    ):\n        index = str(index) if subindex is None else \"%s_%s\" % (index, subindex)\n        option_attrs = (\n            self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n        )\n        if selected:\n            option_attrs.update(self.checked_attribute)\n        if \"id\" in option_attrs:\n            option_attrs[\"id\"] = self.id_for_label(option_attrs[\"id\"], index)\n        return {\n            \"name\": name,\n            \"value\": value,\n            \"label\": label,\n            \"selected\": selected,\n            \"index\": index,\n            \"attrs\": option_attrs,\n            \"type\": self.input_type,\n            \"template_name\": self.option_template_name,\n            \"wrap_label\": True,\n        }\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context[\"widget\"][\"optgroups\"] = self.optgroups(\n            name, context[\"widget\"][\"value\"], attrs\n        )\n        return context\n\n    def id_for_label(self, id_, index=\"0\"):\n        \"\"\"\n        Use an incremented id for each option where the main widget\n        references the zero index.\n        \"\"\"\n        if id_ and self.add_id_index:\n            id_ = \"%s_%s\" % (id_, index)\n        return id_\n\n    def value_from_datadict(self, data, files, name):\n        getter = data.get\n        if self.allow_multiple_selected:\n            try:\n                getter = data.getlist\n            except AttributeError:\n                pass\n        return getter(name)\n\n    def format_value(self, value):\n        \"\"\"Return selected values as a list.\"\"\"\n        if value is None and self.allow_multiple_selected:\n            return []\n        if not isinstance(value, (tuple, list)):\n            value = [value]\n        return [str(v) if v is not None else \"\" for v in value]\n\n\nclass Select(ChoiceWidget):\n    input_type = \"select\"\n    template_name = \"django/forms/widgets/select.html\"\n    option_template_name = \"django/forms/widgets/select_option.html\"\n    add_id_index = False\n    checked_attribute = {\"selected\": True}\n    option_inherits_attrs = False\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.allow_multiple_selected:\n            context[\"widget\"][\"attrs\"][\"multiple\"] = True\n        return context\n\n    @staticmethod\n    def _choice_has_empty_value(choice):\n        \"\"\"Return True if the choice's value is empty string or None.\"\"\"\n        value, _ = choice\n        return value is None or value == \"\"\n\n    def use_required_attribute(self, initial):\n        \"\"\"\n        Don't render 'required' if the first <option> has a value, as that's\n        invalid HTML.\n        \"\"\"\n        use_required_attribute = super().use_required_attribute(initial)\n        # 'required' is always okay for <select multiple>.\n        if self.allow_multiple_selected:\n            return use_required_attribute\n\n        first_choice = next(iter(self.choices), None)\n        return (\n            use_required_attribute\n            and first_choice is not None\n            and self._choice_has_empty_value(first_choice)\n        )\n\n\nclass NullBooleanSelect(Select):\n    \"\"\"\n    A Select Widget intended to be used with NullBooleanField.\n    \"\"\"\n\n    def __init__(self, attrs=None):\n        choices = (\n            (\"unknown\", _(\"Unknown\")),\n            (\"true\", _(\"Yes\")),\n            (\"false\", _(\"No\")),\n        )\n        super().__init__(attrs, choices)\n\n    def format_value(self, value):\n        try:\n            return {\n                True: \"true\",\n                False: \"false\",\n                \"true\": \"true\",\n                \"false\": \"false\",\n                # For backwards compatibility with Django < 2.2.\n                \"2\": \"true\",\n                \"3\": \"false\",\n            }[value]\n        except KeyError:\n            return \"unknown\"\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        return {\n            True: True,\n            \"True\": True,\n            \"False\": False,\n            False: False,\n            \"true\": True,\n            \"false\": False,\n            # For backwards compatibility with Django < 2.2.\n            \"2\": True,\n            \"3\": False,\n        }.get(value)\n\n\nclass SelectMultiple(Select):\n    allow_multiple_selected = True\n\n    def value_from_datadict(self, data, files, name):\n        try:\n            getter = data.getlist\n        except AttributeError:\n            getter = data.get\n        return getter(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        # An unselected <select multiple> doesn't appear in POST data, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass RadioSelect(ChoiceWidget):\n    input_type = \"radio\"\n    template_name = \"django/forms/widgets/radio.html\"\n    option_template_name = \"django/forms/widgets/radio_option.html\"\n    use_fieldset = True\n\n    def id_for_label(self, id_, index=None):\n        \"\"\"\n        Don't include for=\"field_0\" in <label> to improve accessibility when\n        using a screen reader, in addition clicking such a label would toggle\n        the first input.\n        \"\"\"\n        if index is None:\n            return \"\"\n        return super().id_for_label(id_, index)\n\n\nclass CheckboxSelectMultiple(RadioSelect):\n    allow_multiple_selected = True\n    input_type = \"checkbox\"\n    template_name = \"django/forms/widgets/checkbox_select.html\"\n    option_template_name = \"django/forms/widgets/checkbox_option.html\"\n\n    def use_required_attribute(self, initial):\n        # Don't use the 'required' attribute because browser validation would\n        # require all checkboxes to be checked instead of at least one.\n        return False\n\n    def value_omitted_from_data(self, data, files, name):\n        # HTML checkboxes don't appear in POST data if not checked, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass MultiWidget(Widget):\n    \"\"\"\n    A widget that is composed of multiple widgets.\n\n    In addition to the values added by Widget.get_context(), this widget\n    adds a list of subwidgets to the context as widget['subwidgets'].\n    These can be looped over and rendered like normal widgets.\n\n    You'll probably want to use this class with MultiValueField.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/multiwidget.html\"\n    use_fieldset = True\n\n    def __init__(self, widgets, attrs=None):\n        if isinstance(widgets, dict):\n            self.widgets_names = [(\"_%s\" % name) if name else \"\" for name in widgets]\n            widgets = widgets.values()\n        else:\n            self.widgets_names = [\"_%s\" % i for i in range(len(widgets))]\n        self.widgets = [w() if isinstance(w, type) else w for w in widgets]\n        super().__init__(attrs)\n\n    @property\n    def is_hidden(self):\n        return all(w.is_hidden for w in self.widgets)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.is_localized:\n            for widget in self.widgets:\n                widget.is_localized = self.is_localized\n        # value is a list/tuple of values, each corresponding to a widget\n        # in self.widgets.\n        if not isinstance(value, (list, tuple)):\n            value = self.decompress(value)\n\n        final_attrs = context[\"widget\"][\"attrs\"]\n        input_type = final_attrs.pop(\"type\", None)\n        id_ = final_attrs.get(\"id\")\n        subwidgets = []\n        for i, (widget_name, widget) in enumerate(\n            zip(self.widgets_names, self.widgets)\n        ):\n            if input_type is not None:\n                widget.input_type = input_type\n            widget_name = name + widget_name\n            try:\n                widget_value = value[i]\n            except IndexError:\n                widget_value = None\n            if id_:\n                widget_attrs = final_attrs.copy()\n                widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)\n            else:\n                widget_attrs = final_attrs\n            subwidgets.append(\n                widget.get_context(widget_name, widget_value, widget_attrs)[\"widget\"]\n            )\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def id_for_label(self, id_):\n        return \"\"\n\n    def value_from_datadict(self, data, files, name):\n        return [\n            widget.value_from_datadict(data, files, name + widget_name)\n            for widget_name, widget in zip(self.widgets_names, self.widgets)\n        ]\n\n    def value_omitted_from_data(self, data, files, name):\n        return all(\n            widget.value_omitted_from_data(data, files, name + widget_name)\n            for widget_name, widget in zip(self.widgets_names, self.widgets)\n        )\n\n    def decompress(self, value):\n        \"\"\"\n        Return a list of decompressed values for the given compressed value.\n        The given value can be assumed to be valid, but not necessarily\n        non-empty.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _get_media(self):\n        \"\"\"\n        Media for a multiwidget is the combination of all media of the\n        subwidgets.\n        \"\"\"\n        media = Media()\n        for w in self.widgets:\n            media += w.media\n        return media\n\n    media = property(_get_media)\n\n    def __deepcopy__(self, memo):\n        obj = super().__deepcopy__(memo)\n        obj.widgets = copy.deepcopy(self.widgets)\n        return obj\n\n    @property\n    def needs_multipart_form(self):\n        return any(w.needs_multipart_form for w in self.widgets)\n\n\nclass SplitDateTimeWidget(MultiWidget):\n    \"\"\"\n    A widget that splits datetime input into two <input type=\"text\"> boxes.\n    \"\"\"\n\n    supports_microseconds = False\n    template_name = \"django/forms/widgets/splitdatetime.html\"\n\n    def __init__(\n        self,\n        attrs=None,\n        date_format=None,\n        time_format=None,\n        date_attrs=None,\n        time_attrs=None,\n    ):\n        widgets = (\n            DateInput(\n                attrs=attrs if date_attrs is None else date_attrs,\n                format=date_format,\n            ),\n            TimeInput(\n                attrs=attrs if time_attrs is None else time_attrs,\n                format=time_format,\n            ),\n        )\n        super().__init__(widgets)\n\n    def decompress(self, value):\n        if value:\n            value = to_current_timezone(value)\n            return [value.date(), value.time()]\n        return [None, None]\n\n\nclass SplitHiddenDateTimeWidget(SplitDateTimeWidget):\n    \"\"\"\n    A widget that splits datetime input into two <input type=\"hidden\"> inputs.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/splithiddendatetime.html\"\n\n    def __init__(\n        self,\n        attrs=None,\n        date_format=None,\n        time_format=None,\n        date_attrs=None,\n        time_attrs=None,\n    ):\n        super().__init__(attrs, date_format, time_format, date_attrs, time_attrs)\n        for widget in self.widgets:\n            widget.input_type = \"hidden\"\n\n\nclass SelectDateWidget(Widget):\n    \"\"\"\n    A widget that splits date input into three <select> boxes.\n\n    This also serves as an example of a Widget that has more than one HTML\n    element and hence implements value_from_datadict.\n    \"\"\"\n\n    none_value = (\"\", \"---\")\n    month_field = \"%s_month\"\n    day_field = \"%s_day\"\n    year_field = \"%s_year\"\n    template_name = \"django/forms/widgets/select_date.html\"\n    input_type = \"select\"\n    select_widget = Select\n    date_re = _lazy_re_compile(r\"(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$\")\n    use_fieldset = True\n\n    def __init__(self, attrs=None, years=None, months=None, empty_label=None):\n        self.attrs = attrs or {}\n\n        # Optional list or tuple of years to use in the \"year\" select box.\n        if years:\n            self.years = years\n        else:\n            this_year = datetime.date.today().year\n            self.years = range(this_year, this_year + 10)\n\n        # Optional dict of months to use in the \"month\" select box.\n        if months:\n            self.months = months\n        else:\n            self.months = MONTHS\n\n        # Optional string, list, or tuple to use as empty_label.\n        if isinstance(empty_label, (list, tuple)):\n            if not len(empty_label) == 3:\n                raise ValueError(\"empty_label list/tuple must have 3 elements.\")\n\n            self.year_none_value = (\"\", empty_label[0])\n            self.month_none_value = (\"\", empty_label[1])\n            self.day_none_value = (\"\", empty_label[2])\n        else:\n            if empty_label is not None:\n                self.none_value = (\"\", empty_label)\n\n            self.year_none_value = self.none_value\n            self.month_none_value = self.none_value\n            self.day_none_value = self.none_value\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        date_context = {}\n        year_choices = [(i, str(i)) for i in self.years]\n        if not self.is_required:\n            year_choices.insert(0, self.year_none_value)\n        year_name = self.year_field % name\n        date_context[\"year\"] = self.select_widget(\n            attrs, choices=year_choices\n        ).get_context(\n            name=year_name,\n            value=context[\"widget\"][\"value\"][\"year\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % year_name},\n        )\n        month_choices = list(self.months.items())\n        if not self.is_required:\n            month_choices.insert(0, self.month_none_value)\n        month_name = self.month_field % name\n        date_context[\"month\"] = self.select_widget(\n            attrs, choices=month_choices\n        ).get_context(\n            name=month_name,\n            value=context[\"widget\"][\"value\"][\"month\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % month_name},\n        )\n        day_choices = [(i, i) for i in range(1, 32)]\n        if not self.is_required:\n            day_choices.insert(0, self.day_none_value)\n        day_name = self.day_field % name\n        date_context[\"day\"] = self.select_widget(\n            attrs,\n            choices=day_choices,\n        ).get_context(\n            name=day_name,\n            value=context[\"widget\"][\"value\"][\"day\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % day_name},\n        )\n        subwidgets = []\n        for field in self._parse_date_fmt():\n            subwidgets.append(date_context[field][\"widget\"])\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def format_value(self, value):\n        \"\"\"\n        Return a dict containing the year, month, and day of the current value.\n        Use dict instead of a datetime to allow invalid dates such as February\n        31 to display correctly.\n        \"\"\"\n        year, month, day = None, None, None\n        if isinstance(value, (datetime.date, datetime.datetime)):\n            year, month, day = value.year, value.month, value.day\n        elif isinstance(value, str):\n            match = self.date_re.match(value)\n            if match:\n                # Convert any zeros in the date to empty strings to match the\n                # empty option value.\n                year, month, day = [int(val) or \"\" for val in match.groups()]\n            else:\n                input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n                try:\n                    d = datetime.datetime.strptime(value, input_format)\n                except ValueError:\n                    pass\n                else:\n                    year, month, day = d.year, d.month, d.day\n        return {\"year\": year, \"month\": month, \"day\": day}\n\n    @staticmethod\n    def _parse_date_fmt():\n        fmt = get_format(\"DATE_FORMAT\")\n        escaped = False\n        for char in fmt:\n            if escaped:\n                escaped = False\n            elif char == \"\\\\\":\n                escaped = True\n            elif char in \"Yy\":\n                yield \"year\"\n            elif char in \"bEFMmNn\":\n                yield \"month\"\n            elif char in \"dj\":\n                yield \"day\"\n\n    def id_for_label(self, id_):\n        for first_select in self._parse_date_fmt():\n            return \"%s_%s\" % (id_, first_select)\n        return \"%s_month\" % id_\n\n    def value_from_datadict(self, data, files, name):\n        y = data.get(self.year_field % name)\n        m = data.get(self.month_field % name)\n        d = data.get(self.day_field % name)\n        if y == m == d == \"\":\n            return None\n        if y is not None and m is not None and d is not None:\n            input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n            input_format = formats.sanitize_strftime_format(input_format)\n            try:\n                date_value = datetime.date(int(y), int(m), int(d))\n            except ValueError:\n                # Return pseudo-ISO dates with zeros for any unselected values,\n                # e.g. '2017-0-23'.\n                return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n            except OverflowError:\n                return \"0-0-0\"\n            return date_value.strftime(input_format)\n        return data.get(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return not any(\n            (\"{}_{}\".format(name, interval) in data)\n            for interval in (\"year\", \"month\", \"day\")\n        )\n",
    "code_after": "\"\"\"\nHTML Widget classes\n\"\"\"\n\nimport copy\nimport datetime\nimport warnings\nfrom collections import defaultdict\nfrom graphlib import CycleError, TopologicalSorter\nfrom itertools import chain\n\nfrom django.forms.utils import to_current_timezone\nfrom django.templatetags.static import static\nfrom django.utils import formats\nfrom django.utils.dates import MONTHS\nfrom django.utils.formats import get_format\nfrom django.utils.html import format_html, html_safe\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import gettext_lazy as _\n\nfrom .renderers import get_default_renderer\n\n__all__ = (\n    \"Media\",\n    \"MediaDefiningClass\",\n    \"Widget\",\n    \"TextInput\",\n    \"NumberInput\",\n    \"EmailInput\",\n    \"URLInput\",\n    \"PasswordInput\",\n    \"HiddenInput\",\n    \"MultipleHiddenInput\",\n    \"FileInput\",\n    \"ClearableFileInput\",\n    \"Textarea\",\n    \"DateInput\",\n    \"DateTimeInput\",\n    \"TimeInput\",\n    \"CheckboxInput\",\n    \"Select\",\n    \"NullBooleanSelect\",\n    \"SelectMultiple\",\n    \"RadioSelect\",\n    \"CheckboxSelectMultiple\",\n    \"MultiWidget\",\n    \"SplitDateTimeWidget\",\n    \"SplitHiddenDateTimeWidget\",\n    \"SelectDateWidget\",\n)\n\nMEDIA_TYPES = (\"css\", \"js\")\n\n\nclass MediaOrderConflictWarning(RuntimeWarning):\n    pass\n\n\n@html_safe\nclass Media:\n    def __init__(self, media=None, css=None, js=None):\n        if media is not None:\n            css = getattr(media, \"css\", {})\n            js = getattr(media, \"js\", [])\n        else:\n            if css is None:\n                css = {}\n            if js is None:\n                js = []\n        self._css_lists = [css]\n        self._js_lists = [js]\n\n    def __repr__(self):\n        return \"Media(css=%r, js=%r)\" % (self._css, self._js)\n\n    def __str__(self):\n        return self.render()\n\n    @property\n    def _css(self):\n        css = defaultdict(list)\n        for css_list in self._css_lists:\n            for medium, sublist in css_list.items():\n                css[medium].append(sublist)\n        return {medium: self.merge(*lists) for medium, lists in css.items()}\n\n    @property\n    def _js(self):\n        return self.merge(*self._js_lists)\n\n    def render(self):\n        return mark_safe(\n            \"\\n\".join(\n                chain.from_iterable(\n                    getattr(self, \"render_\" + name)() for name in MEDIA_TYPES\n                )\n            )\n        )\n\n    def render_js(self):\n        return [\n            path.__html__()\n            if hasattr(path, \"__html__\")\n            else format_html('<script src=\"{}\"></script>', self.absolute_path(path))\n            for path in self._js\n        ]\n\n    def render_css(self):\n        # To keep rendering order consistent, we can't just iterate over items().\n        # We need to sort the keys, and iterate over the sorted list.\n        media = sorted(self._css)\n        return chain.from_iterable(\n            [\n                path.__html__()\n                if hasattr(path, \"__html__\")\n                else format_html(\n                    '<link href=\"{}\" media=\"{}\" rel=\"stylesheet\">',\n                    self.absolute_path(path),\n                    medium,\n                )\n                for path in self._css[medium]\n            ]\n            for medium in media\n        )\n\n    def absolute_path(self, path):\n        \"\"\"\n        Given a relative or absolute path to a static asset, return an absolute\n        path. An absolute path will be returned unchanged while a relative path\n        will be passed to django.templatetags.static.static().\n        \"\"\"\n        if path.startswith((\"http://\", \"https://\", \"/\")):\n            return path\n        return static(path)\n\n    def __getitem__(self, name):\n        \"\"\"Return a Media object that only contains media of the given type.\"\"\"\n        if name in MEDIA_TYPES:\n            return Media(**{str(name): getattr(self, \"_\" + name)})\n        raise KeyError('Unknown media type \"%s\"' % name)\n\n    @staticmethod\n    def merge(*lists):\n        \"\"\"\n        Merge lists while trying to keep the relative order of the elements.\n        Warn if the lists have the same elements in a different relative order.\n\n        For static assets it can be important to have them included in the DOM\n        in a certain order. In JavaScript you may not be able to reference a\n        global or in CSS you might want to override a style.\n        \"\"\"\n        ts = TopologicalSorter()\n        for head, *tail in filter(None, lists):\n            ts.add(head)  # Ensure that the first items are included.\n            for item in tail:\n                if head != item:  # Avoid circular dependency to self.\n                    ts.add(item, head)\n                head = item\n        try:\n            return list(ts.static_order())\n        except CycleError:\n            warnings.warn(\n                \"Detected duplicate Media files in an opposite order: {}\".format(\n                    \", \".join(repr(list_) for list_ in lists)\n                ),\n                MediaOrderConflictWarning,\n            )\n            return list(dict.fromkeys(chain.from_iterable(filter(None, lists))))\n\n    def __add__(self, other):\n        combined = Media()\n        combined._css_lists = self._css_lists[:]\n        combined._js_lists = self._js_lists[:]\n        for item in other._css_lists:\n            if item and item not in self._css_lists:\n                combined._css_lists.append(item)\n        for item in other._js_lists:\n            if item and item not in self._js_lists:\n                combined._js_lists.append(item)\n        return combined\n\n\ndef media_property(cls):\n    def _media(self):\n        # Get the media property of the superclass, if it exists\n        sup_cls = super(cls, self)\n        try:\n            base = sup_cls.media\n        except AttributeError:\n            base = Media()\n\n        # Get the media definition for this class\n        definition = getattr(cls, \"Media\", None)\n        if definition:\n            extend = getattr(definition, \"extend\", True)\n            if extend:\n                if extend is True:\n                    m = base\n                else:\n                    m = Media()\n                    for medium in extend:\n                        m += base[medium]\n                return m + Media(definition)\n            return Media(definition)\n        return base\n\n    return property(_media)\n\n\nclass MediaDefiningClass(type):\n    \"\"\"\n    Metaclass for classes that can have media definitions.\n    \"\"\"\n\n    def __new__(mcs, name, bases, attrs):\n        new_class = super().__new__(mcs, name, bases, attrs)\n\n        if \"media\" not in attrs:\n            new_class.media = media_property(new_class)\n\n        return new_class\n\n\nclass Widget(metaclass=MediaDefiningClass):\n    needs_multipart_form = False  # Determines does this widget need multipart form\n    is_localized = False\n    is_required = False\n    supports_microseconds = True\n    use_fieldset = False\n\n    def __init__(self, attrs=None):\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.attrs = self.attrs.copy()\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.input_type == \"hidden\" if hasattr(self, \"input_type\") else False\n\n    def subwidgets(self, name, value, attrs=None):\n        context = self.get_context(name, value, attrs)\n        yield context[\"widget\"]\n\n    def format_value(self, value):\n        \"\"\"\n        Return a value as it should appear when rendered in a template.\n        \"\"\"\n        if value == \"\" or value is None:\n            return None\n        if self.is_localized:\n            return formats.localize_input(value)\n        return str(value)\n\n    def get_context(self, name, value, attrs):\n        return {\n            \"widget\": {\n                \"name\": name,\n                \"is_hidden\": self.is_hidden,\n                \"required\": self.is_required,\n                \"value\": self.format_value(value),\n                \"attrs\": self.build_attrs(self.attrs, attrs),\n                \"template_name\": self.template_name,\n            },\n        }\n\n    def render(self, name, value, attrs=None, renderer=None):\n        \"\"\"Render the widget as an HTML string.\"\"\"\n        context = self.get_context(name, value, attrs)\n        return self._render(self.template_name, context, renderer)\n\n    def _render(self, template_name, context, renderer=None):\n        if renderer is None:\n            renderer = get_default_renderer()\n        return mark_safe(renderer.render(template_name, context))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"Build an attribute dictionary.\"\"\"\n        return {**base_attrs, **(extra_attrs or {})}\n\n    def value_from_datadict(self, data, files, name):\n        \"\"\"\n        Given a dictionary of data and this widget's name, return the value\n        of this widget or None if it's not provided.\n        \"\"\"\n        return data.get(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return name not in data\n\n    def id_for_label(self, id_):\n        \"\"\"\n        Return the HTML ID attribute of this Widget for use by a <label>, given\n        the ID of the field. Return an empty string if no ID is available.\n\n        This hook is necessary because some widgets have multiple HTML\n        elements and, thus, multiple IDs. In that case, this method should\n        return an ID value that corresponds to the first ID in the widget's\n        tags.\n        \"\"\"\n        return id_\n\n    def use_required_attribute(self, initial):\n        return not self.is_hidden\n\n\nclass Input(Widget):\n    \"\"\"\n    Base class for all <input> widgets.\n    \"\"\"\n\n    input_type = None  # Subclasses must define this.\n    template_name = \"django/forms/widgets/input.html\"\n\n    def __init__(self, attrs=None):\n        if attrs is not None:\n            attrs = attrs.copy()\n            self.input_type = attrs.pop(\"type\", self.input_type)\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context[\"widget\"][\"type\"] = self.input_type\n        return context\n\n\nclass TextInput(Input):\n    input_type = \"text\"\n    template_name = \"django/forms/widgets/text.html\"\n\n\nclass NumberInput(Input):\n    input_type = \"number\"\n    template_name = \"django/forms/widgets/number.html\"\n\n\nclass EmailInput(Input):\n    input_type = \"email\"\n    template_name = \"django/forms/widgets/email.html\"\n\n\nclass URLInput(Input):\n    input_type = \"url\"\n    template_name = \"django/forms/widgets/url.html\"\n\n\nclass PasswordInput(Input):\n    input_type = \"password\"\n    template_name = \"django/forms/widgets/password.html\"\n\n    def __init__(self, attrs=None, render_value=False):\n        super().__init__(attrs)\n        self.render_value = render_value\n\n    def get_context(self, name, value, attrs):\n        if not self.render_value:\n            value = None\n        return super().get_context(name, value, attrs)\n\n\nclass HiddenInput(Input):\n    input_type = \"hidden\"\n    template_name = \"django/forms/widgets/hidden.html\"\n\n\nclass MultipleHiddenInput(HiddenInput):\n    \"\"\"\n    Handle <input type=\"hidden\"> for fields that have a list\n    of values.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/multiple_hidden.html\"\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        final_attrs = context[\"widget\"][\"attrs\"]\n        id_ = context[\"widget\"][\"attrs\"].get(\"id\")\n\n        subwidgets = []\n        for index, value_ in enumerate(context[\"widget\"][\"value\"]):\n            widget_attrs = final_attrs.copy()\n            if id_:\n                # An ID attribute was given. Add a numeric index as a suffix\n                # so that the inputs don't all have the same ID attribute.\n                widget_attrs[\"id\"] = \"%s_%s\" % (id_, index)\n            widget = HiddenInput()\n            widget.is_required = self.is_required\n            subwidgets.append(widget.get_context(name, value_, widget_attrs)[\"widget\"])\n\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        try:\n            getter = data.getlist\n        except AttributeError:\n            getter = data.get\n        return getter(name)\n\n    def format_value(self, value):\n        return [] if value is None else value\n\n\nclass FileInput(Input):\n    allow_multiple_selected = False\n    input_type = \"file\"\n    needs_multipart_form = True\n    template_name = \"django/forms/widgets/file.html\"\n\n    def __init__(self, attrs=None):\n        if (\n            attrs is not None\n            and not self.allow_multiple_selected\n            and attrs.get(\"multiple\", False)\n        ):\n            raise ValueError(\n                \"%s doesn't support uploading multiple files.\"\n                % self.__class__.__qualname__\n            )\n        if self.allow_multiple_selected:\n            if attrs is None:\n                attrs = {\"multiple\": True}\n            else:\n                attrs.setdefault(\"multiple\", True)\n        super().__init__(attrs)\n\n    def format_value(self, value):\n        \"\"\"File input never renders a value.\"\"\"\n        return\n\n    def value_from_datadict(self, data, files, name):\n        \"File widgets take data from FILES, not POST\"\n        getter = files.get\n        if self.allow_multiple_selected:\n            try:\n                getter = files.getlist\n            except AttributeError:\n                pass\n        return getter(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return name not in files\n\n    def use_required_attribute(self, initial):\n        return super().use_required_attribute(initial) and not initial\n\n\nFILE_INPUT_CONTRADICTION = object()\n\n\nclass ClearableFileInput(FileInput):\n    clear_checkbox_label = _(\"Clear\")\n    initial_text = _(\"Currently\")\n    input_text = _(\"Change\")\n    template_name = \"django/forms/widgets/clearable_file_input.html\"\n    checked = False\n\n    def clear_checkbox_name(self, name):\n        \"\"\"\n        Given the name of the file input, return the name of the clear checkbox\n        input.\n        \"\"\"\n        return name + \"-clear\"\n\n    def clear_checkbox_id(self, name):\n        \"\"\"\n        Given the name of the clear checkbox input, return the HTML id for it.\n        \"\"\"\n        return name + \"_id\"\n\n    def is_initial(self, value):\n        \"\"\"\n        Return whether value is considered to be initial value.\n        \"\"\"\n        return bool(value and getattr(value, \"url\", False))\n\n    def format_value(self, value):\n        \"\"\"\n        Return the file object if it has a defined url attribute.\n        \"\"\"\n        if self.is_initial(value):\n            return value\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        checkbox_name = self.clear_checkbox_name(name)\n        checkbox_id = self.clear_checkbox_id(checkbox_name)\n        context[\"widget\"].update(\n            {\n                \"checkbox_name\": checkbox_name,\n                \"checkbox_id\": checkbox_id,\n                \"is_initial\": self.is_initial(value),\n                \"input_text\": self.input_text,\n                \"initial_text\": self.initial_text,\n                \"clear_checkbox_label\": self.clear_checkbox_label,\n            }\n        )\n        context[\"widget\"][\"attrs\"].setdefault(\"disabled\", False)\n        context[\"widget\"][\"attrs\"][\"checked\"] = self.checked\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        upload = super().value_from_datadict(data, files, name)\n        self.checked = self.clear_checkbox_name(name) in data\n        if not self.is_required and CheckboxInput().value_from_datadict(\n            data, files, self.clear_checkbox_name(name)\n        ):\n            if upload:\n                # If the user contradicts themselves (uploads a new file AND\n                # checks the \"clear\" checkbox), we return a unique marker\n                # object that FileField will turn into a ValidationError.\n                return FILE_INPUT_CONTRADICTION\n            # False signals to clear any existing value, as opposed to just None\n            return False\n        return upload\n\n    def value_omitted_from_data(self, data, files, name):\n        return (\n            super().value_omitted_from_data(data, files, name)\n            and self.clear_checkbox_name(name) not in data\n        )\n\n\nclass Textarea(Widget):\n    template_name = \"django/forms/widgets/textarea.html\"\n\n    def __init__(self, attrs=None):\n        # Use slightly better defaults than HTML's 20x2 box\n        default_attrs = {\"cols\": \"40\", \"rows\": \"10\"}\n        if attrs:\n            default_attrs.update(attrs)\n        super().__init__(default_attrs)\n\n\nclass DateTimeBaseInput(TextInput):\n    format_key = \"\"\n    supports_microseconds = False\n\n    def __init__(self, attrs=None, format=None):\n        super().__init__(attrs)\n        self.format = format or None\n\n    def format_value(self, value):\n        return formats.localize_input(\n            value, self.format or formats.get_format(self.format_key)[0]\n        )\n\n\nclass DateInput(DateTimeBaseInput):\n    format_key = \"DATE_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/date.html\"\n\n\nclass DateTimeInput(DateTimeBaseInput):\n    format_key = \"DATETIME_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/datetime.html\"\n\n\nclass TimeInput(DateTimeBaseInput):\n    format_key = \"TIME_INPUT_FORMATS\"\n    template_name = \"django/forms/widgets/time.html\"\n\n\n# Defined at module level so that CheckboxInput is picklable (#17976)\ndef boolean_check(v):\n    return not (v is False or v is None or v == \"\")\n\n\nclass CheckboxInput(Input):\n    input_type = \"checkbox\"\n    template_name = \"django/forms/widgets/checkbox.html\"\n\n    def __init__(self, attrs=None, check_test=None):\n        super().__init__(attrs)\n        # check_test is a callable that takes a value and returns True\n        # if the checkbox should be checked for that value.\n        self.check_test = boolean_check if check_test is None else check_test\n\n    def format_value(self, value):\n        \"\"\"Only return the 'value' attribute if value isn't empty.\"\"\"\n        if value is True or value is False or value is None or value == \"\":\n            return\n        return str(value)\n\n    def get_context(self, name, value, attrs):\n        if self.check_test(value):\n            attrs = {**(attrs or {}), \"checked\": True}\n        return super().get_context(name, value, attrs)\n\n    def value_from_datadict(self, data, files, name):\n        if name not in data:\n            # A missing value means False because HTML form submission does not\n            # send results for unselected checkboxes.\n            return False\n        value = data.get(name)\n        # Translate true and false strings to boolean values.\n        values = {\"true\": True, \"false\": False}\n        if isinstance(value, str):\n            value = values.get(value.lower(), value)\n        return bool(value)\n\n    def value_omitted_from_data(self, data, files, name):\n        # HTML checkboxes don't appear in POST data if not checked, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass ChoiceWidget(Widget):\n    allow_multiple_selected = False\n    input_type = None\n    template_name = None\n    option_template_name = None\n    add_id_index = True\n    checked_attribute = {\"checked\": True}\n    option_inherits_attrs = True\n\n    def __init__(self, attrs=None, choices=()):\n        super().__init__(attrs)\n        # choices can be any iterable, but we may need to render this widget\n        # multiple times. Thus, collapse it into a list so it can be consumed\n        # more than once.\n        self.choices = list(choices)\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.attrs = self.attrs.copy()\n        obj.choices = copy.copy(self.choices)\n        memo[id(self)] = obj\n        return obj\n\n    def subwidgets(self, name, value, attrs=None):\n        \"\"\"\n        Yield all \"subwidgets\" of this widget. Used to enable iterating\n        options from a BoundField for choice widgets.\n        \"\"\"\n        value = self.format_value(value)\n        yield from self.options(name, value, attrs)\n\n    def options(self, name, value, attrs=None):\n        \"\"\"Yield a flat list of options for this widget.\"\"\"\n        for group in self.optgroups(name, value, attrs):\n            yield from group[1]\n\n    def optgroups(self, name, value, attrs=None):\n        \"\"\"Return a list of optgroups for this widget.\"\"\"\n        groups = []\n        has_selected = False\n\n        for index, (option_value, option_label) in enumerate(self.choices):\n            if option_value is None:\n                option_value = \"\"\n\n            subgroup = []\n            if isinstance(option_label, (list, tuple)):\n                group_name = option_value\n                subindex = 0\n                choices = option_label\n            else:\n                group_name = None\n                subindex = None\n                choices = [(option_value, option_label)]\n            groups.append((group_name, subgroup, index))\n\n            for subvalue, sublabel in choices:\n                selected = (not has_selected or self.allow_multiple_selected) and str(\n                    subvalue\n                ) in value\n                has_selected |= selected\n                subgroup.append(\n                    self.create_option(\n                        name,\n                        subvalue,\n                        sublabel,\n                        selected,\n                        index,\n                        subindex=subindex,\n                        attrs=attrs,\n                    )\n                )\n                if subindex is not None:\n                    subindex += 1\n        return groups\n\n    def create_option(\n        self, name, value, label, selected, index, subindex=None, attrs=None\n    ):\n        index = str(index) if subindex is None else \"%s_%s\" % (index, subindex)\n        option_attrs = (\n            self.build_attrs(self.attrs, attrs) if self.option_inherits_attrs else {}\n        )\n        if selected:\n            option_attrs.update(self.checked_attribute)\n        if \"id\" in option_attrs:\n            option_attrs[\"id\"] = self.id_for_label(option_attrs[\"id\"], index)\n        return {\n            \"name\": name,\n            \"value\": value,\n            \"label\": label,\n            \"selected\": selected,\n            \"index\": index,\n            \"attrs\": option_attrs,\n            \"type\": self.input_type,\n            \"template_name\": self.option_template_name,\n            \"wrap_label\": True,\n        }\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context[\"widget\"][\"optgroups\"] = self.optgroups(\n            name, context[\"widget\"][\"value\"], attrs\n        )\n        return context\n\n    def id_for_label(self, id_, index=\"0\"):\n        \"\"\"\n        Use an incremented id for each option where the main widget\n        references the zero index.\n        \"\"\"\n        if id_ and self.add_id_index:\n            id_ = \"%s_%s\" % (id_, index)\n        return id_\n\n    def value_from_datadict(self, data, files, name):\n        getter = data.get\n        if self.allow_multiple_selected:\n            try:\n                getter = data.getlist\n            except AttributeError:\n                pass\n        return getter(name)\n\n    def format_value(self, value):\n        \"\"\"Return selected values as a list.\"\"\"\n        if value is None and self.allow_multiple_selected:\n            return []\n        if not isinstance(value, (tuple, list)):\n            value = [value]\n        return [str(v) if v is not None else \"\" for v in value]\n\n\nclass Select(ChoiceWidget):\n    input_type = \"select\"\n    template_name = \"django/forms/widgets/select.html\"\n    option_template_name = \"django/forms/widgets/select_option.html\"\n    add_id_index = False\n    checked_attribute = {\"selected\": True}\n    option_inherits_attrs = False\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.allow_multiple_selected:\n            context[\"widget\"][\"attrs\"][\"multiple\"] = True\n        return context\n\n    @staticmethod\n    def _choice_has_empty_value(choice):\n        \"\"\"Return True if the choice's value is empty string or None.\"\"\"\n        value, _ = choice\n        return value is None or value == \"\"\n\n    def use_required_attribute(self, initial):\n        \"\"\"\n        Don't render 'required' if the first <option> has a value, as that's\n        invalid HTML.\n        \"\"\"\n        use_required_attribute = super().use_required_attribute(initial)\n        # 'required' is always okay for <select multiple>.\n        if self.allow_multiple_selected:\n            return use_required_attribute\n\n        first_choice = next(iter(self.choices), None)\n        return (\n            use_required_attribute\n            and first_choice is not None\n            and self._choice_has_empty_value(first_choice)\n        )\n\n\nclass NullBooleanSelect(Select):\n    \"\"\"\n    A Select Widget intended to be used with NullBooleanField.\n    \"\"\"\n\n    def __init__(self, attrs=None):\n        choices = (\n            (\"unknown\", _(\"Unknown\")),\n            (\"true\", _(\"Yes\")),\n            (\"false\", _(\"No\")),\n        )\n        super().__init__(attrs, choices)\n\n    def format_value(self, value):\n        try:\n            return {\n                True: \"true\",\n                False: \"false\",\n                \"true\": \"true\",\n                \"false\": \"false\",\n                # For backwards compatibility with Django < 2.2.\n                \"2\": \"true\",\n                \"3\": \"false\",\n            }[value]\n        except KeyError:\n            return \"unknown\"\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        return {\n            True: True,\n            \"True\": True,\n            \"False\": False,\n            False: False,\n            \"true\": True,\n            \"false\": False,\n            # For backwards compatibility with Django < 2.2.\n            \"2\": True,\n            \"3\": False,\n        }.get(value)\n\n\nclass SelectMultiple(Select):\n    allow_multiple_selected = True\n\n    def value_from_datadict(self, data, files, name):\n        try:\n            getter = data.getlist\n        except AttributeError:\n            getter = data.get\n        return getter(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        # An unselected <select multiple> doesn't appear in POST data, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass RadioSelect(ChoiceWidget):\n    input_type = \"radio\"\n    template_name = \"django/forms/widgets/radio.html\"\n    option_template_name = \"django/forms/widgets/radio_option.html\"\n    use_fieldset = True\n\n    def id_for_label(self, id_, index=None):\n        \"\"\"\n        Don't include for=\"field_0\" in <label> to improve accessibility when\n        using a screen reader, in addition clicking such a label would toggle\n        the first input.\n        \"\"\"\n        if index is None:\n            return \"\"\n        return super().id_for_label(id_, index)\n\n\nclass CheckboxSelectMultiple(RadioSelect):\n    allow_multiple_selected = True\n    input_type = \"checkbox\"\n    template_name = \"django/forms/widgets/checkbox_select.html\"\n    option_template_name = \"django/forms/widgets/checkbox_option.html\"\n\n    def use_required_attribute(self, initial):\n        # Don't use the 'required' attribute because browser validation would\n        # require all checkboxes to be checked instead of at least one.\n        return False\n\n    def value_omitted_from_data(self, data, files, name):\n        # HTML checkboxes don't appear in POST data if not checked, so it's\n        # never known if the value is actually omitted.\n        return False\n\n\nclass MultiWidget(Widget):\n    \"\"\"\n    A widget that is composed of multiple widgets.\n\n    In addition to the values added by Widget.get_context(), this widget\n    adds a list of subwidgets to the context as widget['subwidgets'].\n    These can be looped over and rendered like normal widgets.\n\n    You'll probably want to use this class with MultiValueField.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/multiwidget.html\"\n    use_fieldset = True\n\n    def __init__(self, widgets, attrs=None):\n        if isinstance(widgets, dict):\n            self.widgets_names = [(\"_%s\" % name) if name else \"\" for name in widgets]\n            widgets = widgets.values()\n        else:\n            self.widgets_names = [\"_%s\" % i for i in range(len(widgets))]\n        self.widgets = [w() if isinstance(w, type) else w for w in widgets]\n        super().__init__(attrs)\n\n    @property\n    def is_hidden(self):\n        return all(w.is_hidden for w in self.widgets)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.is_localized:\n            for widget in self.widgets:\n                widget.is_localized = self.is_localized\n        # value is a list/tuple of values, each corresponding to a widget\n        # in self.widgets.\n        if not isinstance(value, (list, tuple)):\n            value = self.decompress(value)\n\n        final_attrs = context[\"widget\"][\"attrs\"]\n        input_type = final_attrs.pop(\"type\", None)\n        id_ = final_attrs.get(\"id\")\n        subwidgets = []\n        for i, (widget_name, widget) in enumerate(\n            zip(self.widgets_names, self.widgets)\n        ):\n            if input_type is not None:\n                widget.input_type = input_type\n            widget_name = name + widget_name\n            try:\n                widget_value = value[i]\n            except IndexError:\n                widget_value = None\n            if id_:\n                widget_attrs = final_attrs.copy()\n                widget_attrs[\"id\"] = \"%s_%s\" % (id_, i)\n            else:\n                widget_attrs = final_attrs\n            subwidgets.append(\n                widget.get_context(widget_name, widget_value, widget_attrs)[\"widget\"]\n            )\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def id_for_label(self, id_):\n        return \"\"\n\n    def value_from_datadict(self, data, files, name):\n        return [\n            widget.value_from_datadict(data, files, name + widget_name)\n            for widget_name, widget in zip(self.widgets_names, self.widgets)\n        ]\n\n    def value_omitted_from_data(self, data, files, name):\n        return all(\n            widget.value_omitted_from_data(data, files, name + widget_name)\n            for widget_name, widget in zip(self.widgets_names, self.widgets)\n        )\n\n    def decompress(self, value):\n        \"\"\"\n        Return a list of decompressed values for the given compressed value.\n        The given value can be assumed to be valid, but not necessarily\n        non-empty.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n\n    def _get_media(self):\n        \"\"\"\n        Media for a multiwidget is the combination of all media of the\n        subwidgets.\n        \"\"\"\n        media = Media()\n        for w in self.widgets:\n            media += w.media\n        return media\n\n    media = property(_get_media)\n\n    def __deepcopy__(self, memo):\n        obj = super().__deepcopy__(memo)\n        obj.widgets = copy.deepcopy(self.widgets)\n        return obj\n\n    @property\n    def needs_multipart_form(self):\n        return any(w.needs_multipart_form for w in self.widgets)\n\n\nclass SplitDateTimeWidget(MultiWidget):\n    \"\"\"\n    A widget that splits datetime input into two <input type=\"text\"> boxes.\n    \"\"\"\n\n    supports_microseconds = False\n    template_name = \"django/forms/widgets/splitdatetime.html\"\n\n    def __init__(\n        self,\n        attrs=None,\n        date_format=None,\n        time_format=None,\n        date_attrs=None,\n        time_attrs=None,\n    ):\n        widgets = (\n            DateInput(\n                attrs=attrs if date_attrs is None else date_attrs,\n                format=date_format,\n            ),\n            TimeInput(\n                attrs=attrs if time_attrs is None else time_attrs,\n                format=time_format,\n            ),\n        )\n        super().__init__(widgets)\n\n    def decompress(self, value):\n        if value:\n            value = to_current_timezone(value)\n            return [value.date(), value.time()]\n        return [None, None]\n\n\nclass SplitHiddenDateTimeWidget(SplitDateTimeWidget):\n    \"\"\"\n    A widget that splits datetime input into two <input type=\"hidden\"> inputs.\n    \"\"\"\n\n    template_name = \"django/forms/widgets/splithiddendatetime.html\"\n\n    def __init__(\n        self,\n        attrs=None,\n        date_format=None,\n        time_format=None,\n        date_attrs=None,\n        time_attrs=None,\n    ):\n        super().__init__(attrs, date_format, time_format, date_attrs, time_attrs)\n        for widget in self.widgets:\n            widget.input_type = \"hidden\"\n\n\nclass SelectDateWidget(Widget):\n    \"\"\"\n    A widget that splits date input into three <select> boxes.\n\n    This also serves as an example of a Widget that has more than one HTML\n    element and hence implements value_from_datadict.\n    \"\"\"\n\n    none_value = (\"\", \"---\")\n    month_field = \"%s_month\"\n    day_field = \"%s_day\"\n    year_field = \"%s_year\"\n    template_name = \"django/forms/widgets/select_date.html\"\n    input_type = \"select\"\n    select_widget = Select\n    date_re = _lazy_re_compile(r\"(\\d{4}|0)-(\\d\\d?)-(\\d\\d?)$\")\n    use_fieldset = True\n\n    def __init__(self, attrs=None, years=None, months=None, empty_label=None):\n        self.attrs = attrs or {}\n\n        # Optional list or tuple of years to use in the \"year\" select box.\n        if years:\n            self.years = years\n        else:\n            this_year = datetime.date.today().year\n            self.years = range(this_year, this_year + 10)\n\n        # Optional dict of months to use in the \"month\" select box.\n        if months:\n            self.months = months\n        else:\n            self.months = MONTHS\n\n        # Optional string, list, or tuple to use as empty_label.\n        if isinstance(empty_label, (list, tuple)):\n            if not len(empty_label) == 3:\n                raise ValueError(\"empty_label list/tuple must have 3 elements.\")\n\n            self.year_none_value = (\"\", empty_label[0])\n            self.month_none_value = (\"\", empty_label[1])\n            self.day_none_value = (\"\", empty_label[2])\n        else:\n            if empty_label is not None:\n                self.none_value = (\"\", empty_label)\n\n            self.year_none_value = self.none_value\n            self.month_none_value = self.none_value\n            self.day_none_value = self.none_value\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        date_context = {}\n        year_choices = [(i, str(i)) for i in self.years]\n        if not self.is_required:\n            year_choices.insert(0, self.year_none_value)\n        year_name = self.year_field % name\n        date_context[\"year\"] = self.select_widget(\n            attrs, choices=year_choices\n        ).get_context(\n            name=year_name,\n            value=context[\"widget\"][\"value\"][\"year\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % year_name},\n        )\n        month_choices = list(self.months.items())\n        if not self.is_required:\n            month_choices.insert(0, self.month_none_value)\n        month_name = self.month_field % name\n        date_context[\"month\"] = self.select_widget(\n            attrs, choices=month_choices\n        ).get_context(\n            name=month_name,\n            value=context[\"widget\"][\"value\"][\"month\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % month_name},\n        )\n        day_choices = [(i, i) for i in range(1, 32)]\n        if not self.is_required:\n            day_choices.insert(0, self.day_none_value)\n        day_name = self.day_field % name\n        date_context[\"day\"] = self.select_widget(\n            attrs,\n            choices=day_choices,\n        ).get_context(\n            name=day_name,\n            value=context[\"widget\"][\"value\"][\"day\"],\n            attrs={**context[\"widget\"][\"attrs\"], \"id\": \"id_%s\" % day_name},\n        )\n        subwidgets = []\n        for field in self._parse_date_fmt():\n            subwidgets.append(date_context[field][\"widget\"])\n        context[\"widget\"][\"subwidgets\"] = subwidgets\n        return context\n\n    def format_value(self, value):\n        \"\"\"\n        Return a dict containing the year, month, and day of the current value.\n        Use dict instead of a datetime to allow invalid dates such as February\n        31 to display correctly.\n        \"\"\"\n        year, month, day = None, None, None\n        if isinstance(value, (datetime.date, datetime.datetime)):\n            year, month, day = value.year, value.month, value.day\n        elif isinstance(value, str):\n            match = self.date_re.match(value)\n            if match:\n                # Convert any zeros in the date to empty strings to match the\n                # empty option value.\n                year, month, day = [int(val) or \"\" for val in match.groups()]\n            else:\n                input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n                try:\n                    d = datetime.datetime.strptime(value, input_format)\n                except ValueError:\n                    pass\n                else:\n                    year, month, day = d.year, d.month, d.day\n        return {\"year\": year, \"month\": month, \"day\": day}\n\n    @staticmethod\n    def _parse_date_fmt():\n        fmt = get_format(\"DATE_FORMAT\")\n        escaped = False\n        for char in fmt:\n            if escaped:\n                escaped = False\n            elif char == \"\\\\\":\n                escaped = True\n            elif char in \"Yy\":\n                yield \"year\"\n            elif char in \"bEFMmNn\":\n                yield \"month\"\n            elif char in \"dj\":\n                yield \"day\"\n\n    def id_for_label(self, id_):\n        for first_select in self._parse_date_fmt():\n            return \"%s_%s\" % (id_, first_select)\n        return \"%s_month\" % id_\n\n    def value_from_datadict(self, data, files, name):\n        y = data.get(self.year_field % name)\n        m = data.get(self.month_field % name)\n        d = data.get(self.day_field % name)\n        if y == m == d == \"\":\n            return None\n        if y is not None and m is not None and d is not None:\n            input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n            input_format = formats.sanitize_strftime_format(input_format)\n            try:\n                date_value = datetime.date(int(y), int(m), int(d))\n            except ValueError:\n                # Return pseudo-ISO dates with zeros for any unselected values,\n                # e.g. '2017-0-23'.\n                return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n            except OverflowError:\n                return \"0-0-0\"\n            return date_value.strftime(input_format)\n        return data.get(name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return not any(\n            (\"{}_{}\".format(name, interval) in data)\n            for interval in (\"year\", \"month\", \"day\")\n        )\n"
  },
  {
    "patch": "diff --git a/django/utils/translation/trans_real.py b/django/utils/translation/trans_real.py\nindex c1e64d4ebd..46a94b99ff 100644\n--- a/django/utils/translation/trans_real.py\n+++ b/django/utils/translation/trans_real.py\n@@ -30,6 +30,11 @@ _default = None\n # magic gettext number to separate context from message\n CONTEXT_SEPARATOR = \"\\x04\"\n \n+# Maximum number of characters that will be parsed from the Accept-Language\n+# header to prevent possible denial of service or memory exhaustion attacks.\n+# About 10x longer than the longest value shown on MDN\u2019s Accept-Language page.\n+ACCEPT_LANGUAGE_HEADER_MAX_LENGTH = 500\n+\n # Format of Accept-Language header values. From RFC 9110 Sections 12.4.2 and\n # 12.5.4, and RFC 5646 Section 2.1.\n accept_language_re = _lazy_re_compile(\n@@ -582,7 +587,7 @@ def get_language_from_request(request, check_path=False):\n \n \n @functools.lru_cache(maxsize=1000)\n-def parse_accept_lang_header(lang_string):\n+def _parse_accept_lang_header(lang_string):\n     \"\"\"\n     Parse the lang_string, which is the body of an HTTP Accept-Language\n     header, and return a tuple of (lang, q-value), ordered by 'q' values.\n@@ -604,3 +609,27 @@ def parse_accept_lang_header(lang_string):\n         result.append((lang, priority))\n     result.sort(key=lambda k: k[1], reverse=True)\n     return tuple(result)\n+\n+\n+def parse_accept_lang_header(lang_string):\n+    \"\"\"\n+    Parse the value of the Accept-Language header up to a maximum length.\n+\n+    The value of the header is truncated to a maximum length to avoid potential\n+    denial of service and memory exhaustion attacks. Excessive memory could be\n+    used if the raw value is very large as it would be cached due to the use of\n+    functools.lru_cache() to avoid repetitive parsing of common header values.\n+    \"\"\"\n+    # If the header value doesn't exceed the maximum allowed length, parse it.\n+    if len(lang_string) <= ACCEPT_LANGUAGE_HEADER_MAX_LENGTH:\n+        return _parse_accept_lang_header(lang_string)\n+\n+    # If there is at least one comma in the value, parse up to the last comma\n+    # before the max length, skipping any truncated parts at the end of the\n+    # header value.\n+    if (index := lang_string.rfind(\",\", 0, ACCEPT_LANGUAGE_HEADER_MAX_LENGTH)) > 0:\n+        return _parse_accept_lang_header(lang_string[:index])\n+\n+    # Don't attempt to parse if there is only one language-range value which is\n+    # longer than the maximum allowed length and so truncated.\n+    return ()\n",
    "commit_message": "Fixed CVE-2023-23969 -- Prevented DoS with pathological values for Accept-Language.\n\nThe parsed values of Accept-Language headers are cached in order to\navoid repetitive parsing. This leads to a potential denial-of-service\nvector via excessive memory usage if the raw value of Accept-Language\nheaders is very large.\n\nAccept-Language headers are now limited to a maximum length in order\nto avoid this issue.\n\n",
    "code_before": "\"\"\"Translation helper functions.\"\"\"\nimport functools\nimport gettext as gettext_module\nimport os\nimport re\nimport sys\nimport warnings\n\nfrom asgiref.local import Local\n\nfrom django.apps import apps\nfrom django.conf import settings\nfrom django.conf.locale import LANG_INFO\nfrom django.core.exceptions import AppRegistryNotReady\nfrom django.core.signals import setting_changed\nfrom django.dispatch import receiver\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.safestring import SafeData, mark_safe\n\nfrom . import to_language, to_locale\n\n# Translations are cached in a dictionary for every language.\n# The active translations are stored by threadid to make them thread local.\n_translations = {}\n_active = Local()\n\n# The default translation is based on the settings file.\n_default = None\n\n# magic gettext number to separate context from message\nCONTEXT_SEPARATOR = \"\\x04\"\n\n# Format of Accept-Language header values. From RFC 9110 Sections 12.4.2 and\n# 12.5.4, and RFC 5646 Section 2.1.\naccept_language_re = _lazy_re_compile(\n    r\"\"\"\n        # \"en\", \"en-au\", \"x-y-z\", \"es-419\", \"*\"\n        ([A-Za-z]{1,8}(?:-[A-Za-z0-9]{1,8})*|\\*)\n        # Optional \"q=1.00\", \"q=0.8\"\n        (?:\\s*;\\s*q=(0(?:\\.[0-9]{,3})?|1(?:\\.0{,3})?))?\n        # Multiple accepts per header.\n        (?:\\s*,\\s*|$)\n    \"\"\",\n    re.VERBOSE,\n)\n\nlanguage_code_re = _lazy_re_compile(\n    r\"^[a-z]{1,8}(?:-[a-z0-9]{1,8})*(?:@[a-z0-9]{1,20})?$\", re.IGNORECASE\n)\n\nlanguage_code_prefix_re = _lazy_re_compile(r\"^/(\\w+([@-]\\w+){0,2})(/|$)\")\n\n\n@receiver(setting_changed)\ndef reset_cache(*, setting, **kwargs):\n    \"\"\"\n    Reset global state when LANGUAGES setting has been changed, as some\n    languages should no longer be accepted.\n    \"\"\"\n    if setting in (\"LANGUAGES\", \"LANGUAGE_CODE\"):\n        check_for_language.cache_clear()\n        get_languages.cache_clear()\n        get_supported_language_variant.cache_clear()\n\n\nclass TranslationCatalog:\n    \"\"\"\n    Simulate a dict for DjangoTranslation._catalog so as multiple catalogs\n    with different plural equations are kept separate.\n    \"\"\"\n\n    def __init__(self, trans=None):\n        self._catalogs = [trans._catalog.copy()] if trans else [{}]\n        self._plurals = [trans.plural] if trans else [lambda n: int(n != 1)]\n\n    def __getitem__(self, key):\n        for cat in self._catalogs:\n            try:\n                return cat[key]\n            except KeyError:\n                pass\n        raise KeyError(key)\n\n    def __setitem__(self, key, value):\n        self._catalogs[0][key] = value\n\n    def __contains__(self, key):\n        return any(key in cat for cat in self._catalogs)\n\n    def items(self):\n        for cat in self._catalogs:\n            yield from cat.items()\n\n    def keys(self):\n        for cat in self._catalogs:\n            yield from cat.keys()\n\n    def update(self, trans):\n        # Merge if plural function is the same, else prepend.\n        for cat, plural in zip(self._catalogs, self._plurals):\n            if trans.plural.__code__ == plural.__code__:\n                cat.update(trans._catalog)\n                break\n        else:\n            self._catalogs.insert(0, trans._catalog.copy())\n            self._plurals.insert(0, trans.plural)\n\n    def get(self, key, default=None):\n        missing = object()\n        for cat in self._catalogs:\n            result = cat.get(key, missing)\n            if result is not missing:\n                return result\n        return default\n\n    def plural(self, msgid, num):\n        for cat, plural in zip(self._catalogs, self._plurals):\n            tmsg = cat.get((msgid, plural(num)))\n            if tmsg is not None:\n                return tmsg\n        raise KeyError\n\n\nclass DjangoTranslation(gettext_module.GNUTranslations):\n    \"\"\"\n    Set up the GNUTranslations context with regard to output charset.\n\n    This translation object will be constructed out of multiple GNUTranslations\n    objects by merging their catalogs. It will construct an object for the\n    requested language and add a fallback to the default language, if it's\n    different from the requested language.\n    \"\"\"\n\n    domain = \"django\"\n\n    def __init__(self, language, domain=None, localedirs=None):\n        \"\"\"Create a GNUTranslations() using many locale directories\"\"\"\n        gettext_module.GNUTranslations.__init__(self)\n        if domain is not None:\n            self.domain = domain\n\n        self.__language = language\n        self.__to_language = to_language(language)\n        self.__locale = to_locale(language)\n        self._catalog = None\n        # If a language doesn't have a catalog, use the Germanic default for\n        # pluralization: anything except one is pluralized.\n        self.plural = lambda n: int(n != 1)\n\n        if self.domain == \"django\":\n            if localedirs is not None:\n                # A module-level cache is used for caching 'django' translations\n                warnings.warn(\n                    \"localedirs is ignored when domain is 'django'.\", RuntimeWarning\n                )\n                localedirs = None\n            self._init_translation_catalog()\n\n        if localedirs:\n            for localedir in localedirs:\n                translation = self._new_gnu_trans(localedir)\n                self.merge(translation)\n        else:\n            self._add_installed_apps_translations()\n\n        self._add_local_translations()\n        if (\n            self.__language == settings.LANGUAGE_CODE\n            and self.domain == \"django\"\n            and self._catalog is None\n        ):\n            # default lang should have at least one translation file available.\n            raise OSError(\n                \"No translation files found for default language %s.\"\n                % settings.LANGUAGE_CODE\n            )\n        self._add_fallback(localedirs)\n        if self._catalog is None:\n            # No catalogs found for this language, set an empty catalog.\n            self._catalog = TranslationCatalog()\n\n    def __repr__(self):\n        return \"<DjangoTranslation lang:%s>\" % self.__language\n\n    def _new_gnu_trans(self, localedir, use_null_fallback=True):\n        \"\"\"\n        Return a mergeable gettext.GNUTranslations instance.\n\n        A convenience wrapper. By default gettext uses 'fallback=False'.\n        Using param `use_null_fallback` to avoid confusion with any other\n        references to 'fallback'.\n        \"\"\"\n        return gettext_module.translation(\n            domain=self.domain,\n            localedir=localedir,\n            languages=[self.__locale],\n            fallback=use_null_fallback,\n        )\n\n    def _init_translation_catalog(self):\n        \"\"\"Create a base catalog using global django translations.\"\"\"\n        settingsfile = sys.modules[settings.__module__].__file__\n        localedir = os.path.join(os.path.dirname(settingsfile), \"locale\")\n        translation = self._new_gnu_trans(localedir)\n        self.merge(translation)\n\n    def _add_installed_apps_translations(self):\n        \"\"\"Merge translations from each installed app.\"\"\"\n        try:\n            app_configs = reversed(apps.get_app_configs())\n        except AppRegistryNotReady:\n            raise AppRegistryNotReady(\n                \"The translation infrastructure cannot be initialized before the \"\n                \"apps registry is ready. Check that you don't make non-lazy \"\n                \"gettext calls at import time.\"\n            )\n        for app_config in app_configs:\n            localedir = os.path.join(app_config.path, \"locale\")\n            if os.path.exists(localedir):\n                translation = self._new_gnu_trans(localedir)\n                self.merge(translation)\n\n    def _add_local_translations(self):\n        \"\"\"Merge translations defined in LOCALE_PATHS.\"\"\"\n        for localedir in reversed(settings.LOCALE_PATHS):\n            translation = self._new_gnu_trans(localedir)\n            self.merge(translation)\n\n    def _add_fallback(self, localedirs=None):\n        \"\"\"Set the GNUTranslations() fallback with the default language.\"\"\"\n        # Don't set a fallback for the default language or any English variant\n        # (as it's empty, so it'll ALWAYS fall back to the default language)\n        if self.__language == settings.LANGUAGE_CODE or self.__language.startswith(\n            \"en\"\n        ):\n            return\n        if self.domain == \"django\":\n            # Get from cache\n            default_translation = translation(settings.LANGUAGE_CODE)\n        else:\n            default_translation = DjangoTranslation(\n                settings.LANGUAGE_CODE, domain=self.domain, localedirs=localedirs\n            )\n        self.add_fallback(default_translation)\n\n    def merge(self, other):\n        \"\"\"Merge another translation into this catalog.\"\"\"\n        if not getattr(other, \"_catalog\", None):\n            return  # NullTranslations() has no _catalog\n        if self._catalog is None:\n            # Take plural and _info from first catalog found (generally Django's).\n            self.plural = other.plural\n            self._info = other._info.copy()\n            self._catalog = TranslationCatalog(other)\n        else:\n            self._catalog.update(other)\n        if other._fallback:\n            self.add_fallback(other._fallback)\n\n    def language(self):\n        \"\"\"Return the translation language.\"\"\"\n        return self.__language\n\n    def to_language(self):\n        \"\"\"Return the translation language name.\"\"\"\n        return self.__to_language\n\n    def ngettext(self, msgid1, msgid2, n):\n        try:\n            tmsg = self._catalog.plural(msgid1, n)\n        except KeyError:\n            if self._fallback:\n                return self._fallback.ngettext(msgid1, msgid2, n)\n            if n == 1:\n                tmsg = msgid1\n            else:\n                tmsg = msgid2\n        return tmsg\n\n\ndef translation(language):\n    \"\"\"\n    Return a translation object in the default 'django' domain.\n    \"\"\"\n    global _translations\n    if language not in _translations:\n        _translations[language] = DjangoTranslation(language)\n    return _translations[language]\n\n\ndef activate(language):\n    \"\"\"\n    Fetch the translation object for a given language and install it as the\n    current translation object for the current thread.\n    \"\"\"\n    if not language:\n        return\n    _active.value = translation(language)\n\n\ndef deactivate():\n    \"\"\"\n    Uninstall the active translation object so that further _() calls resolve\n    to the default translation object.\n    \"\"\"\n    if hasattr(_active, \"value\"):\n        del _active.value\n\n\ndef deactivate_all():\n    \"\"\"\n    Make the active translation object a NullTranslations() instance. This is\n    useful when we want delayed translations to appear as the original string\n    for some reason.\n    \"\"\"\n    _active.value = gettext_module.NullTranslations()\n    _active.value.to_language = lambda *args: None\n\n\ndef get_language():\n    \"\"\"Return the currently selected language.\"\"\"\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        try:\n            return t.to_language()\n        except AttributeError:\n            pass\n    # If we don't have a real translation object, assume it's the default language.\n    return settings.LANGUAGE_CODE\n\n\ndef get_language_bidi():\n    \"\"\"\n    Return selected language's BiDi layout.\n\n    * False = left-to-right layout\n    * True = right-to-left layout\n    \"\"\"\n    lang = get_language()\n    if lang is None:\n        return False\n    else:\n        base_lang = get_language().split(\"-\")[0]\n        return base_lang in settings.LANGUAGES_BIDI\n\n\ndef catalog():\n    \"\"\"\n    Return the current active catalog for further processing.\n    This can be used if you need to modify the catalog or want to access the\n    whole message catalog instead of just translating one string.\n    \"\"\"\n    global _default\n\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        return t\n    if _default is None:\n        _default = translation(settings.LANGUAGE_CODE)\n    return _default\n\n\ndef gettext(message):\n    \"\"\"\n    Translate the 'message' string. It uses the current thread to find the\n    translation object to use. If no current translation is activated, the\n    message will be run through the default translation object.\n    \"\"\"\n    global _default\n\n    eol_message = message.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n\n    if eol_message:\n        _default = _default or translation(settings.LANGUAGE_CODE)\n        translation_object = getattr(_active, \"value\", _default)\n\n        result = translation_object.gettext(eol_message)\n    else:\n        # Return an empty value of the corresponding type if an empty message\n        # is given, instead of metadata, which is the default gettext behavior.\n        result = type(message)(\"\")\n\n    if isinstance(message, SafeData):\n        return mark_safe(result)\n\n    return result\n\n\ndef pgettext(context, message):\n    msg_with_ctxt = \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message)\n    result = gettext(msg_with_ctxt)\n    if CONTEXT_SEPARATOR in result:\n        # Translation not found\n        result = message\n    elif isinstance(message, SafeData):\n        result = mark_safe(result)\n    return result\n\n\ndef gettext_noop(message):\n    \"\"\"\n    Mark strings for translation but don't translate them now. This can be\n    used to store strings in global variables that should stay in the base\n    language (because they might be used externally) and will be translated\n    later.\n    \"\"\"\n    return message\n\n\ndef do_ntranslate(singular, plural, number, translation_function):\n    global _default\n\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        return getattr(t, translation_function)(singular, plural, number)\n    if _default is None:\n        _default = translation(settings.LANGUAGE_CODE)\n    return getattr(_default, translation_function)(singular, plural, number)\n\n\ndef ngettext(singular, plural, number):\n    \"\"\"\n    Return a string of the translation of either the singular or plural,\n    based on the number.\n    \"\"\"\n    return do_ntranslate(singular, plural, number, \"ngettext\")\n\n\ndef npgettext(context, singular, plural, number):\n    msgs_with_ctxt = (\n        \"%s%s%s\" % (context, CONTEXT_SEPARATOR, singular),\n        \"%s%s%s\" % (context, CONTEXT_SEPARATOR, plural),\n        number,\n    )\n    result = ngettext(*msgs_with_ctxt)\n    if CONTEXT_SEPARATOR in result:\n        # Translation not found\n        result = ngettext(singular, plural, number)\n    return result\n\n\ndef all_locale_paths():\n    \"\"\"\n    Return a list of paths to user-provides languages files.\n    \"\"\"\n    globalpath = os.path.join(\n        os.path.dirname(sys.modules[settings.__module__].__file__), \"locale\"\n    )\n    app_paths = []\n    for app_config in apps.get_app_configs():\n        locale_path = os.path.join(app_config.path, \"locale\")\n        if os.path.exists(locale_path):\n            app_paths.append(locale_path)\n    return [globalpath, *settings.LOCALE_PATHS, *app_paths]\n\n\n@functools.lru_cache(maxsize=1000)\ndef check_for_language(lang_code):\n    \"\"\"\n    Check whether there is a global language file for the given language\n    code. This is used to decide whether a user-provided language is\n    available.\n\n    lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n    as the provided language codes are taken from the HTTP request. See also\n    <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n    \"\"\"\n    # First, a quick check to make sure lang_code is well-formed (#21458)\n    if lang_code is None or not language_code_re.search(lang_code):\n        return False\n    return any(\n        gettext_module.find(\"django\", path, [to_locale(lang_code)]) is not None\n        for path in all_locale_paths()\n    )\n\n\n@functools.lru_cache\ndef get_languages():\n    \"\"\"\n    Cache of settings.LANGUAGES in a dictionary for easy lookups by key.\n    Convert keys to lowercase as they should be treated as case-insensitive.\n    \"\"\"\n    return {key.lower(): value for key, value in dict(settings.LANGUAGES).items()}\n\n\n@functools.lru_cache(maxsize=1000)\ndef get_supported_language_variant(lang_code, strict=False):\n    \"\"\"\n    Return the language code that's listed in supported languages, possibly\n    selecting a more generic variant. Raise LookupError if nothing is found.\n\n    If `strict` is False (the default), look for a country-specific variant\n    when neither the language code nor its generic variant is found.\n\n    lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n    as the provided language codes are taken from the HTTP request. See also\n    <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n    \"\"\"\n    if lang_code:\n        # If 'zh-hant-tw' is not supported, try special fallback or subsequent\n        # language codes i.e. 'zh-hant' and 'zh'.\n        possible_lang_codes = [lang_code]\n        try:\n            possible_lang_codes.extend(LANG_INFO[lang_code][\"fallback\"])\n        except KeyError:\n            pass\n        i = None\n        while (i := lang_code.rfind(\"-\", 0, i)) > -1:\n            possible_lang_codes.append(lang_code[:i])\n        generic_lang_code = possible_lang_codes[-1]\n        supported_lang_codes = get_languages()\n\n        for code in possible_lang_codes:\n            if code.lower() in supported_lang_codes and check_for_language(code):\n                return code\n        if not strict:\n            # if fr-fr is not supported, try fr-ca.\n            for supported_code in supported_lang_codes:\n                if supported_code.startswith(generic_lang_code + \"-\"):\n                    return supported_code\n    raise LookupError(lang_code)\n\n\ndef get_language_from_path(path, strict=False):\n    \"\"\"\n    Return the language code if there's a valid language code found in `path`.\n\n    If `strict` is False (the default), look for a country-specific variant\n    when neither the language code nor its generic variant is found.\n    \"\"\"\n    regex_match = language_code_prefix_re.match(path)\n    if not regex_match:\n        return None\n    lang_code = regex_match[1]\n    try:\n        return get_supported_language_variant(lang_code, strict=strict)\n    except LookupError:\n        return None\n\n\ndef get_language_from_request(request, check_path=False):\n    \"\"\"\n    Analyze the request to find what language the user wants the system to\n    show. Only languages listed in settings.LANGUAGES are taken into account.\n    If the user requests a sublanguage where we have a main language, we send\n    out the main language.\n\n    If check_path is True, the URL path prefix will be checked for a language\n    code, otherwise this is skipped for backwards compatibility.\n    \"\"\"\n    if check_path:\n        lang_code = get_language_from_path(request.path_info)\n        if lang_code is not None:\n            return lang_code\n\n    lang_code = request.COOKIES.get(settings.LANGUAGE_COOKIE_NAME)\n    if (\n        lang_code is not None\n        and lang_code in get_languages()\n        and check_for_language(lang_code)\n    ):\n        return lang_code\n\n    try:\n        return get_supported_language_variant(lang_code)\n    except LookupError:\n        pass\n\n    accept = request.META.get(\"HTTP_ACCEPT_LANGUAGE\", \"\")\n    for accept_lang, unused in parse_accept_lang_header(accept):\n        if accept_lang == \"*\":\n            break\n\n        if not language_code_re.search(accept_lang):\n            continue\n\n        try:\n            return get_supported_language_variant(accept_lang)\n        except LookupError:\n            continue\n    return None\n\n\n@functools.lru_cache(maxsize=1000)\ndef parse_accept_lang_header(lang_string):\n    \"\"\"\n    Parse the lang_string, which is the body of an HTTP Accept-Language\n    header, and return a tuple of (lang, q-value), ordered by 'q' values.\n\n    Return an empty tuple if there are any format errors in lang_string.\n    \"\"\"\n    result = []\n    pieces = accept_language_re.split(lang_string.lower())\n    if pieces[-1]:\n        return ()\n    for i in range(0, len(pieces) - 1, 3):\n        first, lang, priority = pieces[i : i + 3]\n        if first:\n            return ()\n        if priority:\n            priority = float(priority)\n        else:\n            priority = 1.0\n        result.append((lang, priority))\n    result.sort(key=lambda k: k[1], reverse=True)\n    return tuple(result)\n",
    "code_after": "\"\"\"Translation helper functions.\"\"\"\nimport functools\nimport gettext as gettext_module\nimport os\nimport re\nimport sys\nimport warnings\n\nfrom asgiref.local import Local\n\nfrom django.apps import apps\nfrom django.conf import settings\nfrom django.conf.locale import LANG_INFO\nfrom django.core.exceptions import AppRegistryNotReady\nfrom django.core.signals import setting_changed\nfrom django.dispatch import receiver\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.safestring import SafeData, mark_safe\n\nfrom . import to_language, to_locale\n\n# Translations are cached in a dictionary for every language.\n# The active translations are stored by threadid to make them thread local.\n_translations = {}\n_active = Local()\n\n# The default translation is based on the settings file.\n_default = None\n\n# magic gettext number to separate context from message\nCONTEXT_SEPARATOR = \"\\x04\"\n\n# Maximum number of characters that will be parsed from the Accept-Language\n# header to prevent possible denial of service or memory exhaustion attacks.\n# About 10x longer than the longest value shown on MDN\u2019s Accept-Language page.\nACCEPT_LANGUAGE_HEADER_MAX_LENGTH = 500\n\n# Format of Accept-Language header values. From RFC 9110 Sections 12.4.2 and\n# 12.5.4, and RFC 5646 Section 2.1.\naccept_language_re = _lazy_re_compile(\n    r\"\"\"\n        # \"en\", \"en-au\", \"x-y-z\", \"es-419\", \"*\"\n        ([A-Za-z]{1,8}(?:-[A-Za-z0-9]{1,8})*|\\*)\n        # Optional \"q=1.00\", \"q=0.8\"\n        (?:\\s*;\\s*q=(0(?:\\.[0-9]{,3})?|1(?:\\.0{,3})?))?\n        # Multiple accepts per header.\n        (?:\\s*,\\s*|$)\n    \"\"\",\n    re.VERBOSE,\n)\n\nlanguage_code_re = _lazy_re_compile(\n    r\"^[a-z]{1,8}(?:-[a-z0-9]{1,8})*(?:@[a-z0-9]{1,20})?$\", re.IGNORECASE\n)\n\nlanguage_code_prefix_re = _lazy_re_compile(r\"^/(\\w+([@-]\\w+){0,2})(/|$)\")\n\n\n@receiver(setting_changed)\ndef reset_cache(*, setting, **kwargs):\n    \"\"\"\n    Reset global state when LANGUAGES setting has been changed, as some\n    languages should no longer be accepted.\n    \"\"\"\n    if setting in (\"LANGUAGES\", \"LANGUAGE_CODE\"):\n        check_for_language.cache_clear()\n        get_languages.cache_clear()\n        get_supported_language_variant.cache_clear()\n\n\nclass TranslationCatalog:\n    \"\"\"\n    Simulate a dict for DjangoTranslation._catalog so as multiple catalogs\n    with different plural equations are kept separate.\n    \"\"\"\n\n    def __init__(self, trans=None):\n        self._catalogs = [trans._catalog.copy()] if trans else [{}]\n        self._plurals = [trans.plural] if trans else [lambda n: int(n != 1)]\n\n    def __getitem__(self, key):\n        for cat in self._catalogs:\n            try:\n                return cat[key]\n            except KeyError:\n                pass\n        raise KeyError(key)\n\n    def __setitem__(self, key, value):\n        self._catalogs[0][key] = value\n\n    def __contains__(self, key):\n        return any(key in cat for cat in self._catalogs)\n\n    def items(self):\n        for cat in self._catalogs:\n            yield from cat.items()\n\n    def keys(self):\n        for cat in self._catalogs:\n            yield from cat.keys()\n\n    def update(self, trans):\n        # Merge if plural function is the same, else prepend.\n        for cat, plural in zip(self._catalogs, self._plurals):\n            if trans.plural.__code__ == plural.__code__:\n                cat.update(trans._catalog)\n                break\n        else:\n            self._catalogs.insert(0, trans._catalog.copy())\n            self._plurals.insert(0, trans.plural)\n\n    def get(self, key, default=None):\n        missing = object()\n        for cat in self._catalogs:\n            result = cat.get(key, missing)\n            if result is not missing:\n                return result\n        return default\n\n    def plural(self, msgid, num):\n        for cat, plural in zip(self._catalogs, self._plurals):\n            tmsg = cat.get((msgid, plural(num)))\n            if tmsg is not None:\n                return tmsg\n        raise KeyError\n\n\nclass DjangoTranslation(gettext_module.GNUTranslations):\n    \"\"\"\n    Set up the GNUTranslations context with regard to output charset.\n\n    This translation object will be constructed out of multiple GNUTranslations\n    objects by merging their catalogs. It will construct an object for the\n    requested language and add a fallback to the default language, if it's\n    different from the requested language.\n    \"\"\"\n\n    domain = \"django\"\n\n    def __init__(self, language, domain=None, localedirs=None):\n        \"\"\"Create a GNUTranslations() using many locale directories\"\"\"\n        gettext_module.GNUTranslations.__init__(self)\n        if domain is not None:\n            self.domain = domain\n\n        self.__language = language\n        self.__to_language = to_language(language)\n        self.__locale = to_locale(language)\n        self._catalog = None\n        # If a language doesn't have a catalog, use the Germanic default for\n        # pluralization: anything except one is pluralized.\n        self.plural = lambda n: int(n != 1)\n\n        if self.domain == \"django\":\n            if localedirs is not None:\n                # A module-level cache is used for caching 'django' translations\n                warnings.warn(\n                    \"localedirs is ignored when domain is 'django'.\", RuntimeWarning\n                )\n                localedirs = None\n            self._init_translation_catalog()\n\n        if localedirs:\n            for localedir in localedirs:\n                translation = self._new_gnu_trans(localedir)\n                self.merge(translation)\n        else:\n            self._add_installed_apps_translations()\n\n        self._add_local_translations()\n        if (\n            self.__language == settings.LANGUAGE_CODE\n            and self.domain == \"django\"\n            and self._catalog is None\n        ):\n            # default lang should have at least one translation file available.\n            raise OSError(\n                \"No translation files found for default language %s.\"\n                % settings.LANGUAGE_CODE\n            )\n        self._add_fallback(localedirs)\n        if self._catalog is None:\n            # No catalogs found for this language, set an empty catalog.\n            self._catalog = TranslationCatalog()\n\n    def __repr__(self):\n        return \"<DjangoTranslation lang:%s>\" % self.__language\n\n    def _new_gnu_trans(self, localedir, use_null_fallback=True):\n        \"\"\"\n        Return a mergeable gettext.GNUTranslations instance.\n\n        A convenience wrapper. By default gettext uses 'fallback=False'.\n        Using param `use_null_fallback` to avoid confusion with any other\n        references to 'fallback'.\n        \"\"\"\n        return gettext_module.translation(\n            domain=self.domain,\n            localedir=localedir,\n            languages=[self.__locale],\n            fallback=use_null_fallback,\n        )\n\n    def _init_translation_catalog(self):\n        \"\"\"Create a base catalog using global django translations.\"\"\"\n        settingsfile = sys.modules[settings.__module__].__file__\n        localedir = os.path.join(os.path.dirname(settingsfile), \"locale\")\n        translation = self._new_gnu_trans(localedir)\n        self.merge(translation)\n\n    def _add_installed_apps_translations(self):\n        \"\"\"Merge translations from each installed app.\"\"\"\n        try:\n            app_configs = reversed(apps.get_app_configs())\n        except AppRegistryNotReady:\n            raise AppRegistryNotReady(\n                \"The translation infrastructure cannot be initialized before the \"\n                \"apps registry is ready. Check that you don't make non-lazy \"\n                \"gettext calls at import time.\"\n            )\n        for app_config in app_configs:\n            localedir = os.path.join(app_config.path, \"locale\")\n            if os.path.exists(localedir):\n                translation = self._new_gnu_trans(localedir)\n                self.merge(translation)\n\n    def _add_local_translations(self):\n        \"\"\"Merge translations defined in LOCALE_PATHS.\"\"\"\n        for localedir in reversed(settings.LOCALE_PATHS):\n            translation = self._new_gnu_trans(localedir)\n            self.merge(translation)\n\n    def _add_fallback(self, localedirs=None):\n        \"\"\"Set the GNUTranslations() fallback with the default language.\"\"\"\n        # Don't set a fallback for the default language or any English variant\n        # (as it's empty, so it'll ALWAYS fall back to the default language)\n        if self.__language == settings.LANGUAGE_CODE or self.__language.startswith(\n            \"en\"\n        ):\n            return\n        if self.domain == \"django\":\n            # Get from cache\n            default_translation = translation(settings.LANGUAGE_CODE)\n        else:\n            default_translation = DjangoTranslation(\n                settings.LANGUAGE_CODE, domain=self.domain, localedirs=localedirs\n            )\n        self.add_fallback(default_translation)\n\n    def merge(self, other):\n        \"\"\"Merge another translation into this catalog.\"\"\"\n        if not getattr(other, \"_catalog\", None):\n            return  # NullTranslations() has no _catalog\n        if self._catalog is None:\n            # Take plural and _info from first catalog found (generally Django's).\n            self.plural = other.plural\n            self._info = other._info.copy()\n            self._catalog = TranslationCatalog(other)\n        else:\n            self._catalog.update(other)\n        if other._fallback:\n            self.add_fallback(other._fallback)\n\n    def language(self):\n        \"\"\"Return the translation language.\"\"\"\n        return self.__language\n\n    def to_language(self):\n        \"\"\"Return the translation language name.\"\"\"\n        return self.__to_language\n\n    def ngettext(self, msgid1, msgid2, n):\n        try:\n            tmsg = self._catalog.plural(msgid1, n)\n        except KeyError:\n            if self._fallback:\n                return self._fallback.ngettext(msgid1, msgid2, n)\n            if n == 1:\n                tmsg = msgid1\n            else:\n                tmsg = msgid2\n        return tmsg\n\n\ndef translation(language):\n    \"\"\"\n    Return a translation object in the default 'django' domain.\n    \"\"\"\n    global _translations\n    if language not in _translations:\n        _translations[language] = DjangoTranslation(language)\n    return _translations[language]\n\n\ndef activate(language):\n    \"\"\"\n    Fetch the translation object for a given language and install it as the\n    current translation object for the current thread.\n    \"\"\"\n    if not language:\n        return\n    _active.value = translation(language)\n\n\ndef deactivate():\n    \"\"\"\n    Uninstall the active translation object so that further _() calls resolve\n    to the default translation object.\n    \"\"\"\n    if hasattr(_active, \"value\"):\n        del _active.value\n\n\ndef deactivate_all():\n    \"\"\"\n    Make the active translation object a NullTranslations() instance. This is\n    useful when we want delayed translations to appear as the original string\n    for some reason.\n    \"\"\"\n    _active.value = gettext_module.NullTranslations()\n    _active.value.to_language = lambda *args: None\n\n\ndef get_language():\n    \"\"\"Return the currently selected language.\"\"\"\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        try:\n            return t.to_language()\n        except AttributeError:\n            pass\n    # If we don't have a real translation object, assume it's the default language.\n    return settings.LANGUAGE_CODE\n\n\ndef get_language_bidi():\n    \"\"\"\n    Return selected language's BiDi layout.\n\n    * False = left-to-right layout\n    * True = right-to-left layout\n    \"\"\"\n    lang = get_language()\n    if lang is None:\n        return False\n    else:\n        base_lang = get_language().split(\"-\")[0]\n        return base_lang in settings.LANGUAGES_BIDI\n\n\ndef catalog():\n    \"\"\"\n    Return the current active catalog for further processing.\n    This can be used if you need to modify the catalog or want to access the\n    whole message catalog instead of just translating one string.\n    \"\"\"\n    global _default\n\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        return t\n    if _default is None:\n        _default = translation(settings.LANGUAGE_CODE)\n    return _default\n\n\ndef gettext(message):\n    \"\"\"\n    Translate the 'message' string. It uses the current thread to find the\n    translation object to use. If no current translation is activated, the\n    message will be run through the default translation object.\n    \"\"\"\n    global _default\n\n    eol_message = message.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n\n    if eol_message:\n        _default = _default or translation(settings.LANGUAGE_CODE)\n        translation_object = getattr(_active, \"value\", _default)\n\n        result = translation_object.gettext(eol_message)\n    else:\n        # Return an empty value of the corresponding type if an empty message\n        # is given, instead of metadata, which is the default gettext behavior.\n        result = type(message)(\"\")\n\n    if isinstance(message, SafeData):\n        return mark_safe(result)\n\n    return result\n\n\ndef pgettext(context, message):\n    msg_with_ctxt = \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message)\n    result = gettext(msg_with_ctxt)\n    if CONTEXT_SEPARATOR in result:\n        # Translation not found\n        result = message\n    elif isinstance(message, SafeData):\n        result = mark_safe(result)\n    return result\n\n\ndef gettext_noop(message):\n    \"\"\"\n    Mark strings for translation but don't translate them now. This can be\n    used to store strings in global variables that should stay in the base\n    language (because they might be used externally) and will be translated\n    later.\n    \"\"\"\n    return message\n\n\ndef do_ntranslate(singular, plural, number, translation_function):\n    global _default\n\n    t = getattr(_active, \"value\", None)\n    if t is not None:\n        return getattr(t, translation_function)(singular, plural, number)\n    if _default is None:\n        _default = translation(settings.LANGUAGE_CODE)\n    return getattr(_default, translation_function)(singular, plural, number)\n\n\ndef ngettext(singular, plural, number):\n    \"\"\"\n    Return a string of the translation of either the singular or plural,\n    based on the number.\n    \"\"\"\n    return do_ntranslate(singular, plural, number, \"ngettext\")\n\n\ndef npgettext(context, singular, plural, number):\n    msgs_with_ctxt = (\n        \"%s%s%s\" % (context, CONTEXT_SEPARATOR, singular),\n        \"%s%s%s\" % (context, CONTEXT_SEPARATOR, plural),\n        number,\n    )\n    result = ngettext(*msgs_with_ctxt)\n    if CONTEXT_SEPARATOR in result:\n        # Translation not found\n        result = ngettext(singular, plural, number)\n    return result\n\n\ndef all_locale_paths():\n    \"\"\"\n    Return a list of paths to user-provides languages files.\n    \"\"\"\n    globalpath = os.path.join(\n        os.path.dirname(sys.modules[settings.__module__].__file__), \"locale\"\n    )\n    app_paths = []\n    for app_config in apps.get_app_configs():\n        locale_path = os.path.join(app_config.path, \"locale\")\n        if os.path.exists(locale_path):\n            app_paths.append(locale_path)\n    return [globalpath, *settings.LOCALE_PATHS, *app_paths]\n\n\n@functools.lru_cache(maxsize=1000)\ndef check_for_language(lang_code):\n    \"\"\"\n    Check whether there is a global language file for the given language\n    code. This is used to decide whether a user-provided language is\n    available.\n\n    lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n    as the provided language codes are taken from the HTTP request. See also\n    <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n    \"\"\"\n    # First, a quick check to make sure lang_code is well-formed (#21458)\n    if lang_code is None or not language_code_re.search(lang_code):\n        return False\n    return any(\n        gettext_module.find(\"django\", path, [to_locale(lang_code)]) is not None\n        for path in all_locale_paths()\n    )\n\n\n@functools.lru_cache\ndef get_languages():\n    \"\"\"\n    Cache of settings.LANGUAGES in a dictionary for easy lookups by key.\n    Convert keys to lowercase as they should be treated as case-insensitive.\n    \"\"\"\n    return {key.lower(): value for key, value in dict(settings.LANGUAGES).items()}\n\n\n@functools.lru_cache(maxsize=1000)\ndef get_supported_language_variant(lang_code, strict=False):\n    \"\"\"\n    Return the language code that's listed in supported languages, possibly\n    selecting a more generic variant. Raise LookupError if nothing is found.\n\n    If `strict` is False (the default), look for a country-specific variant\n    when neither the language code nor its generic variant is found.\n\n    lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n    as the provided language codes are taken from the HTTP request. See also\n    <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n    \"\"\"\n    if lang_code:\n        # If 'zh-hant-tw' is not supported, try special fallback or subsequent\n        # language codes i.e. 'zh-hant' and 'zh'.\n        possible_lang_codes = [lang_code]\n        try:\n            possible_lang_codes.extend(LANG_INFO[lang_code][\"fallback\"])\n        except KeyError:\n            pass\n        i = None\n        while (i := lang_code.rfind(\"-\", 0, i)) > -1:\n            possible_lang_codes.append(lang_code[:i])\n        generic_lang_code = possible_lang_codes[-1]\n        supported_lang_codes = get_languages()\n\n        for code in possible_lang_codes:\n            if code.lower() in supported_lang_codes and check_for_language(code):\n                return code\n        if not strict:\n            # if fr-fr is not supported, try fr-ca.\n            for supported_code in supported_lang_codes:\n                if supported_code.startswith(generic_lang_code + \"-\"):\n                    return supported_code\n    raise LookupError(lang_code)\n\n\ndef get_language_from_path(path, strict=False):\n    \"\"\"\n    Return the language code if there's a valid language code found in `path`.\n\n    If `strict` is False (the default), look for a country-specific variant\n    when neither the language code nor its generic variant is found.\n    \"\"\"\n    regex_match = language_code_prefix_re.match(path)\n    if not regex_match:\n        return None\n    lang_code = regex_match[1]\n    try:\n        return get_supported_language_variant(lang_code, strict=strict)\n    except LookupError:\n        return None\n\n\ndef get_language_from_request(request, check_path=False):\n    \"\"\"\n    Analyze the request to find what language the user wants the system to\n    show. Only languages listed in settings.LANGUAGES are taken into account.\n    If the user requests a sublanguage where we have a main language, we send\n    out the main language.\n\n    If check_path is True, the URL path prefix will be checked for a language\n    code, otherwise this is skipped for backwards compatibility.\n    \"\"\"\n    if check_path:\n        lang_code = get_language_from_path(request.path_info)\n        if lang_code is not None:\n            return lang_code\n\n    lang_code = request.COOKIES.get(settings.LANGUAGE_COOKIE_NAME)\n    if (\n        lang_code is not None\n        and lang_code in get_languages()\n        and check_for_language(lang_code)\n    ):\n        return lang_code\n\n    try:\n        return get_supported_language_variant(lang_code)\n    except LookupError:\n        pass\n\n    accept = request.META.get(\"HTTP_ACCEPT_LANGUAGE\", \"\")\n    for accept_lang, unused in parse_accept_lang_header(accept):\n        if accept_lang == \"*\":\n            break\n\n        if not language_code_re.search(accept_lang):\n            continue\n\n        try:\n            return get_supported_language_variant(accept_lang)\n        except LookupError:\n            continue\n    return None\n\n\n@functools.lru_cache(maxsize=1000)\ndef _parse_accept_lang_header(lang_string):\n    \"\"\"\n    Parse the lang_string, which is the body of an HTTP Accept-Language\n    header, and return a tuple of (lang, q-value), ordered by 'q' values.\n\n    Return an empty tuple if there are any format errors in lang_string.\n    \"\"\"\n    result = []\n    pieces = accept_language_re.split(lang_string.lower())\n    if pieces[-1]:\n        return ()\n    for i in range(0, len(pieces) - 1, 3):\n        first, lang, priority = pieces[i : i + 3]\n        if first:\n            return ()\n        if priority:\n            priority = float(priority)\n        else:\n            priority = 1.0\n        result.append((lang, priority))\n    result.sort(key=lambda k: k[1], reverse=True)\n    return tuple(result)\n\n\ndef parse_accept_lang_header(lang_string):\n    \"\"\"\n    Parse the value of the Accept-Language header up to a maximum length.\n\n    The value of the header is truncated to a maximum length to avoid potential\n    denial of service and memory exhaustion attacks. Excessive memory could be\n    used if the raw value is very large as it would be cached due to the use of\n    functools.lru_cache() to avoid repetitive parsing of common header values.\n    \"\"\"\n    # If the header value doesn't exceed the maximum allowed length, parse it.\n    if len(lang_string) <= ACCEPT_LANGUAGE_HEADER_MAX_LENGTH:\n        return _parse_accept_lang_header(lang_string)\n\n    # If there is at least one comma in the value, parse up to the last comma\n    # before the max length, skipping any truncated parts at the end of the\n    # header value.\n    if (index := lang_string.rfind(\",\", 0, ACCEPT_LANGUAGE_HEADER_MAX_LENGTH)) > 0:\n        return _parse_accept_lang_header(lang_string[:index])\n\n    # Don't attempt to parse if there is only one language-range value which is\n    # longer than the maximum allowed length and so truncated.\n    return ()\n"
  },
  {
    "patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9f42e2738c..9a22b0d87d 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -346,7 +346,7 @@ class LocalePrefixPattern:\n     @property\n     def regex(self):\n         # This is only used by reverse() and cached in _reverse_dict.\n-        return re.compile(self.language_prefix)\n+        return re.compile(re.escape(self.language_prefix))\n \n     @property\n     def language_prefix(self):\n",
    "commit_message": "Fixed CVE-2022-41323 -- Prevented locales being interpreted as regular expressions.\n\nThanks to Benjamin Balder Bach for the report.\n\n",
    "code_before": "\"\"\"\nThis module converts requested URLs to callback view functions.\n\nURLResolver is the main class here. Its resolve() method takes a URL (as\na string) and returns a ResolverMatch object which provides access to all\nattributes of the resolved URL match.\n\"\"\"\nimport functools\nimport inspect\nimport re\nimport string\nfrom importlib import import_module\nfrom pickle import PicklingError\nfrom urllib.parse import quote\n\nfrom asgiref.local import Local\n\nfrom django.conf import settings\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.urls import check_resolver\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.functional import cached_property\nfrom django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\nfrom django.utils.regex_helper import _lazy_re_compile, normalize\nfrom django.utils.translation import get_language\n\nfrom .converters import get_converter\nfrom .exceptions import NoReverseMatch, Resolver404\nfrom .utils import get_callable\n\n\nclass ResolverMatch:\n    def __init__(\n        self,\n        func,\n        args,\n        kwargs,\n        url_name=None,\n        app_names=None,\n        namespaces=None,\n        route=None,\n        tried=None,\n        captured_kwargs=None,\n        extra_kwargs=None,\n    ):\n        self.func = func\n        self.args = args\n        self.kwargs = kwargs\n        self.url_name = url_name\n        self.route = route\n        self.tried = tried\n        self.captured_kwargs = captured_kwargs\n        self.extra_kwargs = extra_kwargs\n\n        # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n        # in an empty value.\n        self.app_names = [x for x in app_names if x] if app_names else []\n        self.app_name = \":\".join(self.app_names)\n        self.namespaces = [x for x in namespaces if x] if namespaces else []\n        self.namespace = \":\".join(self.namespaces)\n\n        if hasattr(func, \"view_class\"):\n            func = func.view_class\n        if not hasattr(func, \"__name__\"):\n            # A class-based view\n            self._func_path = func.__class__.__module__ + \".\" + func.__class__.__name__\n        else:\n            # A function-based view\n            self._func_path = func.__module__ + \".\" + func.__name__\n\n        view_path = url_name or self._func_path\n        self.view_name = \":\".join(self.namespaces + [view_path])\n\n    def __getitem__(self, index):\n        return (self.func, self.args, self.kwargs)[index]\n\n    def __repr__(self):\n        if isinstance(self.func, functools.partial):\n            func = repr(self.func)\n        else:\n            func = self._func_path\n        return (\n            \"ResolverMatch(func=%s, args=%r, kwargs=%r, url_name=%r, \"\n            \"app_names=%r, namespaces=%r, route=%r%s%s)\"\n            % (\n                func,\n                self.args,\n                self.kwargs,\n                self.url_name,\n                self.app_names,\n                self.namespaces,\n                self.route,\n                f\", captured_kwargs={self.captured_kwargs!r}\"\n                if self.captured_kwargs\n                else \"\",\n                f\", extra_kwargs={self.extra_kwargs!r}\" if self.extra_kwargs else \"\",\n            )\n        )\n\n    def __reduce_ex__(self, protocol):\n        raise PicklingError(f\"Cannot pickle {self.__class__.__qualname__}.\")\n\n\ndef get_resolver(urlconf=None):\n    if urlconf is None:\n        urlconf = settings.ROOT_URLCONF\n    return _get_cached_resolver(urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef _get_cached_resolver(urlconf=None):\n    return URLResolver(RegexPattern(r\"^/\"), urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef get_ns_resolver(ns_pattern, resolver, converters):\n    # Build a namespaced resolver for the given parent URLconf pattern.\n    # This makes it possible to have captured parameters in the parent\n    # URLconf pattern.\n    pattern = RegexPattern(ns_pattern)\n    pattern.converters = dict(converters)\n    ns_resolver = URLResolver(pattern, resolver.url_patterns)\n    return URLResolver(RegexPattern(r\"^/\"), [ns_resolver])\n\n\nclass LocaleRegexDescriptor:\n    def __init__(self, attr):\n        self.attr = attr\n\n    def __get__(self, instance, cls=None):\n        \"\"\"\n        Return a compiled regular expression based on the active language.\n        \"\"\"\n        if instance is None:\n            return self\n        # As a performance optimization, if the given regex string is a regular\n        # string (not a lazily-translated string proxy), compile it once and\n        # avoid per-language compilation.\n        pattern = getattr(instance, self.attr)\n        if isinstance(pattern, str):\n            instance.__dict__[\"regex\"] = instance._compile(pattern)\n            return instance.__dict__[\"regex\"]\n        language_code = get_language()\n        if language_code not in instance._regex_dict:\n            instance._regex_dict[language_code] = instance._compile(str(pattern))\n        return instance._regex_dict[language_code]\n\n\nclass CheckURLMixin:\n    def describe(self):\n        \"\"\"\n        Format the URL pattern for display in warning messages.\n        \"\"\"\n        description = \"'{}'\".format(self)\n        if self.name:\n            description += \" [name='{}']\".format(self.name)\n        return description\n\n    def _check_pattern_startswith_slash(self):\n        \"\"\"\n        Check that the pattern does not begin with a forward slash.\n        \"\"\"\n        regex_pattern = self.regex.pattern\n        if not settings.APPEND_SLASH:\n            # Skip check as it can be useful to start a URL pattern with a slash\n            # when APPEND_SLASH=False.\n            return []\n        if regex_pattern.startswith((\"/\", \"^/\", \"^\\\\/\")) and not regex_pattern.endswith(\n            \"/\"\n        ):\n            warning = Warning(\n                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                \"slash as it is unnecessary. If this pattern is targeted in an \"\n                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n                    self.describe()\n                ),\n                id=\"urls.W002\",\n            )\n            return [warning]\n        else:\n            return []\n\n\nclass RegexPattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor(\"_regex\")\n\n    def __init__(self, regex, name=None, is_endpoint=False):\n        self._regex = regex\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = {}\n\n    def match(self, path):\n        match = (\n            self.regex.fullmatch(path)\n            if self._is_endpoint and self.regex.pattern.endswith(\"$\")\n            else self.regex.search(path)\n        )\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end() :], args, kwargs\n        return None\n\n    def check(self):\n        warnings = []\n        warnings.extend(self._check_pattern_startswith_slash())\n        if not self._is_endpoint:\n            warnings.extend(self._check_include_trailing_dollar())\n        return warnings\n\n    def _check_include_trailing_dollar(self):\n        regex_pattern = self.regex.pattern\n        if regex_pattern.endswith(\"$\") and not regex_pattern.endswith(r\"\\$\"):\n            return [\n                Warning(\n                    \"Your URL pattern {} uses include with a route ending with a '$'. \"\n                    \"Remove the dollar from the route to avoid problems including \"\n                    \"URLs.\".format(self.describe()),\n                    id=\"urls.W001\",\n                )\n            ]\n        else:\n            return []\n\n    def _compile(self, regex):\n        \"\"\"Compile and return the given regular expression.\"\"\"\n        try:\n            return re.compile(regex)\n        except re.error as e:\n            raise ImproperlyConfigured(\n                '\"%s\" is not a valid regular expression: %s' % (regex, e)\n            ) from e\n\n    def __str__(self):\n        return str(self._regex)\n\n\n_PATH_PARAMETER_COMPONENT_RE = _lazy_re_compile(\n    r\"<(?:(?P<converter>[^>:]+):)?(?P<parameter>[^>]+)>\"\n)\n\n\ndef _route_to_regex(route, is_endpoint=False):\n    \"\"\"\n    Convert a path pattern into a regular expression. Return the regular\n    expression and a dictionary mapping the capture names to the converters.\n    For example, 'foo/<int:pk>' returns '^foo\\\\/(?P<pk>[0-9]+)'\n    and {'pk': <django.urls.converters.IntConverter>}.\n    \"\"\"\n    original_route = route\n    parts = [\"^\"]\n    converters = {}\n    while True:\n        match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n        if not match:\n            parts.append(re.escape(route))\n            break\n        elif not set(match.group()).isdisjoint(string.whitespace):\n            raise ImproperlyConfigured(\n                \"URL route '%s' cannot contain whitespace in angle brackets \"\n                \"<\u2026>.\" % original_route\n            )\n        parts.append(re.escape(route[: match.start()]))\n        route = route[match.end() :]\n        parameter = match[\"parameter\"]\n        if not parameter.isidentifier():\n            raise ImproperlyConfigured(\n                \"URL route '%s' uses parameter name %r which isn't a valid \"\n                \"Python identifier.\" % (original_route, parameter)\n            )\n        raw_converter = match[\"converter\"]\n        if raw_converter is None:\n            # If a converter isn't specified, the default is `str`.\n            raw_converter = \"str\"\n        try:\n            converter = get_converter(raw_converter)\n        except KeyError as e:\n            raise ImproperlyConfigured(\n                \"URL route %r uses invalid converter %r.\"\n                % (original_route, raw_converter)\n            ) from e\n        converters[parameter] = converter\n        parts.append(\"(?P<\" + parameter + \">\" + converter.regex + \")\")\n    if is_endpoint:\n        parts.append(r\"\\Z\")\n    return \"\".join(parts), converters\n\n\nclass RoutePattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor(\"_route\")\n\n    def __init__(self, route, name=None, is_endpoint=False):\n        self._route = route\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = _route_to_regex(str(route), is_endpoint)[1]\n\n    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # RoutePattern doesn't allow non-named groups so args are ignored.\n            kwargs = match.groupdict()\n            for key, value in kwargs.items():\n                converter = self.converters[key]\n                try:\n                    kwargs[key] = converter.to_python(value)\n                except ValueError:\n                    return None\n            return path[match.end() :], (), kwargs\n        return None\n\n    def check(self):\n        warnings = self._check_pattern_startswith_slash()\n        route = self._route\n        if \"(?P<\" in route or route.startswith(\"^\") or route.endswith(\"$\"):\n            warnings.append(\n                Warning(\n                    \"Your URL pattern {} has a route that contains '(?P<', begins \"\n                    \"with a '^', or ends with a '$'. This was likely an oversight \"\n                    \"when migrating to django.urls.path().\".format(self.describe()),\n                    id=\"2_0.W001\",\n                )\n            )\n        return warnings\n\n    def _compile(self, route):\n        return re.compile(_route_to_regex(route, self._is_endpoint)[0])\n\n    def __str__(self):\n        return str(self._route)\n\n\nclass LocalePrefixPattern:\n    def __init__(self, prefix_default_language=True):\n        self.prefix_default_language = prefix_default_language\n        self.converters = {}\n\n    @property\n    def regex(self):\n        # This is only used by reverse() and cached in _reverse_dict.\n        return re.compile(self.language_prefix)\n\n    @property\n    def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n            return \"\"\n        else:\n            return \"%s/\" % language_code\n\n    def match(self, path):\n        language_prefix = self.language_prefix\n        if path.startswith(language_prefix):\n            return path[len(language_prefix) :], (), {}\n        return None\n\n    def check(self):\n        return []\n\n    def describe(self):\n        return \"'{}'\".format(self)\n\n    def __str__(self):\n        return self.language_prefix\n\n\nclass URLPattern:\n    def __init__(self, pattern, callback, default_args=None, name=None):\n        self.pattern = pattern\n        self.callback = callback  # the view\n        self.default_args = default_args or {}\n        self.name = name\n\n    def __repr__(self):\n        return \"<%s %s>\" % (self.__class__.__name__, self.pattern.describe())\n\n    def check(self):\n        warnings = self._check_pattern_name()\n        warnings.extend(self.pattern.check())\n        warnings.extend(self._check_callback())\n        return warnings\n\n    def _check_pattern_name(self):\n        \"\"\"\n        Check that the pattern name does not contain a colon.\n        \"\"\"\n        if self.pattern.name is not None and \":\" in self.pattern.name:\n            warning = Warning(\n                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"\n                \"avoid ambiguous namespace references.\".format(self.pattern.describe()),\n                id=\"urls.W003\",\n            )\n            return [warning]\n        else:\n            return []\n\n    def _check_callback(self):\n        from django.views import View\n\n        view = self.callback\n        if inspect.isclass(view) and issubclass(view, View):\n            return [\n                Error(\n                    \"Your URL pattern %s has an invalid view, pass %s.as_view() \"\n                    \"instead of %s.\"\n                    % (\n                        self.pattern.describe(),\n                        view.__name__,\n                        view.__name__,\n                    ),\n                    id=\"urls.E009\",\n                )\n            ]\n        return []\n\n    def resolve(self, path):\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, captured_kwargs = match\n            # Pass any default args as **kwargs.\n            kwargs = {**captured_kwargs, **self.default_args}\n            return ResolverMatch(\n                self.callback,\n                args,\n                kwargs,\n                self.pattern.name,\n                route=str(self.pattern),\n                captured_kwargs=captured_kwargs,\n                extra_kwargs=self.default_args,\n            )\n\n    @cached_property\n    def lookup_str(self):\n        \"\"\"\n        A string that identifies the view (e.g. 'path.to.view_function' or\n        'path.to.ClassBasedView').\n        \"\"\"\n        callback = self.callback\n        if isinstance(callback, functools.partial):\n            callback = callback.func\n        if hasattr(callback, \"view_class\"):\n            callback = callback.view_class\n        elif not hasattr(callback, \"__name__\"):\n            return callback.__module__ + \".\" + callback.__class__.__name__\n        return callback.__module__ + \".\" + callback.__qualname__\n\n\nclass URLResolver:\n    def __init__(\n        self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None\n    ):\n        self.pattern = pattern\n        # urlconf_name is the dotted Python path to the module defining\n        # urlpatterns. It may also be an object with an urlpatterns attribute\n        # or urlpatterns itself.\n        self.urlconf_name = urlconf_name\n        self.callback = None\n        self.default_kwargs = default_kwargs or {}\n        self.namespace = namespace\n        self.app_name = app_name\n        self._reverse_dict = {}\n        self._namespace_dict = {}\n        self._app_dict = {}\n        # set of dotted paths to all functions and classes that are used in\n        # urlpatterns\n        self._callback_strs = set()\n        self._populated = False\n        self._local = Local()\n\n    def __repr__(self):\n        if isinstance(self.urlconf_name, list) and self.urlconf_name:\n            # Don't bother to output the whole list, it can be huge\n            urlconf_repr = \"<%s list>\" % self.urlconf_name[0].__class__.__name__\n        else:\n            urlconf_repr = repr(self.urlconf_name)\n        return \"<%s %s (%s:%s) %s>\" % (\n            self.__class__.__name__,\n            urlconf_repr,\n            self.app_name,\n            self.namespace,\n            self.pattern.describe(),\n        )\n\n    def check(self):\n        messages = []\n        for pattern in self.url_patterns:\n            messages.extend(check_resolver(pattern))\n        messages.extend(self._check_custom_error_handlers())\n        return messages or self.pattern.check()\n\n    def _check_custom_error_handlers(self):\n        messages = []\n        # All handlers take (request, exception) arguments except handler500\n        # which takes (request).\n        for status_code, num_parameters in [(400, 2), (403, 2), (404, 2), (500, 1)]:\n            try:\n                handler = self.resolve_error_handler(status_code)\n            except (ImportError, ViewDoesNotExist) as e:\n                path = getattr(self.urlconf_module, \"handler%s\" % status_code)\n                msg = (\n                    \"The custom handler{status_code} view '{path}' could not be \"\n                    \"imported.\"\n                ).format(status_code=status_code, path=path)\n                messages.append(Error(msg, hint=str(e), id=\"urls.E008\"))\n                continue\n            signature = inspect.signature(handler)\n            args = [None] * num_parameters\n            try:\n                signature.bind(*args)\n            except TypeError:\n                msg = (\n                    \"The custom handler{status_code} view '{path}' does not \"\n                    \"take the correct number of arguments ({args}).\"\n                ).format(\n                    status_code=status_code,\n                    path=handler.__module__ + \".\" + handler.__qualname__,\n                    args=\"request, exception\" if num_parameters == 2 else \"request\",\n                )\n                messages.append(Error(msg, id=\"urls.E007\"))\n        return messages\n\n    def _populate(self):\n        # Short-circuit if called recursively in this thread to prevent\n        # infinite recursion. Concurrent threads may call this at the same\n        # time and will need to continue, so set 'populating' on a\n        # thread-local variable.\n        if getattr(self._local, \"populating\", False):\n            return\n        try:\n            self._local.populating = True\n            lookups = MultiValueDict()\n            namespaces = {}\n            apps = {}\n            language_code = get_language()\n            for url_pattern in reversed(self.url_patterns):\n                p_pattern = url_pattern.pattern.regex.pattern\n                if p_pattern.startswith(\"^\"):\n                    p_pattern = p_pattern[1:]\n                if isinstance(url_pattern, URLPattern):\n                    self._callback_strs.add(url_pattern.lookup_str)\n                    bits = normalize(url_pattern.pattern.regex.pattern)\n                    lookups.appendlist(\n                        url_pattern.callback,\n                        (\n                            bits,\n                            p_pattern,\n                            url_pattern.default_args,\n                            url_pattern.pattern.converters,\n                        ),\n                    )\n                    if url_pattern.name is not None:\n                        lookups.appendlist(\n                            url_pattern.name,\n                            (\n                                bits,\n                                p_pattern,\n                                url_pattern.default_args,\n                                url_pattern.pattern.converters,\n                            ),\n                        )\n                else:  # url_pattern is a URLResolver.\n                    url_pattern._populate()\n                    if url_pattern.app_name:\n                        apps.setdefault(url_pattern.app_name, []).append(\n                            url_pattern.namespace\n                        )\n                        namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                    else:\n                        for name in url_pattern.reverse_dict:\n                            for (\n                                matches,\n                                pat,\n                                defaults,\n                                converters,\n                            ) in url_pattern.reverse_dict.getlist(name):\n                                new_matches = normalize(p_pattern + pat)\n                                lookups.appendlist(\n                                    name,\n                                    (\n                                        new_matches,\n                                        p_pattern + pat,\n                                        {**defaults, **url_pattern.default_kwargs},\n                                        {\n                                            **self.pattern.converters,\n                                            **url_pattern.pattern.converters,\n                                            **converters,\n                                        },\n                                    ),\n                                )\n                        for namespace, (\n                            prefix,\n                            sub_pattern,\n                        ) in url_pattern.namespace_dict.items():\n                            current_converters = url_pattern.pattern.converters\n                            sub_pattern.pattern.converters.update(current_converters)\n                            namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n                        for app_name, namespace_list in url_pattern.app_dict.items():\n                            apps.setdefault(app_name, []).extend(namespace_list)\n                    self._callback_strs.update(url_pattern._callback_strs)\n            self._namespace_dict[language_code] = namespaces\n            self._app_dict[language_code] = apps\n            self._reverse_dict[language_code] = lookups\n            self._populated = True\n        finally:\n            self._local.populating = False\n\n    @property\n    def reverse_dict(self):\n        language_code = get_language()\n        if language_code not in self._reverse_dict:\n            self._populate()\n        return self._reverse_dict[language_code]\n\n    @property\n    def namespace_dict(self):\n        language_code = get_language()\n        if language_code not in self._namespace_dict:\n            self._populate()\n        return self._namespace_dict[language_code]\n\n    @property\n    def app_dict(self):\n        language_code = get_language()\n        if language_code not in self._app_dict:\n            self._populate()\n        return self._app_dict[language_code]\n\n    @staticmethod\n    def _extend_tried(tried, pattern, sub_tried=None):\n        if sub_tried is None:\n            tried.append([pattern])\n        else:\n            tried.extend([pattern, *t] for t in sub_tried)\n\n    @staticmethod\n    def _join_route(route1, route2):\n        \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n        if not route1:\n            return route2\n        if route2.startswith(\"^\"):\n            route2 = route2[1:]\n        return route1 + route2\n\n    def _is_callback(self, name):\n        if not self._populated:\n            self._populate()\n        return name in self._callback_strs\n\n    def resolve(self, path):\n        path = str(path)  # path may be a reverse_lazy object\n        tried = []\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            for pattern in self.url_patterns:\n                try:\n                    sub_match = pattern.resolve(new_path)\n                except Resolver404 as e:\n                    self._extend_tried(tried, pattern, e.args[0].get(\"tried\"))\n                else:\n                    if sub_match:\n                        # Merge captured arguments in match with submatch\n                        sub_match_dict = {**kwargs, **self.default_kwargs}\n                        # Update the sub_match_dict with the kwargs from the sub_match.\n                        sub_match_dict.update(sub_match.kwargs)\n                        # If there are *any* named groups, ignore all non-named groups.\n                        # Otherwise, pass all non-named arguments as positional\n                        # arguments.\n                        sub_match_args = sub_match.args\n                        if not sub_match_dict:\n                            sub_match_args = args + sub_match.args\n                        current_route = (\n                            \"\"\n                            if isinstance(pattern, URLPattern)\n                            else str(pattern.pattern)\n                        )\n                        self._extend_tried(tried, pattern, sub_match.tried)\n                        return ResolverMatch(\n                            sub_match.func,\n                            sub_match_args,\n                            sub_match_dict,\n                            sub_match.url_name,\n                            [self.app_name] + sub_match.app_names,\n                            [self.namespace] + sub_match.namespaces,\n                            self._join_route(current_route, sub_match.route),\n                            tried,\n                            captured_kwargs=sub_match.captured_kwargs,\n                            extra_kwargs={\n                                **self.default_kwargs,\n                                **sub_match.extra_kwargs,\n                            },\n                        )\n                    tried.append([pattern])\n            raise Resolver404({\"tried\": tried, \"path\": new_path})\n        raise Resolver404({\"path\": path})\n\n    @cached_property\n    def urlconf_module(self):\n        if isinstance(self.urlconf_name, str):\n            return import_module(self.urlconf_name)\n        else:\n            return self.urlconf_name\n\n    @cached_property\n    def url_patterns(self):\n        # urlconf_module might be a valid set of patterns, so we default to it\n        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\n        try:\n            iter(patterns)\n        except TypeError as e:\n            msg = (\n                \"The included URLconf '{name}' does not appear to have \"\n                \"any patterns in it. If you see the 'urlpatterns' variable \"\n                \"with valid patterns in the file then the issue is probably \"\n                \"caused by a circular import.\"\n            )\n            raise ImproperlyConfigured(msg.format(name=self.urlconf_name)) from e\n        return patterns\n\n    def resolve_error_handler(self, view_type):\n        callback = getattr(self.urlconf_module, \"handler%s\" % view_type, None)\n        if not callback:\n            # No handler specified in file; use lazy import, since\n            # django.conf.urls imports this file.\n            from django.conf import urls\n\n            callback = getattr(urls, \"handler%s\" % view_type)\n        return get_callable(callback)\n\n    def reverse(self, lookup_view, *args, **kwargs):\n        return self._reverse_with_prefix(lookup_view, \"\", *args, **kwargs)\n\n    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n        if args and kwargs:\n            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")\n\n        if not self._populated:\n            self._populate()\n\n        possibilities = self.reverse_dict.getlist(lookup_view)\n\n        for possibility, pattern, defaults, converters in possibilities:\n            for result, params in possibility:\n                if args:\n                    if len(args) != len(params):\n                        continue\n                    candidate_subs = dict(zip(params, args))\n                else:\n                    if set(kwargs).symmetric_difference(params).difference(defaults):\n                        continue\n                    matches = True\n                    for k, v in defaults.items():\n                        if k in params:\n                            continue\n                        if kwargs.get(k, v) != v:\n                            matches = False\n                            break\n                    if not matches:\n                        continue\n                    candidate_subs = kwargs\n                # Convert the candidate subs to text using Converter.to_url().\n                text_candidate_subs = {}\n                match = True\n                for k, v in candidate_subs.items():\n                    if k in converters:\n                        try:\n                            text_candidate_subs[k] = converters[k].to_url(v)\n                        except ValueError:\n                            match = False\n                            break\n                    else:\n                        text_candidate_subs[k] = str(v)\n                if not match:\n                    continue\n                # WSGI provides decoded URLs, without %xx escapes, and the URL\n                # resolver operates on such URLs. First substitute arguments\n                # without quoting to build a decoded URL and look for a match.\n                # Then, if we have a match, redo the substitution with quoted\n                # arguments in order to return a properly encoded URL.\n                candidate_pat = _prefix.replace(\"%\", \"%%\") + result\n                if re.search(\n                    \"^%s%s\" % (re.escape(_prefix), pattern),\n                    candidate_pat % text_candidate_subs,\n                ):\n                    # safe characters from `pchar` definition of RFC 3986\n                    url = quote(\n                        candidate_pat % text_candidate_subs,\n                        safe=RFC3986_SUBDELIMS + \"/~:@\",\n                    )\n                    # Don't allow construction of scheme relative urls.\n                    return escape_leading_slashes(url)\n        # lookup_view can be URL name or callable, but callables are not\n        # friendly in error messages.\n        m = getattr(lookup_view, \"__module__\", None)\n        n = getattr(lookup_view, \"__name__\", None)\n        if m is not None and n is not None:\n            lookup_view_s = \"%s.%s\" % (m, n)\n        else:\n            lookup_view_s = lookup_view\n\n        patterns = [pattern for (_, pattern, _, _) in possibilities]\n        if patterns:\n            if args:\n                arg_msg = \"arguments '%s'\" % (args,)\n            elif kwargs:\n                arg_msg = \"keyword arguments '%s'\" % kwargs\n            else:\n                arg_msg = \"no arguments\"\n            msg = \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" % (\n                lookup_view_s,\n                arg_msg,\n                len(patterns),\n                patterns,\n            )\n        else:\n            msg = (\n                \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n                \"a valid view function or pattern name.\" % {\"view\": lookup_view_s}\n            )\n        raise NoReverseMatch(msg)\n",
    "code_after": "\"\"\"\nThis module converts requested URLs to callback view functions.\n\nURLResolver is the main class here. Its resolve() method takes a URL (as\na string) and returns a ResolverMatch object which provides access to all\nattributes of the resolved URL match.\n\"\"\"\nimport functools\nimport inspect\nimport re\nimport string\nfrom importlib import import_module\nfrom pickle import PicklingError\nfrom urllib.parse import quote\n\nfrom asgiref.local import Local\n\nfrom django.conf import settings\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.urls import check_resolver\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.functional import cached_property\nfrom django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\nfrom django.utils.regex_helper import _lazy_re_compile, normalize\nfrom django.utils.translation import get_language\n\nfrom .converters import get_converter\nfrom .exceptions import NoReverseMatch, Resolver404\nfrom .utils import get_callable\n\n\nclass ResolverMatch:\n    def __init__(\n        self,\n        func,\n        args,\n        kwargs,\n        url_name=None,\n        app_names=None,\n        namespaces=None,\n        route=None,\n        tried=None,\n        captured_kwargs=None,\n        extra_kwargs=None,\n    ):\n        self.func = func\n        self.args = args\n        self.kwargs = kwargs\n        self.url_name = url_name\n        self.route = route\n        self.tried = tried\n        self.captured_kwargs = captured_kwargs\n        self.extra_kwargs = extra_kwargs\n\n        # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n        # in an empty value.\n        self.app_names = [x for x in app_names if x] if app_names else []\n        self.app_name = \":\".join(self.app_names)\n        self.namespaces = [x for x in namespaces if x] if namespaces else []\n        self.namespace = \":\".join(self.namespaces)\n\n        if hasattr(func, \"view_class\"):\n            func = func.view_class\n        if not hasattr(func, \"__name__\"):\n            # A class-based view\n            self._func_path = func.__class__.__module__ + \".\" + func.__class__.__name__\n        else:\n            # A function-based view\n            self._func_path = func.__module__ + \".\" + func.__name__\n\n        view_path = url_name or self._func_path\n        self.view_name = \":\".join(self.namespaces + [view_path])\n\n    def __getitem__(self, index):\n        return (self.func, self.args, self.kwargs)[index]\n\n    def __repr__(self):\n        if isinstance(self.func, functools.partial):\n            func = repr(self.func)\n        else:\n            func = self._func_path\n        return (\n            \"ResolverMatch(func=%s, args=%r, kwargs=%r, url_name=%r, \"\n            \"app_names=%r, namespaces=%r, route=%r%s%s)\"\n            % (\n                func,\n                self.args,\n                self.kwargs,\n                self.url_name,\n                self.app_names,\n                self.namespaces,\n                self.route,\n                f\", captured_kwargs={self.captured_kwargs!r}\"\n                if self.captured_kwargs\n                else \"\",\n                f\", extra_kwargs={self.extra_kwargs!r}\" if self.extra_kwargs else \"\",\n            )\n        )\n\n    def __reduce_ex__(self, protocol):\n        raise PicklingError(f\"Cannot pickle {self.__class__.__qualname__}.\")\n\n\ndef get_resolver(urlconf=None):\n    if urlconf is None:\n        urlconf = settings.ROOT_URLCONF\n    return _get_cached_resolver(urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef _get_cached_resolver(urlconf=None):\n    return URLResolver(RegexPattern(r\"^/\"), urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef get_ns_resolver(ns_pattern, resolver, converters):\n    # Build a namespaced resolver for the given parent URLconf pattern.\n    # This makes it possible to have captured parameters in the parent\n    # URLconf pattern.\n    pattern = RegexPattern(ns_pattern)\n    pattern.converters = dict(converters)\n    ns_resolver = URLResolver(pattern, resolver.url_patterns)\n    return URLResolver(RegexPattern(r\"^/\"), [ns_resolver])\n\n\nclass LocaleRegexDescriptor:\n    def __init__(self, attr):\n        self.attr = attr\n\n    def __get__(self, instance, cls=None):\n        \"\"\"\n        Return a compiled regular expression based on the active language.\n        \"\"\"\n        if instance is None:\n            return self\n        # As a performance optimization, if the given regex string is a regular\n        # string (not a lazily-translated string proxy), compile it once and\n        # avoid per-language compilation.\n        pattern = getattr(instance, self.attr)\n        if isinstance(pattern, str):\n            instance.__dict__[\"regex\"] = instance._compile(pattern)\n            return instance.__dict__[\"regex\"]\n        language_code = get_language()\n        if language_code not in instance._regex_dict:\n            instance._regex_dict[language_code] = instance._compile(str(pattern))\n        return instance._regex_dict[language_code]\n\n\nclass CheckURLMixin:\n    def describe(self):\n        \"\"\"\n        Format the URL pattern for display in warning messages.\n        \"\"\"\n        description = \"'{}'\".format(self)\n        if self.name:\n            description += \" [name='{}']\".format(self.name)\n        return description\n\n    def _check_pattern_startswith_slash(self):\n        \"\"\"\n        Check that the pattern does not begin with a forward slash.\n        \"\"\"\n        regex_pattern = self.regex.pattern\n        if not settings.APPEND_SLASH:\n            # Skip check as it can be useful to start a URL pattern with a slash\n            # when APPEND_SLASH=False.\n            return []\n        if regex_pattern.startswith((\"/\", \"^/\", \"^\\\\/\")) and not regex_pattern.endswith(\n            \"/\"\n        ):\n            warning = Warning(\n                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                \"slash as it is unnecessary. If this pattern is targeted in an \"\n                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n                    self.describe()\n                ),\n                id=\"urls.W002\",\n            )\n            return [warning]\n        else:\n            return []\n\n\nclass RegexPattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor(\"_regex\")\n\n    def __init__(self, regex, name=None, is_endpoint=False):\n        self._regex = regex\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = {}\n\n    def match(self, path):\n        match = (\n            self.regex.fullmatch(path)\n            if self._is_endpoint and self.regex.pattern.endswith(\"$\")\n            else self.regex.search(path)\n        )\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end() :], args, kwargs\n        return None\n\n    def check(self):\n        warnings = []\n        warnings.extend(self._check_pattern_startswith_slash())\n        if not self._is_endpoint:\n            warnings.extend(self._check_include_trailing_dollar())\n        return warnings\n\n    def _check_include_trailing_dollar(self):\n        regex_pattern = self.regex.pattern\n        if regex_pattern.endswith(\"$\") and not regex_pattern.endswith(r\"\\$\"):\n            return [\n                Warning(\n                    \"Your URL pattern {} uses include with a route ending with a '$'. \"\n                    \"Remove the dollar from the route to avoid problems including \"\n                    \"URLs.\".format(self.describe()),\n                    id=\"urls.W001\",\n                )\n            ]\n        else:\n            return []\n\n    def _compile(self, regex):\n        \"\"\"Compile and return the given regular expression.\"\"\"\n        try:\n            return re.compile(regex)\n        except re.error as e:\n            raise ImproperlyConfigured(\n                '\"%s\" is not a valid regular expression: %s' % (regex, e)\n            ) from e\n\n    def __str__(self):\n        return str(self._regex)\n\n\n_PATH_PARAMETER_COMPONENT_RE = _lazy_re_compile(\n    r\"<(?:(?P<converter>[^>:]+):)?(?P<parameter>[^>]+)>\"\n)\n\n\ndef _route_to_regex(route, is_endpoint=False):\n    \"\"\"\n    Convert a path pattern into a regular expression. Return the regular\n    expression and a dictionary mapping the capture names to the converters.\n    For example, 'foo/<int:pk>' returns '^foo\\\\/(?P<pk>[0-9]+)'\n    and {'pk': <django.urls.converters.IntConverter>}.\n    \"\"\"\n    original_route = route\n    parts = [\"^\"]\n    converters = {}\n    while True:\n        match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n        if not match:\n            parts.append(re.escape(route))\n            break\n        elif not set(match.group()).isdisjoint(string.whitespace):\n            raise ImproperlyConfigured(\n                \"URL route '%s' cannot contain whitespace in angle brackets \"\n                \"<\u2026>.\" % original_route\n            )\n        parts.append(re.escape(route[: match.start()]))\n        route = route[match.end() :]\n        parameter = match[\"parameter\"]\n        if not parameter.isidentifier():\n            raise ImproperlyConfigured(\n                \"URL route '%s' uses parameter name %r which isn't a valid \"\n                \"Python identifier.\" % (original_route, parameter)\n            )\n        raw_converter = match[\"converter\"]\n        if raw_converter is None:\n            # If a converter isn't specified, the default is `str`.\n            raw_converter = \"str\"\n        try:\n            converter = get_converter(raw_converter)\n        except KeyError as e:\n            raise ImproperlyConfigured(\n                \"URL route %r uses invalid converter %r.\"\n                % (original_route, raw_converter)\n            ) from e\n        converters[parameter] = converter\n        parts.append(\"(?P<\" + parameter + \">\" + converter.regex + \")\")\n    if is_endpoint:\n        parts.append(r\"\\Z\")\n    return \"\".join(parts), converters\n\n\nclass RoutePattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor(\"_route\")\n\n    def __init__(self, route, name=None, is_endpoint=False):\n        self._route = route\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = _route_to_regex(str(route), is_endpoint)[1]\n\n    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # RoutePattern doesn't allow non-named groups so args are ignored.\n            kwargs = match.groupdict()\n            for key, value in kwargs.items():\n                converter = self.converters[key]\n                try:\n                    kwargs[key] = converter.to_python(value)\n                except ValueError:\n                    return None\n            return path[match.end() :], (), kwargs\n        return None\n\n    def check(self):\n        warnings = self._check_pattern_startswith_slash()\n        route = self._route\n        if \"(?P<\" in route or route.startswith(\"^\") or route.endswith(\"$\"):\n            warnings.append(\n                Warning(\n                    \"Your URL pattern {} has a route that contains '(?P<', begins \"\n                    \"with a '^', or ends with a '$'. This was likely an oversight \"\n                    \"when migrating to django.urls.path().\".format(self.describe()),\n                    id=\"2_0.W001\",\n                )\n            )\n        return warnings\n\n    def _compile(self, route):\n        return re.compile(_route_to_regex(route, self._is_endpoint)[0])\n\n    def __str__(self):\n        return str(self._route)\n\n\nclass LocalePrefixPattern:\n    def __init__(self, prefix_default_language=True):\n        self.prefix_default_language = prefix_default_language\n        self.converters = {}\n\n    @property\n    def regex(self):\n        # This is only used by reverse() and cached in _reverse_dict.\n        return re.compile(re.escape(self.language_prefix))\n\n    @property\n    def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n            return \"\"\n        else:\n            return \"%s/\" % language_code\n\n    def match(self, path):\n        language_prefix = self.language_prefix\n        if path.startswith(language_prefix):\n            return path[len(language_prefix) :], (), {}\n        return None\n\n    def check(self):\n        return []\n\n    def describe(self):\n        return \"'{}'\".format(self)\n\n    def __str__(self):\n        return self.language_prefix\n\n\nclass URLPattern:\n    def __init__(self, pattern, callback, default_args=None, name=None):\n        self.pattern = pattern\n        self.callback = callback  # the view\n        self.default_args = default_args or {}\n        self.name = name\n\n    def __repr__(self):\n        return \"<%s %s>\" % (self.__class__.__name__, self.pattern.describe())\n\n    def check(self):\n        warnings = self._check_pattern_name()\n        warnings.extend(self.pattern.check())\n        warnings.extend(self._check_callback())\n        return warnings\n\n    def _check_pattern_name(self):\n        \"\"\"\n        Check that the pattern name does not contain a colon.\n        \"\"\"\n        if self.pattern.name is not None and \":\" in self.pattern.name:\n            warning = Warning(\n                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"\n                \"avoid ambiguous namespace references.\".format(self.pattern.describe()),\n                id=\"urls.W003\",\n            )\n            return [warning]\n        else:\n            return []\n\n    def _check_callback(self):\n        from django.views import View\n\n        view = self.callback\n        if inspect.isclass(view) and issubclass(view, View):\n            return [\n                Error(\n                    \"Your URL pattern %s has an invalid view, pass %s.as_view() \"\n                    \"instead of %s.\"\n                    % (\n                        self.pattern.describe(),\n                        view.__name__,\n                        view.__name__,\n                    ),\n                    id=\"urls.E009\",\n                )\n            ]\n        return []\n\n    def resolve(self, path):\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, captured_kwargs = match\n            # Pass any default args as **kwargs.\n            kwargs = {**captured_kwargs, **self.default_args}\n            return ResolverMatch(\n                self.callback,\n                args,\n                kwargs,\n                self.pattern.name,\n                route=str(self.pattern),\n                captured_kwargs=captured_kwargs,\n                extra_kwargs=self.default_args,\n            )\n\n    @cached_property\n    def lookup_str(self):\n        \"\"\"\n        A string that identifies the view (e.g. 'path.to.view_function' or\n        'path.to.ClassBasedView').\n        \"\"\"\n        callback = self.callback\n        if isinstance(callback, functools.partial):\n            callback = callback.func\n        if hasattr(callback, \"view_class\"):\n            callback = callback.view_class\n        elif not hasattr(callback, \"__name__\"):\n            return callback.__module__ + \".\" + callback.__class__.__name__\n        return callback.__module__ + \".\" + callback.__qualname__\n\n\nclass URLResolver:\n    def __init__(\n        self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None\n    ):\n        self.pattern = pattern\n        # urlconf_name is the dotted Python path to the module defining\n        # urlpatterns. It may also be an object with an urlpatterns attribute\n        # or urlpatterns itself.\n        self.urlconf_name = urlconf_name\n        self.callback = None\n        self.default_kwargs = default_kwargs or {}\n        self.namespace = namespace\n        self.app_name = app_name\n        self._reverse_dict = {}\n        self._namespace_dict = {}\n        self._app_dict = {}\n        # set of dotted paths to all functions and classes that are used in\n        # urlpatterns\n        self._callback_strs = set()\n        self._populated = False\n        self._local = Local()\n\n    def __repr__(self):\n        if isinstance(self.urlconf_name, list) and self.urlconf_name:\n            # Don't bother to output the whole list, it can be huge\n            urlconf_repr = \"<%s list>\" % self.urlconf_name[0].__class__.__name__\n        else:\n            urlconf_repr = repr(self.urlconf_name)\n        return \"<%s %s (%s:%s) %s>\" % (\n            self.__class__.__name__,\n            urlconf_repr,\n            self.app_name,\n            self.namespace,\n            self.pattern.describe(),\n        )\n\n    def check(self):\n        messages = []\n        for pattern in self.url_patterns:\n            messages.extend(check_resolver(pattern))\n        messages.extend(self._check_custom_error_handlers())\n        return messages or self.pattern.check()\n\n    def _check_custom_error_handlers(self):\n        messages = []\n        # All handlers take (request, exception) arguments except handler500\n        # which takes (request).\n        for status_code, num_parameters in [(400, 2), (403, 2), (404, 2), (500, 1)]:\n            try:\n                handler = self.resolve_error_handler(status_code)\n            except (ImportError, ViewDoesNotExist) as e:\n                path = getattr(self.urlconf_module, \"handler%s\" % status_code)\n                msg = (\n                    \"The custom handler{status_code} view '{path}' could not be \"\n                    \"imported.\"\n                ).format(status_code=status_code, path=path)\n                messages.append(Error(msg, hint=str(e), id=\"urls.E008\"))\n                continue\n            signature = inspect.signature(handler)\n            args = [None] * num_parameters\n            try:\n                signature.bind(*args)\n            except TypeError:\n                msg = (\n                    \"The custom handler{status_code} view '{path}' does not \"\n                    \"take the correct number of arguments ({args}).\"\n                ).format(\n                    status_code=status_code,\n                    path=handler.__module__ + \".\" + handler.__qualname__,\n                    args=\"request, exception\" if num_parameters == 2 else \"request\",\n                )\n                messages.append(Error(msg, id=\"urls.E007\"))\n        return messages\n\n    def _populate(self):\n        # Short-circuit if called recursively in this thread to prevent\n        # infinite recursion. Concurrent threads may call this at the same\n        # time and will need to continue, so set 'populating' on a\n        # thread-local variable.\n        if getattr(self._local, \"populating\", False):\n            return\n        try:\n            self._local.populating = True\n            lookups = MultiValueDict()\n            namespaces = {}\n            apps = {}\n            language_code = get_language()\n            for url_pattern in reversed(self.url_patterns):\n                p_pattern = url_pattern.pattern.regex.pattern\n                if p_pattern.startswith(\"^\"):\n                    p_pattern = p_pattern[1:]\n                if isinstance(url_pattern, URLPattern):\n                    self._callback_strs.add(url_pattern.lookup_str)\n                    bits = normalize(url_pattern.pattern.regex.pattern)\n                    lookups.appendlist(\n                        url_pattern.callback,\n                        (\n                            bits,\n                            p_pattern,\n                            url_pattern.default_args,\n                            url_pattern.pattern.converters,\n                        ),\n                    )\n                    if url_pattern.name is not None:\n                        lookups.appendlist(\n                            url_pattern.name,\n                            (\n                                bits,\n                                p_pattern,\n                                url_pattern.default_args,\n                                url_pattern.pattern.converters,\n                            ),\n                        )\n                else:  # url_pattern is a URLResolver.\n                    url_pattern._populate()\n                    if url_pattern.app_name:\n                        apps.setdefault(url_pattern.app_name, []).append(\n                            url_pattern.namespace\n                        )\n                        namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                    else:\n                        for name in url_pattern.reverse_dict:\n                            for (\n                                matches,\n                                pat,\n                                defaults,\n                                converters,\n                            ) in url_pattern.reverse_dict.getlist(name):\n                                new_matches = normalize(p_pattern + pat)\n                                lookups.appendlist(\n                                    name,\n                                    (\n                                        new_matches,\n                                        p_pattern + pat,\n                                        {**defaults, **url_pattern.default_kwargs},\n                                        {\n                                            **self.pattern.converters,\n                                            **url_pattern.pattern.converters,\n                                            **converters,\n                                        },\n                                    ),\n                                )\n                        for namespace, (\n                            prefix,\n                            sub_pattern,\n                        ) in url_pattern.namespace_dict.items():\n                            current_converters = url_pattern.pattern.converters\n                            sub_pattern.pattern.converters.update(current_converters)\n                            namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n                        for app_name, namespace_list in url_pattern.app_dict.items():\n                            apps.setdefault(app_name, []).extend(namespace_list)\n                    self._callback_strs.update(url_pattern._callback_strs)\n            self._namespace_dict[language_code] = namespaces\n            self._app_dict[language_code] = apps\n            self._reverse_dict[language_code] = lookups\n            self._populated = True\n        finally:\n            self._local.populating = False\n\n    @property\n    def reverse_dict(self):\n        language_code = get_language()\n        if language_code not in self._reverse_dict:\n            self._populate()\n        return self._reverse_dict[language_code]\n\n    @property\n    def namespace_dict(self):\n        language_code = get_language()\n        if language_code not in self._namespace_dict:\n            self._populate()\n        return self._namespace_dict[language_code]\n\n    @property\n    def app_dict(self):\n        language_code = get_language()\n        if language_code not in self._app_dict:\n            self._populate()\n        return self._app_dict[language_code]\n\n    @staticmethod\n    def _extend_tried(tried, pattern, sub_tried=None):\n        if sub_tried is None:\n            tried.append([pattern])\n        else:\n            tried.extend([pattern, *t] for t in sub_tried)\n\n    @staticmethod\n    def _join_route(route1, route2):\n        \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n        if not route1:\n            return route2\n        if route2.startswith(\"^\"):\n            route2 = route2[1:]\n        return route1 + route2\n\n    def _is_callback(self, name):\n        if not self._populated:\n            self._populate()\n        return name in self._callback_strs\n\n    def resolve(self, path):\n        path = str(path)  # path may be a reverse_lazy object\n        tried = []\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            for pattern in self.url_patterns:\n                try:\n                    sub_match = pattern.resolve(new_path)\n                except Resolver404 as e:\n                    self._extend_tried(tried, pattern, e.args[0].get(\"tried\"))\n                else:\n                    if sub_match:\n                        # Merge captured arguments in match with submatch\n                        sub_match_dict = {**kwargs, **self.default_kwargs}\n                        # Update the sub_match_dict with the kwargs from the sub_match.\n                        sub_match_dict.update(sub_match.kwargs)\n                        # If there are *any* named groups, ignore all non-named groups.\n                        # Otherwise, pass all non-named arguments as positional\n                        # arguments.\n                        sub_match_args = sub_match.args\n                        if not sub_match_dict:\n                            sub_match_args = args + sub_match.args\n                        current_route = (\n                            \"\"\n                            if isinstance(pattern, URLPattern)\n                            else str(pattern.pattern)\n                        )\n                        self._extend_tried(tried, pattern, sub_match.tried)\n                        return ResolverMatch(\n                            sub_match.func,\n                            sub_match_args,\n                            sub_match_dict,\n                            sub_match.url_name,\n                            [self.app_name] + sub_match.app_names,\n                            [self.namespace] + sub_match.namespaces,\n                            self._join_route(current_route, sub_match.route),\n                            tried,\n                            captured_kwargs=sub_match.captured_kwargs,\n                            extra_kwargs={\n                                **self.default_kwargs,\n                                **sub_match.extra_kwargs,\n                            },\n                        )\n                    tried.append([pattern])\n            raise Resolver404({\"tried\": tried, \"path\": new_path})\n        raise Resolver404({\"path\": path})\n\n    @cached_property\n    def urlconf_module(self):\n        if isinstance(self.urlconf_name, str):\n            return import_module(self.urlconf_name)\n        else:\n            return self.urlconf_name\n\n    @cached_property\n    def url_patterns(self):\n        # urlconf_module might be a valid set of patterns, so we default to it\n        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\n        try:\n            iter(patterns)\n        except TypeError as e:\n            msg = (\n                \"The included URLconf '{name}' does not appear to have \"\n                \"any patterns in it. If you see the 'urlpatterns' variable \"\n                \"with valid patterns in the file then the issue is probably \"\n                \"caused by a circular import.\"\n            )\n            raise ImproperlyConfigured(msg.format(name=self.urlconf_name)) from e\n        return patterns\n\n    def resolve_error_handler(self, view_type):\n        callback = getattr(self.urlconf_module, \"handler%s\" % view_type, None)\n        if not callback:\n            # No handler specified in file; use lazy import, since\n            # django.conf.urls imports this file.\n            from django.conf import urls\n\n            callback = getattr(urls, \"handler%s\" % view_type)\n        return get_callable(callback)\n\n    def reverse(self, lookup_view, *args, **kwargs):\n        return self._reverse_with_prefix(lookup_view, \"\", *args, **kwargs)\n\n    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n        if args and kwargs:\n            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")\n\n        if not self._populated:\n            self._populate()\n\n        possibilities = self.reverse_dict.getlist(lookup_view)\n\n        for possibility, pattern, defaults, converters in possibilities:\n            for result, params in possibility:\n                if args:\n                    if len(args) != len(params):\n                        continue\n                    candidate_subs = dict(zip(params, args))\n                else:\n                    if set(kwargs).symmetric_difference(params).difference(defaults):\n                        continue\n                    matches = True\n                    for k, v in defaults.items():\n                        if k in params:\n                            continue\n                        if kwargs.get(k, v) != v:\n                            matches = False\n                            break\n                    if not matches:\n                        continue\n                    candidate_subs = kwargs\n                # Convert the candidate subs to text using Converter.to_url().\n                text_candidate_subs = {}\n                match = True\n                for k, v in candidate_subs.items():\n                    if k in converters:\n                        try:\n                            text_candidate_subs[k] = converters[k].to_url(v)\n                        except ValueError:\n                            match = False\n                            break\n                    else:\n                        text_candidate_subs[k] = str(v)\n                if not match:\n                    continue\n                # WSGI provides decoded URLs, without %xx escapes, and the URL\n                # resolver operates on such URLs. First substitute arguments\n                # without quoting to build a decoded URL and look for a match.\n                # Then, if we have a match, redo the substitution with quoted\n                # arguments in order to return a properly encoded URL.\n                candidate_pat = _prefix.replace(\"%\", \"%%\") + result\n                if re.search(\n                    \"^%s%s\" % (re.escape(_prefix), pattern),\n                    candidate_pat % text_candidate_subs,\n                ):\n                    # safe characters from `pchar` definition of RFC 3986\n                    url = quote(\n                        candidate_pat % text_candidate_subs,\n                        safe=RFC3986_SUBDELIMS + \"/~:@\",\n                    )\n                    # Don't allow construction of scheme relative urls.\n                    return escape_leading_slashes(url)\n        # lookup_view can be URL name or callable, but callables are not\n        # friendly in error messages.\n        m = getattr(lookup_view, \"__module__\", None)\n        n = getattr(lookup_view, \"__name__\", None)\n        if m is not None and n is not None:\n            lookup_view_s = \"%s.%s\" % (m, n)\n        else:\n            lookup_view_s = lookup_view\n\n        patterns = [pattern for (_, pattern, _, _) in possibilities]\n        if patterns:\n            if args:\n                arg_msg = \"arguments '%s'\" % (args,)\n            elif kwargs:\n                arg_msg = \"keyword arguments '%s'\" % kwargs\n            else:\n                arg_msg = \"no arguments\"\n            msg = \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" % (\n                lookup_view_s,\n                arg_msg,\n                len(patterns),\n                patterns,\n            )\n        else:\n            msg = (\n                \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n                \"a valid view function or pattern name.\" % {\"view\": lookup_view_s}\n            )\n        raise NoReverseMatch(msg)\n"
  },
  {
    "patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 2bcd549f34..7a0dd688f7 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -575,7 +575,9 @@ class FileResponse(StreamingHttpResponse):\n             disposition = \"attachment\" if self.as_attachment else \"inline\"\n             try:\n                 filename.encode(\"ascii\")\n-                file_expr = 'filename=\"{}\"'.format(filename)\n+                file_expr = 'filename=\"{}\"'.format(\n+                    filename.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', r\"\\\"\")\n+                )\n             except UnicodeEncodeError:\n                 file_expr = \"filename*=utf-8''{}\".format(quote(filename))\n             self.headers[\"Content-Disposition\"] = \"{}; {}\".format(\n",
    "commit_message": "Fixed CVE-2022-36359 -- Escaped filename in Content-Disposition header.\n\nThanks to Motoyasu Saburi for the report.\n\n",
    "code_before": "import datetime\nimport io\nimport json\nimport mimetypes\nimport os\nimport re\nimport sys\nimport time\nfrom email.header import Header\nfrom http.client import responses\nfrom urllib.parse import quote, urlparse\n\nfrom django.conf import settings\nfrom django.core import signals, signing\nfrom django.core.exceptions import DisallowedRedirect\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.http.cookie import SimpleCookie\nfrom django.utils import timezone\nfrom django.utils.datastructures import CaseInsensitiveMapping\nfrom django.utils.encoding import iri_to_uri\nfrom django.utils.http import http_date\nfrom django.utils.regex_helper import _lazy_re_compile\n\n_charset_from_content_type_re = _lazy_re_compile(\n    r\";\\s*charset=(?P<charset>[^\\s;]+)\", re.I\n)\n\n\nclass ResponseHeaders(CaseInsensitiveMapping):\n    def __init__(self, data):\n        \"\"\"\n        Populate the initial data using __setitem__ to ensure values are\n        correctly encoded.\n        \"\"\"\n        self._store = {}\n        if data:\n            for header, value in self._unpack_items(data):\n                self[header] = value\n\n    def _convert_to_charset(self, value, charset, mime_encode=False):\n        \"\"\"\n        Convert headers key/value to ascii/latin-1 native strings.\n        `charset` must be 'ascii' or 'latin-1'. If `mime_encode` is True and\n        `value` can't be represented in the given charset, apply MIME-encoding.\n        \"\"\"\n        try:\n            if isinstance(value, str):\n                # Ensure string is valid in given charset\n                value.encode(charset)\n            elif isinstance(value, bytes):\n                # Convert bytestring using given charset\n                value = value.decode(charset)\n            else:\n                value = str(value)\n                # Ensure string is valid in given charset.\n                value.encode(charset)\n            if \"\\n\" in value or \"\\r\" in value:\n                raise BadHeaderError(\n                    f\"Header values can't contain newlines (got {value!r})\"\n                )\n        except UnicodeError as e:\n            # Encoding to a string of the specified charset failed, but we\n            # don't know what type that value was, or if it contains newlines,\n            # which we may need to check for before sending it to be\n            # encoded for multiple character sets.\n            if (isinstance(value, bytes) and (b\"\\n\" in value or b\"\\r\" in value)) or (\n                isinstance(value, str) and (\"\\n\" in value or \"\\r\" in value)\n            ):\n                raise BadHeaderError(\n                    f\"Header values can't contain newlines (got {value!r})\"\n                ) from e\n            if mime_encode:\n                value = Header(value, \"utf-8\", maxlinelen=sys.maxsize).encode()\n            else:\n                e.reason += \", HTTP response headers must be in %s format\" % charset\n                raise\n        return value\n\n    def __delitem__(self, key):\n        self.pop(key)\n\n    def __setitem__(self, key, value):\n        key = self._convert_to_charset(key, \"ascii\")\n        value = self._convert_to_charset(value, \"latin-1\", mime_encode=True)\n        self._store[key.lower()] = (key, value)\n\n    def pop(self, key, default=None):\n        return self._store.pop(key.lower(), default)\n\n    def setdefault(self, key, value):\n        if key not in self:\n            self[key] = value\n\n\nclass BadHeaderError(ValueError):\n    pass\n\n\nclass HttpResponseBase:\n    \"\"\"\n    An HTTP response base class with dictionary-accessed headers.\n\n    This class doesn't handle content. It should not be used directly.\n    Use the HttpResponse and StreamingHttpResponse subclasses instead.\n    \"\"\"\n\n    status_code = 200\n\n    def __init__(\n        self, content_type=None, status=None, reason=None, charset=None, headers=None\n    ):\n        self.headers = ResponseHeaders(headers)\n        self._charset = charset\n        if \"Content-Type\" not in self.headers:\n            if content_type is None:\n                content_type = f\"text/html; charset={self.charset}\"\n            self.headers[\"Content-Type\"] = content_type\n        elif content_type:\n            raise ValueError(\n                \"'headers' must not contain 'Content-Type' when the \"\n                \"'content_type' parameter is provided.\"\n            )\n        self._resource_closers = []\n        # This parameter is set by the handler. It's necessary to preserve the\n        # historical behavior of request_finished.\n        self._handler_class = None\n        self.cookies = SimpleCookie()\n        self.closed = False\n        if status is not None:\n            try:\n                self.status_code = int(status)\n            except (ValueError, TypeError):\n                raise TypeError(\"HTTP status code must be an integer.\")\n\n            if not 100 <= self.status_code <= 599:\n                raise ValueError(\"HTTP status code must be an integer from 100 to 599.\")\n        self._reason_phrase = reason\n\n    @property\n    def reason_phrase(self):\n        if self._reason_phrase is not None:\n            return self._reason_phrase\n        # Leave self._reason_phrase unset in order to use the default\n        # reason phrase for status code.\n        return responses.get(self.status_code, \"Unknown Status Code\")\n\n    @reason_phrase.setter\n    def reason_phrase(self, value):\n        self._reason_phrase = value\n\n    @property\n    def charset(self):\n        if self._charset is not None:\n            return self._charset\n        # The Content-Type header may not yet be set, because the charset is\n        # being inserted *into* it.\n        if content_type := self.headers.get(\"Content-Type\"):\n            if matched := _charset_from_content_type_re.search(content_type):\n                # Extract the charset and strip its double quotes.\n                # Note that having parsed it from the Content-Type, we don't\n                # store it back into the _charset for later intentionally, to\n                # allow for the Content-Type to be switched again later.\n                return matched[\"charset\"].replace('\"', \"\")\n        return settings.DEFAULT_CHARSET\n\n    @charset.setter\n    def charset(self, value):\n        self._charset = value\n\n    def serialize_headers(self):\n        \"\"\"HTTP headers as a bytestring.\"\"\"\n        return b\"\\r\\n\".join(\n            [\n                key.encode(\"ascii\") + b\": \" + value.encode(\"latin-1\")\n                for key, value in self.headers.items()\n            ]\n        )\n\n    __bytes__ = serialize_headers\n\n    @property\n    def _content_type_for_repr(self):\n        return (\n            ', \"%s\"' % self.headers[\"Content-Type\"]\n            if \"Content-Type\" in self.headers\n            else \"\"\n        )\n\n    def __setitem__(self, header, value):\n        self.headers[header] = value\n\n    def __delitem__(self, header):\n        del self.headers[header]\n\n    def __getitem__(self, header):\n        return self.headers[header]\n\n    def has_header(self, header):\n        \"\"\"Case-insensitive check for a header.\"\"\"\n        return header in self.headers\n\n    __contains__ = has_header\n\n    def items(self):\n        return self.headers.items()\n\n    def get(self, header, alternate=None):\n        return self.headers.get(header, alternate)\n\n    def set_cookie(\n        self,\n        key,\n        value=\"\",\n        max_age=None,\n        expires=None,\n        path=\"/\",\n        domain=None,\n        secure=False,\n        httponly=False,\n        samesite=None,\n    ):\n        \"\"\"\n        Set a cookie.\n\n        ``expires`` can be:\n        - a string in the correct format,\n        - a naive ``datetime.datetime`` object in UTC,\n        - an aware ``datetime.datetime`` object in any time zone.\n        If it is a ``datetime.datetime`` object then calculate ``max_age``.\n\n        ``max_age`` can be:\n        - int/float specifying seconds,\n        - ``datetime.timedelta`` object.\n        \"\"\"\n        self.cookies[key] = value\n        if expires is not None:\n            if isinstance(expires, datetime.datetime):\n                if timezone.is_naive(expires):\n                    expires = timezone.make_aware(expires, datetime.timezone.utc)\n                delta = expires - datetime.datetime.now(tz=datetime.timezone.utc)\n                # Add one second so the date matches exactly (a fraction of\n                # time gets lost between converting to a timedelta and\n                # then the date string).\n                delta = delta + datetime.timedelta(seconds=1)\n                # Just set max_age - the max_age logic will set expires.\n                expires = None\n                if max_age is not None:\n                    raise ValueError(\"'expires' and 'max_age' can't be used together.\")\n                max_age = max(0, delta.days * 86400 + delta.seconds)\n            else:\n                self.cookies[key][\"expires\"] = expires\n        else:\n            self.cookies[key][\"expires\"] = \"\"\n        if max_age is not None:\n            if isinstance(max_age, datetime.timedelta):\n                max_age = max_age.total_seconds()\n            self.cookies[key][\"max-age\"] = int(max_age)\n            # IE requires expires, so set it if hasn't been already.\n            if not expires:\n                self.cookies[key][\"expires\"] = http_date(time.time() + max_age)\n        if path is not None:\n            self.cookies[key][\"path\"] = path\n        if domain is not None:\n            self.cookies[key][\"domain\"] = domain\n        if secure:\n            self.cookies[key][\"secure\"] = True\n        if httponly:\n            self.cookies[key][\"httponly\"] = True\n        if samesite:\n            if samesite.lower() not in (\"lax\", \"none\", \"strict\"):\n                raise ValueError('samesite must be \"lax\", \"none\", or \"strict\".')\n            self.cookies[key][\"samesite\"] = samesite\n\n    def setdefault(self, key, value):\n        \"\"\"Set a header unless it has already been set.\"\"\"\n        self.headers.setdefault(key, value)\n\n    def set_signed_cookie(self, key, value, salt=\"\", **kwargs):\n        value = signing.get_cookie_signer(salt=key + salt).sign(value)\n        return self.set_cookie(key, value, **kwargs)\n\n    def delete_cookie(self, key, path=\"/\", domain=None, samesite=None):\n        # Browsers can ignore the Set-Cookie header if the cookie doesn't use\n        # the secure flag and:\n        # - the cookie name starts with \"__Host-\" or \"__Secure-\", or\n        # - the samesite is \"none\".\n        secure = key.startswith((\"__Secure-\", \"__Host-\")) or (\n            samesite and samesite.lower() == \"none\"\n        )\n        self.set_cookie(\n            key,\n            max_age=0,\n            path=path,\n            domain=domain,\n            secure=secure,\n            expires=\"Thu, 01 Jan 1970 00:00:00 GMT\",\n            samesite=samesite,\n        )\n\n    # Common methods used by subclasses\n\n    def make_bytes(self, value):\n        \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n        # Per PEP 3333, this response body must be bytes. To avoid returning\n        # an instance of a subclass, this function returns `bytes(value)`.\n        # This doesn't make a copy when `value` already contains bytes.\n\n        # Handle string types -- we can't rely on force_bytes here because:\n        # - Python attempts str conversion first\n        # - when self._charset != 'utf-8' it re-encodes the content\n        if isinstance(value, (bytes, memoryview)):\n            return bytes(value)\n        if isinstance(value, str):\n            return bytes(value.encode(self.charset))\n        # Handle non-string types.\n        return str(value).encode(self.charset)\n\n    # These methods partially implement the file-like object interface.\n    # See https://docs.python.org/library/io.html#io.IOBase\n\n    # The WSGI server must call this method upon completion of the request.\n    # See http://blog.dscpl.com.au/2012/10/obligations-for-calling-close-on.html\n    def close(self):\n        for closer in self._resource_closers:\n            try:\n                closer()\n            except Exception:\n                pass\n        # Free resources that were still referenced.\n        self._resource_closers.clear()\n        self.closed = True\n        signals.request_finished.send(sender=self._handler_class)\n\n    def write(self, content):\n        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n\n    def flush(self):\n        pass\n\n    def tell(self):\n        raise OSError(\n            \"This %s instance cannot tell its position\" % self.__class__.__name__\n        )\n\n    # These methods partially implement a stream-like object interface.\n    # See https://docs.python.org/library/io.html#io.IOBase\n\n    def readable(self):\n        return False\n\n    def seekable(self):\n        return False\n\n    def writable(self):\n        return False\n\n    def writelines(self, lines):\n        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n\n\nclass HttpResponse(HttpResponseBase):\n    \"\"\"\n    An HTTP response class with a string as content.\n\n    This content can be read, appended to, or replaced.\n    \"\"\"\n\n    streaming = False\n    non_picklable_attrs = frozenset(\n        [\n            \"resolver_match\",\n            # Non-picklable attributes added by test clients.\n            \"asgi_request\",\n            \"client\",\n            \"context\",\n            \"json\",\n            \"templates\",\n            \"wsgi_request\",\n        ]\n    )\n\n    def __init__(self, content=b\"\", *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Content is a bytestring. See the `content` property methods.\n        self.content = content\n\n    def __getstate__(self):\n        obj_dict = self.__dict__.copy()\n        for attr in self.non_picklable_attrs:\n            if attr in obj_dict:\n                del obj_dict[attr]\n        return obj_dict\n\n    def __repr__(self):\n        return \"<%(cls)s status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__name__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n        }\n\n    def serialize(self):\n        \"\"\"Full HTTP message, including headers, as a bytestring.\"\"\"\n        return self.serialize_headers() + b\"\\r\\n\\r\\n\" + self.content\n\n    __bytes__ = serialize\n\n    @property\n    def content(self):\n        return b\"\".join(self._container)\n\n    @content.setter\n    def content(self, value):\n        # Consume iterators upon assignment to allow repeated iteration.\n        if hasattr(value, \"__iter__\") and not isinstance(\n            value, (bytes, memoryview, str)\n        ):\n            content = b\"\".join(self.make_bytes(chunk) for chunk in value)\n            if hasattr(value, \"close\"):\n                try:\n                    value.close()\n                except Exception:\n                    pass\n        else:\n            content = self.make_bytes(value)\n        # Create a list of properly encoded bytestrings to support write().\n        self._container = [content]\n\n    def __iter__(self):\n        return iter(self._container)\n\n    def write(self, content):\n        self._container.append(self.make_bytes(content))\n\n    def tell(self):\n        return len(self.content)\n\n    def getvalue(self):\n        return self.content\n\n    def writable(self):\n        return True\n\n    def writelines(self, lines):\n        for line in lines:\n            self.write(line)\n\n\nclass StreamingHttpResponse(HttpResponseBase):\n    \"\"\"\n    A streaming HTTP response class with an iterator as content.\n\n    This should only be iterated once, when the response is streamed to the\n    client. However, it can be appended to or replaced with a new iterator\n    that wraps the original content (or yields entirely new content).\n    \"\"\"\n\n    streaming = True\n\n    def __init__(self, streaming_content=(), *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # `streaming_content` should be an iterable of bytestrings.\n        # See the `streaming_content` property methods.\n        self.streaming_content = streaming_content\n\n    def __repr__(self):\n        return \"<%(cls)s status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__qualname__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n        }\n\n    @property\n    def content(self):\n        raise AttributeError(\n            \"This %s instance has no `content` attribute. Use \"\n            \"`streaming_content` instead.\" % self.__class__.__name__\n        )\n\n    @property\n    def streaming_content(self):\n        return map(self.make_bytes, self._iterator)\n\n    @streaming_content.setter\n    def streaming_content(self, value):\n        self._set_streaming_content(value)\n\n    def _set_streaming_content(self, value):\n        # Ensure we can never iterate on \"value\" more than once.\n        self._iterator = iter(value)\n        if hasattr(value, \"close\"):\n            self._resource_closers.append(value.close)\n\n    def __iter__(self):\n        return self.streaming_content\n\n    def getvalue(self):\n        return b\"\".join(self.streaming_content)\n\n\nclass FileResponse(StreamingHttpResponse):\n    \"\"\"\n    A streaming HTTP response class optimized for files.\n    \"\"\"\n\n    block_size = 4096\n\n    def __init__(self, *args, as_attachment=False, filename=\"\", **kwargs):\n        self.as_attachment = as_attachment\n        self.filename = filename\n        self._no_explicit_content_type = (\n            \"content_type\" not in kwargs or kwargs[\"content_type\"] is None\n        )\n        super().__init__(*args, **kwargs)\n\n    def _set_streaming_content(self, value):\n        if not hasattr(value, \"read\"):\n            self.file_to_stream = None\n            return super()._set_streaming_content(value)\n\n        self.file_to_stream = filelike = value\n        if hasattr(filelike, \"close\"):\n            self._resource_closers.append(filelike.close)\n        value = iter(lambda: filelike.read(self.block_size), b\"\")\n        self.set_headers(filelike)\n        super()._set_streaming_content(value)\n\n    def set_headers(self, filelike):\n        \"\"\"\n        Set some common response headers (Content-Length, Content-Type, and\n        Content-Disposition) based on the `filelike` response content.\n        \"\"\"\n        filename = getattr(filelike, \"name\", \"\")\n        filename = filename if isinstance(filename, str) else \"\"\n        seekable = hasattr(filelike, \"seek\") and (\n            not hasattr(filelike, \"seekable\") or filelike.seekable()\n        )\n        if hasattr(filelike, \"tell\"):\n            if seekable:\n                initial_position = filelike.tell()\n                filelike.seek(0, io.SEEK_END)\n                self.headers[\"Content-Length\"] = filelike.tell() - initial_position\n                filelike.seek(initial_position)\n            elif hasattr(filelike, \"getbuffer\"):\n                self.headers[\"Content-Length\"] = (\n                    filelike.getbuffer().nbytes - filelike.tell()\n                )\n            elif os.path.exists(filename):\n                self.headers[\"Content-Length\"] = (\n                    os.path.getsize(filename) - filelike.tell()\n                )\n        elif seekable:\n            self.headers[\"Content-Length\"] = sum(\n                iter(lambda: len(filelike.read(self.block_size)), 0)\n            )\n            filelike.seek(-int(self.headers[\"Content-Length\"]), io.SEEK_END)\n\n        filename = os.path.basename(self.filename or filename)\n        if self._no_explicit_content_type:\n            if filename:\n                content_type, encoding = mimetypes.guess_type(filename)\n                # Encoding isn't set to prevent browsers from automatically\n                # uncompressing files.\n                content_type = {\n                    \"bzip2\": \"application/x-bzip\",\n                    \"gzip\": \"application/gzip\",\n                    \"xz\": \"application/x-xz\",\n                }.get(encoding, content_type)\n                self.headers[\"Content-Type\"] = (\n                    content_type or \"application/octet-stream\"\n                )\n            else:\n                self.headers[\"Content-Type\"] = \"application/octet-stream\"\n\n        if filename:\n            disposition = \"attachment\" if self.as_attachment else \"inline\"\n            try:\n                filename.encode(\"ascii\")\n                file_expr = 'filename=\"{}\"'.format(filename)\n            except UnicodeEncodeError:\n                file_expr = \"filename*=utf-8''{}\".format(quote(filename))\n            self.headers[\"Content-Disposition\"] = \"{}; {}\".format(\n                disposition, file_expr\n            )\n        elif self.as_attachment:\n            self.headers[\"Content-Disposition\"] = \"attachment\"\n\n\nclass HttpResponseRedirectBase(HttpResponse):\n    allowed_schemes = [\"http\", \"https\", \"ftp\"]\n\n    def __init__(self, redirect_to, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self[\"Location\"] = iri_to_uri(redirect_to)\n        parsed = urlparse(str(redirect_to))\n        if parsed.scheme and parsed.scheme not in self.allowed_schemes:\n            raise DisallowedRedirect(\n                \"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme\n            )\n\n    url = property(lambda self: self[\"Location\"])\n\n    def __repr__(self):\n        return (\n            '<%(cls)s status_code=%(status_code)d%(content_type)s, url=\"%(url)s\">'\n            % {\n                \"cls\": self.__class__.__name__,\n                \"status_code\": self.status_code,\n                \"content_type\": self._content_type_for_repr,\n                \"url\": self.url,\n            }\n        )\n\n\nclass HttpResponseRedirect(HttpResponseRedirectBase):\n    status_code = 302\n\n\nclass HttpResponsePermanentRedirect(HttpResponseRedirectBase):\n    status_code = 301\n\n\nclass HttpResponseNotModified(HttpResponse):\n    status_code = 304\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        del self[\"content-type\"]\n\n    @HttpResponse.content.setter\n    def content(self, value):\n        if value:\n            raise AttributeError(\n                \"You cannot set content to a 304 (Not Modified) response\"\n            )\n        self._container = []\n\n\nclass HttpResponseBadRequest(HttpResponse):\n    status_code = 400\n\n\nclass HttpResponseNotFound(HttpResponse):\n    status_code = 404\n\n\nclass HttpResponseForbidden(HttpResponse):\n    status_code = 403\n\n\nclass HttpResponseNotAllowed(HttpResponse):\n    status_code = 405\n\n    def __init__(self, permitted_methods, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self[\"Allow\"] = \", \".join(permitted_methods)\n\n    def __repr__(self):\n        return \"<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__name__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n            \"methods\": self[\"Allow\"],\n        }\n\n\nclass HttpResponseGone(HttpResponse):\n    status_code = 410\n\n\nclass HttpResponseServerError(HttpResponse):\n    status_code = 500\n\n\nclass Http404(Exception):\n    pass\n\n\nclass JsonResponse(HttpResponse):\n    \"\"\"\n    An HTTP response class that consumes data to be serialized to JSON.\n\n    :param data: Data to be dumped into json. By default only ``dict`` objects\n      are allowed to be passed due to a security flaw before ECMAScript 5. See\n      the ``safe`` parameter for more information.\n    :param encoder: Should be a json encoder class. Defaults to\n      ``django.core.serializers.json.DjangoJSONEncoder``.\n    :param safe: Controls if only ``dict`` objects may be serialized. Defaults\n      to ``True``.\n    :param json_dumps_params: A dictionary of kwargs passed to json.dumps().\n    \"\"\"\n\n    def __init__(\n        self,\n        data,\n        encoder=DjangoJSONEncoder,\n        safe=True,\n        json_dumps_params=None,\n        **kwargs,\n    ):\n        if safe and not isinstance(data, dict):\n            raise TypeError(\n                \"In order to allow non-dict objects to be serialized set the \"\n                \"safe parameter to False.\"\n            )\n        if json_dumps_params is None:\n            json_dumps_params = {}\n        kwargs.setdefault(\"content_type\", \"application/json\")\n        data = json.dumps(data, cls=encoder, **json_dumps_params)\n        super().__init__(content=data, **kwargs)\n",
    "code_after": "import datetime\nimport io\nimport json\nimport mimetypes\nimport os\nimport re\nimport sys\nimport time\nfrom email.header import Header\nfrom http.client import responses\nfrom urllib.parse import quote, urlparse\n\nfrom django.conf import settings\nfrom django.core import signals, signing\nfrom django.core.exceptions import DisallowedRedirect\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.http.cookie import SimpleCookie\nfrom django.utils import timezone\nfrom django.utils.datastructures import CaseInsensitiveMapping\nfrom django.utils.encoding import iri_to_uri\nfrom django.utils.http import http_date\nfrom django.utils.regex_helper import _lazy_re_compile\n\n_charset_from_content_type_re = _lazy_re_compile(\n    r\";\\s*charset=(?P<charset>[^\\s;]+)\", re.I\n)\n\n\nclass ResponseHeaders(CaseInsensitiveMapping):\n    def __init__(self, data):\n        \"\"\"\n        Populate the initial data using __setitem__ to ensure values are\n        correctly encoded.\n        \"\"\"\n        self._store = {}\n        if data:\n            for header, value in self._unpack_items(data):\n                self[header] = value\n\n    def _convert_to_charset(self, value, charset, mime_encode=False):\n        \"\"\"\n        Convert headers key/value to ascii/latin-1 native strings.\n        `charset` must be 'ascii' or 'latin-1'. If `mime_encode` is True and\n        `value` can't be represented in the given charset, apply MIME-encoding.\n        \"\"\"\n        try:\n            if isinstance(value, str):\n                # Ensure string is valid in given charset\n                value.encode(charset)\n            elif isinstance(value, bytes):\n                # Convert bytestring using given charset\n                value = value.decode(charset)\n            else:\n                value = str(value)\n                # Ensure string is valid in given charset.\n                value.encode(charset)\n            if \"\\n\" in value or \"\\r\" in value:\n                raise BadHeaderError(\n                    f\"Header values can't contain newlines (got {value!r})\"\n                )\n        except UnicodeError as e:\n            # Encoding to a string of the specified charset failed, but we\n            # don't know what type that value was, or if it contains newlines,\n            # which we may need to check for before sending it to be\n            # encoded for multiple character sets.\n            if (isinstance(value, bytes) and (b\"\\n\" in value or b\"\\r\" in value)) or (\n                isinstance(value, str) and (\"\\n\" in value or \"\\r\" in value)\n            ):\n                raise BadHeaderError(\n                    f\"Header values can't contain newlines (got {value!r})\"\n                ) from e\n            if mime_encode:\n                value = Header(value, \"utf-8\", maxlinelen=sys.maxsize).encode()\n            else:\n                e.reason += \", HTTP response headers must be in %s format\" % charset\n                raise\n        return value\n\n    def __delitem__(self, key):\n        self.pop(key)\n\n    def __setitem__(self, key, value):\n        key = self._convert_to_charset(key, \"ascii\")\n        value = self._convert_to_charset(value, \"latin-1\", mime_encode=True)\n        self._store[key.lower()] = (key, value)\n\n    def pop(self, key, default=None):\n        return self._store.pop(key.lower(), default)\n\n    def setdefault(self, key, value):\n        if key not in self:\n            self[key] = value\n\n\nclass BadHeaderError(ValueError):\n    pass\n\n\nclass HttpResponseBase:\n    \"\"\"\n    An HTTP response base class with dictionary-accessed headers.\n\n    This class doesn't handle content. It should not be used directly.\n    Use the HttpResponse and StreamingHttpResponse subclasses instead.\n    \"\"\"\n\n    status_code = 200\n\n    def __init__(\n        self, content_type=None, status=None, reason=None, charset=None, headers=None\n    ):\n        self.headers = ResponseHeaders(headers)\n        self._charset = charset\n        if \"Content-Type\" not in self.headers:\n            if content_type is None:\n                content_type = f\"text/html; charset={self.charset}\"\n            self.headers[\"Content-Type\"] = content_type\n        elif content_type:\n            raise ValueError(\n                \"'headers' must not contain 'Content-Type' when the \"\n                \"'content_type' parameter is provided.\"\n            )\n        self._resource_closers = []\n        # This parameter is set by the handler. It's necessary to preserve the\n        # historical behavior of request_finished.\n        self._handler_class = None\n        self.cookies = SimpleCookie()\n        self.closed = False\n        if status is not None:\n            try:\n                self.status_code = int(status)\n            except (ValueError, TypeError):\n                raise TypeError(\"HTTP status code must be an integer.\")\n\n            if not 100 <= self.status_code <= 599:\n                raise ValueError(\"HTTP status code must be an integer from 100 to 599.\")\n        self._reason_phrase = reason\n\n    @property\n    def reason_phrase(self):\n        if self._reason_phrase is not None:\n            return self._reason_phrase\n        # Leave self._reason_phrase unset in order to use the default\n        # reason phrase for status code.\n        return responses.get(self.status_code, \"Unknown Status Code\")\n\n    @reason_phrase.setter\n    def reason_phrase(self, value):\n        self._reason_phrase = value\n\n    @property\n    def charset(self):\n        if self._charset is not None:\n            return self._charset\n        # The Content-Type header may not yet be set, because the charset is\n        # being inserted *into* it.\n        if content_type := self.headers.get(\"Content-Type\"):\n            if matched := _charset_from_content_type_re.search(content_type):\n                # Extract the charset and strip its double quotes.\n                # Note that having parsed it from the Content-Type, we don't\n                # store it back into the _charset for later intentionally, to\n                # allow for the Content-Type to be switched again later.\n                return matched[\"charset\"].replace('\"', \"\")\n        return settings.DEFAULT_CHARSET\n\n    @charset.setter\n    def charset(self, value):\n        self._charset = value\n\n    def serialize_headers(self):\n        \"\"\"HTTP headers as a bytestring.\"\"\"\n        return b\"\\r\\n\".join(\n            [\n                key.encode(\"ascii\") + b\": \" + value.encode(\"latin-1\")\n                for key, value in self.headers.items()\n            ]\n        )\n\n    __bytes__ = serialize_headers\n\n    @property\n    def _content_type_for_repr(self):\n        return (\n            ', \"%s\"' % self.headers[\"Content-Type\"]\n            if \"Content-Type\" in self.headers\n            else \"\"\n        )\n\n    def __setitem__(self, header, value):\n        self.headers[header] = value\n\n    def __delitem__(self, header):\n        del self.headers[header]\n\n    def __getitem__(self, header):\n        return self.headers[header]\n\n    def has_header(self, header):\n        \"\"\"Case-insensitive check for a header.\"\"\"\n        return header in self.headers\n\n    __contains__ = has_header\n\n    def items(self):\n        return self.headers.items()\n\n    def get(self, header, alternate=None):\n        return self.headers.get(header, alternate)\n\n    def set_cookie(\n        self,\n        key,\n        value=\"\",\n        max_age=None,\n        expires=None,\n        path=\"/\",\n        domain=None,\n        secure=False,\n        httponly=False,\n        samesite=None,\n    ):\n        \"\"\"\n        Set a cookie.\n\n        ``expires`` can be:\n        - a string in the correct format,\n        - a naive ``datetime.datetime`` object in UTC,\n        - an aware ``datetime.datetime`` object in any time zone.\n        If it is a ``datetime.datetime`` object then calculate ``max_age``.\n\n        ``max_age`` can be:\n        - int/float specifying seconds,\n        - ``datetime.timedelta`` object.\n        \"\"\"\n        self.cookies[key] = value\n        if expires is not None:\n            if isinstance(expires, datetime.datetime):\n                if timezone.is_naive(expires):\n                    expires = timezone.make_aware(expires, datetime.timezone.utc)\n                delta = expires - datetime.datetime.now(tz=datetime.timezone.utc)\n                # Add one second so the date matches exactly (a fraction of\n                # time gets lost between converting to a timedelta and\n                # then the date string).\n                delta = delta + datetime.timedelta(seconds=1)\n                # Just set max_age - the max_age logic will set expires.\n                expires = None\n                if max_age is not None:\n                    raise ValueError(\"'expires' and 'max_age' can't be used together.\")\n                max_age = max(0, delta.days * 86400 + delta.seconds)\n            else:\n                self.cookies[key][\"expires\"] = expires\n        else:\n            self.cookies[key][\"expires\"] = \"\"\n        if max_age is not None:\n            if isinstance(max_age, datetime.timedelta):\n                max_age = max_age.total_seconds()\n            self.cookies[key][\"max-age\"] = int(max_age)\n            # IE requires expires, so set it if hasn't been already.\n            if not expires:\n                self.cookies[key][\"expires\"] = http_date(time.time() + max_age)\n        if path is not None:\n            self.cookies[key][\"path\"] = path\n        if domain is not None:\n            self.cookies[key][\"domain\"] = domain\n        if secure:\n            self.cookies[key][\"secure\"] = True\n        if httponly:\n            self.cookies[key][\"httponly\"] = True\n        if samesite:\n            if samesite.lower() not in (\"lax\", \"none\", \"strict\"):\n                raise ValueError('samesite must be \"lax\", \"none\", or \"strict\".')\n            self.cookies[key][\"samesite\"] = samesite\n\n    def setdefault(self, key, value):\n        \"\"\"Set a header unless it has already been set.\"\"\"\n        self.headers.setdefault(key, value)\n\n    def set_signed_cookie(self, key, value, salt=\"\", **kwargs):\n        value = signing.get_cookie_signer(salt=key + salt).sign(value)\n        return self.set_cookie(key, value, **kwargs)\n\n    def delete_cookie(self, key, path=\"/\", domain=None, samesite=None):\n        # Browsers can ignore the Set-Cookie header if the cookie doesn't use\n        # the secure flag and:\n        # - the cookie name starts with \"__Host-\" or \"__Secure-\", or\n        # - the samesite is \"none\".\n        secure = key.startswith((\"__Secure-\", \"__Host-\")) or (\n            samesite and samesite.lower() == \"none\"\n        )\n        self.set_cookie(\n            key,\n            max_age=0,\n            path=path,\n            domain=domain,\n            secure=secure,\n            expires=\"Thu, 01 Jan 1970 00:00:00 GMT\",\n            samesite=samesite,\n        )\n\n    # Common methods used by subclasses\n\n    def make_bytes(self, value):\n        \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n        # Per PEP 3333, this response body must be bytes. To avoid returning\n        # an instance of a subclass, this function returns `bytes(value)`.\n        # This doesn't make a copy when `value` already contains bytes.\n\n        # Handle string types -- we can't rely on force_bytes here because:\n        # - Python attempts str conversion first\n        # - when self._charset != 'utf-8' it re-encodes the content\n        if isinstance(value, (bytes, memoryview)):\n            return bytes(value)\n        if isinstance(value, str):\n            return bytes(value.encode(self.charset))\n        # Handle non-string types.\n        return str(value).encode(self.charset)\n\n    # These methods partially implement the file-like object interface.\n    # See https://docs.python.org/library/io.html#io.IOBase\n\n    # The WSGI server must call this method upon completion of the request.\n    # See http://blog.dscpl.com.au/2012/10/obligations-for-calling-close-on.html\n    def close(self):\n        for closer in self._resource_closers:\n            try:\n                closer()\n            except Exception:\n                pass\n        # Free resources that were still referenced.\n        self._resource_closers.clear()\n        self.closed = True\n        signals.request_finished.send(sender=self._handler_class)\n\n    def write(self, content):\n        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n\n    def flush(self):\n        pass\n\n    def tell(self):\n        raise OSError(\n            \"This %s instance cannot tell its position\" % self.__class__.__name__\n        )\n\n    # These methods partially implement a stream-like object interface.\n    # See https://docs.python.org/library/io.html#io.IOBase\n\n    def readable(self):\n        return False\n\n    def seekable(self):\n        return False\n\n    def writable(self):\n        return False\n\n    def writelines(self, lines):\n        raise OSError(\"This %s instance is not writable\" % self.__class__.__name__)\n\n\nclass HttpResponse(HttpResponseBase):\n    \"\"\"\n    An HTTP response class with a string as content.\n\n    This content can be read, appended to, or replaced.\n    \"\"\"\n\n    streaming = False\n    non_picklable_attrs = frozenset(\n        [\n            \"resolver_match\",\n            # Non-picklable attributes added by test clients.\n            \"asgi_request\",\n            \"client\",\n            \"context\",\n            \"json\",\n            \"templates\",\n            \"wsgi_request\",\n        ]\n    )\n\n    def __init__(self, content=b\"\", *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Content is a bytestring. See the `content` property methods.\n        self.content = content\n\n    def __getstate__(self):\n        obj_dict = self.__dict__.copy()\n        for attr in self.non_picklable_attrs:\n            if attr in obj_dict:\n                del obj_dict[attr]\n        return obj_dict\n\n    def __repr__(self):\n        return \"<%(cls)s status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__name__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n        }\n\n    def serialize(self):\n        \"\"\"Full HTTP message, including headers, as a bytestring.\"\"\"\n        return self.serialize_headers() + b\"\\r\\n\\r\\n\" + self.content\n\n    __bytes__ = serialize\n\n    @property\n    def content(self):\n        return b\"\".join(self._container)\n\n    @content.setter\n    def content(self, value):\n        # Consume iterators upon assignment to allow repeated iteration.\n        if hasattr(value, \"__iter__\") and not isinstance(\n            value, (bytes, memoryview, str)\n        ):\n            content = b\"\".join(self.make_bytes(chunk) for chunk in value)\n            if hasattr(value, \"close\"):\n                try:\n                    value.close()\n                except Exception:\n                    pass\n        else:\n            content = self.make_bytes(value)\n        # Create a list of properly encoded bytestrings to support write().\n        self._container = [content]\n\n    def __iter__(self):\n        return iter(self._container)\n\n    def write(self, content):\n        self._container.append(self.make_bytes(content))\n\n    def tell(self):\n        return len(self.content)\n\n    def getvalue(self):\n        return self.content\n\n    def writable(self):\n        return True\n\n    def writelines(self, lines):\n        for line in lines:\n            self.write(line)\n\n\nclass StreamingHttpResponse(HttpResponseBase):\n    \"\"\"\n    A streaming HTTP response class with an iterator as content.\n\n    This should only be iterated once, when the response is streamed to the\n    client. However, it can be appended to or replaced with a new iterator\n    that wraps the original content (or yields entirely new content).\n    \"\"\"\n\n    streaming = True\n\n    def __init__(self, streaming_content=(), *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # `streaming_content` should be an iterable of bytestrings.\n        # See the `streaming_content` property methods.\n        self.streaming_content = streaming_content\n\n    def __repr__(self):\n        return \"<%(cls)s status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__qualname__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n        }\n\n    @property\n    def content(self):\n        raise AttributeError(\n            \"This %s instance has no `content` attribute. Use \"\n            \"`streaming_content` instead.\" % self.__class__.__name__\n        )\n\n    @property\n    def streaming_content(self):\n        return map(self.make_bytes, self._iterator)\n\n    @streaming_content.setter\n    def streaming_content(self, value):\n        self._set_streaming_content(value)\n\n    def _set_streaming_content(self, value):\n        # Ensure we can never iterate on \"value\" more than once.\n        self._iterator = iter(value)\n        if hasattr(value, \"close\"):\n            self._resource_closers.append(value.close)\n\n    def __iter__(self):\n        return self.streaming_content\n\n    def getvalue(self):\n        return b\"\".join(self.streaming_content)\n\n\nclass FileResponse(StreamingHttpResponse):\n    \"\"\"\n    A streaming HTTP response class optimized for files.\n    \"\"\"\n\n    block_size = 4096\n\n    def __init__(self, *args, as_attachment=False, filename=\"\", **kwargs):\n        self.as_attachment = as_attachment\n        self.filename = filename\n        self._no_explicit_content_type = (\n            \"content_type\" not in kwargs or kwargs[\"content_type\"] is None\n        )\n        super().__init__(*args, **kwargs)\n\n    def _set_streaming_content(self, value):\n        if not hasattr(value, \"read\"):\n            self.file_to_stream = None\n            return super()._set_streaming_content(value)\n\n        self.file_to_stream = filelike = value\n        if hasattr(filelike, \"close\"):\n            self._resource_closers.append(filelike.close)\n        value = iter(lambda: filelike.read(self.block_size), b\"\")\n        self.set_headers(filelike)\n        super()._set_streaming_content(value)\n\n    def set_headers(self, filelike):\n        \"\"\"\n        Set some common response headers (Content-Length, Content-Type, and\n        Content-Disposition) based on the `filelike` response content.\n        \"\"\"\n        filename = getattr(filelike, \"name\", \"\")\n        filename = filename if isinstance(filename, str) else \"\"\n        seekable = hasattr(filelike, \"seek\") and (\n            not hasattr(filelike, \"seekable\") or filelike.seekable()\n        )\n        if hasattr(filelike, \"tell\"):\n            if seekable:\n                initial_position = filelike.tell()\n                filelike.seek(0, io.SEEK_END)\n                self.headers[\"Content-Length\"] = filelike.tell() - initial_position\n                filelike.seek(initial_position)\n            elif hasattr(filelike, \"getbuffer\"):\n                self.headers[\"Content-Length\"] = (\n                    filelike.getbuffer().nbytes - filelike.tell()\n                )\n            elif os.path.exists(filename):\n                self.headers[\"Content-Length\"] = (\n                    os.path.getsize(filename) - filelike.tell()\n                )\n        elif seekable:\n            self.headers[\"Content-Length\"] = sum(\n                iter(lambda: len(filelike.read(self.block_size)), 0)\n            )\n            filelike.seek(-int(self.headers[\"Content-Length\"]), io.SEEK_END)\n\n        filename = os.path.basename(self.filename or filename)\n        if self._no_explicit_content_type:\n            if filename:\n                content_type, encoding = mimetypes.guess_type(filename)\n                # Encoding isn't set to prevent browsers from automatically\n                # uncompressing files.\n                content_type = {\n                    \"bzip2\": \"application/x-bzip\",\n                    \"gzip\": \"application/gzip\",\n                    \"xz\": \"application/x-xz\",\n                }.get(encoding, content_type)\n                self.headers[\"Content-Type\"] = (\n                    content_type or \"application/octet-stream\"\n                )\n            else:\n                self.headers[\"Content-Type\"] = \"application/octet-stream\"\n\n        if filename:\n            disposition = \"attachment\" if self.as_attachment else \"inline\"\n            try:\n                filename.encode(\"ascii\")\n                file_expr = 'filename=\"{}\"'.format(\n                    filename.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', r\"\\\"\")\n                )\n            except UnicodeEncodeError:\n                file_expr = \"filename*=utf-8''{}\".format(quote(filename))\n            self.headers[\"Content-Disposition\"] = \"{}; {}\".format(\n                disposition, file_expr\n            )\n        elif self.as_attachment:\n            self.headers[\"Content-Disposition\"] = \"attachment\"\n\n\nclass HttpResponseRedirectBase(HttpResponse):\n    allowed_schemes = [\"http\", \"https\", \"ftp\"]\n\n    def __init__(self, redirect_to, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self[\"Location\"] = iri_to_uri(redirect_to)\n        parsed = urlparse(str(redirect_to))\n        if parsed.scheme and parsed.scheme not in self.allowed_schemes:\n            raise DisallowedRedirect(\n                \"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme\n            )\n\n    url = property(lambda self: self[\"Location\"])\n\n    def __repr__(self):\n        return (\n            '<%(cls)s status_code=%(status_code)d%(content_type)s, url=\"%(url)s\">'\n            % {\n                \"cls\": self.__class__.__name__,\n                \"status_code\": self.status_code,\n                \"content_type\": self._content_type_for_repr,\n                \"url\": self.url,\n            }\n        )\n\n\nclass HttpResponseRedirect(HttpResponseRedirectBase):\n    status_code = 302\n\n\nclass HttpResponsePermanentRedirect(HttpResponseRedirectBase):\n    status_code = 301\n\n\nclass HttpResponseNotModified(HttpResponse):\n    status_code = 304\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        del self[\"content-type\"]\n\n    @HttpResponse.content.setter\n    def content(self, value):\n        if value:\n            raise AttributeError(\n                \"You cannot set content to a 304 (Not Modified) response\"\n            )\n        self._container = []\n\n\nclass HttpResponseBadRequest(HttpResponse):\n    status_code = 400\n\n\nclass HttpResponseNotFound(HttpResponse):\n    status_code = 404\n\n\nclass HttpResponseForbidden(HttpResponse):\n    status_code = 403\n\n\nclass HttpResponseNotAllowed(HttpResponse):\n    status_code = 405\n\n    def __init__(self, permitted_methods, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self[\"Allow\"] = \", \".join(permitted_methods)\n\n    def __repr__(self):\n        return \"<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>\" % {\n            \"cls\": self.__class__.__name__,\n            \"status_code\": self.status_code,\n            \"content_type\": self._content_type_for_repr,\n            \"methods\": self[\"Allow\"],\n        }\n\n\nclass HttpResponseGone(HttpResponse):\n    status_code = 410\n\n\nclass HttpResponseServerError(HttpResponse):\n    status_code = 500\n\n\nclass Http404(Exception):\n    pass\n\n\nclass JsonResponse(HttpResponse):\n    \"\"\"\n    An HTTP response class that consumes data to be serialized to JSON.\n\n    :param data: Data to be dumped into json. By default only ``dict`` objects\n      are allowed to be passed due to a security flaw before ECMAScript 5. See\n      the ``safe`` parameter for more information.\n    :param encoder: Should be a json encoder class. Defaults to\n      ``django.core.serializers.json.DjangoJSONEncoder``.\n    :param safe: Controls if only ``dict`` objects may be serialized. Defaults\n      to ``True``.\n    :param json_dumps_params: A dictionary of kwargs passed to json.dumps().\n    \"\"\"\n\n    def __init__(\n        self,\n        data,\n        encoder=DjangoJSONEncoder,\n        safe=True,\n        json_dumps_params=None,\n        **kwargs,\n    ):\n        if safe and not isinstance(data, dict):\n            raise TypeError(\n                \"In order to allow non-dict objects to be serialized set the \"\n                \"safe parameter to False.\"\n            )\n        if json_dumps_params is None:\n            json_dumps_params = {}\n        kwargs.setdefault(\"content_type\", \"application/json\")\n        data = json.dumps(data, cls=encoder, **json_dumps_params)\n        super().__init__(content=data, **kwargs)\n"
  },
  {
    "patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 51fdc4b149..d2ec2638b0 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -46,6 +46,10 @@ ASCTIME_DATE = _lazy_re_compile(r\"^\\w{3} %s %s %s %s$\" % (__M, __D2, __T, __Y))\n RFC3986_GENDELIMS = \":/?#[]@\"\n RFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n \n+# TODO: Remove when dropping support for PY38.\n+# Unsafe bytes to be removed per WHATWG spec.\n+_UNSAFE_URL_BYTES_TO_REMOVE = [\"\\t\", \"\\r\", \"\\n\"]\n+\n \n def urlencode(query, doseq=False):\n     \"\"\"\n@@ -278,6 +282,7 @@ def url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n     )\n \n \n+# TODO: Remove when dropping support for PY38.\n # Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\n def _urlparse(url, scheme=\"\", allow_fragments=True):\n     \"\"\"Parse a URL into 6 components:\n@@ -296,8 +301,15 @@ def _urlparse(url, scheme=\"\", allow_fragments=True):\n     return _coerce_result(result)\n \n \n-# Copied from urllib.parse.urlsplit() with\n-# https://github.com/python/cpython/pull/661 applied.\n+# TODO: Remove when dropping support for PY38.\n+def _remove_unsafe_bytes_from_url(url):\n+    for b in _UNSAFE_URL_BYTES_TO_REMOVE:\n+        url = url.replace(b, \"\")\n+    return url\n+\n+\n+# TODO: Remove when dropping support for PY38.\n+# Backport of urllib.parse.urlsplit() from Python 3.9.\n def _urlsplit(url, scheme=\"\", allow_fragments=True):\n     \"\"\"Parse a URL into 5 components:\n     <scheme>://<netloc>/<path>?<query>#<fragment>\n@@ -305,6 +317,9 @@ def _urlsplit(url, scheme=\"\", allow_fragments=True):\n     Note that we don't break the components up in smaller bits\n     (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n     url, scheme, _coerce_result = _coerce_args(url, scheme)\n+    url = _remove_unsafe_bytes_from_url(url)\n+    scheme = _remove_unsafe_bytes_from_url(scheme)\n+\n     netloc = query = fragment = \"\"\n     i = url.find(\":\")\n     if i > 0:\n",
    "commit_message": "Updated vendored _urlsplit() to strip newline and tabs.\n\nRefs Python CVE-2022-0391. Django is not affected, but others who\nincorrectly use internal function url_has_allowed_host_and_scheme()\nwith unsanitized input could be at risk.\n\n",
    "code_before": "import base64\nimport datetime\nimport re\nimport unicodedata\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\nfrom urllib.parse import (\n    ParseResult,\n    SplitResult,\n    _coerce_args,\n    _splitnetloc,\n    _splitparams,\n    scheme_chars,\n    unquote,\n)\nfrom urllib.parse import urlencode as original_urlencode\nfrom urllib.parse import uses_params\n\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.regex_helper import _lazy_re_compile\n\n# based on RFC 7232, Appendix C\nETAG_MATCH = _lazy_re_compile(\n    r\"\"\"\n    \\A(      # start of string and capture group\n    (?:W/)?  # optional weak indicator\n    \"        # opening quote\n    [^\"]*    # any sequence of non-quote characters\n    \"        # end quote\n    )\\Z      # end of string and capture group\n\"\"\",\n    re.X,\n)\n\nMONTHS = \"jan feb mar apr may jun jul aug sep oct nov dec\".split()\n__D = r\"(?P<day>[0-9]{2})\"\n__D2 = r\"(?P<day>[ 0-9][0-9])\"\n__M = r\"(?P<mon>\\w{3})\"\n__Y = r\"(?P<year>[0-9]{4})\"\n__Y2 = r\"(?P<year>[0-9]{2})\"\n__T = r\"(?P<hour>[0-9]{2}):(?P<min>[0-9]{2}):(?P<sec>[0-9]{2})\"\nRFC1123_DATE = _lazy_re_compile(r\"^\\w{3}, %s %s %s %s GMT$\" % (__D, __M, __Y, __T))\nRFC850_DATE = _lazy_re_compile(r\"^\\w{6,9}, %s-%s-%s %s GMT$\" % (__D, __M, __Y2, __T))\nASCTIME_DATE = _lazy_re_compile(r\"^\\w{3} %s %s %s %s$\" % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = \":/?#[]@\"\nRFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n\n\ndef urlencode(query, doseq=False):\n    \"\"\"\n    A version of Python's urllib.parse.urlencode() function that can operate on\n    MultiValueDict and non-string values.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, \"items\"):\n        query = query.items()\n    query_params = []\n    for key, value in query:\n        if value is None:\n            raise TypeError(\n                \"Cannot encode None for key '%s' in a query string. Did you \"\n                \"mean to pass an empty string or omit the value?\" % key\n            )\n        elif not doseq or isinstance(value, (str, bytes)):\n            query_val = value\n        else:\n            try:\n                itr = iter(value)\n            except TypeError:\n                query_val = value\n            else:\n                # Consume generators and iterators, when doseq=True, to\n                # work around https://bugs.python.org/issue31706.\n                query_val = []\n                for item in itr:\n                    if item is None:\n                        raise TypeError(\n                            \"Cannot encode None for key '%s' in a query \"\n                            \"string. Did you mean to pass an empty string or \"\n                            \"omit the value?\" % key\n                        )\n                    elif not isinstance(item, bytes):\n                        item = str(item)\n                    query_val.append(item)\n        query_params.append((key, query_val))\n    return original_urlencode(query_params, doseq)\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to match the RFC1123 date format as specified by HTTP\n    RFC7231 section 7.1.1.1.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # email.utils.parsedate() does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        tz = datetime.timezone.utc\n        year = int(m[\"year\"])\n        if year < 100:\n            current_year = datetime.datetime.now(tz=tz).year\n            current_century = current_year - (current_year % 100)\n            if year - (current_year % 100) > 50:\n                # year that appears to be more than 50 years in the future are\n                # interpreted as representing the past.\n                year += current_century - 100\n            else:\n                year += current_century\n        month = MONTHS.index(m[\"mon\"].lower()) + 1\n        day = int(m[\"day\"])\n        hour = int(m[\"hour\"])\n        min = int(m[\"min\"])\n        sec = int(m[\"sec\"])\n        result = datetime.datetime(year, month, day, hour, min, sec, tzinfo=tz)\n        return int(result.timestamp())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but return None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\n\ndef base36_to_int(s):\n    \"\"\"\n    Convert a base 36 string to an int. Raise ValueError if the input won't fit\n    into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is longer than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    return int(s, 36)\n\n\ndef int_to_base36(i):\n    \"\"\"Convert an integer to a base36 string.\"\"\"\n    char_set = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if i < 36:\n        return char_set[i]\n    b36 = \"\"\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encode a bytestring to a base64 string for use in URLs. Strip any trailing\n    equal signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b\"\\n=\").decode(\"ascii\")\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decode a base64 encoded string. Add back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = s.encode()\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b\"=\"))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parse a string of ETags given in an If-None-Match or If-Match header as\n    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags\n    should be matched.\n    \"\"\"\n    if etag_str.strip() == \"*\":\n        return [\"*\"]\n    else:\n        # Parse each ETag individually, and return any that are valid.\n        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(\",\"))\n        return [match[1] for match in etag_matches if match]\n\n\ndef quote_etag(etag_str):\n    \"\"\"\n    If the provided string is already a quoted ETag, return it. Otherwise, wrap\n    the string in quotes, making it a strong ETag.\n    \"\"\"\n    if ETAG_MATCH.match(etag_str):\n        return etag_str\n    else:\n        return '\"%s\"' % etag_str\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == \".\"\n        and (host.endswith(pattern) or host == pattern[1:])\n        or pattern == host\n    )\n\n\ndef url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n    \"\"\"\n    Return ``True`` if the url uses an allowed host and a safe scheme.\n\n    Always return ``False`` on an empty url.\n\n    If ``require_https`` is ``True``, only 'https' will be considered a valid\n    scheme, as opposed to 'http' and 'https' with the default, ``False``.\n\n    Note: \"True\" doesn't entail that a URL is \"safe\". It may still be e.g.\n    quoted incorrectly. Ensure to also use django.utils.encoding.iri_to_uri()\n    on the path component of untrusted URLs.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    if allowed_hosts is None:\n        allowed_hosts = set()\n    elif isinstance(allowed_hosts, str):\n        allowed_hosts = {allowed_hosts}\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _url_has_allowed_host_and_scheme(\n        url, allowed_hosts, require_https=require_https\n    ) and _url_has_allowed_host_and_scheme(\n        url.replace(\"\\\\\", \"/\"), allowed_hosts, require_https=require_https\n    )\n\n\n# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\ndef _urlparse(url, scheme=\"\", allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = _urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and \";\" in url:\n        url, params = _splitparams(url)\n    else:\n        params = \"\"\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\n\n# Copied from urllib.parse.urlsplit() with\n# https://github.com/python/cpython/pull/661 applied.\ndef _urlsplit(url, scheme=\"\", allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    netloc = query = fragment = \"\"\n    i = url.find(\":\")\n    if i > 0:\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            scheme, url = url[:i].lower(), url[i + 1 :]\n\n    if url[:2] == \"//\":\n        netloc, url = _splitnetloc(url, 2)\n        if (\"[\" in netloc and \"]\" not in netloc) or (\n            \"]\" in netloc and \"[\" not in netloc\n        ):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and \"#\" in url:\n        url, fragment = url.split(\"#\", 1)\n    if \"?\" in url:\n        url, query = url.split(\"?\", 1)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    return _coerce_result(v)\n\n\ndef _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith(\"///\"):\n        return False\n    try:\n        url_info = _urlparse(url)\n    except ValueError:  # e.g. invalid IPv6 addresses\n        return False\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == \"C\":\n        return False\n    scheme = url_info.scheme\n    # Consider URLs without a scheme (e.g. //example.com/p) to be http.\n    if not url_info.scheme and url_info.netloc:\n        scheme = \"http\"\n    valid_schemes = [\"https\"] if require_https else [\"http\", \"https\"]\n    return (not url_info.netloc or url_info.netloc in allowed_hosts) and (\n        not scheme or scheme in valid_schemes\n    )\n\n\ndef escape_leading_slashes(url):\n    \"\"\"\n    If redirecting to an absolute path (two leading slashes), a slash must be\n    escaped to prevent browsers from handling the path as schemaless and\n    redirecting to another host.\n    \"\"\"\n    if url.startswith(\"//\"):\n        url = \"/%2F{}\".format(url[2:])\n    return url\n\n\ndef _parseparam(s):\n    while s[:1] == \";\":\n        s = s[1:]\n        end = s.find(\";\")\n        while end > 0 and (s.count('\"', 0, end) - s.count('\\\\\"', 0, end)) % 2:\n            end = s.find(\";\", end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]\n\n\ndef parse_header_parameters(line):\n    \"\"\"\n    Parse a Content-type like header.\n    Return the main content-type and a dictionary of options.\n    \"\"\"\n    parts = _parseparam(\";\" + line)\n    key = parts.__next__().lower()\n    pdict = {}\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower()\n            if name.endswith(\"*\"):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # https://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1 :].strip()\n            if len(value) >= 2 and value[0] == value[-1] == '\"':\n                value = value[1:-1]\n                value = value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n            if has_encoding:\n                encoding, lang, value = value.split(\"'\")\n                value = unquote(value, encoding=encoding)\n            pdict[name] = value\n    return key, pdict\n",
    "code_after": "import base64\nimport datetime\nimport re\nimport unicodedata\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\nfrom urllib.parse import (\n    ParseResult,\n    SplitResult,\n    _coerce_args,\n    _splitnetloc,\n    _splitparams,\n    scheme_chars,\n    unquote,\n)\nfrom urllib.parse import urlencode as original_urlencode\nfrom urllib.parse import uses_params\n\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.regex_helper import _lazy_re_compile\n\n# based on RFC 7232, Appendix C\nETAG_MATCH = _lazy_re_compile(\n    r\"\"\"\n    \\A(      # start of string and capture group\n    (?:W/)?  # optional weak indicator\n    \"        # opening quote\n    [^\"]*    # any sequence of non-quote characters\n    \"        # end quote\n    )\\Z      # end of string and capture group\n\"\"\",\n    re.X,\n)\n\nMONTHS = \"jan feb mar apr may jun jul aug sep oct nov dec\".split()\n__D = r\"(?P<day>[0-9]{2})\"\n__D2 = r\"(?P<day>[ 0-9][0-9])\"\n__M = r\"(?P<mon>\\w{3})\"\n__Y = r\"(?P<year>[0-9]{4})\"\n__Y2 = r\"(?P<year>[0-9]{2})\"\n__T = r\"(?P<hour>[0-9]{2}):(?P<min>[0-9]{2}):(?P<sec>[0-9]{2})\"\nRFC1123_DATE = _lazy_re_compile(r\"^\\w{3}, %s %s %s %s GMT$\" % (__D, __M, __Y, __T))\nRFC850_DATE = _lazy_re_compile(r\"^\\w{6,9}, %s-%s-%s %s GMT$\" % (__D, __M, __Y2, __T))\nASCTIME_DATE = _lazy_re_compile(r\"^\\w{3} %s %s %s %s$\" % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = \":/?#[]@\"\nRFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n\n# TODO: Remove when dropping support for PY38.\n# Unsafe bytes to be removed per WHATWG spec.\n_UNSAFE_URL_BYTES_TO_REMOVE = [\"\\t\", \"\\r\", \"\\n\"]\n\n\ndef urlencode(query, doseq=False):\n    \"\"\"\n    A version of Python's urllib.parse.urlencode() function that can operate on\n    MultiValueDict and non-string values.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, \"items\"):\n        query = query.items()\n    query_params = []\n    for key, value in query:\n        if value is None:\n            raise TypeError(\n                \"Cannot encode None for key '%s' in a query string. Did you \"\n                \"mean to pass an empty string or omit the value?\" % key\n            )\n        elif not doseq or isinstance(value, (str, bytes)):\n            query_val = value\n        else:\n            try:\n                itr = iter(value)\n            except TypeError:\n                query_val = value\n            else:\n                # Consume generators and iterators, when doseq=True, to\n                # work around https://bugs.python.org/issue31706.\n                query_val = []\n                for item in itr:\n                    if item is None:\n                        raise TypeError(\n                            \"Cannot encode None for key '%s' in a query \"\n                            \"string. Did you mean to pass an empty string or \"\n                            \"omit the value?\" % key\n                        )\n                    elif not isinstance(item, bytes):\n                        item = str(item)\n                    query_val.append(item)\n        query_params.append((key, query_val))\n    return original_urlencode(query_params, doseq)\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to match the RFC1123 date format as specified by HTTP\n    RFC7231 section 7.1.1.1.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # email.utils.parsedate() does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        tz = datetime.timezone.utc\n        year = int(m[\"year\"])\n        if year < 100:\n            current_year = datetime.datetime.now(tz=tz).year\n            current_century = current_year - (current_year % 100)\n            if year - (current_year % 100) > 50:\n                # year that appears to be more than 50 years in the future are\n                # interpreted as representing the past.\n                year += current_century - 100\n            else:\n                year += current_century\n        month = MONTHS.index(m[\"mon\"].lower()) + 1\n        day = int(m[\"day\"])\n        hour = int(m[\"hour\"])\n        min = int(m[\"min\"])\n        sec = int(m[\"sec\"])\n        result = datetime.datetime(year, month, day, hour, min, sec, tzinfo=tz)\n        return int(result.timestamp())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but return None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\n\ndef base36_to_int(s):\n    \"\"\"\n    Convert a base 36 string to an int. Raise ValueError if the input won't fit\n    into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is longer than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    return int(s, 36)\n\n\ndef int_to_base36(i):\n    \"\"\"Convert an integer to a base36 string.\"\"\"\n    char_set = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if i < 36:\n        return char_set[i]\n    b36 = \"\"\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encode a bytestring to a base64 string for use in URLs. Strip any trailing\n    equal signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b\"\\n=\").decode(\"ascii\")\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decode a base64 encoded string. Add back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = s.encode()\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b\"=\"))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parse a string of ETags given in an If-None-Match or If-Match header as\n    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags\n    should be matched.\n    \"\"\"\n    if etag_str.strip() == \"*\":\n        return [\"*\"]\n    else:\n        # Parse each ETag individually, and return any that are valid.\n        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(\",\"))\n        return [match[1] for match in etag_matches if match]\n\n\ndef quote_etag(etag_str):\n    \"\"\"\n    If the provided string is already a quoted ETag, return it. Otherwise, wrap\n    the string in quotes, making it a strong ETag.\n    \"\"\"\n    if ETAG_MATCH.match(etag_str):\n        return etag_str\n    else:\n        return '\"%s\"' % etag_str\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == \".\"\n        and (host.endswith(pattern) or host == pattern[1:])\n        or pattern == host\n    )\n\n\ndef url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n    \"\"\"\n    Return ``True`` if the url uses an allowed host and a safe scheme.\n\n    Always return ``False`` on an empty url.\n\n    If ``require_https`` is ``True``, only 'https' will be considered a valid\n    scheme, as opposed to 'http' and 'https' with the default, ``False``.\n\n    Note: \"True\" doesn't entail that a URL is \"safe\". It may still be e.g.\n    quoted incorrectly. Ensure to also use django.utils.encoding.iri_to_uri()\n    on the path component of untrusted URLs.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    if allowed_hosts is None:\n        allowed_hosts = set()\n    elif isinstance(allowed_hosts, str):\n        allowed_hosts = {allowed_hosts}\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _url_has_allowed_host_and_scheme(\n        url, allowed_hosts, require_https=require_https\n    ) and _url_has_allowed_host_and_scheme(\n        url.replace(\"\\\\\", \"/\"), allowed_hosts, require_https=require_https\n    )\n\n\n# TODO: Remove when dropping support for PY38.\n# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\ndef _urlparse(url, scheme=\"\", allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = _urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and \";\" in url:\n        url, params = _splitparams(url)\n    else:\n        params = \"\"\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\n\n# TODO: Remove when dropping support for PY38.\ndef _remove_unsafe_bytes_from_url(url):\n    for b in _UNSAFE_URL_BYTES_TO_REMOVE:\n        url = url.replace(b, \"\")\n    return url\n\n\n# TODO: Remove when dropping support for PY38.\n# Backport of urllib.parse.urlsplit() from Python 3.9.\ndef _urlsplit(url, scheme=\"\", allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    url = _remove_unsafe_bytes_from_url(url)\n    scheme = _remove_unsafe_bytes_from_url(scheme)\n\n    netloc = query = fragment = \"\"\n    i = url.find(\":\")\n    if i > 0:\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            scheme, url = url[:i].lower(), url[i + 1 :]\n\n    if url[:2] == \"//\":\n        netloc, url = _splitnetloc(url, 2)\n        if (\"[\" in netloc and \"]\" not in netloc) or (\n            \"]\" in netloc and \"[\" not in netloc\n        ):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and \"#\" in url:\n        url, fragment = url.split(\"#\", 1)\n    if \"?\" in url:\n        url, query = url.split(\"?\", 1)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    return _coerce_result(v)\n\n\ndef _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith(\"///\"):\n        return False\n    try:\n        url_info = _urlparse(url)\n    except ValueError:  # e.g. invalid IPv6 addresses\n        return False\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == \"C\":\n        return False\n    scheme = url_info.scheme\n    # Consider URLs without a scheme (e.g. //example.com/p) to be http.\n    if not url_info.scheme and url_info.netloc:\n        scheme = \"http\"\n    valid_schemes = [\"https\"] if require_https else [\"http\", \"https\"]\n    return (not url_info.netloc or url_info.netloc in allowed_hosts) and (\n        not scheme or scheme in valid_schemes\n    )\n\n\ndef escape_leading_slashes(url):\n    \"\"\"\n    If redirecting to an absolute path (two leading slashes), a slash must be\n    escaped to prevent browsers from handling the path as schemaless and\n    redirecting to another host.\n    \"\"\"\n    if url.startswith(\"//\"):\n        url = \"/%2F{}\".format(url[2:])\n    return url\n\n\ndef _parseparam(s):\n    while s[:1] == \";\":\n        s = s[1:]\n        end = s.find(\";\")\n        while end > 0 and (s.count('\"', 0, end) - s.count('\\\\\"', 0, end)) % 2:\n            end = s.find(\";\", end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]\n\n\ndef parse_header_parameters(line):\n    \"\"\"\n    Parse a Content-type like header.\n    Return the main content-type and a dictionary of options.\n    \"\"\"\n    parts = _parseparam(\";\" + line)\n    key = parts.__next__().lower()\n    pdict = {}\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower()\n            if name.endswith(\"*\"):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # https://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1 :].strip()\n            if len(value) >= 2 and value[0] == value[-1] == '\"':\n                value = value[1:-1]\n                value = value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n            if has_encoding:\n                encoding, lang, value = value.split(\"'\")\n                value = unquote(value, encoding=encoding)\n            pdict[name] = value\n    return key, pdict\n"
  },
  {
    "patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex c07a4b342a..894aa7db4a 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -40,10 +40,15 @@ from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\n from django.db.models.sql.datastructures import BaseTable, Empty, Join, MultiJoin\n from django.db.models.sql.where import AND, OR, ExtraWhere, NothingNode, WhereNode\n from django.utils.functional import cached_property\n+from django.utils.regex_helper import _lazy_re_compile\n from django.utils.tree import Node\n \n __all__ = [\"Query\", \"RawQuery\"]\n \n+# Quotation marks ('\"`[]), whitespace characters, semicolons, or inline\n+# SQL comments are forbidden in column aliases.\n+FORBIDDEN_ALIAS_PATTERN = _lazy_re_compile(r\"['`\\\"\\]\\[;\\s]|--|/\\*|\\*/\")\n+\n \n def get_field_names_from_opts(opts):\n     if opts is None:\n@@ -1091,8 +1096,16 @@ class Query(BaseExpression):\n             alias = seen[int_model] = join_info.joins[-1]\n         return alias or seen[None]\n \n+    def check_alias(self, alias):\n+        if FORBIDDEN_ALIAS_PATTERN.search(alias):\n+            raise ValueError(\n+                \"Column aliases cannot contain whitespace characters, quotation marks, \"\n+                \"semicolons, or SQL comments.\"\n+            )\n+\n     def add_annotation(self, annotation, alias, is_summary=False, select=True):\n         \"\"\"Add a single annotation expression to the Query.\"\"\"\n+        self.check_alias(alias)\n         annotation = annotation.resolve_expression(\n             self, allow_joins=True, reuse=None, summarize=is_summary\n         )\n@@ -2269,6 +2282,7 @@ class Query(BaseExpression):\n             else:\n                 param_iter = iter([])\n             for name, entry in select.items():\n+                self.check_alias(name)\n                 entry = str(entry)\n                 entry_params = []\n                 pos = entry.find(\"%s\")\n",
    "commit_message": "Fixed CVE-2022-28346 -- Protected QuerySet.annotate(), aggregate(), and extra() against SQL injection in column aliases.\n\nThanks Splunk team: Preston Elder, Jacob Davis, Jacob Moore,\nMatt Hanson, David Briggs, and a security researcher: Danylo Dmytriiev\n(DDV_UA) for the report.\n\n",
    "code_before": "\"\"\"\nCreate SQL statements for QuerySets.\n\nThe code in here encapsulates all of the SQL construction so that QuerySets\nthemselves do not have to (and could be backed by things other than SQL\ndatabases). The abstraction barrier only works one way: this module has to know\nall about the internals of models in order to get the information it needs.\n\"\"\"\nimport copy\nimport difflib\nimport functools\nimport sys\nfrom collections import Counter, namedtuple\nfrom collections.abc import Iterator, Mapping\nfrom itertools import chain, count, product\nfrom string import ascii_uppercase\n\nfrom django.core.exceptions import FieldDoesNotExist, FieldError\nfrom django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\nfrom django.db.models.aggregates import Count\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.expressions import (\n    BaseExpression,\n    Col,\n    Exists,\n    F,\n    OuterRef,\n    Ref,\n    ResolvedOuterRef,\n)\nfrom django.db.models.fields import Field\nfrom django.db.models.fields.related_lookups import MultiColSource\nfrom django.db.models.lookups import Lookup\nfrom django.db.models.query_utils import (\n    Q,\n    check_rel_lookup_compatibility,\n    refs_expression,\n)\nfrom django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\nfrom django.db.models.sql.datastructures import BaseTable, Empty, Join, MultiJoin\nfrom django.db.models.sql.where import AND, OR, ExtraWhere, NothingNode, WhereNode\nfrom django.utils.functional import cached_property\nfrom django.utils.tree import Node\n\n__all__ = [\"Query\", \"RawQuery\"]\n\n\ndef get_field_names_from_opts(opts):\n    if opts is None:\n        return set()\n    return set(\n        chain.from_iterable(\n            (f.name, f.attname) if f.concrete else (f.name,) for f in opts.get_fields()\n        )\n    )\n\n\ndef get_children_from_q(q):\n    for child in q.children:\n        if isinstance(child, Node):\n            yield from get_children_from_q(child)\n        else:\n            yield child\n\n\nJoinInfo = namedtuple(\n    \"JoinInfo\",\n    (\"final_field\", \"targets\", \"opts\", \"joins\", \"path\", \"transform_function\"),\n)\n\n\nclass RawQuery:\n    \"\"\"A single raw SQL query.\"\"\"\n\n    def __init__(self, sql, using, params=()):\n        self.params = params\n        self.sql = sql\n        self.using = using\n        self.cursor = None\n\n        # Mirror some properties of a normal query so that\n        # the compiler can be used to process results.\n        self.low_mark, self.high_mark = 0, None  # Used for offset/limit\n        self.extra_select = {}\n        self.annotation_select = {}\n\n    def chain(self, using):\n        return self.clone(using)\n\n    def clone(self, using):\n        return RawQuery(self.sql, using, params=self.params)\n\n    def get_columns(self):\n        if self.cursor is None:\n            self._execute_query()\n        converter = connections[self.using].introspection.identifier_converter\n        return [converter(column_meta[0]) for column_meta in self.cursor.description]\n\n    def __iter__(self):\n        # Always execute a new query for a new iterator.\n        # This could be optimized with a cache at the expense of RAM.\n        self._execute_query()\n        if not connections[self.using].features.can_use_chunked_reads:\n            # If the database can't use chunked reads we need to make sure we\n            # evaluate the entire query up front.\n            result = list(self.cursor)\n        else:\n            result = self.cursor\n        return iter(result)\n\n    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self)\n\n    @property\n    def params_type(self):\n        if self.params is None:\n            return None\n        return dict if isinstance(self.params, Mapping) else tuple\n\n    def __str__(self):\n        if self.params_type is None:\n            return self.sql\n        return self.sql % self.params_type(self.params)\n\n    def _execute_query(self):\n        connection = connections[self.using]\n\n        # Adapt parameters to the database, as much as possible considering\n        # that the target type isn't known. See #17755.\n        params_type = self.params_type\n        adapter = connection.ops.adapt_unknown_value\n        if params_type is tuple:\n            params = tuple(adapter(val) for val in self.params)\n        elif params_type is dict:\n            params = {key: adapter(val) for key, val in self.params.items()}\n        elif params_type is None:\n            params = None\n        else:\n            raise RuntimeError(\"Unexpected params type: %s\" % params_type)\n\n        self.cursor = connection.cursor()\n        self.cursor.execute(self.sql, params)\n\n\nExplainInfo = namedtuple(\"ExplainInfo\", (\"format\", \"options\"))\n\n\nclass Query(BaseExpression):\n    \"\"\"A single SQL query.\"\"\"\n\n    alias_prefix = \"T\"\n    empty_result_set_value = None\n    subq_aliases = frozenset([alias_prefix])\n\n    compiler = \"SQLCompiler\"\n\n    base_table_class = BaseTable\n    join_class = Join\n\n    default_cols = True\n    default_ordering = True\n    standard_ordering = True\n\n    filter_is_sticky = False\n    subquery = False\n\n    # SQL-related attributes.\n    # Select and related select clauses are expressions to use in the SELECT\n    # clause of the query. The select is used for cases where we want to set up\n    # the select clause to contain other than default fields (values(),\n    # subqueries...). Note that annotations go to annotations dictionary.\n    select = ()\n    # The group_by attribute can have one of the following forms:\n    #  - None: no group by at all in the query\n    #  - A tuple of expressions: group by (at least) those expressions.\n    #    String refs are also allowed for now.\n    #  - True: group by all select fields of the model\n    # See compiler.get_group_by() for details.\n    group_by = None\n    order_by = ()\n    low_mark = 0  # Used for offset/limit.\n    high_mark = None  # Used for offset/limit.\n    distinct = False\n    distinct_fields = ()\n    select_for_update = False\n    select_for_update_nowait = False\n    select_for_update_skip_locked = False\n    select_for_update_of = ()\n    select_for_no_key_update = False\n    select_related = False\n    # Arbitrary limit for select_related to prevents infinite recursion.\n    max_depth = 5\n    # Holds the selects defined by a call to values() or values_list()\n    # excluding annotation_select and extra_select.\n    values_select = ()\n\n    # SQL annotation-related attributes.\n    annotation_select_mask = None\n    _annotation_select_cache = None\n\n    # Set combination attributes.\n    combinator = None\n    combinator_all = False\n    combined_queries = ()\n\n    # These are for extensions. The contents are more or less appended verbatim\n    # to the appropriate clause.\n    extra_select_mask = None\n    _extra_select_cache = None\n\n    extra_tables = ()\n    extra_order_by = ()\n\n    # A tuple that is a set of model field names and either True, if these are\n    # the fields to defer, or False if these are the only fields to load.\n    deferred_loading = (frozenset(), True)\n\n    explain_info = None\n\n    def __init__(self, model, alias_cols=True):\n        self.model = model\n        self.alias_refcount = {}\n        # alias_map is the most important data structure regarding joins.\n        # It's used for recording which joins exist in the query and what\n        # types they are. The key is the alias of the joined table (possibly\n        # the table name) and the value is a Join-like object (see\n        # sql.datastructures.Join for more information).\n        self.alias_map = {}\n        # Whether to provide alias to columns during reference resolving.\n        self.alias_cols = alias_cols\n        # Sometimes the query contains references to aliases in outer queries (as\n        # a result of split_exclude). Correct alias quoting needs to know these\n        # aliases too.\n        # Map external tables to whether they are aliased.\n        self.external_aliases = {}\n        self.table_map = {}  # Maps table names to list of aliases.\n        self.used_aliases = set()\n\n        self.where = WhereNode()\n        # Maps alias -> Annotation Expression.\n        self.annotations = {}\n        # These are for extensions. The contents are more or less appended\n        # verbatim to the appropriate clause.\n        self.extra = {}  # Maps col_alias -> (col_sql, params).\n\n        self._filtered_relations = {}\n\n    @property\n    def output_field(self):\n        if len(self.select) == 1:\n            select = self.select[0]\n            return getattr(select, \"target\", None) or select.field\n        elif len(self.annotation_select) == 1:\n            return next(iter(self.annotation_select.values())).output_field\n\n    @property\n    def has_select_fields(self):\n        return bool(\n            self.select or self.annotation_select_mask or self.extra_select_mask\n        )\n\n    @cached_property\n    def base_table(self):\n        for alias in self.alias_map:\n            return alias\n\n    def __str__(self):\n        \"\"\"\n        Return the query as a string of SQL with the parameter values\n        substituted in (use sql_with_params() to see the unsubstituted string).\n\n        Parameter values won't necessarily be quoted correctly, since that is\n        done by the database interface at execution time.\n        \"\"\"\n        sql, params = self.sql_with_params()\n        return sql % params\n\n    def sql_with_params(self):\n        \"\"\"\n        Return the query as an SQL string and the parameters that will be\n        substituted into the query.\n        \"\"\"\n        return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n\n    def __deepcopy__(self, memo):\n        \"\"\"Limit the amount of work when a Query is deepcopied.\"\"\"\n        result = self.clone()\n        memo[id(self)] = result\n        return result\n\n    def get_compiler(self, using=None, connection=None, elide_empty=True):\n        if using is None and connection is None:\n            raise ValueError(\"Need either using or connection\")\n        if using:\n            connection = connections[using]\n        return connection.ops.compiler(self.compiler)(\n            self, connection, using, elide_empty\n        )\n\n    def get_meta(self):\n        \"\"\"\n        Return the Options instance (the model._meta) from which to start\n        processing. Normally, this is self.model._meta, but it can be changed\n        by subclasses.\n        \"\"\"\n        if self.model:\n            return self.model._meta\n\n    def clone(self):\n        \"\"\"\n        Return a copy of the current Query. A lightweight alternative to\n        to deepcopy().\n        \"\"\"\n        obj = Empty()\n        obj.__class__ = self.__class__\n        # Copy references to everything.\n        obj.__dict__ = self.__dict__.copy()\n        # Clone attributes that can't use shallow copy.\n        obj.alias_refcount = self.alias_refcount.copy()\n        obj.alias_map = self.alias_map.copy()\n        obj.external_aliases = self.external_aliases.copy()\n        obj.table_map = self.table_map.copy()\n        obj.where = self.where.clone()\n        obj.annotations = self.annotations.copy()\n        if self.annotation_select_mask is not None:\n            obj.annotation_select_mask = self.annotation_select_mask.copy()\n        if self.combined_queries:\n            obj.combined_queries = tuple(\n                [query.clone() for query in self.combined_queries]\n            )\n        # _annotation_select_cache cannot be copied, as doing so breaks the\n        # (necessary) state in which both annotations and\n        # _annotation_select_cache point to the same underlying objects.\n        # It will get re-populated in the cloned queryset the next time it's\n        # used.\n        obj._annotation_select_cache = None\n        obj.extra = self.extra.copy()\n        if self.extra_select_mask is not None:\n            obj.extra_select_mask = self.extra_select_mask.copy()\n        if self._extra_select_cache is not None:\n            obj._extra_select_cache = self._extra_select_cache.copy()\n        if self.select_related is not False:\n            # Use deepcopy because select_related stores fields in nested\n            # dicts.\n            obj.select_related = copy.deepcopy(obj.select_related)\n        if \"subq_aliases\" in self.__dict__:\n            obj.subq_aliases = self.subq_aliases.copy()\n        obj.used_aliases = self.used_aliases.copy()\n        obj._filtered_relations = self._filtered_relations.copy()\n        # Clear the cached_property, if it exists.\n        obj.__dict__.pop(\"base_table\", None)\n        return obj\n\n    def chain(self, klass=None):\n        \"\"\"\n        Return a copy of the current Query that's ready for another operation.\n        The klass argument changes the type of the Query, e.g. UpdateQuery.\n        \"\"\"\n        obj = self.clone()\n        if klass and obj.__class__ != klass:\n            obj.__class__ = klass\n        if not obj.filter_is_sticky:\n            obj.used_aliases = set()\n        obj.filter_is_sticky = False\n        if hasattr(obj, \"_setup_query\"):\n            obj._setup_query()\n        return obj\n\n    def relabeled_clone(self, change_map):\n        clone = self.clone()\n        clone.change_aliases(change_map)\n        return clone\n\n    def _get_col(self, target, field, alias):\n        if not self.alias_cols:\n            alias = None\n        return target.get_col(alias, field)\n\n    def rewrite_cols(self, annotation, col_cnt):\n        # We must make sure the inner query has the referred columns in it.\n        # If we are aggregating over an annotation, then Django uses Ref()\n        # instances to note this. However, if we are annotating over a column\n        # of a related model, then it might be that column isn't part of the\n        # SELECT clause of the inner query, and we must manually make sure\n        # the column is selected. An example case is:\n        #    .aggregate(Sum('author__awards'))\n        # Resolving this expression results in a join to author, but there\n        # is no guarantee the awards column of author is in the select clause\n        # of the query. Thus we must manually add the column to the inner\n        # query.\n        orig_exprs = annotation.get_source_expressions()\n        new_exprs = []\n        for expr in orig_exprs:\n            # FIXME: These conditions are fairly arbitrary. Identify a better\n            # method of having expressions decide which code path they should\n            # take.\n            if isinstance(expr, Ref):\n                # Its already a Ref to subquery (see resolve_ref() for\n                # details)\n                new_exprs.append(expr)\n            elif isinstance(expr, (WhereNode, Lookup)):\n                # Decompose the subexpressions further. The code here is\n                # copied from the else clause, but this condition must appear\n                # before the contains_aggregate/is_summary condition below.\n                new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n                new_exprs.append(new_expr)\n            else:\n                # Reuse aliases of expressions already selected in subquery.\n                for col_alias, selected_annotation in self.annotation_select.items():\n                    if selected_annotation is expr:\n                        new_expr = Ref(col_alias, expr)\n                        break\n                else:\n                    # An expression that is not selected the subquery.\n                    if isinstance(expr, Col) or (\n                        expr.contains_aggregate and not expr.is_summary\n                    ):\n                        # Reference column or another aggregate. Select it\n                        # under a non-conflicting alias.\n                        col_cnt += 1\n                        col_alias = \"__col%d\" % col_cnt\n                        self.annotations[col_alias] = expr\n                        self.append_annotation_mask([col_alias])\n                        new_expr = Ref(col_alias, expr)\n                    else:\n                        # Some other expression not referencing database values\n                        # directly. Its subexpression might contain Cols.\n                        new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n                new_exprs.append(new_expr)\n        annotation.set_source_expressions(new_exprs)\n        return annotation, col_cnt\n\n    def get_aggregation(self, using, added_aggregate_names):\n        \"\"\"\n        Return the dictionary with the values of the existing aggregations.\n        \"\"\"\n        if not self.annotation_select:\n            return {}\n        existing_annotations = [\n            annotation\n            for alias, annotation in self.annotations.items()\n            if alias not in added_aggregate_names\n        ]\n        # Decide if we need to use a subquery.\n        #\n        # Existing annotations would cause incorrect results as get_aggregation()\n        # must produce just one result and thus must not use GROUP BY. But we\n        # aren't smart enough to remove the existing annotations from the\n        # query, so those would force us to use GROUP BY.\n        #\n        # If the query has limit or distinct, or uses set operations, then\n        # those operations must be done in a subquery so that the query\n        # aggregates on the limit and/or distinct results instead of applying\n        # the distinct and limit after the aggregation.\n        if (\n            isinstance(self.group_by, tuple)\n            or self.is_sliced\n            or existing_annotations\n            or self.distinct\n            or self.combinator\n        ):\n            from django.db.models.sql.subqueries import AggregateQuery\n\n            inner_query = self.clone()\n            inner_query.subquery = True\n            outer_query = AggregateQuery(self.model, inner_query)\n            inner_query.select_for_update = False\n            inner_query.select_related = False\n            inner_query.set_annotation_mask(self.annotation_select)\n            # Queries with distinct_fields need ordering and when a limit is\n            # applied we must take the slice from the ordered query. Otherwise\n            # no need for ordering.\n            inner_query.clear_ordering(force=False)\n            if not inner_query.distinct:\n                # If the inner query uses default select and it has some\n                # aggregate annotations, then we must make sure the inner\n                # query is grouped by the main model's primary key. However,\n                # clearing the select clause can alter results if distinct is\n                # used.\n                has_existing_aggregate_annotations = any(\n                    annotation\n                    for annotation in existing_annotations\n                    if getattr(annotation, \"contains_aggregate\", True)\n                )\n                if inner_query.default_cols and has_existing_aggregate_annotations:\n                    inner_query.group_by = (\n                        self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n                    )\n                inner_query.default_cols = False\n\n            relabels = {t: \"subquery\" for t in inner_query.alias_map}\n            relabels[None] = \"subquery\"\n            # Remove any aggregates marked for reduction from the subquery\n            # and move them to the outer AggregateQuery.\n            col_cnt = 0\n            for alias, expression in list(inner_query.annotation_select.items()):\n                annotation_select_mask = inner_query.annotation_select_mask\n                if expression.is_summary:\n                    expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)\n                    outer_query.annotations[alias] = expression.relabeled_clone(\n                        relabels\n                    )\n                    del inner_query.annotations[alias]\n                    annotation_select_mask.remove(alias)\n                # Make sure the annotation_select wont use cached results.\n                inner_query.set_annotation_mask(inner_query.annotation_select_mask)\n            if (\n                inner_query.select == ()\n                and not inner_query.default_cols\n                and not inner_query.annotation_select_mask\n            ):\n                # In case of Model.objects[0:3].count(), there would be no\n                # field selected in the inner query, yet we must use a subquery.\n                # So, make sure at least one field is selected.\n                inner_query.select = (\n                    self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n                )\n        else:\n            outer_query = self\n            self.select = ()\n            self.default_cols = False\n            self.extra = {}\n\n        empty_set_result = [\n            expression.empty_result_set_value\n            for expression in outer_query.annotation_select.values()\n        ]\n        elide_empty = not any(result is NotImplemented for result in empty_set_result)\n        outer_query.clear_ordering(force=True)\n        outer_query.clear_limits()\n        outer_query.select_for_update = False\n        outer_query.select_related = False\n        compiler = outer_query.get_compiler(using, elide_empty=elide_empty)\n        result = compiler.execute_sql(SINGLE)\n        if result is None:\n            result = empty_set_result\n\n        converters = compiler.get_converters(outer_query.annotation_select.values())\n        result = next(compiler.apply_converters((result,), converters))\n\n        return dict(zip(outer_query.annotation_select, result))\n\n    def get_count(self, using):\n        \"\"\"\n        Perform a COUNT() query using the current filter constraints.\n        \"\"\"\n        obj = self.clone()\n        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n        return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n\n    def has_filters(self):\n        return self.where\n\n    def exists(self, using, limit=True):\n        q = self.clone()\n        if not q.distinct:\n            if q.group_by is True:\n                q.add_fields(\n                    (f.attname for f in self.model._meta.concrete_fields), False\n                )\n                # Disable GROUP BY aliases to avoid orphaning references to the\n                # SELECT clause which is about to be cleared.\n                q.set_group_by(allow_aliases=False)\n            q.clear_select_clause()\n        if q.combined_queries and q.combinator == \"union\":\n            limit_combined = connections[\n                using\n            ].features.supports_slicing_ordering_in_compound\n            q.combined_queries = tuple(\n                combined_query.exists(using, limit=limit_combined)\n                for combined_query in q.combined_queries\n            )\n        q.clear_ordering(force=True)\n        if limit:\n            q.set_limits(high=1)\n        q.add_extra({\"a\": 1}, None, None, None, None, None)\n        q.set_extra_mask([\"a\"])\n        return q\n\n    def has_results(self, using):\n        q = self.exists(using)\n        compiler = q.get_compiler(using=using)\n        return compiler.has_results()\n\n    def explain(self, using, format=None, **options):\n        q = self.clone()\n        q.explain_info = ExplainInfo(format, options)\n        compiler = q.get_compiler(using=using)\n        return \"\\n\".join(compiler.explain_query())\n\n    def combine(self, rhs, connector):\n        \"\"\"\n        Merge the 'rhs' query into the current one (with any 'rhs' effects\n        being applied *after* (that is, \"to the right of\") anything in the\n        current query. 'rhs' is not modified during a call to this function.\n\n        The 'connector' parameter describes how to connect filters from the\n        'rhs' query.\n        \"\"\"\n        if self.model != rhs.model:\n            raise TypeError(\"Cannot combine queries on two different base models.\")\n        if self.is_sliced:\n            raise TypeError(\"Cannot combine queries once a slice has been taken.\")\n        if self.distinct != rhs.distinct:\n            raise TypeError(\"Cannot combine a unique query with a non-unique query.\")\n        if self.distinct_fields != rhs.distinct_fields:\n            raise TypeError(\"Cannot combine queries with different distinct fields.\")\n\n        # If lhs and rhs shares the same alias prefix, it is possible to have\n        # conflicting alias changes like T4 -> T5, T5 -> T6, which might end up\n        # as T4 -> T6 while combining two querysets. To prevent this, change an\n        # alias prefix of the rhs and update current aliases accordingly,\n        # except if the alias is the base table since it must be present in the\n        # query on both sides.\n        initial_alias = self.get_initial_alias()\n        rhs.bump_prefix(self, exclude={initial_alias})\n\n        # Work out how to relabel the rhs aliases, if necessary.\n        change_map = {}\n        conjunction = connector == AND\n\n        # Determine which existing joins can be reused. When combining the\n        # query with AND we must recreate all joins for m2m filters. When\n        # combining with OR we can reuse joins. The reason is that in AND\n        # case a single row can't fulfill a condition like:\n        #     revrel__col=1 & revrel__col=2\n        # But, there might be two different related rows matching this\n        # condition. In OR case a single True is enough, so single row is\n        # enough, too.\n        #\n        # Note that we will be creating duplicate joins for non-m2m joins in\n        # the AND case. The results will be correct but this creates too many\n        # joins. This is something that could be fixed later on.\n        reuse = set() if conjunction else set(self.alias_map)\n        joinpromoter = JoinPromoter(connector, 2, False)\n        joinpromoter.add_votes(\n            j for j in self.alias_map if self.alias_map[j].join_type == INNER\n        )\n        rhs_votes = set()\n        # Now, add the joins from rhs query into the new query (skipping base\n        # table).\n        rhs_tables = list(rhs.alias_map)[1:]\n        for alias in rhs_tables:\n            join = rhs.alias_map[alias]\n            # If the left side of the join was already relabeled, use the\n            # updated alias.\n            join = join.relabeled_clone(change_map)\n            new_alias = self.join(join, reuse=reuse)\n            if join.join_type == INNER:\n                rhs_votes.add(new_alias)\n            # We can't reuse the same join again in the query. If we have two\n            # distinct joins for the same connection in rhs query, then the\n            # combined query must have two joins, too.\n            reuse.discard(new_alias)\n            if alias != new_alias:\n                change_map[alias] = new_alias\n            if not rhs.alias_refcount[alias]:\n                # The alias was unused in the rhs query. Unref it so that it\n                # will be unused in the new query, too. We have to add and\n                # unref the alias so that join promotion has information of\n                # the join type for the unused alias.\n                self.unref_alias(new_alias)\n        joinpromoter.add_votes(rhs_votes)\n        joinpromoter.update_join_types(self)\n\n        # Combine subqueries aliases to ensure aliases relabelling properly\n        # handle subqueries when combining where and select clauses.\n        self.subq_aliases |= rhs.subq_aliases\n\n        # Now relabel a copy of the rhs where-clause and add it to the current\n        # one.\n        w = rhs.where.clone()\n        w.relabel_aliases(change_map)\n        self.where.add(w, connector)\n\n        # Selection columns and extra extensions are those provided by 'rhs'.\n        if rhs.select:\n            self.set_select([col.relabeled_clone(change_map) for col in rhs.select])\n        else:\n            self.select = ()\n\n        if connector == OR:\n            # It would be nice to be able to handle this, but the queries don't\n            # really make sense (or return consistent value sets). Not worth\n            # the extra complexity when you can write a real query instead.\n            if self.extra and rhs.extra:\n                raise ValueError(\n                    \"When merging querysets using 'or', you cannot have \"\n                    \"extra(select=...) on both sides.\"\n                )\n        self.extra.update(rhs.extra)\n        extra_select_mask = set()\n        if self.extra_select_mask is not None:\n            extra_select_mask.update(self.extra_select_mask)\n        if rhs.extra_select_mask is not None:\n            extra_select_mask.update(rhs.extra_select_mask)\n        if extra_select_mask:\n            self.set_extra_mask(extra_select_mask)\n        self.extra_tables += rhs.extra_tables\n\n        # Ordering uses the 'rhs' ordering, unless it has none, in which case\n        # the current ordering is used.\n        self.order_by = rhs.order_by or self.order_by\n        self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n\n    def deferred_to_data(self, target):\n        \"\"\"\n        Convert the self.deferred_loading data structure to an alternate data\n        structure, describing the field that *will* be loaded. This is used to\n        compute the columns to select from the database and also by the\n        QuerySet class to work out which fields are being initialized on each\n        model. Models that have all their fields included aren't mentioned in\n        the result, only those that have field restrictions in place.\n\n        The \"target\" parameter is the instance that is populated (in place).\n        \"\"\"\n        field_names, defer = self.deferred_loading\n        if not field_names:\n            return\n        orig_opts = self.get_meta()\n        seen = {}\n        must_include = {orig_opts.concrete_model: {orig_opts.pk}}\n        for field_name in field_names:\n            parts = field_name.split(LOOKUP_SEP)\n            cur_model = self.model._meta.concrete_model\n            opts = orig_opts\n            for name in parts[:-1]:\n                old_model = cur_model\n                if name in self._filtered_relations:\n                    name = self._filtered_relations[name].relation_name\n                source = opts.get_field(name)\n                if is_reverse_o2o(source):\n                    cur_model = source.related_model\n                else:\n                    cur_model = source.remote_field.model\n                opts = cur_model._meta\n                # Even if we're \"just passing through\" this model, we must add\n                # both the current model's pk and the related reference field\n                # (if it's not a reverse relation) to the things we select.\n                if not is_reverse_o2o(source):\n                    must_include[old_model].add(source)\n                add_to_dict(must_include, cur_model, opts.pk)\n            field = opts.get_field(parts[-1])\n            is_reverse_object = field.auto_created and not field.concrete\n            model = field.related_model if is_reverse_object else field.model\n            model = model._meta.concrete_model\n            if model == opts.model:\n                model = cur_model\n            if not is_reverse_o2o(field):\n                add_to_dict(seen, model, field)\n\n        if defer:\n            # We need to load all fields for each model, except those that\n            # appear in \"seen\" (for all models that appear in \"seen\"). The only\n            # slight complexity here is handling fields that exist on parent\n            # models.\n            workset = {}\n            for model, values in seen.items():\n                for field in model._meta.local_fields:\n                    if field not in values:\n                        m = field.model._meta.concrete_model\n                        add_to_dict(workset, m, field)\n            for model, values in must_include.items():\n                # If we haven't included a model in workset, we don't add the\n                # corresponding must_include fields for that model, since an\n                # empty set means \"include all fields\". That's why there's no\n                # \"else\" branch here.\n                if model in workset:\n                    workset[model].update(values)\n            for model, fields in workset.items():\n                target[model] = {f.attname for f in fields}\n        else:\n            for model, values in must_include.items():\n                if model in seen:\n                    seen[model].update(values)\n                else:\n                    # As we've passed through this model, but not explicitly\n                    # included any fields, we have to make sure it's mentioned\n                    # so that only the \"must include\" fields are pulled in.\n                    seen[model] = values\n            # Now ensure that every model in the inheritance chain is mentioned\n            # in the parent list. Again, it must be mentioned to ensure that\n            # only \"must include\" fields are pulled in.\n            for model in orig_opts.get_parent_list():\n                seen.setdefault(model, set())\n            for model, fields in seen.items():\n                target[model] = {f.attname for f in fields}\n\n    def table_alias(self, table_name, create=False, filtered_relation=None):\n        \"\"\"\n        Return a table alias for the given table_name and whether this is a\n        new alias or not.\n\n        If 'create' is true, a new alias is always created. Otherwise, the\n        most recently created alias for the table (if one exists) is reused.\n        \"\"\"\n        alias_list = self.table_map.get(table_name)\n        if not create and alias_list:\n            alias = alias_list[0]\n            self.alias_refcount[alias] += 1\n            return alias, False\n\n        # Create a new alias for this table.\n        if alias_list:\n            alias = \"%s%d\" % (self.alias_prefix, len(self.alias_map) + 1)\n            alias_list.append(alias)\n        else:\n            # The first occurrence of a table uses the table name directly.\n            alias = (\n                filtered_relation.alias if filtered_relation is not None else table_name\n            )\n            self.table_map[table_name] = [alias]\n        self.alias_refcount[alias] = 1\n        return alias, True\n\n    def ref_alias(self, alias):\n        \"\"\"Increases the reference count for this alias.\"\"\"\n        self.alias_refcount[alias] += 1\n\n    def unref_alias(self, alias, amount=1):\n        \"\"\"Decreases the reference count for this alias.\"\"\"\n        self.alias_refcount[alias] -= amount\n\n    def promote_joins(self, aliases):\n        \"\"\"\n        Promote recursively the join type of given aliases and its children to\n        an outer join. If 'unconditional' is False, only promote the join if\n        it is nullable or the parent join is an outer join.\n\n        The children promotion is done to avoid join chains that contain a LOUTER\n        b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,\n        then we must also promote b->c automatically, or otherwise the promotion\n        of a->b doesn't actually change anything in the query results.\n        \"\"\"\n        aliases = list(aliases)\n        while aliases:\n            alias = aliases.pop(0)\n            if self.alias_map[alias].join_type is None:\n                # This is the base table (first FROM entry) - this table\n                # isn't really joined at all in the query, so we should not\n                # alter its join type.\n                continue\n            # Only the first alias (skipped above) should have None join_type\n            assert self.alias_map[alias].join_type is not None\n            parent_alias = self.alias_map[alias].parent_alias\n            parent_louter = (\n                parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n            )\n            already_louter = self.alias_map[alias].join_type == LOUTER\n            if (self.alias_map[alias].nullable or parent_louter) and not already_louter:\n                self.alias_map[alias] = self.alias_map[alias].promote()\n                # Join type of 'alias' changed, so re-examine all aliases that\n                # refer to this one.\n                aliases.extend(\n                    join\n                    for join in self.alias_map\n                    if self.alias_map[join].parent_alias == alias\n                    and join not in aliases\n                )\n\n    def demote_joins(self, aliases):\n        \"\"\"\n        Change join type from LOUTER to INNER for all joins in aliases.\n\n        Similarly to promote_joins(), this method must ensure no join chains\n        containing first an outer, then an inner join are generated. If we\n        are demoting b->c join in chain a LOUTER b LOUTER c then we must\n        demote a->b automatically, or otherwise the demotion of b->c doesn't\n        actually change anything in the query results. .\n        \"\"\"\n        aliases = list(aliases)\n        while aliases:\n            alias = aliases.pop(0)\n            if self.alias_map[alias].join_type == LOUTER:\n                self.alias_map[alias] = self.alias_map[alias].demote()\n                parent_alias = self.alias_map[alias].parent_alias\n                if self.alias_map[parent_alias].join_type == INNER:\n                    aliases.append(parent_alias)\n\n    def reset_refcounts(self, to_counts):\n        \"\"\"\n        Reset reference counts for aliases so that they match the value passed\n        in `to_counts`.\n        \"\"\"\n        for alias, cur_refcount in self.alias_refcount.copy().items():\n            unref_amount = cur_refcount - to_counts.get(alias, 0)\n            self.unref_alias(alias, unref_amount)\n\n    def change_aliases(self, change_map):\n        \"\"\"\n        Change the aliases in change_map (which maps old-alias -> new-alias),\n        relabelling any references to them in select columns and the where\n        clause.\n        \"\"\"\n        # If keys and values of change_map were to intersect, an alias might be\n        # updated twice (e.g. T4 -> T5, T5 -> T6, so also T4 -> T6) depending\n        # on their order in change_map.\n        assert set(change_map).isdisjoint(change_map.values())\n\n        # 1. Update references in \"select\" (normal columns plus aliases),\n        # \"group by\" and \"where\".\n        self.where.relabel_aliases(change_map)\n        if isinstance(self.group_by, tuple):\n            self.group_by = tuple(\n                [col.relabeled_clone(change_map) for col in self.group_by]\n            )\n        self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n        self.annotations = self.annotations and {\n            key: col.relabeled_clone(change_map)\n            for key, col in self.annotations.items()\n        }\n\n        # 2. Rename the alias in the internal table/alias datastructures.\n        for old_alias, new_alias in change_map.items():\n            if old_alias not in self.alias_map:\n                continue\n            alias_data = self.alias_map[old_alias].relabeled_clone(change_map)\n            self.alias_map[new_alias] = alias_data\n            self.alias_refcount[new_alias] = self.alias_refcount[old_alias]\n            del self.alias_refcount[old_alias]\n            del self.alias_map[old_alias]\n\n            table_aliases = self.table_map[alias_data.table_name]\n            for pos, alias in enumerate(table_aliases):\n                if alias == old_alias:\n                    table_aliases[pos] = new_alias\n                    break\n        self.external_aliases = {\n            # Table is aliased or it's being changed and thus is aliased.\n            change_map.get(alias, alias): (aliased or alias in change_map)\n            for alias, aliased in self.external_aliases.items()\n        }\n\n    def bump_prefix(self, other_query, exclude=None):\n        \"\"\"\n        Change the alias prefix to the next letter in the alphabet in a way\n        that the other query's aliases and this query's aliases will not\n        conflict. Even tables that previously had no alias will get an alias\n        after this call. To prevent changing aliases use the exclude parameter.\n        \"\"\"\n\n        def prefix_gen():\n            \"\"\"\n            Generate a sequence of characters in alphabetical order:\n                -> 'A', 'B', 'C', ...\n\n            When the alphabet is finished, the sequence will continue with the\n            Cartesian product:\n                -> 'AA', 'AB', 'AC', ...\n            \"\"\"\n            alphabet = ascii_uppercase\n            prefix = chr(ord(self.alias_prefix) + 1)\n            yield prefix\n            for n in count(1):\n                seq = alphabet[alphabet.index(prefix) :] if prefix else alphabet\n                for s in product(seq, repeat=n):\n                    yield \"\".join(s)\n                prefix = None\n\n        if self.alias_prefix != other_query.alias_prefix:\n            # No clashes between self and outer query should be possible.\n            return\n\n        # Explicitly avoid infinite loop. The constant divider is based on how\n        # much depth recursive subquery references add to the stack. This value\n        # might need to be adjusted when adding or removing function calls from\n        # the code path in charge of performing these operations.\n        local_recursion_limit = sys.getrecursionlimit() // 16\n        for pos, prefix in enumerate(prefix_gen()):\n            if prefix not in self.subq_aliases:\n                self.alias_prefix = prefix\n                break\n            if pos > local_recursion_limit:\n                raise RecursionError(\n                    \"Maximum recursion depth exceeded: too many subqueries.\"\n                )\n        self.subq_aliases = self.subq_aliases.union([self.alias_prefix])\n        other_query.subq_aliases = other_query.subq_aliases.union(self.subq_aliases)\n        if exclude is None:\n            exclude = {}\n        self.change_aliases(\n            {\n                alias: \"%s%d\" % (self.alias_prefix, pos)\n                for pos, alias in enumerate(self.alias_map)\n                if alias not in exclude\n            }\n        )\n\n    def get_initial_alias(self):\n        \"\"\"\n        Return the first alias for this query, after increasing its reference\n        count.\n        \"\"\"\n        if self.alias_map:\n            alias = self.base_table\n            self.ref_alias(alias)\n        elif self.model:\n            alias = self.join(self.base_table_class(self.get_meta().db_table, None))\n        else:\n            alias = None\n        return alias\n\n    def count_active_tables(self):\n        \"\"\"\n        Return the number of tables in this query with a non-zero reference\n        count. After execution, the reference counts are zeroed, so tables\n        added in compiler will not be seen by this method.\n        \"\"\"\n        return len([1 for count in self.alias_refcount.values() if count])\n\n    def join(self, join, reuse=None, reuse_with_filtered_relation=False):\n        \"\"\"\n        Return an alias for the 'join', either reusing an existing alias for\n        that join or creating a new one. 'join' is either a base_table_class or\n        join_class.\n\n        The 'reuse' parameter can be either None which means all joins are\n        reusable, or it can be a set containing the aliases that can be reused.\n\n        The 'reuse_with_filtered_relation' parameter is used when computing\n        FilteredRelation instances.\n\n        A join is always created as LOUTER if the lhs alias is LOUTER to make\n        sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new\n        joins are created as LOUTER if the join is nullable.\n        \"\"\"\n        if reuse_with_filtered_relation and reuse:\n            reuse_aliases = [\n                a for a, j in self.alias_map.items() if a in reuse and j.equals(join)\n            ]\n        else:\n            reuse_aliases = [\n                a\n                for a, j in self.alias_map.items()\n                if (reuse is None or a in reuse) and j == join\n            ]\n        if reuse_aliases:\n            if join.table_alias in reuse_aliases:\n                reuse_alias = join.table_alias\n            else:\n                # Reuse the most recent alias of the joined table\n                # (a many-to-many relation may be joined multiple times).\n                reuse_alias = reuse_aliases[-1]\n            self.ref_alias(reuse_alias)\n            return reuse_alias\n\n        # No reuse is possible, so we need a new alias.\n        alias, _ = self.table_alias(\n            join.table_name, create=True, filtered_relation=join.filtered_relation\n        )\n        if join.join_type:\n            if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n                join_type = LOUTER\n            else:\n                join_type = INNER\n            join.join_type = join_type\n        join.table_alias = alias\n        self.alias_map[alias] = join\n        return alias\n\n    def join_parent_model(self, opts, model, alias, seen):\n        \"\"\"\n        Make sure the given 'model' is joined in the query. If 'model' isn't\n        a parent of 'opts' or if it is None this method is a no-op.\n\n        The 'alias' is the root alias for starting the join, 'seen' is a dict\n        of model -> alias of existing joins. It must also contain a mapping\n        of None -> some alias. This will be returned in the no-op case.\n        \"\"\"\n        if model in seen:\n            return seen[model]\n        chain = opts.get_base_chain(model)\n        if not chain:\n            return alias\n        curr_opts = opts\n        for int_model in chain:\n            if int_model in seen:\n                curr_opts = int_model._meta\n                alias = seen[int_model]\n                continue\n            # Proxy model have elements in base chain\n            # with no parents, assign the new options\n            # object and skip to the next base in that\n            # case\n            if not curr_opts.parents[int_model]:\n                curr_opts = int_model._meta\n                continue\n            link_field = curr_opts.get_ancestor_link(int_model)\n            join_info = self.setup_joins([link_field.name], curr_opts, alias)\n            curr_opts = int_model._meta\n            alias = seen[int_model] = join_info.joins[-1]\n        return alias or seen[None]\n\n    def add_annotation(self, annotation, alias, is_summary=False, select=True):\n        \"\"\"Add a single annotation expression to the Query.\"\"\"\n        annotation = annotation.resolve_expression(\n            self, allow_joins=True, reuse=None, summarize=is_summary\n        )\n        if select:\n            self.append_annotation_mask([alias])\n        else:\n            self.set_annotation_mask(set(self.annotation_select).difference({alias}))\n        self.annotations[alias] = annotation\n\n    def resolve_expression(self, query, *args, **kwargs):\n        clone = self.clone()\n        # Subqueries need to use a different set of aliases than the outer query.\n        clone.bump_prefix(query)\n        clone.subquery = True\n        clone.where.resolve_expression(query, *args, **kwargs)\n        # Resolve combined queries.\n        if clone.combinator:\n            clone.combined_queries = tuple(\n                [\n                    combined_query.resolve_expression(query, *args, **kwargs)\n                    for combined_query in clone.combined_queries\n                ]\n            )\n        for key, value in clone.annotations.items():\n            resolved = value.resolve_expression(query, *args, **kwargs)\n            if hasattr(resolved, \"external_aliases\"):\n                resolved.external_aliases.update(clone.external_aliases)\n            clone.annotations[key] = resolved\n        # Outer query's aliases are considered external.\n        for alias, table in query.alias_map.items():\n            clone.external_aliases[alias] = (\n                isinstance(table, Join)\n                and table.join_field.related_model._meta.db_table != alias\n            ) or (\n                isinstance(table, BaseTable) and table.table_name != table.table_alias\n            )\n        return clone\n\n    def get_external_cols(self):\n        exprs = chain(self.annotations.values(), self.where.children)\n        return [\n            col\n            for col in self._gen_cols(exprs, include_external=True)\n            if col.alias in self.external_aliases\n        ]\n\n    def get_group_by_cols(self, alias=None):\n        if alias:\n            return [Ref(alias, self)]\n        external_cols = self.get_external_cols()\n        if any(col.possibly_multivalued for col in external_cols):\n            return [self]\n        return external_cols\n\n    def as_sql(self, compiler, connection):\n        # Some backends (e.g. Oracle) raise an error when a subquery contains\n        # unnecessary ORDER BY clause.\n        if (\n            self.subquery\n            and not connection.features.ignores_unnecessary_order_by_in_subqueries\n        ):\n            self.clear_ordering(force=False)\n        sql, params = self.get_compiler(connection=connection).as_sql()\n        if self.subquery:\n            sql = \"(%s)\" % sql\n        return sql, params\n\n    def resolve_lookup_value(self, value, can_reuse, allow_joins):\n        if hasattr(value, \"resolve_expression\"):\n            value = value.resolve_expression(\n                self,\n                reuse=can_reuse,\n                allow_joins=allow_joins,\n            )\n        elif isinstance(value, (list, tuple)):\n            # The items of the iterable may be expressions and therefore need\n            # to be resolved independently.\n            values = (\n                self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                for sub_value in value\n            )\n            type_ = type(value)\n            if hasattr(type_, \"_make\"):  # namedtuple\n                return type_(*values)\n            return type_(values)\n        return value\n\n    def solve_lookup_type(self, lookup):\n        \"\"\"\n        Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').\n        \"\"\"\n        lookup_splitted = lookup.split(LOOKUP_SEP)\n        if self.annotations:\n            expression, expression_lookups = refs_expression(\n                lookup_splitted, self.annotations\n            )\n            if expression:\n                return expression_lookups, (), expression\n        _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n        field_parts = lookup_splitted[0 : len(lookup_splitted) - len(lookup_parts)]\n        if len(lookup_parts) > 1 and not field_parts:\n            raise FieldError(\n                'Invalid lookup \"%s\" for model %s\".'\n                % (lookup, self.get_meta().model.__name__)\n            )\n        return lookup_parts, field_parts, False\n\n    def check_query_object_type(self, value, opts, field):\n        \"\"\"\n        Check whether the object passed while querying is of the correct type.\n        If not, raise a ValueError specifying the wrong object.\n        \"\"\"\n        if hasattr(value, \"_meta\"):\n            if not check_rel_lookup_compatibility(value._meta.model, opts, field):\n                raise ValueError(\n                    'Cannot query \"%s\": Must be \"%s\" instance.'\n                    % (value, opts.object_name)\n                )\n\n    def check_related_objects(self, field, value, opts):\n        \"\"\"Check the type of object passed to query relations.\"\"\"\n        if field.is_relation:\n            # Check that the field and the queryset use the same model in a\n            # query like .filter(author=Author.objects.all()). For example, the\n            # opts would be Author's (from the author field) and value.model\n            # would be Author.objects.all() queryset's .model (Author also).\n            # The field is the related field on the lhs side.\n            if (\n                isinstance(value, Query)\n                and not value.has_select_fields\n                and not check_rel_lookup_compatibility(value.model, opts, field)\n            ):\n                raise ValueError(\n                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".'\n                    % (value.model._meta.object_name, opts.object_name)\n                )\n            elif hasattr(value, \"_meta\"):\n                self.check_query_object_type(value, opts, field)\n            elif hasattr(value, \"__iter__\"):\n                for v in value:\n                    self.check_query_object_type(v, opts, field)\n\n    def check_filterable(self, expression):\n        \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n        if hasattr(expression, \"resolve_expression\") and not getattr(\n            expression, \"filterable\", True\n        ):\n            raise NotSupportedError(\n                expression.__class__.__name__ + \" is disallowed in the filter \"\n                \"clause.\"\n            )\n        if hasattr(expression, \"get_source_expressions\"):\n            for expr in expression.get_source_expressions():\n                self.check_filterable(expr)\n\n    def build_lookup(self, lookups, lhs, rhs):\n        \"\"\"\n        Try to extract transforms and lookup from given lhs.\n\n        The lhs value is something that works like SQLExpression.\n        The rhs value is what the lookup is going to compare against.\n        The lookups is a list of names to extract using get_lookup()\n        and get_transform().\n        \"\"\"\n        # __exact is the default lookup if one isn't given.\n        *transforms, lookup_name = lookups or [\"exact\"]\n        for name in transforms:\n            lhs = self.try_transform(lhs, name)\n        # First try get_lookup() so that the lookup takes precedence if the lhs\n        # supports both transform and lookup for the name.\n        lookup_class = lhs.get_lookup(lookup_name)\n        if not lookup_class:\n            if lhs.field.is_relation:\n                raise FieldError(\n                    \"Related Field got invalid lookup: {}\".format(lookup_name)\n                )\n            # A lookup wasn't found. Try to interpret the name as a transform\n            # and do an Exact lookup against it.\n            lhs = self.try_transform(lhs, lookup_name)\n            lookup_name = \"exact\"\n            lookup_class = lhs.get_lookup(lookup_name)\n            if not lookup_class:\n                return\n\n        lookup = lookup_class(lhs, rhs)\n        # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n        # uses of None as a query value unless the lookup supports it.\n        if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n            if lookup_name not in (\"exact\", \"iexact\"):\n                raise ValueError(\"Cannot use None as a query value\")\n            return lhs.get_lookup(\"isnull\")(lhs, True)\n\n        # For Oracle '' is equivalent to null. The check must be done at this\n        # stage because join promotion can't be done in the compiler. Using\n        # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n        # A similar thing is done in is_nullable(), too.\n        if (\n            lookup_name == \"exact\"\n            and lookup.rhs == \"\"\n            and connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n        ):\n            return lhs.get_lookup(\"isnull\")(lhs, True)\n\n        return lookup\n\n    def try_transform(self, lhs, name):\n        \"\"\"\n        Helper method for build_lookup(). Try to fetch and initialize\n        a transform for name parameter from lhs.\n        \"\"\"\n        transform_class = lhs.get_transform(name)\n        if transform_class:\n            return transform_class(lhs)\n        else:\n            output_field = lhs.output_field.__class__\n            suggested_lookups = difflib.get_close_matches(\n                name, output_field.get_lookups()\n            )\n            if suggested_lookups:\n                suggestion = \", perhaps you meant %s?\" % \" or \".join(suggested_lookups)\n            else:\n                suggestion = \".\"\n            raise FieldError(\n                \"Unsupported lookup '%s' for %s or join on the field not \"\n                \"permitted%s\" % (name, output_field.__name__, suggestion)\n            )\n\n    def build_filter(\n        self,\n        filter_expr,\n        branch_negated=False,\n        current_negated=False,\n        can_reuse=None,\n        allow_joins=True,\n        split_subq=True,\n        reuse_with_filtered_relation=False,\n        check_filterable=True,\n    ):\n        \"\"\"\n        Build a WhereNode for a single filter clause but don't add it\n        to this Query. Query.add_q() will then add this filter to the where\n        Node.\n\n        The 'branch_negated' tells us if the current branch contains any\n        negations. This will be used to determine if subqueries are needed.\n\n        The 'current_negated' is used to determine if the current filter is\n        negated or not and this will be used to determine if IS NULL filtering\n        is needed.\n\n        The difference between current_negated and branch_negated is that\n        branch_negated is set on first negation, but current_negated is\n        flipped for each negation.\n\n        Note that add_filter will not do any negating itself, that is done\n        upper in the code by add_q().\n\n        The 'can_reuse' is a set of reusable joins for multijoins.\n\n        If 'reuse_with_filtered_relation' is True, then only joins in can_reuse\n        will be reused.\n\n        The method will create a filter clause that can be added to the current\n        query. However, if the filter isn't added to the query then the caller\n        is responsible for unreffing the joins used.\n        \"\"\"\n        if isinstance(filter_expr, dict):\n            raise FieldError(\"Cannot parse keyword query as dict\")\n        if isinstance(filter_expr, Q):\n            return self._add_q(\n                filter_expr,\n                branch_negated=branch_negated,\n                current_negated=current_negated,\n                used_aliases=can_reuse,\n                allow_joins=allow_joins,\n                split_subq=split_subq,\n                check_filterable=check_filterable,\n            )\n        if hasattr(filter_expr, \"resolve_expression\"):\n            if not getattr(filter_expr, \"conditional\", False):\n                raise TypeError(\"Cannot filter against a non-conditional expression.\")\n            condition = filter_expr.resolve_expression(self, allow_joins=allow_joins)\n            if not isinstance(condition, Lookup):\n                condition = self.build_lookup([\"exact\"], condition, True)\n            return WhereNode([condition], connector=AND), []\n        arg, value = filter_expr\n        if not arg:\n            raise FieldError(\"Cannot parse keyword query %r\" % arg)\n        lookups, parts, reffed_expression = self.solve_lookup_type(arg)\n\n        if check_filterable:\n            self.check_filterable(reffed_expression)\n\n        if not allow_joins and len(parts) > 1:\n            raise FieldError(\"Joined field references are not permitted in this query\")\n\n        pre_joins = self.alias_refcount.copy()\n        value = self.resolve_lookup_value(value, can_reuse, allow_joins)\n        used_joins = {\n            k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)\n        }\n\n        if check_filterable:\n            self.check_filterable(value)\n\n        if reffed_expression:\n            condition = self.build_lookup(lookups, reffed_expression, value)\n            return WhereNode([condition], connector=AND), []\n\n        opts = self.get_meta()\n        alias = self.get_initial_alias()\n        allow_many = not branch_negated or not split_subq\n\n        try:\n            join_info = self.setup_joins(\n                parts,\n                opts,\n                alias,\n                can_reuse=can_reuse,\n                allow_many=allow_many,\n                reuse_with_filtered_relation=reuse_with_filtered_relation,\n            )\n\n            # Prevent iterator from being consumed by check_related_objects()\n            if isinstance(value, Iterator):\n                value = list(value)\n            self.check_related_objects(join_info.final_field, value, join_info.opts)\n\n            # split_exclude() needs to know which joins were generated for the\n            # lookup parts\n            self._lookup_joins = join_info.joins\n        except MultiJoin as e:\n            return self.split_exclude(filter_expr, can_reuse, e.names_with_path)\n\n        # Update used_joins before trimming since they are reused to determine\n        # which joins could be later promoted to INNER.\n        used_joins.update(join_info.joins)\n        targets, alias, join_list = self.trim_joins(\n            join_info.targets, join_info.joins, join_info.path\n        )\n        if can_reuse is not None:\n            can_reuse.update(join_list)\n\n        if join_info.final_field.is_relation:\n            # No support for transforms for relational fields\n            num_lookups = len(lookups)\n            if num_lookups > 1:\n                raise FieldError(\n                    \"Related Field got invalid lookup: {}\".format(lookups[0])\n                )\n            if len(targets) == 1:\n                col = self._get_col(targets[0], join_info.final_field, alias)\n            else:\n                col = MultiColSource(\n                    alias, targets, join_info.targets, join_info.final_field\n                )\n        else:\n            col = self._get_col(targets[0], join_info.final_field, alias)\n\n        condition = self.build_lookup(lookups, col, value)\n        lookup_type = condition.lookup_name\n        clause = WhereNode([condition], connector=AND)\n\n        require_outer = (\n            lookup_type == \"isnull\" and condition.rhs is True and not current_negated\n        )\n        if (\n            current_negated\n            and (lookup_type != \"isnull\" or condition.rhs is False)\n            and condition.rhs is not None\n        ):\n            require_outer = True\n            if lookup_type != \"isnull\":\n                # The condition added here will be SQL like this:\n                # NOT (col IS NOT NULL), where the first NOT is added in\n                # upper layers of code. The reason for addition is that if col\n                # is null, then col != someval will result in SQL \"unknown\"\n                # which isn't the same as in Python. The Python None handling\n                # is wanted, and it can be gotten by\n                # (col IS NULL OR col != someval)\n                #   <=>\n                # NOT (col IS NOT NULL AND col = someval).\n                if (\n                    self.is_nullable(targets[0])\n                    or self.alias_map[join_list[-1]].join_type == LOUTER\n                ):\n                    lookup_class = targets[0].get_lookup(\"isnull\")\n                    col = self._get_col(targets[0], join_info.targets[0], alias)\n                    clause.add(lookup_class(col, False), AND)\n                # If someval is a nullable column, someval IS NOT NULL is\n                # added.\n                if isinstance(value, Col) and self.is_nullable(value.target):\n                    lookup_class = value.target.get_lookup(\"isnull\")\n                    clause.add(lookup_class(value, False), AND)\n        return clause, used_joins if not require_outer else ()\n\n    def add_filter(self, filter_lhs, filter_rhs):\n        self.add_q(Q((filter_lhs, filter_rhs)))\n\n    def add_q(self, q_object):\n        \"\"\"\n        A preprocessor for the internal _add_q(). Responsible for doing final\n        join promotion.\n        \"\"\"\n        # For join promotion this case is doing an AND for the added q_object\n        # and existing conditions. So, any existing inner join forces the join\n        # type to remain inner. Existing outer joins can however be demoted.\n        # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if\n        # rel_a doesn't produce any rows, then the whole condition must fail.\n        # So, demotion is OK.\n        existing_inner = {\n            a for a in self.alias_map if self.alias_map[a].join_type == INNER\n        }\n        clause, _ = self._add_q(q_object, self.used_aliases)\n        if clause:\n            self.where.add(clause, AND)\n        self.demote_joins(existing_inner)\n\n    def build_where(self, filter_expr):\n        return self.build_filter(filter_expr, allow_joins=False)[0]\n\n    def clear_where(self):\n        self.where = WhereNode()\n\n    def _add_q(\n        self,\n        q_object,\n        used_aliases,\n        branch_negated=False,\n        current_negated=False,\n        allow_joins=True,\n        split_subq=True,\n        check_filterable=True,\n    ):\n        \"\"\"Add a Q-object to the current filter.\"\"\"\n        connector = q_object.connector\n        current_negated = current_negated ^ q_object.negated\n        branch_negated = branch_negated or q_object.negated\n        target_clause = WhereNode(connector=connector, negated=q_object.negated)\n        joinpromoter = JoinPromoter(\n            q_object.connector, len(q_object.children), current_negated\n        )\n        for child in q_object.children:\n            child_clause, needed_inner = self.build_filter(\n                child,\n                can_reuse=used_aliases,\n                branch_negated=branch_negated,\n                current_negated=current_negated,\n                allow_joins=allow_joins,\n                split_subq=split_subq,\n                check_filterable=check_filterable,\n            )\n            joinpromoter.add_votes(needed_inner)\n            if child_clause:\n                target_clause.add(child_clause, connector)\n        needed_inner = joinpromoter.update_join_types(self)\n        return target_clause, needed_inner\n\n    def build_filtered_relation_q(\n        self, q_object, reuse, branch_negated=False, current_negated=False\n    ):\n        \"\"\"Add a FilteredRelation object to the current filter.\"\"\"\n        connector = q_object.connector\n        current_negated ^= q_object.negated\n        branch_negated = branch_negated or q_object.negated\n        target_clause = WhereNode(connector=connector, negated=q_object.negated)\n        for child in q_object.children:\n            if isinstance(child, Node):\n                child_clause = self.build_filtered_relation_q(\n                    child,\n                    reuse=reuse,\n                    branch_negated=branch_negated,\n                    current_negated=current_negated,\n                )\n            else:\n                child_clause, _ = self.build_filter(\n                    child,\n                    can_reuse=reuse,\n                    branch_negated=branch_negated,\n                    current_negated=current_negated,\n                    allow_joins=True,\n                    split_subq=False,\n                    reuse_with_filtered_relation=True,\n                )\n            target_clause.add(child_clause, connector)\n        return target_clause\n\n    def add_filtered_relation(self, filtered_relation, alias):\n        filtered_relation.alias = alias\n        lookups = dict(get_children_from_q(filtered_relation.condition))\n        relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(\n            filtered_relation.relation_name\n        )\n        if relation_lookup_parts:\n            raise ValueError(\n                \"FilteredRelation's relation_name cannot contain lookups \"\n                \"(got %r).\" % filtered_relation.relation_name\n            )\n        for lookup in chain(lookups):\n            lookup_parts, lookup_field_parts, _ = self.solve_lookup_type(lookup)\n            shift = 2 if not lookup_parts else 1\n            lookup_field_path = lookup_field_parts[:-shift]\n            for idx, lookup_field_part in enumerate(lookup_field_path):\n                if len(relation_field_parts) > idx:\n                    if relation_field_parts[idx] != lookup_field_part:\n                        raise ValueError(\n                            \"FilteredRelation's condition doesn't support \"\n                            \"relations outside the %r (got %r).\"\n                            % (filtered_relation.relation_name, lookup)\n                        )\n                else:\n                    raise ValueError(\n                        \"FilteredRelation's condition doesn't support nested \"\n                        \"relations deeper than the relation_name (got %r for \"\n                        \"%r).\" % (lookup, filtered_relation.relation_name)\n                    )\n        self._filtered_relations[filtered_relation.alias] = filtered_relation\n\n    def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):\n        \"\"\"\n        Walk the list of names and turns them into PathInfo tuples. A single\n        name in 'names' can generate multiple PathInfos (m2m, for example).\n\n        'names' is the path of names to travel, 'opts' is the model Options we\n        start the name resolving from, 'allow_many' is as for setup_joins().\n        If fail_on_missing is set to True, then a name that can't be resolved\n        will generate a FieldError.\n\n        Return a list of PathInfo tuples. In addition return the final field\n        (the last used join field) and target (which is a field guaranteed to\n        contain the same value as the final field). Finally, return those names\n        that weren't found (which are likely transforms and the final lookup).\n        \"\"\"\n        path, names_with_path = [], []\n        for pos, name in enumerate(names):\n            cur_names_with_path = (name, [])\n            if name == \"pk\":\n                name = opts.pk.name\n\n            field = None\n            filtered_relation = None\n            try:\n                if opts is None:\n                    raise FieldDoesNotExist\n                field = opts.get_field(name)\n            except FieldDoesNotExist:\n                if name in self.annotation_select:\n                    field = self.annotation_select[name].output_field\n                elif name in self._filtered_relations and pos == 0:\n                    filtered_relation = self._filtered_relations[name]\n                    if LOOKUP_SEP in filtered_relation.relation_name:\n                        parts = filtered_relation.relation_name.split(LOOKUP_SEP)\n                        filtered_relation_path, field, _, _ = self.names_to_path(\n                            parts,\n                            opts,\n                            allow_many,\n                            fail_on_missing,\n                        )\n                        path.extend(filtered_relation_path[:-1])\n                    else:\n                        field = opts.get_field(filtered_relation.relation_name)\n            if field is not None:\n                # Fields that contain one-to-many relations with a generic\n                # model (like a GenericForeignKey) cannot generate reverse\n                # relations and therefore cannot be used for reverse querying.\n                if field.is_relation and not field.related_model:\n                    raise FieldError(\n                        \"Field %r does not generate an automatic reverse \"\n                        \"relation and therefore cannot be used for reverse \"\n                        \"querying. If it is a GenericForeignKey, consider \"\n                        \"adding a GenericRelation.\" % name\n                    )\n                try:\n                    model = field.model._meta.concrete_model\n                except AttributeError:\n                    # QuerySet.annotate() may introduce fields that aren't\n                    # attached to a model.\n                    model = None\n            else:\n                # We didn't find the current field, so move position back\n                # one step.\n                pos -= 1\n                if pos == -1 or fail_on_missing:\n                    available = sorted(\n                        [\n                            *get_field_names_from_opts(opts),\n                            *self.annotation_select,\n                            *self._filtered_relations,\n                        ]\n                    )\n                    raise FieldError(\n                        \"Cannot resolve keyword '%s' into field. \"\n                        \"Choices are: %s\" % (name, \", \".join(available))\n                    )\n                break\n            # Check if we need any joins for concrete inheritance cases (the\n            # field lives in parent, but we are currently in one of its\n            # children)\n            if opts is not None and model is not opts.model:\n                path_to_parent = opts.get_path_to_parent(model)\n                if path_to_parent:\n                    path.extend(path_to_parent)\n                    cur_names_with_path[1].extend(path_to_parent)\n                    opts = path_to_parent[-1].to_opts\n            if hasattr(field, \"path_infos\"):\n                if filtered_relation:\n                    pathinfos = field.get_path_info(filtered_relation)\n                else:\n                    pathinfos = field.path_infos\n                if not allow_many:\n                    for inner_pos, p in enumerate(pathinfos):\n                        if p.m2m:\n                            cur_names_with_path[1].extend(pathinfos[0 : inner_pos + 1])\n                            names_with_path.append(cur_names_with_path)\n                            raise MultiJoin(pos + 1, names_with_path)\n                last = pathinfos[-1]\n                path.extend(pathinfos)\n                final_field = last.join_field\n                opts = last.to_opts\n                targets = last.target_fields\n                cur_names_with_path[1].extend(pathinfos)\n                names_with_path.append(cur_names_with_path)\n            else:\n                # Local non-relational field.\n                final_field = field\n                targets = (field,)\n                if fail_on_missing and pos + 1 != len(names):\n                    raise FieldError(\n                        \"Cannot resolve keyword %r into field. Join on '%s'\"\n                        \" not permitted.\" % (names[pos + 1], name)\n                    )\n                break\n        return path, final_field, targets, names[pos + 1 :]\n\n    def setup_joins(\n        self,\n        names,\n        opts,\n        alias,\n        can_reuse=None,\n        allow_many=True,\n        reuse_with_filtered_relation=False,\n    ):\n        \"\"\"\n        Compute the necessary table joins for the passage through the fields\n        given in 'names'. 'opts' is the Options class for the current model\n        (which gives the table we are starting from), 'alias' is the alias for\n        the table to start the joining from.\n\n        The 'can_reuse' defines the reverse foreign key joins we can reuse. It\n        can be None in which case all joins are reusable or a set of aliases\n        that can be reused. Note that non-reverse foreign keys are always\n        reusable when using setup_joins().\n\n        The 'reuse_with_filtered_relation' can be used to force 'can_reuse'\n        parameter and force the relation on the given connections.\n\n        If 'allow_many' is False, then any reverse foreign key seen will\n        generate a MultiJoin exception.\n\n        Return the final field involved in the joins, the target field (used\n        for any 'where' constraint), the final 'opts' value, the joins, the\n        field path traveled to generate the joins, and a transform function\n        that takes a field and alias and is equivalent to `field.get_col(alias)`\n        in the simple case but wraps field transforms if they were included in\n        names.\n\n        The target field is the field containing the concrete value. Final\n        field can be something different, for example foreign key pointing to\n        that value. Final field is needed for example in some value\n        conversions (convert 'obj' in fk__id=obj to pk val using the foreign\n        key field for example).\n        \"\"\"\n        joins = [alias]\n        # The transform can't be applied yet, as joins must be trimmed later.\n        # To avoid making every caller of this method look up transforms\n        # directly, compute transforms here and create a partial that converts\n        # fields to the appropriate wrapped version.\n\n        def final_transformer(field, alias):\n            if not self.alias_cols:\n                alias = None\n            return field.get_col(alias)\n\n        # Try resolving all the names as fields first. If there's an error,\n        # treat trailing names as lookups until a field can be resolved.\n        last_field_exception = None\n        for pivot in range(len(names), 0, -1):\n            try:\n                path, final_field, targets, rest = self.names_to_path(\n                    names[:pivot],\n                    opts,\n                    allow_many,\n                    fail_on_missing=True,\n                )\n            except FieldError as exc:\n                if pivot == 1:\n                    # The first item cannot be a lookup, so it's safe\n                    # to raise the field error here.\n                    raise\n                else:\n                    last_field_exception = exc\n            else:\n                # The transforms are the remaining items that couldn't be\n                # resolved into fields.\n                transforms = names[pivot:]\n                break\n        for name in transforms:\n\n            def transform(field, alias, *, name, previous):\n                try:\n                    wrapped = previous(field, alias)\n                    return self.try_transform(wrapped, name)\n                except FieldError:\n                    # FieldError is raised if the transform doesn't exist.\n                    if isinstance(final_field, Field) and last_field_exception:\n                        raise last_field_exception\n                    else:\n                        raise\n\n            final_transformer = functools.partial(\n                transform, name=name, previous=final_transformer\n            )\n        # Then, add the path to the query's joins. Note that we can't trim\n        # joins at this stage - we will need the information about join type\n        # of the trimmed joins.\n        for join in path:\n            if join.filtered_relation:\n                filtered_relation = join.filtered_relation.clone()\n                table_alias = filtered_relation.alias\n            else:\n                filtered_relation = None\n                table_alias = None\n            opts = join.to_opts\n            if join.direct:\n                nullable = self.is_nullable(join.join_field)\n            else:\n                nullable = True\n            connection = self.join_class(\n                opts.db_table,\n                alias,\n                table_alias,\n                INNER,\n                join.join_field,\n                nullable,\n                filtered_relation=filtered_relation,\n            )\n            reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None\n            alias = self.join(\n                connection,\n                reuse=reuse,\n                reuse_with_filtered_relation=reuse_with_filtered_relation,\n            )\n            joins.append(alias)\n            if filtered_relation:\n                filtered_relation.path = joins[:]\n        return JoinInfo(final_field, targets, opts, joins, path, final_transformer)\n\n    def trim_joins(self, targets, joins, path):\n        \"\"\"\n        The 'target' parameter is the final field being joined to, 'joins'\n        is the full list of join aliases. The 'path' contain the PathInfos\n        used to create the joins.\n\n        Return the final target field and table alias and the new active\n        joins.\n\n        Always trim any direct join if the target column is already in the\n        previous table. Can't trim reverse joins as it's unknown if there's\n        anything on the other side of the join.\n        \"\"\"\n        joins = joins[:]\n        for pos, info in enumerate(reversed(path)):\n            if len(joins) == 1 or not info.direct:\n                break\n            if info.filtered_relation:\n                break\n            join_targets = {t.column for t in info.join_field.foreign_related_fields}\n            cur_targets = {t.column for t in targets}\n            if not cur_targets.issubset(join_targets):\n                break\n            targets_dict = {\n                r[1].column: r[0]\n                for r in info.join_field.related_fields\n                if r[1].column in cur_targets\n            }\n            targets = tuple(targets_dict[t.column] for t in targets)\n            self.unref_alias(joins.pop())\n        return targets, joins[-1], joins\n\n    @classmethod\n    def _gen_cols(cls, exprs, include_external=False):\n        for expr in exprs:\n            if isinstance(expr, Col):\n                yield expr\n            elif include_external and callable(\n                getattr(expr, \"get_external_cols\", None)\n            ):\n                yield from expr.get_external_cols()\n            elif hasattr(expr, \"get_source_expressions\"):\n                yield from cls._gen_cols(\n                    expr.get_source_expressions(),\n                    include_external=include_external,\n                )\n\n    @classmethod\n    def _gen_col_aliases(cls, exprs):\n        yield from (expr.alias for expr in cls._gen_cols(exprs))\n\n    def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):\n        annotation = self.annotations.get(name)\n        if annotation is not None:\n            if not allow_joins:\n                for alias in self._gen_col_aliases([annotation]):\n                    if isinstance(self.alias_map[alias], Join):\n                        raise FieldError(\n                            \"Joined field references are not permitted in this query\"\n                        )\n            if summarize:\n                # Summarize currently means we are doing an aggregate() query\n                # which is executed as a wrapped subquery if any of the\n                # aggregate() elements reference an existing annotation. In\n                # that case we need to return a Ref to the subquery's annotation.\n                if name not in self.annotation_select:\n                    raise FieldError(\n                        \"Cannot aggregate over the '%s' alias. Use annotate() \"\n                        \"to promote it.\" % name\n                    )\n                return Ref(name, self.annotation_select[name])\n            else:\n                return annotation\n        else:\n            field_list = name.split(LOOKUP_SEP)\n            annotation = self.annotations.get(field_list[0])\n            if annotation is not None:\n                for transform in field_list[1:]:\n                    annotation = self.try_transform(annotation, transform)\n                return annotation\n            join_info = self.setup_joins(\n                field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse\n            )\n            targets, final_alias, join_list = self.trim_joins(\n                join_info.targets, join_info.joins, join_info.path\n            )\n            if not allow_joins and len(join_list) > 1:\n                raise FieldError(\n                    \"Joined field references are not permitted in this query\"\n                )\n            if len(targets) > 1:\n                raise FieldError(\n                    \"Referencing multicolumn fields with F() objects isn't supported\"\n                )\n            # Verify that the last lookup in name is a field or a transform:\n            # transform_function() raises FieldError if not.\n            transform = join_info.transform_function(targets[0], final_alias)\n            if reuse is not None:\n                reuse.update(join_list)\n            return transform\n\n    def split_exclude(self, filter_expr, can_reuse, names_with_path):\n        \"\"\"\n        When doing an exclude against any kind of N-to-many relation, we need\n        to use a subquery. This method constructs the nested query, given the\n        original exclude filter (filter_expr) and the portion up to the first\n        N-to-many relation field.\n\n        For example, if the origin filter is ~Q(child__name='foo'), filter_expr\n        is ('child__name', 'foo') and can_reuse is a set of joins usable for\n        filters in the original query.\n\n        We will turn this into equivalent of:\n            WHERE NOT EXISTS(\n                SELECT 1\n                FROM child\n                WHERE name = 'foo' AND child.parent_id = parent.id\n                LIMIT 1\n            )\n        \"\"\"\n        # Generate the inner query.\n        query = self.__class__(self.model)\n        query._filtered_relations = self._filtered_relations\n        filter_lhs, filter_rhs = filter_expr\n        if isinstance(filter_rhs, OuterRef):\n            filter_rhs = OuterRef(filter_rhs)\n        elif isinstance(filter_rhs, F):\n            filter_rhs = OuterRef(filter_rhs.name)\n        query.add_filter(filter_lhs, filter_rhs)\n        query.clear_ordering(force=True)\n        # Try to have as simple as possible subquery -> trim leading joins from\n        # the subquery.\n        trimmed_prefix, contains_louter = query.trim_start(names_with_path)\n\n        col = query.select[0]\n        select_field = col.target\n        alias = col.alias\n        if alias in can_reuse:\n            pk = select_field.model._meta.pk\n            # Need to add a restriction so that outer query's filters are in effect for\n            # the subquery, too.\n            query.bump_prefix(self)\n            lookup_class = select_field.get_lookup(\"exact\")\n            # Note that the query.select[0].alias is different from alias\n            # due to bump_prefix above.\n            lookup = lookup_class(pk.get_col(query.select[0].alias), pk.get_col(alias))\n            query.where.add(lookup, AND)\n            query.external_aliases[alias] = True\n\n        lookup_class = select_field.get_lookup(\"exact\")\n        lookup = lookup_class(col, ResolvedOuterRef(trimmed_prefix))\n        query.where.add(lookup, AND)\n        condition, needed_inner = self.build_filter(Exists(query))\n\n        if contains_louter:\n            or_null_condition, _ = self.build_filter(\n                (\"%s__isnull\" % trimmed_prefix, True),\n                current_negated=True,\n                branch_negated=True,\n                can_reuse=can_reuse,\n            )\n            condition.add(or_null_condition, OR)\n            # Note that the end result will be:\n            # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.\n            # This might look crazy but due to how IN works, this seems to be\n            # correct. If the IS NOT NULL check is removed then outercol NOT\n            # IN will return UNKNOWN. If the IS NULL check is removed, then if\n            # outercol IS NULL we will not match the row.\n        return condition, needed_inner\n\n    def set_empty(self):\n        self.where.add(NothingNode(), AND)\n        for query in self.combined_queries:\n            query.set_empty()\n\n    def is_empty(self):\n        return any(isinstance(c, NothingNode) for c in self.where.children)\n\n    def set_limits(self, low=None, high=None):\n        \"\"\"\n        Adjust the limits on the rows retrieved. Use low/high to set these,\n        as it makes it more Pythonic to read and write. When the SQL query is\n        created, convert them to the appropriate offset and limit values.\n\n        Apply any limits passed in here to the existing constraints. Add low\n        to the current low value and clamp both to any existing high value.\n        \"\"\"\n        if high is not None:\n            if self.high_mark is not None:\n                self.high_mark = min(self.high_mark, self.low_mark + high)\n            else:\n                self.high_mark = self.low_mark + high\n        if low is not None:\n            if self.high_mark is not None:\n                self.low_mark = min(self.high_mark, self.low_mark + low)\n            else:\n                self.low_mark = self.low_mark + low\n\n        if self.low_mark == self.high_mark:\n            self.set_empty()\n\n    def clear_limits(self):\n        \"\"\"Clear any existing limits.\"\"\"\n        self.low_mark, self.high_mark = 0, None\n\n    @property\n    def is_sliced(self):\n        return self.low_mark != 0 or self.high_mark is not None\n\n    def has_limit_one(self):\n        return self.high_mark is not None and (self.high_mark - self.low_mark) == 1\n\n    def can_filter(self):\n        \"\"\"\n        Return True if adding filters to this instance is still possible.\n\n        Typically, this means no limits or offsets have been put on the results.\n        \"\"\"\n        return not self.is_sliced\n\n    def clear_select_clause(self):\n        \"\"\"Remove all fields from SELECT clause.\"\"\"\n        self.select = ()\n        self.default_cols = False\n        self.select_related = False\n        self.set_extra_mask(())\n        self.set_annotation_mask(())\n\n    def clear_select_fields(self):\n        \"\"\"\n        Clear the list of fields to select (but not extra_select columns).\n        Some queryset types completely replace any existing list of select\n        columns.\n        \"\"\"\n        self.select = ()\n        self.values_select = ()\n\n    def add_select_col(self, col, name):\n        self.select += (col,)\n        self.values_select += (name,)\n\n    def set_select(self, cols):\n        self.default_cols = False\n        self.select = tuple(cols)\n\n    def add_distinct_fields(self, *field_names):\n        \"\"\"\n        Add and resolve the given fields to the query's \"distinct on\" clause.\n        \"\"\"\n        self.distinct_fields = field_names\n        self.distinct = True\n\n    def add_fields(self, field_names, allow_m2m=True):\n        \"\"\"\n        Add the given (model) fields to the select set. Add the field names in\n        the order specified.\n        \"\"\"\n        alias = self.get_initial_alias()\n        opts = self.get_meta()\n\n        try:\n            cols = []\n            for name in field_names:\n                # Join promotion note - we must not remove any rows here, so\n                # if there is no existing joins, use outer join.\n                join_info = self.setup_joins(\n                    name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m\n                )\n                targets, final_alias, joins = self.trim_joins(\n                    join_info.targets,\n                    join_info.joins,\n                    join_info.path,\n                )\n                for target in targets:\n                    cols.append(join_info.transform_function(target, final_alias))\n            if cols:\n                self.set_select(cols)\n        except MultiJoin:\n            raise FieldError(\"Invalid field name: '%s'\" % name)\n        except FieldError:\n            if LOOKUP_SEP in name:\n                # For lookups spanning over relationships, show the error\n                # from the model on which the lookup failed.\n                raise\n            elif name in self.annotations:\n                raise FieldError(\n                    \"Cannot select the '%s' alias. Use annotate() to promote \"\n                    \"it.\" % name\n                )\n            else:\n                names = sorted(\n                    [\n                        *get_field_names_from_opts(opts),\n                        *self.extra,\n                        *self.annotation_select,\n                        *self._filtered_relations,\n                    ]\n                )\n                raise FieldError(\n                    \"Cannot resolve keyword %r into field. \"\n                    \"Choices are: %s\" % (name, \", \".join(names))\n                )\n\n    def add_ordering(self, *ordering):\n        \"\"\"\n        Add items from the 'ordering' sequence to the query's \"order by\"\n        clause. These items are either field names (not column names) --\n        possibly with a direction prefix ('-' or '?') -- or OrderBy\n        expressions.\n\n        If 'ordering' is empty, clear all ordering from the query.\n        \"\"\"\n        errors = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == \"?\":\n                    continue\n                if item.startswith(\"-\"):\n                    item = item[1:]\n                if item in self.annotations:\n                    continue\n                if self.extra and item in self.extra:\n                    continue\n                # names_to_path() validates the lookup. A descriptive\n                # FieldError will be raise if it's not.\n                self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n            elif not hasattr(item, \"resolve_expression\"):\n                errors.append(item)\n            if getattr(item, \"contains_aggregate\", False):\n                raise FieldError(\n                    \"Using an aggregate in order_by() without also including \"\n                    \"it in annotate() is not allowed: %s\" % item\n                )\n        if errors:\n            raise FieldError(\"Invalid order_by arguments: %s\" % errors)\n        if ordering:\n            self.order_by += ordering\n        else:\n            self.default_ordering = False\n\n    def clear_ordering(self, force=False, clear_default=True):\n        \"\"\"\n        Remove any ordering settings if the current query allows it without\n        side effects, set 'force' to True to clear the ordering regardless.\n        If 'clear_default' is True, there will be no ordering in the resulting\n        query (not even the model's default).\n        \"\"\"\n        if not force and (\n            self.is_sliced or self.distinct_fields or self.select_for_update\n        ):\n            return\n        self.order_by = ()\n        self.extra_order_by = ()\n        if clear_default:\n            self.default_ordering = False\n\n    def set_group_by(self, allow_aliases=True):\n        \"\"\"\n        Expand the GROUP BY clause required by the query.\n\n        This will usually be the set of all non-aggregate fields in the\n        return data. If the database backend supports grouping by the\n        primary key, and the query would be equivalent, the optimization\n        will be made automatically.\n        \"\"\"\n        # Column names from JOINs to check collisions with aliases.\n        if allow_aliases:\n            column_names = set()\n            seen_models = set()\n            for join in list(self.alias_map.values())[1:]:  # Skip base table.\n                model = join.join_field.related_model\n                if model not in seen_models:\n                    column_names.update(\n                        {field.column for field in model._meta.local_concrete_fields}\n                    )\n                    seen_models.add(model)\n\n        group_by = list(self.select)\n        if self.annotation_select:\n            for alias, annotation in self.annotation_select.items():\n                if not allow_aliases or alias in column_names:\n                    alias = None\n                group_by_cols = annotation.get_group_by_cols(alias=alias)\n                group_by.extend(group_by_cols)\n        self.group_by = tuple(group_by)\n\n    def add_select_related(self, fields):\n        \"\"\"\n        Set up the select_related data structure so that we only select\n        certain related models (as opposed to all models, when\n        self.select_related=True).\n        \"\"\"\n        if isinstance(self.select_related, bool):\n            field_dict = {}\n        else:\n            field_dict = self.select_related\n        for field in fields:\n            d = field_dict\n            for part in field.split(LOOKUP_SEP):\n                d = d.setdefault(part, {})\n        self.select_related = field_dict\n\n    def add_extra(self, select, select_params, where, params, tables, order_by):\n        \"\"\"\n        Add data to the various extra_* attributes for user-created additions\n        to the query.\n        \"\"\"\n        if select:\n            # We need to pair any placeholder markers in the 'select'\n            # dictionary with their parameters in 'select_params' so that\n            # subsequent updates to the select dictionary also adjust the\n            # parameters appropriately.\n            select_pairs = {}\n            if select_params:\n                param_iter = iter(select_params)\n            else:\n                param_iter = iter([])\n            for name, entry in select.items():\n                entry = str(entry)\n                entry_params = []\n                pos = entry.find(\"%s\")\n                while pos != -1:\n                    if pos == 0 or entry[pos - 1] != \"%\":\n                        entry_params.append(next(param_iter))\n                    pos = entry.find(\"%s\", pos + 2)\n                select_pairs[name] = (entry, entry_params)\n            self.extra.update(select_pairs)\n        if where or params:\n            self.where.add(ExtraWhere(where, params), AND)\n        if tables:\n            self.extra_tables += tuple(tables)\n        if order_by:\n            self.extra_order_by = order_by\n\n    def clear_deferred_loading(self):\n        \"\"\"Remove any fields from the deferred loading set.\"\"\"\n        self.deferred_loading = (frozenset(), True)\n\n    def add_deferred_loading(self, field_names):\n        \"\"\"\n        Add the given list of model field names to the set of fields to\n        exclude from loading from the database when automatic column selection\n        is done. Add the new field names to any existing field names that\n        are deferred (or removed from any existing field names that are marked\n        as the only ones for immediate loading).\n        \"\"\"\n        # Fields on related models are stored in the literal double-underscore\n        # format, so that we can use a set datastructure. We do the foo__bar\n        # splitting and handling when computing the SQL column names (as part of\n        # get_columns()).\n        existing, defer = self.deferred_loading\n        if defer:\n            # Add to existing deferred names.\n            self.deferred_loading = existing.union(field_names), True\n        else:\n            # Remove names from the set of any existing \"immediate load\" names.\n            if new_existing := existing.difference(field_names):\n                self.deferred_loading = new_existing, False\n            else:\n                self.clear_deferred_loading()\n                if new_only := set(field_names).difference(existing):\n                    self.deferred_loading = new_only, True\n\n    def add_immediate_loading(self, field_names):\n        \"\"\"\n        Add the given list of model field names to the set of fields to\n        retrieve when the SQL is executed (\"immediate loading\" fields). The\n        field names replace any existing immediate loading field names. If\n        there are field names already specified for deferred loading, remove\n        those names from the new field_names before storing the new names\n        for immediate loading. (That is, immediate loading overrides any\n        existing immediate values, but respects existing deferrals.)\n        \"\"\"\n        existing, defer = self.deferred_loading\n        field_names = set(field_names)\n        if \"pk\" in field_names:\n            field_names.remove(\"pk\")\n            field_names.add(self.get_meta().pk.name)\n\n        if defer:\n            # Remove any existing deferred names from the current set before\n            # setting the new names.\n            self.deferred_loading = field_names.difference(existing), False\n        else:\n            # Replace any existing \"immediate load\" field names.\n            self.deferred_loading = frozenset(field_names), False\n\n    def set_annotation_mask(self, names):\n        \"\"\"Set the mask of annotations that will be returned by the SELECT.\"\"\"\n        if names is None:\n            self.annotation_select_mask = None\n        else:\n            self.annotation_select_mask = set(names)\n        self._annotation_select_cache = None\n\n    def append_annotation_mask(self, names):\n        if self.annotation_select_mask is not None:\n            self.set_annotation_mask(self.annotation_select_mask.union(names))\n\n    def set_extra_mask(self, names):\n        \"\"\"\n        Set the mask of extra select items that will be returned by SELECT.\n        Don't remove them from the Query since they might be used later.\n        \"\"\"\n        if names is None:\n            self.extra_select_mask = None\n        else:\n            self.extra_select_mask = set(names)\n        self._extra_select_cache = None\n\n    def set_values(self, fields):\n        self.select_related = False\n        self.clear_deferred_loading()\n        self.clear_select_fields()\n\n        if fields:\n            field_names = []\n            extra_names = []\n            annotation_names = []\n            if not self.extra and not self.annotations:\n                # Shortcut - if there are no extra or annotations, then\n                # the values() clause must be just field names.\n                field_names = list(fields)\n            else:\n                self.default_cols = False\n                for f in fields:\n                    if f in self.extra_select:\n                        extra_names.append(f)\n                    elif f in self.annotation_select:\n                        annotation_names.append(f)\n                    else:\n                        field_names.append(f)\n            self.set_extra_mask(extra_names)\n            self.set_annotation_mask(annotation_names)\n            selected = frozenset(field_names + extra_names + annotation_names)\n        else:\n            field_names = [f.attname for f in self.model._meta.concrete_fields]\n            selected = frozenset(field_names)\n        # Selected annotations must be known before setting the GROUP BY\n        # clause.\n        if self.group_by is True:\n            self.add_fields(\n                (f.attname for f in self.model._meta.concrete_fields), False\n            )\n            # Disable GROUP BY aliases to avoid orphaning references to the\n            # SELECT clause which is about to be cleared.\n            self.set_group_by(allow_aliases=False)\n            self.clear_select_fields()\n        elif self.group_by:\n            # Resolve GROUP BY annotation references if they are not part of\n            # the selected fields anymore.\n            group_by = []\n            for expr in self.group_by:\n                if isinstance(expr, Ref) and expr.refs not in selected:\n                    expr = self.annotations[expr.refs]\n                group_by.append(expr)\n            self.group_by = tuple(group_by)\n\n        self.values_select = tuple(field_names)\n        self.add_fields(field_names, True)\n\n    @property\n    def annotation_select(self):\n        \"\"\"\n        Return the dictionary of aggregate columns that are not masked and\n        should be used in the SELECT clause. Cache this result for performance.\n        \"\"\"\n        if self._annotation_select_cache is not None:\n            return self._annotation_select_cache\n        elif not self.annotations:\n            return {}\n        elif self.annotation_select_mask is not None:\n            self._annotation_select_cache = {\n                k: v\n                for k, v in self.annotations.items()\n                if k in self.annotation_select_mask\n            }\n            return self._annotation_select_cache\n        else:\n            return self.annotations\n\n    @property\n    def extra_select(self):\n        if self._extra_select_cache is not None:\n            return self._extra_select_cache\n        if not self.extra:\n            return {}\n        elif self.extra_select_mask is not None:\n            self._extra_select_cache = {\n                k: v for k, v in self.extra.items() if k in self.extra_select_mask\n            }\n            return self._extra_select_cache\n        else:\n            return self.extra\n\n    def trim_start(self, names_with_path):\n        \"\"\"\n        Trim joins from the start of the join path. The candidates for trim\n        are the PathInfos in names_with_path structure that are m2m joins.\n\n        Also set the select column so the start matches the join.\n\n        This method is meant to be used for generating the subquery joins &\n        cols in split_exclude().\n\n        Return a lookup usable for doing outerq.filter(lookup=self) and a\n        boolean indicating if the joins in the prefix contain a LEFT OUTER join.\n        _\"\"\"\n        all_paths = []\n        for _, paths in names_with_path:\n            all_paths.extend(paths)\n        contains_louter = False\n        # Trim and operate only on tables that were generated for\n        # the lookup part of the query. That is, avoid trimming\n        # joins generated for F() expressions.\n        lookup_tables = [\n            t for t in self.alias_map if t in self._lookup_joins or t == self.base_table\n        ]\n        for trimmed_paths, path in enumerate(all_paths):\n            if path.m2m:\n                break\n            if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:\n                contains_louter = True\n            alias = lookup_tables[trimmed_paths]\n            self.unref_alias(alias)\n        # The path.join_field is a Rel, lets get the other side's field\n        join_field = path.join_field.field\n        # Build the filter prefix.\n        paths_in_prefix = trimmed_paths\n        trimmed_prefix = []\n        for name, path in names_with_path:\n            if paths_in_prefix - len(path) < 0:\n                break\n            trimmed_prefix.append(name)\n            paths_in_prefix -= len(path)\n        trimmed_prefix.append(join_field.foreign_related_fields[0].name)\n        trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)\n        # Lets still see if we can trim the first join from the inner query\n        # (that is, self). We can't do this for:\n        # - LEFT JOINs because we would miss those rows that have nothing on\n        #   the outer side,\n        # - INNER JOINs from filtered relations because we would miss their\n        #   filters.\n        first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]\n        if first_join.join_type != LOUTER and not first_join.filtered_relation:\n            select_fields = [r[0] for r in join_field.related_fields]\n            select_alias = lookup_tables[trimmed_paths + 1]\n            self.unref_alias(lookup_tables[trimmed_paths])\n            extra_restriction = join_field.get_extra_restriction(\n                None, lookup_tables[trimmed_paths + 1]\n            )\n            if extra_restriction:\n                self.where.add(extra_restriction, AND)\n        else:\n            # TODO: It might be possible to trim more joins from the start of the\n            # inner query if it happens to have a longer join chain containing the\n            # values in select_fields. Lets punt this one for now.\n            select_fields = [r[1] for r in join_field.related_fields]\n            select_alias = lookup_tables[trimmed_paths]\n        # The found starting point is likely a join_class instead of a\n        # base_table_class reference. But the first entry in the query's FROM\n        # clause must not be a JOIN.\n        for table in self.alias_map:\n            if self.alias_refcount[table] > 0:\n                self.alias_map[table] = self.base_table_class(\n                    self.alias_map[table].table_name,\n                    table,\n                )\n                break\n        self.set_select([f.get_col(select_alias) for f in select_fields])\n        return trimmed_prefix, contains_louter\n\n    def is_nullable(self, field):\n        \"\"\"\n        Check if the given field should be treated as nullable.\n\n        Some backends treat '' as null and Django treats such fields as\n        nullable for those backends. In such situations field.null can be\n        False even if we should treat the field as nullable.\n        \"\"\"\n        # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have\n        # (nor should it have) knowledge of which connection is going to be\n        # used. The proper fix would be to defer all decisions where\n        # is_nullable() is needed to the compiler stage, but that is not easy\n        # to do currently.\n        return field.null or (\n            field.empty_strings_allowed\n            and connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n        )\n\n\ndef get_order_dir(field, default=\"ASC\"):\n    \"\"\"\n    Return the field name and direction for an order specification. For\n    example, '-foo' is returned as ('foo', 'DESC').\n\n    The 'default' param is used to indicate which way no prefix (or a '+'\n    prefix) should sort. The '-' prefix always sorts the opposite way.\n    \"\"\"\n    dirn = ORDER_DIR[default]\n    if field[0] == \"-\":\n        return field[1:], dirn[1]\n    return field, dirn[0]\n\n\ndef add_to_dict(data, key, value):\n    \"\"\"\n    Add \"value\" to the set of values for \"key\", whether or not \"key\" already\n    exists.\n    \"\"\"\n    if key in data:\n        data[key].add(value)\n    else:\n        data[key] = {value}\n\n\ndef is_reverse_o2o(field):\n    \"\"\"\n    Check if the given field is reverse-o2o. The field is expected to be some\n    sort of relation field or related object.\n    \"\"\"\n    return field.is_relation and field.one_to_one and not field.concrete\n\n\nclass JoinPromoter:\n    \"\"\"\n    A class to abstract away join promotion problems for complex filter\n    conditions.\n    \"\"\"\n\n    def __init__(self, connector, num_children, negated):\n        self.connector = connector\n        self.negated = negated\n        if self.negated:\n            if connector == AND:\n                self.effective_connector = OR\n            else:\n                self.effective_connector = AND\n        else:\n            self.effective_connector = self.connector\n        self.num_children = num_children\n        # Maps of table alias to how many times it is seen as required for\n        # inner and/or outer joins.\n        self.votes = Counter()\n\n    def __repr__(self):\n        return (\n            f\"{self.__class__.__qualname__}(connector={self.connector!r}, \"\n            f\"num_children={self.num_children!r}, negated={self.negated!r})\"\n        )\n\n    def add_votes(self, votes):\n        \"\"\"\n        Add single vote per item to self.votes. Parameter can be any\n        iterable.\n        \"\"\"\n        self.votes.update(votes)\n\n    def update_join_types(self, query):\n        \"\"\"\n        Change join types so that the generated query is as efficient as\n        possible, but still correct. So, change as many joins as possible\n        to INNER, but don't make OUTER joins INNER if that could remove\n        results from the query.\n        \"\"\"\n        to_promote = set()\n        to_demote = set()\n        # The effective_connector is used so that NOT (a AND b) is treated\n        # similarly to (a OR b) for join promotion.\n        for table, votes in self.votes.items():\n            # We must use outer joins in OR case when the join isn't contained\n            # in all of the joins. Otherwise the INNER JOIN itself could remove\n            # valid results. Consider the case where a model with rel_a and\n            # rel_b relations is queried with rel_a__col=1 | rel_b__col=2. Now,\n            # if rel_a join doesn't produce any results is null (for example\n            # reverse foreign key or null value in direct foreign key), and\n            # there is a matching row in rel_b with col=2, then an INNER join\n            # to rel_a would remove a valid match from the query. So, we need\n            # to promote any existing INNER to LOUTER (it is possible this\n            # promotion in turn will be demoted later on).\n            if self.effective_connector == \"OR\" and votes < self.num_children:\n                to_promote.add(table)\n            # If connector is AND and there is a filter that can match only\n            # when there is a joinable row, then use INNER. For example, in\n            # rel_a__col=1 & rel_b__col=2, if either of the rels produce NULL\n            # as join output, then the col=1 or col=2 can't match (as\n            # NULL=anything is always false).\n            # For the OR case, if all children voted for a join to be inner,\n            # then we can use INNER for the join. For example:\n            #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)\n            # then if rel_a doesn't produce any rows, the whole condition\n            # can't match. Hence we can safely use INNER join.\n            if self.effective_connector == \"AND\" or (\n                self.effective_connector == \"OR\" and votes == self.num_children\n            ):\n                to_demote.add(table)\n            # Finally, what happens in cases where we have:\n            #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0\n            # Now, we first generate the OR clause, and promote joins for it\n            # in the first if branch above. Both rel_a and rel_b are promoted\n            # to LOUTER joins. After that we do the AND case. The OR case\n            # voted no inner joins but the rel_a__col__gte=0 votes inner join\n            # for rel_a. We demote it back to INNER join (in AND case a single\n            # vote is enough). The demotion is OK, if rel_a doesn't produce\n            # rows, then the rel_a__col__gte=0 clause can't be true, and thus\n            # the whole clause must be false. So, it is safe to use INNER\n            # join.\n            # Note that in this example we could just as well have the __gte\n            # clause and the OR clause swapped. Or we could replace the __gte\n            # clause with an OR clause containing rel_a__col=1|rel_a__col=2,\n            # and again we could safely demote to INNER.\n        query.promote_joins(to_promote)\n        query.demote_joins(to_demote)\n        return to_demote\n",
    "code_after": "\"\"\"\nCreate SQL statements for QuerySets.\n\nThe code in here encapsulates all of the SQL construction so that QuerySets\nthemselves do not have to (and could be backed by things other than SQL\ndatabases). The abstraction barrier only works one way: this module has to know\nall about the internals of models in order to get the information it needs.\n\"\"\"\nimport copy\nimport difflib\nimport functools\nimport sys\nfrom collections import Counter, namedtuple\nfrom collections.abc import Iterator, Mapping\nfrom itertools import chain, count, product\nfrom string import ascii_uppercase\n\nfrom django.core.exceptions import FieldDoesNotExist, FieldError\nfrom django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\nfrom django.db.models.aggregates import Count\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.expressions import (\n    BaseExpression,\n    Col,\n    Exists,\n    F,\n    OuterRef,\n    Ref,\n    ResolvedOuterRef,\n)\nfrom django.db.models.fields import Field\nfrom django.db.models.fields.related_lookups import MultiColSource\nfrom django.db.models.lookups import Lookup\nfrom django.db.models.query_utils import (\n    Q,\n    check_rel_lookup_compatibility,\n    refs_expression,\n)\nfrom django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\nfrom django.db.models.sql.datastructures import BaseTable, Empty, Join, MultiJoin\nfrom django.db.models.sql.where import AND, OR, ExtraWhere, NothingNode, WhereNode\nfrom django.utils.functional import cached_property\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.tree import Node\n\n__all__ = [\"Query\", \"RawQuery\"]\n\n# Quotation marks ('\"`[]), whitespace characters, semicolons, or inline\n# SQL comments are forbidden in column aliases.\nFORBIDDEN_ALIAS_PATTERN = _lazy_re_compile(r\"['`\\\"\\]\\[;\\s]|--|/\\*|\\*/\")\n\n\ndef get_field_names_from_opts(opts):\n    if opts is None:\n        return set()\n    return set(\n        chain.from_iterable(\n            (f.name, f.attname) if f.concrete else (f.name,) for f in opts.get_fields()\n        )\n    )\n\n\ndef get_children_from_q(q):\n    for child in q.children:\n        if isinstance(child, Node):\n            yield from get_children_from_q(child)\n        else:\n            yield child\n\n\nJoinInfo = namedtuple(\n    \"JoinInfo\",\n    (\"final_field\", \"targets\", \"opts\", \"joins\", \"path\", \"transform_function\"),\n)\n\n\nclass RawQuery:\n    \"\"\"A single raw SQL query.\"\"\"\n\n    def __init__(self, sql, using, params=()):\n        self.params = params\n        self.sql = sql\n        self.using = using\n        self.cursor = None\n\n        # Mirror some properties of a normal query so that\n        # the compiler can be used to process results.\n        self.low_mark, self.high_mark = 0, None  # Used for offset/limit\n        self.extra_select = {}\n        self.annotation_select = {}\n\n    def chain(self, using):\n        return self.clone(using)\n\n    def clone(self, using):\n        return RawQuery(self.sql, using, params=self.params)\n\n    def get_columns(self):\n        if self.cursor is None:\n            self._execute_query()\n        converter = connections[self.using].introspection.identifier_converter\n        return [converter(column_meta[0]) for column_meta in self.cursor.description]\n\n    def __iter__(self):\n        # Always execute a new query for a new iterator.\n        # This could be optimized with a cache at the expense of RAM.\n        self._execute_query()\n        if not connections[self.using].features.can_use_chunked_reads:\n            # If the database can't use chunked reads we need to make sure we\n            # evaluate the entire query up front.\n            result = list(self.cursor)\n        else:\n            result = self.cursor\n        return iter(result)\n\n    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self)\n\n    @property\n    def params_type(self):\n        if self.params is None:\n            return None\n        return dict if isinstance(self.params, Mapping) else tuple\n\n    def __str__(self):\n        if self.params_type is None:\n            return self.sql\n        return self.sql % self.params_type(self.params)\n\n    def _execute_query(self):\n        connection = connections[self.using]\n\n        # Adapt parameters to the database, as much as possible considering\n        # that the target type isn't known. See #17755.\n        params_type = self.params_type\n        adapter = connection.ops.adapt_unknown_value\n        if params_type is tuple:\n            params = tuple(adapter(val) for val in self.params)\n        elif params_type is dict:\n            params = {key: adapter(val) for key, val in self.params.items()}\n        elif params_type is None:\n            params = None\n        else:\n            raise RuntimeError(\"Unexpected params type: %s\" % params_type)\n\n        self.cursor = connection.cursor()\n        self.cursor.execute(self.sql, params)\n\n\nExplainInfo = namedtuple(\"ExplainInfo\", (\"format\", \"options\"))\n\n\nclass Query(BaseExpression):\n    \"\"\"A single SQL query.\"\"\"\n\n    alias_prefix = \"T\"\n    empty_result_set_value = None\n    subq_aliases = frozenset([alias_prefix])\n\n    compiler = \"SQLCompiler\"\n\n    base_table_class = BaseTable\n    join_class = Join\n\n    default_cols = True\n    default_ordering = True\n    standard_ordering = True\n\n    filter_is_sticky = False\n    subquery = False\n\n    # SQL-related attributes.\n    # Select and related select clauses are expressions to use in the SELECT\n    # clause of the query. The select is used for cases where we want to set up\n    # the select clause to contain other than default fields (values(),\n    # subqueries...). Note that annotations go to annotations dictionary.\n    select = ()\n    # The group_by attribute can have one of the following forms:\n    #  - None: no group by at all in the query\n    #  - A tuple of expressions: group by (at least) those expressions.\n    #    String refs are also allowed for now.\n    #  - True: group by all select fields of the model\n    # See compiler.get_group_by() for details.\n    group_by = None\n    order_by = ()\n    low_mark = 0  # Used for offset/limit.\n    high_mark = None  # Used for offset/limit.\n    distinct = False\n    distinct_fields = ()\n    select_for_update = False\n    select_for_update_nowait = False\n    select_for_update_skip_locked = False\n    select_for_update_of = ()\n    select_for_no_key_update = False\n    select_related = False\n    # Arbitrary limit for select_related to prevents infinite recursion.\n    max_depth = 5\n    # Holds the selects defined by a call to values() or values_list()\n    # excluding annotation_select and extra_select.\n    values_select = ()\n\n    # SQL annotation-related attributes.\n    annotation_select_mask = None\n    _annotation_select_cache = None\n\n    # Set combination attributes.\n    combinator = None\n    combinator_all = False\n    combined_queries = ()\n\n    # These are for extensions. The contents are more or less appended verbatim\n    # to the appropriate clause.\n    extra_select_mask = None\n    _extra_select_cache = None\n\n    extra_tables = ()\n    extra_order_by = ()\n\n    # A tuple that is a set of model field names and either True, if these are\n    # the fields to defer, or False if these are the only fields to load.\n    deferred_loading = (frozenset(), True)\n\n    explain_info = None\n\n    def __init__(self, model, alias_cols=True):\n        self.model = model\n        self.alias_refcount = {}\n        # alias_map is the most important data structure regarding joins.\n        # It's used for recording which joins exist in the query and what\n        # types they are. The key is the alias of the joined table (possibly\n        # the table name) and the value is a Join-like object (see\n        # sql.datastructures.Join for more information).\n        self.alias_map = {}\n        # Whether to provide alias to columns during reference resolving.\n        self.alias_cols = alias_cols\n        # Sometimes the query contains references to aliases in outer queries (as\n        # a result of split_exclude). Correct alias quoting needs to know these\n        # aliases too.\n        # Map external tables to whether they are aliased.\n        self.external_aliases = {}\n        self.table_map = {}  # Maps table names to list of aliases.\n        self.used_aliases = set()\n\n        self.where = WhereNode()\n        # Maps alias -> Annotation Expression.\n        self.annotations = {}\n        # These are for extensions. The contents are more or less appended\n        # verbatim to the appropriate clause.\n        self.extra = {}  # Maps col_alias -> (col_sql, params).\n\n        self._filtered_relations = {}\n\n    @property\n    def output_field(self):\n        if len(self.select) == 1:\n            select = self.select[0]\n            return getattr(select, \"target\", None) or select.field\n        elif len(self.annotation_select) == 1:\n            return next(iter(self.annotation_select.values())).output_field\n\n    @property\n    def has_select_fields(self):\n        return bool(\n            self.select or self.annotation_select_mask or self.extra_select_mask\n        )\n\n    @cached_property\n    def base_table(self):\n        for alias in self.alias_map:\n            return alias\n\n    def __str__(self):\n        \"\"\"\n        Return the query as a string of SQL with the parameter values\n        substituted in (use sql_with_params() to see the unsubstituted string).\n\n        Parameter values won't necessarily be quoted correctly, since that is\n        done by the database interface at execution time.\n        \"\"\"\n        sql, params = self.sql_with_params()\n        return sql % params\n\n    def sql_with_params(self):\n        \"\"\"\n        Return the query as an SQL string and the parameters that will be\n        substituted into the query.\n        \"\"\"\n        return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n\n    def __deepcopy__(self, memo):\n        \"\"\"Limit the amount of work when a Query is deepcopied.\"\"\"\n        result = self.clone()\n        memo[id(self)] = result\n        return result\n\n    def get_compiler(self, using=None, connection=None, elide_empty=True):\n        if using is None and connection is None:\n            raise ValueError(\"Need either using or connection\")\n        if using:\n            connection = connections[using]\n        return connection.ops.compiler(self.compiler)(\n            self, connection, using, elide_empty\n        )\n\n    def get_meta(self):\n        \"\"\"\n        Return the Options instance (the model._meta) from which to start\n        processing. Normally, this is self.model._meta, but it can be changed\n        by subclasses.\n        \"\"\"\n        if self.model:\n            return self.model._meta\n\n    def clone(self):\n        \"\"\"\n        Return a copy of the current Query. A lightweight alternative to\n        to deepcopy().\n        \"\"\"\n        obj = Empty()\n        obj.__class__ = self.__class__\n        # Copy references to everything.\n        obj.__dict__ = self.__dict__.copy()\n        # Clone attributes that can't use shallow copy.\n        obj.alias_refcount = self.alias_refcount.copy()\n        obj.alias_map = self.alias_map.copy()\n        obj.external_aliases = self.external_aliases.copy()\n        obj.table_map = self.table_map.copy()\n        obj.where = self.where.clone()\n        obj.annotations = self.annotations.copy()\n        if self.annotation_select_mask is not None:\n            obj.annotation_select_mask = self.annotation_select_mask.copy()\n        if self.combined_queries:\n            obj.combined_queries = tuple(\n                [query.clone() for query in self.combined_queries]\n            )\n        # _annotation_select_cache cannot be copied, as doing so breaks the\n        # (necessary) state in which both annotations and\n        # _annotation_select_cache point to the same underlying objects.\n        # It will get re-populated in the cloned queryset the next time it's\n        # used.\n        obj._annotation_select_cache = None\n        obj.extra = self.extra.copy()\n        if self.extra_select_mask is not None:\n            obj.extra_select_mask = self.extra_select_mask.copy()\n        if self._extra_select_cache is not None:\n            obj._extra_select_cache = self._extra_select_cache.copy()\n        if self.select_related is not False:\n            # Use deepcopy because select_related stores fields in nested\n            # dicts.\n            obj.select_related = copy.deepcopy(obj.select_related)\n        if \"subq_aliases\" in self.__dict__:\n            obj.subq_aliases = self.subq_aliases.copy()\n        obj.used_aliases = self.used_aliases.copy()\n        obj._filtered_relations = self._filtered_relations.copy()\n        # Clear the cached_property, if it exists.\n        obj.__dict__.pop(\"base_table\", None)\n        return obj\n\n    def chain(self, klass=None):\n        \"\"\"\n        Return a copy of the current Query that's ready for another operation.\n        The klass argument changes the type of the Query, e.g. UpdateQuery.\n        \"\"\"\n        obj = self.clone()\n        if klass and obj.__class__ != klass:\n            obj.__class__ = klass\n        if not obj.filter_is_sticky:\n            obj.used_aliases = set()\n        obj.filter_is_sticky = False\n        if hasattr(obj, \"_setup_query\"):\n            obj._setup_query()\n        return obj\n\n    def relabeled_clone(self, change_map):\n        clone = self.clone()\n        clone.change_aliases(change_map)\n        return clone\n\n    def _get_col(self, target, field, alias):\n        if not self.alias_cols:\n            alias = None\n        return target.get_col(alias, field)\n\n    def rewrite_cols(self, annotation, col_cnt):\n        # We must make sure the inner query has the referred columns in it.\n        # If we are aggregating over an annotation, then Django uses Ref()\n        # instances to note this. However, if we are annotating over a column\n        # of a related model, then it might be that column isn't part of the\n        # SELECT clause of the inner query, and we must manually make sure\n        # the column is selected. An example case is:\n        #    .aggregate(Sum('author__awards'))\n        # Resolving this expression results in a join to author, but there\n        # is no guarantee the awards column of author is in the select clause\n        # of the query. Thus we must manually add the column to the inner\n        # query.\n        orig_exprs = annotation.get_source_expressions()\n        new_exprs = []\n        for expr in orig_exprs:\n            # FIXME: These conditions are fairly arbitrary. Identify a better\n            # method of having expressions decide which code path they should\n            # take.\n            if isinstance(expr, Ref):\n                # Its already a Ref to subquery (see resolve_ref() for\n                # details)\n                new_exprs.append(expr)\n            elif isinstance(expr, (WhereNode, Lookup)):\n                # Decompose the subexpressions further. The code here is\n                # copied from the else clause, but this condition must appear\n                # before the contains_aggregate/is_summary condition below.\n                new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n                new_exprs.append(new_expr)\n            else:\n                # Reuse aliases of expressions already selected in subquery.\n                for col_alias, selected_annotation in self.annotation_select.items():\n                    if selected_annotation is expr:\n                        new_expr = Ref(col_alias, expr)\n                        break\n                else:\n                    # An expression that is not selected the subquery.\n                    if isinstance(expr, Col) or (\n                        expr.contains_aggregate and not expr.is_summary\n                    ):\n                        # Reference column or another aggregate. Select it\n                        # under a non-conflicting alias.\n                        col_cnt += 1\n                        col_alias = \"__col%d\" % col_cnt\n                        self.annotations[col_alias] = expr\n                        self.append_annotation_mask([col_alias])\n                        new_expr = Ref(col_alias, expr)\n                    else:\n                        # Some other expression not referencing database values\n                        # directly. Its subexpression might contain Cols.\n                        new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n                new_exprs.append(new_expr)\n        annotation.set_source_expressions(new_exprs)\n        return annotation, col_cnt\n\n    def get_aggregation(self, using, added_aggregate_names):\n        \"\"\"\n        Return the dictionary with the values of the existing aggregations.\n        \"\"\"\n        if not self.annotation_select:\n            return {}\n        existing_annotations = [\n            annotation\n            for alias, annotation in self.annotations.items()\n            if alias not in added_aggregate_names\n        ]\n        # Decide if we need to use a subquery.\n        #\n        # Existing annotations would cause incorrect results as get_aggregation()\n        # must produce just one result and thus must not use GROUP BY. But we\n        # aren't smart enough to remove the existing annotations from the\n        # query, so those would force us to use GROUP BY.\n        #\n        # If the query has limit or distinct, or uses set operations, then\n        # those operations must be done in a subquery so that the query\n        # aggregates on the limit and/or distinct results instead of applying\n        # the distinct and limit after the aggregation.\n        if (\n            isinstance(self.group_by, tuple)\n            or self.is_sliced\n            or existing_annotations\n            or self.distinct\n            or self.combinator\n        ):\n            from django.db.models.sql.subqueries import AggregateQuery\n\n            inner_query = self.clone()\n            inner_query.subquery = True\n            outer_query = AggregateQuery(self.model, inner_query)\n            inner_query.select_for_update = False\n            inner_query.select_related = False\n            inner_query.set_annotation_mask(self.annotation_select)\n            # Queries with distinct_fields need ordering and when a limit is\n            # applied we must take the slice from the ordered query. Otherwise\n            # no need for ordering.\n            inner_query.clear_ordering(force=False)\n            if not inner_query.distinct:\n                # If the inner query uses default select and it has some\n                # aggregate annotations, then we must make sure the inner\n                # query is grouped by the main model's primary key. However,\n                # clearing the select clause can alter results if distinct is\n                # used.\n                has_existing_aggregate_annotations = any(\n                    annotation\n                    for annotation in existing_annotations\n                    if getattr(annotation, \"contains_aggregate\", True)\n                )\n                if inner_query.default_cols and has_existing_aggregate_annotations:\n                    inner_query.group_by = (\n                        self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n                    )\n                inner_query.default_cols = False\n\n            relabels = {t: \"subquery\" for t in inner_query.alias_map}\n            relabels[None] = \"subquery\"\n            # Remove any aggregates marked for reduction from the subquery\n            # and move them to the outer AggregateQuery.\n            col_cnt = 0\n            for alias, expression in list(inner_query.annotation_select.items()):\n                annotation_select_mask = inner_query.annotation_select_mask\n                if expression.is_summary:\n                    expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)\n                    outer_query.annotations[alias] = expression.relabeled_clone(\n                        relabels\n                    )\n                    del inner_query.annotations[alias]\n                    annotation_select_mask.remove(alias)\n                # Make sure the annotation_select wont use cached results.\n                inner_query.set_annotation_mask(inner_query.annotation_select_mask)\n            if (\n                inner_query.select == ()\n                and not inner_query.default_cols\n                and not inner_query.annotation_select_mask\n            ):\n                # In case of Model.objects[0:3].count(), there would be no\n                # field selected in the inner query, yet we must use a subquery.\n                # So, make sure at least one field is selected.\n                inner_query.select = (\n                    self.model._meta.pk.get_col(inner_query.get_initial_alias()),\n                )\n        else:\n            outer_query = self\n            self.select = ()\n            self.default_cols = False\n            self.extra = {}\n\n        empty_set_result = [\n            expression.empty_result_set_value\n            for expression in outer_query.annotation_select.values()\n        ]\n        elide_empty = not any(result is NotImplemented for result in empty_set_result)\n        outer_query.clear_ordering(force=True)\n        outer_query.clear_limits()\n        outer_query.select_for_update = False\n        outer_query.select_related = False\n        compiler = outer_query.get_compiler(using, elide_empty=elide_empty)\n        result = compiler.execute_sql(SINGLE)\n        if result is None:\n            result = empty_set_result\n\n        converters = compiler.get_converters(outer_query.annotation_select.values())\n        result = next(compiler.apply_converters((result,), converters))\n\n        return dict(zip(outer_query.annotation_select, result))\n\n    def get_count(self, using):\n        \"\"\"\n        Perform a COUNT() query using the current filter constraints.\n        \"\"\"\n        obj = self.clone()\n        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n        return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n\n    def has_filters(self):\n        return self.where\n\n    def exists(self, using, limit=True):\n        q = self.clone()\n        if not q.distinct:\n            if q.group_by is True:\n                q.add_fields(\n                    (f.attname for f in self.model._meta.concrete_fields), False\n                )\n                # Disable GROUP BY aliases to avoid orphaning references to the\n                # SELECT clause which is about to be cleared.\n                q.set_group_by(allow_aliases=False)\n            q.clear_select_clause()\n        if q.combined_queries and q.combinator == \"union\":\n            limit_combined = connections[\n                using\n            ].features.supports_slicing_ordering_in_compound\n            q.combined_queries = tuple(\n                combined_query.exists(using, limit=limit_combined)\n                for combined_query in q.combined_queries\n            )\n        q.clear_ordering(force=True)\n        if limit:\n            q.set_limits(high=1)\n        q.add_extra({\"a\": 1}, None, None, None, None, None)\n        q.set_extra_mask([\"a\"])\n        return q\n\n    def has_results(self, using):\n        q = self.exists(using)\n        compiler = q.get_compiler(using=using)\n        return compiler.has_results()\n\n    def explain(self, using, format=None, **options):\n        q = self.clone()\n        q.explain_info = ExplainInfo(format, options)\n        compiler = q.get_compiler(using=using)\n        return \"\\n\".join(compiler.explain_query())\n\n    def combine(self, rhs, connector):\n        \"\"\"\n        Merge the 'rhs' query into the current one (with any 'rhs' effects\n        being applied *after* (that is, \"to the right of\") anything in the\n        current query. 'rhs' is not modified during a call to this function.\n\n        The 'connector' parameter describes how to connect filters from the\n        'rhs' query.\n        \"\"\"\n        if self.model != rhs.model:\n            raise TypeError(\"Cannot combine queries on two different base models.\")\n        if self.is_sliced:\n            raise TypeError(\"Cannot combine queries once a slice has been taken.\")\n        if self.distinct != rhs.distinct:\n            raise TypeError(\"Cannot combine a unique query with a non-unique query.\")\n        if self.distinct_fields != rhs.distinct_fields:\n            raise TypeError(\"Cannot combine queries with different distinct fields.\")\n\n        # If lhs and rhs shares the same alias prefix, it is possible to have\n        # conflicting alias changes like T4 -> T5, T5 -> T6, which might end up\n        # as T4 -> T6 while combining two querysets. To prevent this, change an\n        # alias prefix of the rhs and update current aliases accordingly,\n        # except if the alias is the base table since it must be present in the\n        # query on both sides.\n        initial_alias = self.get_initial_alias()\n        rhs.bump_prefix(self, exclude={initial_alias})\n\n        # Work out how to relabel the rhs aliases, if necessary.\n        change_map = {}\n        conjunction = connector == AND\n\n        # Determine which existing joins can be reused. When combining the\n        # query with AND we must recreate all joins for m2m filters. When\n        # combining with OR we can reuse joins. The reason is that in AND\n        # case a single row can't fulfill a condition like:\n        #     revrel__col=1 & revrel__col=2\n        # But, there might be two different related rows matching this\n        # condition. In OR case a single True is enough, so single row is\n        # enough, too.\n        #\n        # Note that we will be creating duplicate joins for non-m2m joins in\n        # the AND case. The results will be correct but this creates too many\n        # joins. This is something that could be fixed later on.\n        reuse = set() if conjunction else set(self.alias_map)\n        joinpromoter = JoinPromoter(connector, 2, False)\n        joinpromoter.add_votes(\n            j for j in self.alias_map if self.alias_map[j].join_type == INNER\n        )\n        rhs_votes = set()\n        # Now, add the joins from rhs query into the new query (skipping base\n        # table).\n        rhs_tables = list(rhs.alias_map)[1:]\n        for alias in rhs_tables:\n            join = rhs.alias_map[alias]\n            # If the left side of the join was already relabeled, use the\n            # updated alias.\n            join = join.relabeled_clone(change_map)\n            new_alias = self.join(join, reuse=reuse)\n            if join.join_type == INNER:\n                rhs_votes.add(new_alias)\n            # We can't reuse the same join again in the query. If we have two\n            # distinct joins for the same connection in rhs query, then the\n            # combined query must have two joins, too.\n            reuse.discard(new_alias)\n            if alias != new_alias:\n                change_map[alias] = new_alias\n            if not rhs.alias_refcount[alias]:\n                # The alias was unused in the rhs query. Unref it so that it\n                # will be unused in the new query, too. We have to add and\n                # unref the alias so that join promotion has information of\n                # the join type for the unused alias.\n                self.unref_alias(new_alias)\n        joinpromoter.add_votes(rhs_votes)\n        joinpromoter.update_join_types(self)\n\n        # Combine subqueries aliases to ensure aliases relabelling properly\n        # handle subqueries when combining where and select clauses.\n        self.subq_aliases |= rhs.subq_aliases\n\n        # Now relabel a copy of the rhs where-clause and add it to the current\n        # one.\n        w = rhs.where.clone()\n        w.relabel_aliases(change_map)\n        self.where.add(w, connector)\n\n        # Selection columns and extra extensions are those provided by 'rhs'.\n        if rhs.select:\n            self.set_select([col.relabeled_clone(change_map) for col in rhs.select])\n        else:\n            self.select = ()\n\n        if connector == OR:\n            # It would be nice to be able to handle this, but the queries don't\n            # really make sense (or return consistent value sets). Not worth\n            # the extra complexity when you can write a real query instead.\n            if self.extra and rhs.extra:\n                raise ValueError(\n                    \"When merging querysets using 'or', you cannot have \"\n                    \"extra(select=...) on both sides.\"\n                )\n        self.extra.update(rhs.extra)\n        extra_select_mask = set()\n        if self.extra_select_mask is not None:\n            extra_select_mask.update(self.extra_select_mask)\n        if rhs.extra_select_mask is not None:\n            extra_select_mask.update(rhs.extra_select_mask)\n        if extra_select_mask:\n            self.set_extra_mask(extra_select_mask)\n        self.extra_tables += rhs.extra_tables\n\n        # Ordering uses the 'rhs' ordering, unless it has none, in which case\n        # the current ordering is used.\n        self.order_by = rhs.order_by or self.order_by\n        self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n\n    def deferred_to_data(self, target):\n        \"\"\"\n        Convert the self.deferred_loading data structure to an alternate data\n        structure, describing the field that *will* be loaded. This is used to\n        compute the columns to select from the database and also by the\n        QuerySet class to work out which fields are being initialized on each\n        model. Models that have all their fields included aren't mentioned in\n        the result, only those that have field restrictions in place.\n\n        The \"target\" parameter is the instance that is populated (in place).\n        \"\"\"\n        field_names, defer = self.deferred_loading\n        if not field_names:\n            return\n        orig_opts = self.get_meta()\n        seen = {}\n        must_include = {orig_opts.concrete_model: {orig_opts.pk}}\n        for field_name in field_names:\n            parts = field_name.split(LOOKUP_SEP)\n            cur_model = self.model._meta.concrete_model\n            opts = orig_opts\n            for name in parts[:-1]:\n                old_model = cur_model\n                if name in self._filtered_relations:\n                    name = self._filtered_relations[name].relation_name\n                source = opts.get_field(name)\n                if is_reverse_o2o(source):\n                    cur_model = source.related_model\n                else:\n                    cur_model = source.remote_field.model\n                opts = cur_model._meta\n                # Even if we're \"just passing through\" this model, we must add\n                # both the current model's pk and the related reference field\n                # (if it's not a reverse relation) to the things we select.\n                if not is_reverse_o2o(source):\n                    must_include[old_model].add(source)\n                add_to_dict(must_include, cur_model, opts.pk)\n            field = opts.get_field(parts[-1])\n            is_reverse_object = field.auto_created and not field.concrete\n            model = field.related_model if is_reverse_object else field.model\n            model = model._meta.concrete_model\n            if model == opts.model:\n                model = cur_model\n            if not is_reverse_o2o(field):\n                add_to_dict(seen, model, field)\n\n        if defer:\n            # We need to load all fields for each model, except those that\n            # appear in \"seen\" (for all models that appear in \"seen\"). The only\n            # slight complexity here is handling fields that exist on parent\n            # models.\n            workset = {}\n            for model, values in seen.items():\n                for field in model._meta.local_fields:\n                    if field not in values:\n                        m = field.model._meta.concrete_model\n                        add_to_dict(workset, m, field)\n            for model, values in must_include.items():\n                # If we haven't included a model in workset, we don't add the\n                # corresponding must_include fields for that model, since an\n                # empty set means \"include all fields\". That's why there's no\n                # \"else\" branch here.\n                if model in workset:\n                    workset[model].update(values)\n            for model, fields in workset.items():\n                target[model] = {f.attname for f in fields}\n        else:\n            for model, values in must_include.items():\n                if model in seen:\n                    seen[model].update(values)\n                else:\n                    # As we've passed through this model, but not explicitly\n                    # included any fields, we have to make sure it's mentioned\n                    # so that only the \"must include\" fields are pulled in.\n                    seen[model] = values\n            # Now ensure that every model in the inheritance chain is mentioned\n            # in the parent list. Again, it must be mentioned to ensure that\n            # only \"must include\" fields are pulled in.\n            for model in orig_opts.get_parent_list():\n                seen.setdefault(model, set())\n            for model, fields in seen.items():\n                target[model] = {f.attname for f in fields}\n\n    def table_alias(self, table_name, create=False, filtered_relation=None):\n        \"\"\"\n        Return a table alias for the given table_name and whether this is a\n        new alias or not.\n\n        If 'create' is true, a new alias is always created. Otherwise, the\n        most recently created alias for the table (if one exists) is reused.\n        \"\"\"\n        alias_list = self.table_map.get(table_name)\n        if not create and alias_list:\n            alias = alias_list[0]\n            self.alias_refcount[alias] += 1\n            return alias, False\n\n        # Create a new alias for this table.\n        if alias_list:\n            alias = \"%s%d\" % (self.alias_prefix, len(self.alias_map) + 1)\n            alias_list.append(alias)\n        else:\n            # The first occurrence of a table uses the table name directly.\n            alias = (\n                filtered_relation.alias if filtered_relation is not None else table_name\n            )\n            self.table_map[table_name] = [alias]\n        self.alias_refcount[alias] = 1\n        return alias, True\n\n    def ref_alias(self, alias):\n        \"\"\"Increases the reference count for this alias.\"\"\"\n        self.alias_refcount[alias] += 1\n\n    def unref_alias(self, alias, amount=1):\n        \"\"\"Decreases the reference count for this alias.\"\"\"\n        self.alias_refcount[alias] -= amount\n\n    def promote_joins(self, aliases):\n        \"\"\"\n        Promote recursively the join type of given aliases and its children to\n        an outer join. If 'unconditional' is False, only promote the join if\n        it is nullable or the parent join is an outer join.\n\n        The children promotion is done to avoid join chains that contain a LOUTER\n        b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,\n        then we must also promote b->c automatically, or otherwise the promotion\n        of a->b doesn't actually change anything in the query results.\n        \"\"\"\n        aliases = list(aliases)\n        while aliases:\n            alias = aliases.pop(0)\n            if self.alias_map[alias].join_type is None:\n                # This is the base table (first FROM entry) - this table\n                # isn't really joined at all in the query, so we should not\n                # alter its join type.\n                continue\n            # Only the first alias (skipped above) should have None join_type\n            assert self.alias_map[alias].join_type is not None\n            parent_alias = self.alias_map[alias].parent_alias\n            parent_louter = (\n                parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n            )\n            already_louter = self.alias_map[alias].join_type == LOUTER\n            if (self.alias_map[alias].nullable or parent_louter) and not already_louter:\n                self.alias_map[alias] = self.alias_map[alias].promote()\n                # Join type of 'alias' changed, so re-examine all aliases that\n                # refer to this one.\n                aliases.extend(\n                    join\n                    for join in self.alias_map\n                    if self.alias_map[join].parent_alias == alias\n                    and join not in aliases\n                )\n\n    def demote_joins(self, aliases):\n        \"\"\"\n        Change join type from LOUTER to INNER for all joins in aliases.\n\n        Similarly to promote_joins(), this method must ensure no join chains\n        containing first an outer, then an inner join are generated. If we\n        are demoting b->c join in chain a LOUTER b LOUTER c then we must\n        demote a->b automatically, or otherwise the demotion of b->c doesn't\n        actually change anything in the query results. .\n        \"\"\"\n        aliases = list(aliases)\n        while aliases:\n            alias = aliases.pop(0)\n            if self.alias_map[alias].join_type == LOUTER:\n                self.alias_map[alias] = self.alias_map[alias].demote()\n                parent_alias = self.alias_map[alias].parent_alias\n                if self.alias_map[parent_alias].join_type == INNER:\n                    aliases.append(parent_alias)\n\n    def reset_refcounts(self, to_counts):\n        \"\"\"\n        Reset reference counts for aliases so that they match the value passed\n        in `to_counts`.\n        \"\"\"\n        for alias, cur_refcount in self.alias_refcount.copy().items():\n            unref_amount = cur_refcount - to_counts.get(alias, 0)\n            self.unref_alias(alias, unref_amount)\n\n    def change_aliases(self, change_map):\n        \"\"\"\n        Change the aliases in change_map (which maps old-alias -> new-alias),\n        relabelling any references to them in select columns and the where\n        clause.\n        \"\"\"\n        # If keys and values of change_map were to intersect, an alias might be\n        # updated twice (e.g. T4 -> T5, T5 -> T6, so also T4 -> T6) depending\n        # on their order in change_map.\n        assert set(change_map).isdisjoint(change_map.values())\n\n        # 1. Update references in \"select\" (normal columns plus aliases),\n        # \"group by\" and \"where\".\n        self.where.relabel_aliases(change_map)\n        if isinstance(self.group_by, tuple):\n            self.group_by = tuple(\n                [col.relabeled_clone(change_map) for col in self.group_by]\n            )\n        self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n        self.annotations = self.annotations and {\n            key: col.relabeled_clone(change_map)\n            for key, col in self.annotations.items()\n        }\n\n        # 2. Rename the alias in the internal table/alias datastructures.\n        for old_alias, new_alias in change_map.items():\n            if old_alias not in self.alias_map:\n                continue\n            alias_data = self.alias_map[old_alias].relabeled_clone(change_map)\n            self.alias_map[new_alias] = alias_data\n            self.alias_refcount[new_alias] = self.alias_refcount[old_alias]\n            del self.alias_refcount[old_alias]\n            del self.alias_map[old_alias]\n\n            table_aliases = self.table_map[alias_data.table_name]\n            for pos, alias in enumerate(table_aliases):\n                if alias == old_alias:\n                    table_aliases[pos] = new_alias\n                    break\n        self.external_aliases = {\n            # Table is aliased or it's being changed and thus is aliased.\n            change_map.get(alias, alias): (aliased or alias in change_map)\n            for alias, aliased in self.external_aliases.items()\n        }\n\n    def bump_prefix(self, other_query, exclude=None):\n        \"\"\"\n        Change the alias prefix to the next letter in the alphabet in a way\n        that the other query's aliases and this query's aliases will not\n        conflict. Even tables that previously had no alias will get an alias\n        after this call. To prevent changing aliases use the exclude parameter.\n        \"\"\"\n\n        def prefix_gen():\n            \"\"\"\n            Generate a sequence of characters in alphabetical order:\n                -> 'A', 'B', 'C', ...\n\n            When the alphabet is finished, the sequence will continue with the\n            Cartesian product:\n                -> 'AA', 'AB', 'AC', ...\n            \"\"\"\n            alphabet = ascii_uppercase\n            prefix = chr(ord(self.alias_prefix) + 1)\n            yield prefix\n            for n in count(1):\n                seq = alphabet[alphabet.index(prefix) :] if prefix else alphabet\n                for s in product(seq, repeat=n):\n                    yield \"\".join(s)\n                prefix = None\n\n        if self.alias_prefix != other_query.alias_prefix:\n            # No clashes between self and outer query should be possible.\n            return\n\n        # Explicitly avoid infinite loop. The constant divider is based on how\n        # much depth recursive subquery references add to the stack. This value\n        # might need to be adjusted when adding or removing function calls from\n        # the code path in charge of performing these operations.\n        local_recursion_limit = sys.getrecursionlimit() // 16\n        for pos, prefix in enumerate(prefix_gen()):\n            if prefix not in self.subq_aliases:\n                self.alias_prefix = prefix\n                break\n            if pos > local_recursion_limit:\n                raise RecursionError(\n                    \"Maximum recursion depth exceeded: too many subqueries.\"\n                )\n        self.subq_aliases = self.subq_aliases.union([self.alias_prefix])\n        other_query.subq_aliases = other_query.subq_aliases.union(self.subq_aliases)\n        if exclude is None:\n            exclude = {}\n        self.change_aliases(\n            {\n                alias: \"%s%d\" % (self.alias_prefix, pos)\n                for pos, alias in enumerate(self.alias_map)\n                if alias not in exclude\n            }\n        )\n\n    def get_initial_alias(self):\n        \"\"\"\n        Return the first alias for this query, after increasing its reference\n        count.\n        \"\"\"\n        if self.alias_map:\n            alias = self.base_table\n            self.ref_alias(alias)\n        elif self.model:\n            alias = self.join(self.base_table_class(self.get_meta().db_table, None))\n        else:\n            alias = None\n        return alias\n\n    def count_active_tables(self):\n        \"\"\"\n        Return the number of tables in this query with a non-zero reference\n        count. After execution, the reference counts are zeroed, so tables\n        added in compiler will not be seen by this method.\n        \"\"\"\n        return len([1 for count in self.alias_refcount.values() if count])\n\n    def join(self, join, reuse=None, reuse_with_filtered_relation=False):\n        \"\"\"\n        Return an alias for the 'join', either reusing an existing alias for\n        that join or creating a new one. 'join' is either a base_table_class or\n        join_class.\n\n        The 'reuse' parameter can be either None which means all joins are\n        reusable, or it can be a set containing the aliases that can be reused.\n\n        The 'reuse_with_filtered_relation' parameter is used when computing\n        FilteredRelation instances.\n\n        A join is always created as LOUTER if the lhs alias is LOUTER to make\n        sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new\n        joins are created as LOUTER if the join is nullable.\n        \"\"\"\n        if reuse_with_filtered_relation and reuse:\n            reuse_aliases = [\n                a for a, j in self.alias_map.items() if a in reuse and j.equals(join)\n            ]\n        else:\n            reuse_aliases = [\n                a\n                for a, j in self.alias_map.items()\n                if (reuse is None or a in reuse) and j == join\n            ]\n        if reuse_aliases:\n            if join.table_alias in reuse_aliases:\n                reuse_alias = join.table_alias\n            else:\n                # Reuse the most recent alias of the joined table\n                # (a many-to-many relation may be joined multiple times).\n                reuse_alias = reuse_aliases[-1]\n            self.ref_alias(reuse_alias)\n            return reuse_alias\n\n        # No reuse is possible, so we need a new alias.\n        alias, _ = self.table_alias(\n            join.table_name, create=True, filtered_relation=join.filtered_relation\n        )\n        if join.join_type:\n            if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n                join_type = LOUTER\n            else:\n                join_type = INNER\n            join.join_type = join_type\n        join.table_alias = alias\n        self.alias_map[alias] = join\n        return alias\n\n    def join_parent_model(self, opts, model, alias, seen):\n        \"\"\"\n        Make sure the given 'model' is joined in the query. If 'model' isn't\n        a parent of 'opts' or if it is None this method is a no-op.\n\n        The 'alias' is the root alias for starting the join, 'seen' is a dict\n        of model -> alias of existing joins. It must also contain a mapping\n        of None -> some alias. This will be returned in the no-op case.\n        \"\"\"\n        if model in seen:\n            return seen[model]\n        chain = opts.get_base_chain(model)\n        if not chain:\n            return alias\n        curr_opts = opts\n        for int_model in chain:\n            if int_model in seen:\n                curr_opts = int_model._meta\n                alias = seen[int_model]\n                continue\n            # Proxy model have elements in base chain\n            # with no parents, assign the new options\n            # object and skip to the next base in that\n            # case\n            if not curr_opts.parents[int_model]:\n                curr_opts = int_model._meta\n                continue\n            link_field = curr_opts.get_ancestor_link(int_model)\n            join_info = self.setup_joins([link_field.name], curr_opts, alias)\n            curr_opts = int_model._meta\n            alias = seen[int_model] = join_info.joins[-1]\n        return alias or seen[None]\n\n    def check_alias(self, alias):\n        if FORBIDDEN_ALIAS_PATTERN.search(alias):\n            raise ValueError(\n                \"Column aliases cannot contain whitespace characters, quotation marks, \"\n                \"semicolons, or SQL comments.\"\n            )\n\n    def add_annotation(self, annotation, alias, is_summary=False, select=True):\n        \"\"\"Add a single annotation expression to the Query.\"\"\"\n        self.check_alias(alias)\n        annotation = annotation.resolve_expression(\n            self, allow_joins=True, reuse=None, summarize=is_summary\n        )\n        if select:\n            self.append_annotation_mask([alias])\n        else:\n            self.set_annotation_mask(set(self.annotation_select).difference({alias}))\n        self.annotations[alias] = annotation\n\n    def resolve_expression(self, query, *args, **kwargs):\n        clone = self.clone()\n        # Subqueries need to use a different set of aliases than the outer query.\n        clone.bump_prefix(query)\n        clone.subquery = True\n        clone.where.resolve_expression(query, *args, **kwargs)\n        # Resolve combined queries.\n        if clone.combinator:\n            clone.combined_queries = tuple(\n                [\n                    combined_query.resolve_expression(query, *args, **kwargs)\n                    for combined_query in clone.combined_queries\n                ]\n            )\n        for key, value in clone.annotations.items():\n            resolved = value.resolve_expression(query, *args, **kwargs)\n            if hasattr(resolved, \"external_aliases\"):\n                resolved.external_aliases.update(clone.external_aliases)\n            clone.annotations[key] = resolved\n        # Outer query's aliases are considered external.\n        for alias, table in query.alias_map.items():\n            clone.external_aliases[alias] = (\n                isinstance(table, Join)\n                and table.join_field.related_model._meta.db_table != alias\n            ) or (\n                isinstance(table, BaseTable) and table.table_name != table.table_alias\n            )\n        return clone\n\n    def get_external_cols(self):\n        exprs = chain(self.annotations.values(), self.where.children)\n        return [\n            col\n            for col in self._gen_cols(exprs, include_external=True)\n            if col.alias in self.external_aliases\n        ]\n\n    def get_group_by_cols(self, alias=None):\n        if alias:\n            return [Ref(alias, self)]\n        external_cols = self.get_external_cols()\n        if any(col.possibly_multivalued for col in external_cols):\n            return [self]\n        return external_cols\n\n    def as_sql(self, compiler, connection):\n        # Some backends (e.g. Oracle) raise an error when a subquery contains\n        # unnecessary ORDER BY clause.\n        if (\n            self.subquery\n            and not connection.features.ignores_unnecessary_order_by_in_subqueries\n        ):\n            self.clear_ordering(force=False)\n        sql, params = self.get_compiler(connection=connection).as_sql()\n        if self.subquery:\n            sql = \"(%s)\" % sql\n        return sql, params\n\n    def resolve_lookup_value(self, value, can_reuse, allow_joins):\n        if hasattr(value, \"resolve_expression\"):\n            value = value.resolve_expression(\n                self,\n                reuse=can_reuse,\n                allow_joins=allow_joins,\n            )\n        elif isinstance(value, (list, tuple)):\n            # The items of the iterable may be expressions and therefore need\n            # to be resolved independently.\n            values = (\n                self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                for sub_value in value\n            )\n            type_ = type(value)\n            if hasattr(type_, \"_make\"):  # namedtuple\n                return type_(*values)\n            return type_(values)\n        return value\n\n    def solve_lookup_type(self, lookup):\n        \"\"\"\n        Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').\n        \"\"\"\n        lookup_splitted = lookup.split(LOOKUP_SEP)\n        if self.annotations:\n            expression, expression_lookups = refs_expression(\n                lookup_splitted, self.annotations\n            )\n            if expression:\n                return expression_lookups, (), expression\n        _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n        field_parts = lookup_splitted[0 : len(lookup_splitted) - len(lookup_parts)]\n        if len(lookup_parts) > 1 and not field_parts:\n            raise FieldError(\n                'Invalid lookup \"%s\" for model %s\".'\n                % (lookup, self.get_meta().model.__name__)\n            )\n        return lookup_parts, field_parts, False\n\n    def check_query_object_type(self, value, opts, field):\n        \"\"\"\n        Check whether the object passed while querying is of the correct type.\n        If not, raise a ValueError specifying the wrong object.\n        \"\"\"\n        if hasattr(value, \"_meta\"):\n            if not check_rel_lookup_compatibility(value._meta.model, opts, field):\n                raise ValueError(\n                    'Cannot query \"%s\": Must be \"%s\" instance.'\n                    % (value, opts.object_name)\n                )\n\n    def check_related_objects(self, field, value, opts):\n        \"\"\"Check the type of object passed to query relations.\"\"\"\n        if field.is_relation:\n            # Check that the field and the queryset use the same model in a\n            # query like .filter(author=Author.objects.all()). For example, the\n            # opts would be Author's (from the author field) and value.model\n            # would be Author.objects.all() queryset's .model (Author also).\n            # The field is the related field on the lhs side.\n            if (\n                isinstance(value, Query)\n                and not value.has_select_fields\n                and not check_rel_lookup_compatibility(value.model, opts, field)\n            ):\n                raise ValueError(\n                    'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".'\n                    % (value.model._meta.object_name, opts.object_name)\n                )\n            elif hasattr(value, \"_meta\"):\n                self.check_query_object_type(value, opts, field)\n            elif hasattr(value, \"__iter__\"):\n                for v in value:\n                    self.check_query_object_type(v, opts, field)\n\n    def check_filterable(self, expression):\n        \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n        if hasattr(expression, \"resolve_expression\") and not getattr(\n            expression, \"filterable\", True\n        ):\n            raise NotSupportedError(\n                expression.__class__.__name__ + \" is disallowed in the filter \"\n                \"clause.\"\n            )\n        if hasattr(expression, \"get_source_expressions\"):\n            for expr in expression.get_source_expressions():\n                self.check_filterable(expr)\n\n    def build_lookup(self, lookups, lhs, rhs):\n        \"\"\"\n        Try to extract transforms and lookup from given lhs.\n\n        The lhs value is something that works like SQLExpression.\n        The rhs value is what the lookup is going to compare against.\n        The lookups is a list of names to extract using get_lookup()\n        and get_transform().\n        \"\"\"\n        # __exact is the default lookup if one isn't given.\n        *transforms, lookup_name = lookups or [\"exact\"]\n        for name in transforms:\n            lhs = self.try_transform(lhs, name)\n        # First try get_lookup() so that the lookup takes precedence if the lhs\n        # supports both transform and lookup for the name.\n        lookup_class = lhs.get_lookup(lookup_name)\n        if not lookup_class:\n            if lhs.field.is_relation:\n                raise FieldError(\n                    \"Related Field got invalid lookup: {}\".format(lookup_name)\n                )\n            # A lookup wasn't found. Try to interpret the name as a transform\n            # and do an Exact lookup against it.\n            lhs = self.try_transform(lhs, lookup_name)\n            lookup_name = \"exact\"\n            lookup_class = lhs.get_lookup(lookup_name)\n            if not lookup_class:\n                return\n\n        lookup = lookup_class(lhs, rhs)\n        # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n        # uses of None as a query value unless the lookup supports it.\n        if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n            if lookup_name not in (\"exact\", \"iexact\"):\n                raise ValueError(\"Cannot use None as a query value\")\n            return lhs.get_lookup(\"isnull\")(lhs, True)\n\n        # For Oracle '' is equivalent to null. The check must be done at this\n        # stage because join promotion can't be done in the compiler. Using\n        # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n        # A similar thing is done in is_nullable(), too.\n        if (\n            lookup_name == \"exact\"\n            and lookup.rhs == \"\"\n            and connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n        ):\n            return lhs.get_lookup(\"isnull\")(lhs, True)\n\n        return lookup\n\n    def try_transform(self, lhs, name):\n        \"\"\"\n        Helper method for build_lookup(). Try to fetch and initialize\n        a transform for name parameter from lhs.\n        \"\"\"\n        transform_class = lhs.get_transform(name)\n        if transform_class:\n            return transform_class(lhs)\n        else:\n            output_field = lhs.output_field.__class__\n            suggested_lookups = difflib.get_close_matches(\n                name, output_field.get_lookups()\n            )\n            if suggested_lookups:\n                suggestion = \", perhaps you meant %s?\" % \" or \".join(suggested_lookups)\n            else:\n                suggestion = \".\"\n            raise FieldError(\n                \"Unsupported lookup '%s' for %s or join on the field not \"\n                \"permitted%s\" % (name, output_field.__name__, suggestion)\n            )\n\n    def build_filter(\n        self,\n        filter_expr,\n        branch_negated=False,\n        current_negated=False,\n        can_reuse=None,\n        allow_joins=True,\n        split_subq=True,\n        reuse_with_filtered_relation=False,\n        check_filterable=True,\n    ):\n        \"\"\"\n        Build a WhereNode for a single filter clause but don't add it\n        to this Query. Query.add_q() will then add this filter to the where\n        Node.\n\n        The 'branch_negated' tells us if the current branch contains any\n        negations. This will be used to determine if subqueries are needed.\n\n        The 'current_negated' is used to determine if the current filter is\n        negated or not and this will be used to determine if IS NULL filtering\n        is needed.\n\n        The difference between current_negated and branch_negated is that\n        branch_negated is set on first negation, but current_negated is\n        flipped for each negation.\n\n        Note that add_filter will not do any negating itself, that is done\n        upper in the code by add_q().\n\n        The 'can_reuse' is a set of reusable joins for multijoins.\n\n        If 'reuse_with_filtered_relation' is True, then only joins in can_reuse\n        will be reused.\n\n        The method will create a filter clause that can be added to the current\n        query. However, if the filter isn't added to the query then the caller\n        is responsible for unreffing the joins used.\n        \"\"\"\n        if isinstance(filter_expr, dict):\n            raise FieldError(\"Cannot parse keyword query as dict\")\n        if isinstance(filter_expr, Q):\n            return self._add_q(\n                filter_expr,\n                branch_negated=branch_negated,\n                current_negated=current_negated,\n                used_aliases=can_reuse,\n                allow_joins=allow_joins,\n                split_subq=split_subq,\n                check_filterable=check_filterable,\n            )\n        if hasattr(filter_expr, \"resolve_expression\"):\n            if not getattr(filter_expr, \"conditional\", False):\n                raise TypeError(\"Cannot filter against a non-conditional expression.\")\n            condition = filter_expr.resolve_expression(self, allow_joins=allow_joins)\n            if not isinstance(condition, Lookup):\n                condition = self.build_lookup([\"exact\"], condition, True)\n            return WhereNode([condition], connector=AND), []\n        arg, value = filter_expr\n        if not arg:\n            raise FieldError(\"Cannot parse keyword query %r\" % arg)\n        lookups, parts, reffed_expression = self.solve_lookup_type(arg)\n\n        if check_filterable:\n            self.check_filterable(reffed_expression)\n\n        if not allow_joins and len(parts) > 1:\n            raise FieldError(\"Joined field references are not permitted in this query\")\n\n        pre_joins = self.alias_refcount.copy()\n        value = self.resolve_lookup_value(value, can_reuse, allow_joins)\n        used_joins = {\n            k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)\n        }\n\n        if check_filterable:\n            self.check_filterable(value)\n\n        if reffed_expression:\n            condition = self.build_lookup(lookups, reffed_expression, value)\n            return WhereNode([condition], connector=AND), []\n\n        opts = self.get_meta()\n        alias = self.get_initial_alias()\n        allow_many = not branch_negated or not split_subq\n\n        try:\n            join_info = self.setup_joins(\n                parts,\n                opts,\n                alias,\n                can_reuse=can_reuse,\n                allow_many=allow_many,\n                reuse_with_filtered_relation=reuse_with_filtered_relation,\n            )\n\n            # Prevent iterator from being consumed by check_related_objects()\n            if isinstance(value, Iterator):\n                value = list(value)\n            self.check_related_objects(join_info.final_field, value, join_info.opts)\n\n            # split_exclude() needs to know which joins were generated for the\n            # lookup parts\n            self._lookup_joins = join_info.joins\n        except MultiJoin as e:\n            return self.split_exclude(filter_expr, can_reuse, e.names_with_path)\n\n        # Update used_joins before trimming since they are reused to determine\n        # which joins could be later promoted to INNER.\n        used_joins.update(join_info.joins)\n        targets, alias, join_list = self.trim_joins(\n            join_info.targets, join_info.joins, join_info.path\n        )\n        if can_reuse is not None:\n            can_reuse.update(join_list)\n\n        if join_info.final_field.is_relation:\n            # No support for transforms for relational fields\n            num_lookups = len(lookups)\n            if num_lookups > 1:\n                raise FieldError(\n                    \"Related Field got invalid lookup: {}\".format(lookups[0])\n                )\n            if len(targets) == 1:\n                col = self._get_col(targets[0], join_info.final_field, alias)\n            else:\n                col = MultiColSource(\n                    alias, targets, join_info.targets, join_info.final_field\n                )\n        else:\n            col = self._get_col(targets[0], join_info.final_field, alias)\n\n        condition = self.build_lookup(lookups, col, value)\n        lookup_type = condition.lookup_name\n        clause = WhereNode([condition], connector=AND)\n\n        require_outer = (\n            lookup_type == \"isnull\" and condition.rhs is True and not current_negated\n        )\n        if (\n            current_negated\n            and (lookup_type != \"isnull\" or condition.rhs is False)\n            and condition.rhs is not None\n        ):\n            require_outer = True\n            if lookup_type != \"isnull\":\n                # The condition added here will be SQL like this:\n                # NOT (col IS NOT NULL), where the first NOT is added in\n                # upper layers of code. The reason for addition is that if col\n                # is null, then col != someval will result in SQL \"unknown\"\n                # which isn't the same as in Python. The Python None handling\n                # is wanted, and it can be gotten by\n                # (col IS NULL OR col != someval)\n                #   <=>\n                # NOT (col IS NOT NULL AND col = someval).\n                if (\n                    self.is_nullable(targets[0])\n                    or self.alias_map[join_list[-1]].join_type == LOUTER\n                ):\n                    lookup_class = targets[0].get_lookup(\"isnull\")\n                    col = self._get_col(targets[0], join_info.targets[0], alias)\n                    clause.add(lookup_class(col, False), AND)\n                # If someval is a nullable column, someval IS NOT NULL is\n                # added.\n                if isinstance(value, Col) and self.is_nullable(value.target):\n                    lookup_class = value.target.get_lookup(\"isnull\")\n                    clause.add(lookup_class(value, False), AND)\n        return clause, used_joins if not require_outer else ()\n\n    def add_filter(self, filter_lhs, filter_rhs):\n        self.add_q(Q((filter_lhs, filter_rhs)))\n\n    def add_q(self, q_object):\n        \"\"\"\n        A preprocessor for the internal _add_q(). Responsible for doing final\n        join promotion.\n        \"\"\"\n        # For join promotion this case is doing an AND for the added q_object\n        # and existing conditions. So, any existing inner join forces the join\n        # type to remain inner. Existing outer joins can however be demoted.\n        # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if\n        # rel_a doesn't produce any rows, then the whole condition must fail.\n        # So, demotion is OK.\n        existing_inner = {\n            a for a in self.alias_map if self.alias_map[a].join_type == INNER\n        }\n        clause, _ = self._add_q(q_object, self.used_aliases)\n        if clause:\n            self.where.add(clause, AND)\n        self.demote_joins(existing_inner)\n\n    def build_where(self, filter_expr):\n        return self.build_filter(filter_expr, allow_joins=False)[0]\n\n    def clear_where(self):\n        self.where = WhereNode()\n\n    def _add_q(\n        self,\n        q_object,\n        used_aliases,\n        branch_negated=False,\n        current_negated=False,\n        allow_joins=True,\n        split_subq=True,\n        check_filterable=True,\n    ):\n        \"\"\"Add a Q-object to the current filter.\"\"\"\n        connector = q_object.connector\n        current_negated = current_negated ^ q_object.negated\n        branch_negated = branch_negated or q_object.negated\n        target_clause = WhereNode(connector=connector, negated=q_object.negated)\n        joinpromoter = JoinPromoter(\n            q_object.connector, len(q_object.children), current_negated\n        )\n        for child in q_object.children:\n            child_clause, needed_inner = self.build_filter(\n                child,\n                can_reuse=used_aliases,\n                branch_negated=branch_negated,\n                current_negated=current_negated,\n                allow_joins=allow_joins,\n                split_subq=split_subq,\n                check_filterable=check_filterable,\n            )\n            joinpromoter.add_votes(needed_inner)\n            if child_clause:\n                target_clause.add(child_clause, connector)\n        needed_inner = joinpromoter.update_join_types(self)\n        return target_clause, needed_inner\n\n    def build_filtered_relation_q(\n        self, q_object, reuse, branch_negated=False, current_negated=False\n    ):\n        \"\"\"Add a FilteredRelation object to the current filter.\"\"\"\n        connector = q_object.connector\n        current_negated ^= q_object.negated\n        branch_negated = branch_negated or q_object.negated\n        target_clause = WhereNode(connector=connector, negated=q_object.negated)\n        for child in q_object.children:\n            if isinstance(child, Node):\n                child_clause = self.build_filtered_relation_q(\n                    child,\n                    reuse=reuse,\n                    branch_negated=branch_negated,\n                    current_negated=current_negated,\n                )\n            else:\n                child_clause, _ = self.build_filter(\n                    child,\n                    can_reuse=reuse,\n                    branch_negated=branch_negated,\n                    current_negated=current_negated,\n                    allow_joins=True,\n                    split_subq=False,\n                    reuse_with_filtered_relation=True,\n                )\n            target_clause.add(child_clause, connector)\n        return target_clause\n\n    def add_filtered_relation(self, filtered_relation, alias):\n        filtered_relation.alias = alias\n        lookups = dict(get_children_from_q(filtered_relation.condition))\n        relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(\n            filtered_relation.relation_name\n        )\n        if relation_lookup_parts:\n            raise ValueError(\n                \"FilteredRelation's relation_name cannot contain lookups \"\n                \"(got %r).\" % filtered_relation.relation_name\n            )\n        for lookup in chain(lookups):\n            lookup_parts, lookup_field_parts, _ = self.solve_lookup_type(lookup)\n            shift = 2 if not lookup_parts else 1\n            lookup_field_path = lookup_field_parts[:-shift]\n            for idx, lookup_field_part in enumerate(lookup_field_path):\n                if len(relation_field_parts) > idx:\n                    if relation_field_parts[idx] != lookup_field_part:\n                        raise ValueError(\n                            \"FilteredRelation's condition doesn't support \"\n                            \"relations outside the %r (got %r).\"\n                            % (filtered_relation.relation_name, lookup)\n                        )\n                else:\n                    raise ValueError(\n                        \"FilteredRelation's condition doesn't support nested \"\n                        \"relations deeper than the relation_name (got %r for \"\n                        \"%r).\" % (lookup, filtered_relation.relation_name)\n                    )\n        self._filtered_relations[filtered_relation.alias] = filtered_relation\n\n    def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):\n        \"\"\"\n        Walk the list of names and turns them into PathInfo tuples. A single\n        name in 'names' can generate multiple PathInfos (m2m, for example).\n\n        'names' is the path of names to travel, 'opts' is the model Options we\n        start the name resolving from, 'allow_many' is as for setup_joins().\n        If fail_on_missing is set to True, then a name that can't be resolved\n        will generate a FieldError.\n\n        Return a list of PathInfo tuples. In addition return the final field\n        (the last used join field) and target (which is a field guaranteed to\n        contain the same value as the final field). Finally, return those names\n        that weren't found (which are likely transforms and the final lookup).\n        \"\"\"\n        path, names_with_path = [], []\n        for pos, name in enumerate(names):\n            cur_names_with_path = (name, [])\n            if name == \"pk\":\n                name = opts.pk.name\n\n            field = None\n            filtered_relation = None\n            try:\n                if opts is None:\n                    raise FieldDoesNotExist\n                field = opts.get_field(name)\n            except FieldDoesNotExist:\n                if name in self.annotation_select:\n                    field = self.annotation_select[name].output_field\n                elif name in self._filtered_relations and pos == 0:\n                    filtered_relation = self._filtered_relations[name]\n                    if LOOKUP_SEP in filtered_relation.relation_name:\n                        parts = filtered_relation.relation_name.split(LOOKUP_SEP)\n                        filtered_relation_path, field, _, _ = self.names_to_path(\n                            parts,\n                            opts,\n                            allow_many,\n                            fail_on_missing,\n                        )\n                        path.extend(filtered_relation_path[:-1])\n                    else:\n                        field = opts.get_field(filtered_relation.relation_name)\n            if field is not None:\n                # Fields that contain one-to-many relations with a generic\n                # model (like a GenericForeignKey) cannot generate reverse\n                # relations and therefore cannot be used for reverse querying.\n                if field.is_relation and not field.related_model:\n                    raise FieldError(\n                        \"Field %r does not generate an automatic reverse \"\n                        \"relation and therefore cannot be used for reverse \"\n                        \"querying. If it is a GenericForeignKey, consider \"\n                        \"adding a GenericRelation.\" % name\n                    )\n                try:\n                    model = field.model._meta.concrete_model\n                except AttributeError:\n                    # QuerySet.annotate() may introduce fields that aren't\n                    # attached to a model.\n                    model = None\n            else:\n                # We didn't find the current field, so move position back\n                # one step.\n                pos -= 1\n                if pos == -1 or fail_on_missing:\n                    available = sorted(\n                        [\n                            *get_field_names_from_opts(opts),\n                            *self.annotation_select,\n                            *self._filtered_relations,\n                        ]\n                    )\n                    raise FieldError(\n                        \"Cannot resolve keyword '%s' into field. \"\n                        \"Choices are: %s\" % (name, \", \".join(available))\n                    )\n                break\n            # Check if we need any joins for concrete inheritance cases (the\n            # field lives in parent, but we are currently in one of its\n            # children)\n            if opts is not None and model is not opts.model:\n                path_to_parent = opts.get_path_to_parent(model)\n                if path_to_parent:\n                    path.extend(path_to_parent)\n                    cur_names_with_path[1].extend(path_to_parent)\n                    opts = path_to_parent[-1].to_opts\n            if hasattr(field, \"path_infos\"):\n                if filtered_relation:\n                    pathinfos = field.get_path_info(filtered_relation)\n                else:\n                    pathinfos = field.path_infos\n                if not allow_many:\n                    for inner_pos, p in enumerate(pathinfos):\n                        if p.m2m:\n                            cur_names_with_path[1].extend(pathinfos[0 : inner_pos + 1])\n                            names_with_path.append(cur_names_with_path)\n                            raise MultiJoin(pos + 1, names_with_path)\n                last = pathinfos[-1]\n                path.extend(pathinfos)\n                final_field = last.join_field\n                opts = last.to_opts\n                targets = last.target_fields\n                cur_names_with_path[1].extend(pathinfos)\n                names_with_path.append(cur_names_with_path)\n            else:\n                # Local non-relational field.\n                final_field = field\n                targets = (field,)\n                if fail_on_missing and pos + 1 != len(names):\n                    raise FieldError(\n                        \"Cannot resolve keyword %r into field. Join on '%s'\"\n                        \" not permitted.\" % (names[pos + 1], name)\n                    )\n                break\n        return path, final_field, targets, names[pos + 1 :]\n\n    def setup_joins(\n        self,\n        names,\n        opts,\n        alias,\n        can_reuse=None,\n        allow_many=True,\n        reuse_with_filtered_relation=False,\n    ):\n        \"\"\"\n        Compute the necessary table joins for the passage through the fields\n        given in 'names'. 'opts' is the Options class for the current model\n        (which gives the table we are starting from), 'alias' is the alias for\n        the table to start the joining from.\n\n        The 'can_reuse' defines the reverse foreign key joins we can reuse. It\n        can be None in which case all joins are reusable or a set of aliases\n        that can be reused. Note that non-reverse foreign keys are always\n        reusable when using setup_joins().\n\n        The 'reuse_with_filtered_relation' can be used to force 'can_reuse'\n        parameter and force the relation on the given connections.\n\n        If 'allow_many' is False, then any reverse foreign key seen will\n        generate a MultiJoin exception.\n\n        Return the final field involved in the joins, the target field (used\n        for any 'where' constraint), the final 'opts' value, the joins, the\n        field path traveled to generate the joins, and a transform function\n        that takes a field and alias and is equivalent to `field.get_col(alias)`\n        in the simple case but wraps field transforms if they were included in\n        names.\n\n        The target field is the field containing the concrete value. Final\n        field can be something different, for example foreign key pointing to\n        that value. Final field is needed for example in some value\n        conversions (convert 'obj' in fk__id=obj to pk val using the foreign\n        key field for example).\n        \"\"\"\n        joins = [alias]\n        # The transform can't be applied yet, as joins must be trimmed later.\n        # To avoid making every caller of this method look up transforms\n        # directly, compute transforms here and create a partial that converts\n        # fields to the appropriate wrapped version.\n\n        def final_transformer(field, alias):\n            if not self.alias_cols:\n                alias = None\n            return field.get_col(alias)\n\n        # Try resolving all the names as fields first. If there's an error,\n        # treat trailing names as lookups until a field can be resolved.\n        last_field_exception = None\n        for pivot in range(len(names), 0, -1):\n            try:\n                path, final_field, targets, rest = self.names_to_path(\n                    names[:pivot],\n                    opts,\n                    allow_many,\n                    fail_on_missing=True,\n                )\n            except FieldError as exc:\n                if pivot == 1:\n                    # The first item cannot be a lookup, so it's safe\n                    # to raise the field error here.\n                    raise\n                else:\n                    last_field_exception = exc\n            else:\n                # The transforms are the remaining items that couldn't be\n                # resolved into fields.\n                transforms = names[pivot:]\n                break\n        for name in transforms:\n\n            def transform(field, alias, *, name, previous):\n                try:\n                    wrapped = previous(field, alias)\n                    return self.try_transform(wrapped, name)\n                except FieldError:\n                    # FieldError is raised if the transform doesn't exist.\n                    if isinstance(final_field, Field) and last_field_exception:\n                        raise last_field_exception\n                    else:\n                        raise\n\n            final_transformer = functools.partial(\n                transform, name=name, previous=final_transformer\n            )\n        # Then, add the path to the query's joins. Note that we can't trim\n        # joins at this stage - we will need the information about join type\n        # of the trimmed joins.\n        for join in path:\n            if join.filtered_relation:\n                filtered_relation = join.filtered_relation.clone()\n                table_alias = filtered_relation.alias\n            else:\n                filtered_relation = None\n                table_alias = None\n            opts = join.to_opts\n            if join.direct:\n                nullable = self.is_nullable(join.join_field)\n            else:\n                nullable = True\n            connection = self.join_class(\n                opts.db_table,\n                alias,\n                table_alias,\n                INNER,\n                join.join_field,\n                nullable,\n                filtered_relation=filtered_relation,\n            )\n            reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None\n            alias = self.join(\n                connection,\n                reuse=reuse,\n                reuse_with_filtered_relation=reuse_with_filtered_relation,\n            )\n            joins.append(alias)\n            if filtered_relation:\n                filtered_relation.path = joins[:]\n        return JoinInfo(final_field, targets, opts, joins, path, final_transformer)\n\n    def trim_joins(self, targets, joins, path):\n        \"\"\"\n        The 'target' parameter is the final field being joined to, 'joins'\n        is the full list of join aliases. The 'path' contain the PathInfos\n        used to create the joins.\n\n        Return the final target field and table alias and the new active\n        joins.\n\n        Always trim any direct join if the target column is already in the\n        previous table. Can't trim reverse joins as it's unknown if there's\n        anything on the other side of the join.\n        \"\"\"\n        joins = joins[:]\n        for pos, info in enumerate(reversed(path)):\n            if len(joins) == 1 or not info.direct:\n                break\n            if info.filtered_relation:\n                break\n            join_targets = {t.column for t in info.join_field.foreign_related_fields}\n            cur_targets = {t.column for t in targets}\n            if not cur_targets.issubset(join_targets):\n                break\n            targets_dict = {\n                r[1].column: r[0]\n                for r in info.join_field.related_fields\n                if r[1].column in cur_targets\n            }\n            targets = tuple(targets_dict[t.column] for t in targets)\n            self.unref_alias(joins.pop())\n        return targets, joins[-1], joins\n\n    @classmethod\n    def _gen_cols(cls, exprs, include_external=False):\n        for expr in exprs:\n            if isinstance(expr, Col):\n                yield expr\n            elif include_external and callable(\n                getattr(expr, \"get_external_cols\", None)\n            ):\n                yield from expr.get_external_cols()\n            elif hasattr(expr, \"get_source_expressions\"):\n                yield from cls._gen_cols(\n                    expr.get_source_expressions(),\n                    include_external=include_external,\n                )\n\n    @classmethod\n    def _gen_col_aliases(cls, exprs):\n        yield from (expr.alias for expr in cls._gen_cols(exprs))\n\n    def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):\n        annotation = self.annotations.get(name)\n        if annotation is not None:\n            if not allow_joins:\n                for alias in self._gen_col_aliases([annotation]):\n                    if isinstance(self.alias_map[alias], Join):\n                        raise FieldError(\n                            \"Joined field references are not permitted in this query\"\n                        )\n            if summarize:\n                # Summarize currently means we are doing an aggregate() query\n                # which is executed as a wrapped subquery if any of the\n                # aggregate() elements reference an existing annotation. In\n                # that case we need to return a Ref to the subquery's annotation.\n                if name not in self.annotation_select:\n                    raise FieldError(\n                        \"Cannot aggregate over the '%s' alias. Use annotate() \"\n                        \"to promote it.\" % name\n                    )\n                return Ref(name, self.annotation_select[name])\n            else:\n                return annotation\n        else:\n            field_list = name.split(LOOKUP_SEP)\n            annotation = self.annotations.get(field_list[0])\n            if annotation is not None:\n                for transform in field_list[1:]:\n                    annotation = self.try_transform(annotation, transform)\n                return annotation\n            join_info = self.setup_joins(\n                field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse\n            )\n            targets, final_alias, join_list = self.trim_joins(\n                join_info.targets, join_info.joins, join_info.path\n            )\n            if not allow_joins and len(join_list) > 1:\n                raise FieldError(\n                    \"Joined field references are not permitted in this query\"\n                )\n            if len(targets) > 1:\n                raise FieldError(\n                    \"Referencing multicolumn fields with F() objects isn't supported\"\n                )\n            # Verify that the last lookup in name is a field or a transform:\n            # transform_function() raises FieldError if not.\n            transform = join_info.transform_function(targets[0], final_alias)\n            if reuse is not None:\n                reuse.update(join_list)\n            return transform\n\n    def split_exclude(self, filter_expr, can_reuse, names_with_path):\n        \"\"\"\n        When doing an exclude against any kind of N-to-many relation, we need\n        to use a subquery. This method constructs the nested query, given the\n        original exclude filter (filter_expr) and the portion up to the first\n        N-to-many relation field.\n\n        For example, if the origin filter is ~Q(child__name='foo'), filter_expr\n        is ('child__name', 'foo') and can_reuse is a set of joins usable for\n        filters in the original query.\n\n        We will turn this into equivalent of:\n            WHERE NOT EXISTS(\n                SELECT 1\n                FROM child\n                WHERE name = 'foo' AND child.parent_id = parent.id\n                LIMIT 1\n            )\n        \"\"\"\n        # Generate the inner query.\n        query = self.__class__(self.model)\n        query._filtered_relations = self._filtered_relations\n        filter_lhs, filter_rhs = filter_expr\n        if isinstance(filter_rhs, OuterRef):\n            filter_rhs = OuterRef(filter_rhs)\n        elif isinstance(filter_rhs, F):\n            filter_rhs = OuterRef(filter_rhs.name)\n        query.add_filter(filter_lhs, filter_rhs)\n        query.clear_ordering(force=True)\n        # Try to have as simple as possible subquery -> trim leading joins from\n        # the subquery.\n        trimmed_prefix, contains_louter = query.trim_start(names_with_path)\n\n        col = query.select[0]\n        select_field = col.target\n        alias = col.alias\n        if alias in can_reuse:\n            pk = select_field.model._meta.pk\n            # Need to add a restriction so that outer query's filters are in effect for\n            # the subquery, too.\n            query.bump_prefix(self)\n            lookup_class = select_field.get_lookup(\"exact\")\n            # Note that the query.select[0].alias is different from alias\n            # due to bump_prefix above.\n            lookup = lookup_class(pk.get_col(query.select[0].alias), pk.get_col(alias))\n            query.where.add(lookup, AND)\n            query.external_aliases[alias] = True\n\n        lookup_class = select_field.get_lookup(\"exact\")\n        lookup = lookup_class(col, ResolvedOuterRef(trimmed_prefix))\n        query.where.add(lookup, AND)\n        condition, needed_inner = self.build_filter(Exists(query))\n\n        if contains_louter:\n            or_null_condition, _ = self.build_filter(\n                (\"%s__isnull\" % trimmed_prefix, True),\n                current_negated=True,\n                branch_negated=True,\n                can_reuse=can_reuse,\n            )\n            condition.add(or_null_condition, OR)\n            # Note that the end result will be:\n            # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.\n            # This might look crazy but due to how IN works, this seems to be\n            # correct. If the IS NOT NULL check is removed then outercol NOT\n            # IN will return UNKNOWN. If the IS NULL check is removed, then if\n            # outercol IS NULL we will not match the row.\n        return condition, needed_inner\n\n    def set_empty(self):\n        self.where.add(NothingNode(), AND)\n        for query in self.combined_queries:\n            query.set_empty()\n\n    def is_empty(self):\n        return any(isinstance(c, NothingNode) for c in self.where.children)\n\n    def set_limits(self, low=None, high=None):\n        \"\"\"\n        Adjust the limits on the rows retrieved. Use low/high to set these,\n        as it makes it more Pythonic to read and write. When the SQL query is\n        created, convert them to the appropriate offset and limit values.\n\n        Apply any limits passed in here to the existing constraints. Add low\n        to the current low value and clamp both to any existing high value.\n        \"\"\"\n        if high is not None:\n            if self.high_mark is not None:\n                self.high_mark = min(self.high_mark, self.low_mark + high)\n            else:\n                self.high_mark = self.low_mark + high\n        if low is not None:\n            if self.high_mark is not None:\n                self.low_mark = min(self.high_mark, self.low_mark + low)\n            else:\n                self.low_mark = self.low_mark + low\n\n        if self.low_mark == self.high_mark:\n            self.set_empty()\n\n    def clear_limits(self):\n        \"\"\"Clear any existing limits.\"\"\"\n        self.low_mark, self.high_mark = 0, None\n\n    @property\n    def is_sliced(self):\n        return self.low_mark != 0 or self.high_mark is not None\n\n    def has_limit_one(self):\n        return self.high_mark is not None and (self.high_mark - self.low_mark) == 1\n\n    def can_filter(self):\n        \"\"\"\n        Return True if adding filters to this instance is still possible.\n\n        Typically, this means no limits or offsets have been put on the results.\n        \"\"\"\n        return not self.is_sliced\n\n    def clear_select_clause(self):\n        \"\"\"Remove all fields from SELECT clause.\"\"\"\n        self.select = ()\n        self.default_cols = False\n        self.select_related = False\n        self.set_extra_mask(())\n        self.set_annotation_mask(())\n\n    def clear_select_fields(self):\n        \"\"\"\n        Clear the list of fields to select (but not extra_select columns).\n        Some queryset types completely replace any existing list of select\n        columns.\n        \"\"\"\n        self.select = ()\n        self.values_select = ()\n\n    def add_select_col(self, col, name):\n        self.select += (col,)\n        self.values_select += (name,)\n\n    def set_select(self, cols):\n        self.default_cols = False\n        self.select = tuple(cols)\n\n    def add_distinct_fields(self, *field_names):\n        \"\"\"\n        Add and resolve the given fields to the query's \"distinct on\" clause.\n        \"\"\"\n        self.distinct_fields = field_names\n        self.distinct = True\n\n    def add_fields(self, field_names, allow_m2m=True):\n        \"\"\"\n        Add the given (model) fields to the select set. Add the field names in\n        the order specified.\n        \"\"\"\n        alias = self.get_initial_alias()\n        opts = self.get_meta()\n\n        try:\n            cols = []\n            for name in field_names:\n                # Join promotion note - we must not remove any rows here, so\n                # if there is no existing joins, use outer join.\n                join_info = self.setup_joins(\n                    name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m\n                )\n                targets, final_alias, joins = self.trim_joins(\n                    join_info.targets,\n                    join_info.joins,\n                    join_info.path,\n                )\n                for target in targets:\n                    cols.append(join_info.transform_function(target, final_alias))\n            if cols:\n                self.set_select(cols)\n        except MultiJoin:\n            raise FieldError(\"Invalid field name: '%s'\" % name)\n        except FieldError:\n            if LOOKUP_SEP in name:\n                # For lookups spanning over relationships, show the error\n                # from the model on which the lookup failed.\n                raise\n            elif name in self.annotations:\n                raise FieldError(\n                    \"Cannot select the '%s' alias. Use annotate() to promote \"\n                    \"it.\" % name\n                )\n            else:\n                names = sorted(\n                    [\n                        *get_field_names_from_opts(opts),\n                        *self.extra,\n                        *self.annotation_select,\n                        *self._filtered_relations,\n                    ]\n                )\n                raise FieldError(\n                    \"Cannot resolve keyword %r into field. \"\n                    \"Choices are: %s\" % (name, \", \".join(names))\n                )\n\n    def add_ordering(self, *ordering):\n        \"\"\"\n        Add items from the 'ordering' sequence to the query's \"order by\"\n        clause. These items are either field names (not column names) --\n        possibly with a direction prefix ('-' or '?') -- or OrderBy\n        expressions.\n\n        If 'ordering' is empty, clear all ordering from the query.\n        \"\"\"\n        errors = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == \"?\":\n                    continue\n                if item.startswith(\"-\"):\n                    item = item[1:]\n                if item in self.annotations:\n                    continue\n                if self.extra and item in self.extra:\n                    continue\n                # names_to_path() validates the lookup. A descriptive\n                # FieldError will be raise if it's not.\n                self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n            elif not hasattr(item, \"resolve_expression\"):\n                errors.append(item)\n            if getattr(item, \"contains_aggregate\", False):\n                raise FieldError(\n                    \"Using an aggregate in order_by() without also including \"\n                    \"it in annotate() is not allowed: %s\" % item\n                )\n        if errors:\n            raise FieldError(\"Invalid order_by arguments: %s\" % errors)\n        if ordering:\n            self.order_by += ordering\n        else:\n            self.default_ordering = False\n\n    def clear_ordering(self, force=False, clear_default=True):\n        \"\"\"\n        Remove any ordering settings if the current query allows it without\n        side effects, set 'force' to True to clear the ordering regardless.\n        If 'clear_default' is True, there will be no ordering in the resulting\n        query (not even the model's default).\n        \"\"\"\n        if not force and (\n            self.is_sliced or self.distinct_fields or self.select_for_update\n        ):\n            return\n        self.order_by = ()\n        self.extra_order_by = ()\n        if clear_default:\n            self.default_ordering = False\n\n    def set_group_by(self, allow_aliases=True):\n        \"\"\"\n        Expand the GROUP BY clause required by the query.\n\n        This will usually be the set of all non-aggregate fields in the\n        return data. If the database backend supports grouping by the\n        primary key, and the query would be equivalent, the optimization\n        will be made automatically.\n        \"\"\"\n        # Column names from JOINs to check collisions with aliases.\n        if allow_aliases:\n            column_names = set()\n            seen_models = set()\n            for join in list(self.alias_map.values())[1:]:  # Skip base table.\n                model = join.join_field.related_model\n                if model not in seen_models:\n                    column_names.update(\n                        {field.column for field in model._meta.local_concrete_fields}\n                    )\n                    seen_models.add(model)\n\n        group_by = list(self.select)\n        if self.annotation_select:\n            for alias, annotation in self.annotation_select.items():\n                if not allow_aliases or alias in column_names:\n                    alias = None\n                group_by_cols = annotation.get_group_by_cols(alias=alias)\n                group_by.extend(group_by_cols)\n        self.group_by = tuple(group_by)\n\n    def add_select_related(self, fields):\n        \"\"\"\n        Set up the select_related data structure so that we only select\n        certain related models (as opposed to all models, when\n        self.select_related=True).\n        \"\"\"\n        if isinstance(self.select_related, bool):\n            field_dict = {}\n        else:\n            field_dict = self.select_related\n        for field in fields:\n            d = field_dict\n            for part in field.split(LOOKUP_SEP):\n                d = d.setdefault(part, {})\n        self.select_related = field_dict\n\n    def add_extra(self, select, select_params, where, params, tables, order_by):\n        \"\"\"\n        Add data to the various extra_* attributes for user-created additions\n        to the query.\n        \"\"\"\n        if select:\n            # We need to pair any placeholder markers in the 'select'\n            # dictionary with their parameters in 'select_params' so that\n            # subsequent updates to the select dictionary also adjust the\n            # parameters appropriately.\n            select_pairs = {}\n            if select_params:\n                param_iter = iter(select_params)\n            else:\n                param_iter = iter([])\n            for name, entry in select.items():\n                self.check_alias(name)\n                entry = str(entry)\n                entry_params = []\n                pos = entry.find(\"%s\")\n                while pos != -1:\n                    if pos == 0 or entry[pos - 1] != \"%\":\n                        entry_params.append(next(param_iter))\n                    pos = entry.find(\"%s\", pos + 2)\n                select_pairs[name] = (entry, entry_params)\n            self.extra.update(select_pairs)\n        if where or params:\n            self.where.add(ExtraWhere(where, params), AND)\n        if tables:\n            self.extra_tables += tuple(tables)\n        if order_by:\n            self.extra_order_by = order_by\n\n    def clear_deferred_loading(self):\n        \"\"\"Remove any fields from the deferred loading set.\"\"\"\n        self.deferred_loading = (frozenset(), True)\n\n    def add_deferred_loading(self, field_names):\n        \"\"\"\n        Add the given list of model field names to the set of fields to\n        exclude from loading from the database when automatic column selection\n        is done. Add the new field names to any existing field names that\n        are deferred (or removed from any existing field names that are marked\n        as the only ones for immediate loading).\n        \"\"\"\n        # Fields on related models are stored in the literal double-underscore\n        # format, so that we can use a set datastructure. We do the foo__bar\n        # splitting and handling when computing the SQL column names (as part of\n        # get_columns()).\n        existing, defer = self.deferred_loading\n        if defer:\n            # Add to existing deferred names.\n            self.deferred_loading = existing.union(field_names), True\n        else:\n            # Remove names from the set of any existing \"immediate load\" names.\n            if new_existing := existing.difference(field_names):\n                self.deferred_loading = new_existing, False\n            else:\n                self.clear_deferred_loading()\n                if new_only := set(field_names).difference(existing):\n                    self.deferred_loading = new_only, True\n\n    def add_immediate_loading(self, field_names):\n        \"\"\"\n        Add the given list of model field names to the set of fields to\n        retrieve when the SQL is executed (\"immediate loading\" fields). The\n        field names replace any existing immediate loading field names. If\n        there are field names already specified for deferred loading, remove\n        those names from the new field_names before storing the new names\n        for immediate loading. (That is, immediate loading overrides any\n        existing immediate values, but respects existing deferrals.)\n        \"\"\"\n        existing, defer = self.deferred_loading\n        field_names = set(field_names)\n        if \"pk\" in field_names:\n            field_names.remove(\"pk\")\n            field_names.add(self.get_meta().pk.name)\n\n        if defer:\n            # Remove any existing deferred names from the current set before\n            # setting the new names.\n            self.deferred_loading = field_names.difference(existing), False\n        else:\n            # Replace any existing \"immediate load\" field names.\n            self.deferred_loading = frozenset(field_names), False\n\n    def set_annotation_mask(self, names):\n        \"\"\"Set the mask of annotations that will be returned by the SELECT.\"\"\"\n        if names is None:\n            self.annotation_select_mask = None\n        else:\n            self.annotation_select_mask = set(names)\n        self._annotation_select_cache = None\n\n    def append_annotation_mask(self, names):\n        if self.annotation_select_mask is not None:\n            self.set_annotation_mask(self.annotation_select_mask.union(names))\n\n    def set_extra_mask(self, names):\n        \"\"\"\n        Set the mask of extra select items that will be returned by SELECT.\n        Don't remove them from the Query since they might be used later.\n        \"\"\"\n        if names is None:\n            self.extra_select_mask = None\n        else:\n            self.extra_select_mask = set(names)\n        self._extra_select_cache = None\n\n    def set_values(self, fields):\n        self.select_related = False\n        self.clear_deferred_loading()\n        self.clear_select_fields()\n\n        if fields:\n            field_names = []\n            extra_names = []\n            annotation_names = []\n            if not self.extra and not self.annotations:\n                # Shortcut - if there are no extra or annotations, then\n                # the values() clause must be just field names.\n                field_names = list(fields)\n            else:\n                self.default_cols = False\n                for f in fields:\n                    if f in self.extra_select:\n                        extra_names.append(f)\n                    elif f in self.annotation_select:\n                        annotation_names.append(f)\n                    else:\n                        field_names.append(f)\n            self.set_extra_mask(extra_names)\n            self.set_annotation_mask(annotation_names)\n            selected = frozenset(field_names + extra_names + annotation_names)\n        else:\n            field_names = [f.attname for f in self.model._meta.concrete_fields]\n            selected = frozenset(field_names)\n        # Selected annotations must be known before setting the GROUP BY\n        # clause.\n        if self.group_by is True:\n            self.add_fields(\n                (f.attname for f in self.model._meta.concrete_fields), False\n            )\n            # Disable GROUP BY aliases to avoid orphaning references to the\n            # SELECT clause which is about to be cleared.\n            self.set_group_by(allow_aliases=False)\n            self.clear_select_fields()\n        elif self.group_by:\n            # Resolve GROUP BY annotation references if they are not part of\n            # the selected fields anymore.\n            group_by = []\n            for expr in self.group_by:\n                if isinstance(expr, Ref) and expr.refs not in selected:\n                    expr = self.annotations[expr.refs]\n                group_by.append(expr)\n            self.group_by = tuple(group_by)\n\n        self.values_select = tuple(field_names)\n        self.add_fields(field_names, True)\n\n    @property\n    def annotation_select(self):\n        \"\"\"\n        Return the dictionary of aggregate columns that are not masked and\n        should be used in the SELECT clause. Cache this result for performance.\n        \"\"\"\n        if self._annotation_select_cache is not None:\n            return self._annotation_select_cache\n        elif not self.annotations:\n            return {}\n        elif self.annotation_select_mask is not None:\n            self._annotation_select_cache = {\n                k: v\n                for k, v in self.annotations.items()\n                if k in self.annotation_select_mask\n            }\n            return self._annotation_select_cache\n        else:\n            return self.annotations\n\n    @property\n    def extra_select(self):\n        if self._extra_select_cache is not None:\n            return self._extra_select_cache\n        if not self.extra:\n            return {}\n        elif self.extra_select_mask is not None:\n            self._extra_select_cache = {\n                k: v for k, v in self.extra.items() if k in self.extra_select_mask\n            }\n            return self._extra_select_cache\n        else:\n            return self.extra\n\n    def trim_start(self, names_with_path):\n        \"\"\"\n        Trim joins from the start of the join path. The candidates for trim\n        are the PathInfos in names_with_path structure that are m2m joins.\n\n        Also set the select column so the start matches the join.\n\n        This method is meant to be used for generating the subquery joins &\n        cols in split_exclude().\n\n        Return a lookup usable for doing outerq.filter(lookup=self) and a\n        boolean indicating if the joins in the prefix contain a LEFT OUTER join.\n        _\"\"\"\n        all_paths = []\n        for _, paths in names_with_path:\n            all_paths.extend(paths)\n        contains_louter = False\n        # Trim and operate only on tables that were generated for\n        # the lookup part of the query. That is, avoid trimming\n        # joins generated for F() expressions.\n        lookup_tables = [\n            t for t in self.alias_map if t in self._lookup_joins or t == self.base_table\n        ]\n        for trimmed_paths, path in enumerate(all_paths):\n            if path.m2m:\n                break\n            if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:\n                contains_louter = True\n            alias = lookup_tables[trimmed_paths]\n            self.unref_alias(alias)\n        # The path.join_field is a Rel, lets get the other side's field\n        join_field = path.join_field.field\n        # Build the filter prefix.\n        paths_in_prefix = trimmed_paths\n        trimmed_prefix = []\n        for name, path in names_with_path:\n            if paths_in_prefix - len(path) < 0:\n                break\n            trimmed_prefix.append(name)\n            paths_in_prefix -= len(path)\n        trimmed_prefix.append(join_field.foreign_related_fields[0].name)\n        trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)\n        # Lets still see if we can trim the first join from the inner query\n        # (that is, self). We can't do this for:\n        # - LEFT JOINs because we would miss those rows that have nothing on\n        #   the outer side,\n        # - INNER JOINs from filtered relations because we would miss their\n        #   filters.\n        first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]\n        if first_join.join_type != LOUTER and not first_join.filtered_relation:\n            select_fields = [r[0] for r in join_field.related_fields]\n            select_alias = lookup_tables[trimmed_paths + 1]\n            self.unref_alias(lookup_tables[trimmed_paths])\n            extra_restriction = join_field.get_extra_restriction(\n                None, lookup_tables[trimmed_paths + 1]\n            )\n            if extra_restriction:\n                self.where.add(extra_restriction, AND)\n        else:\n            # TODO: It might be possible to trim more joins from the start of the\n            # inner query if it happens to have a longer join chain containing the\n            # values in select_fields. Lets punt this one for now.\n            select_fields = [r[1] for r in join_field.related_fields]\n            select_alias = lookup_tables[trimmed_paths]\n        # The found starting point is likely a join_class instead of a\n        # base_table_class reference. But the first entry in the query's FROM\n        # clause must not be a JOIN.\n        for table in self.alias_map:\n            if self.alias_refcount[table] > 0:\n                self.alias_map[table] = self.base_table_class(\n                    self.alias_map[table].table_name,\n                    table,\n                )\n                break\n        self.set_select([f.get_col(select_alias) for f in select_fields])\n        return trimmed_prefix, contains_louter\n\n    def is_nullable(self, field):\n        \"\"\"\n        Check if the given field should be treated as nullable.\n\n        Some backends treat '' as null and Django treats such fields as\n        nullable for those backends. In such situations field.null can be\n        False even if we should treat the field as nullable.\n        \"\"\"\n        # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have\n        # (nor should it have) knowledge of which connection is going to be\n        # used. The proper fix would be to defer all decisions where\n        # is_nullable() is needed to the compiler stage, but that is not easy\n        # to do currently.\n        return field.null or (\n            field.empty_strings_allowed\n            and connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls\n        )\n\n\ndef get_order_dir(field, default=\"ASC\"):\n    \"\"\"\n    Return the field name and direction for an order specification. For\n    example, '-foo' is returned as ('foo', 'DESC').\n\n    The 'default' param is used to indicate which way no prefix (or a '+'\n    prefix) should sort. The '-' prefix always sorts the opposite way.\n    \"\"\"\n    dirn = ORDER_DIR[default]\n    if field[0] == \"-\":\n        return field[1:], dirn[1]\n    return field, dirn[0]\n\n\ndef add_to_dict(data, key, value):\n    \"\"\"\n    Add \"value\" to the set of values for \"key\", whether or not \"key\" already\n    exists.\n    \"\"\"\n    if key in data:\n        data[key].add(value)\n    else:\n        data[key] = {value}\n\n\ndef is_reverse_o2o(field):\n    \"\"\"\n    Check if the given field is reverse-o2o. The field is expected to be some\n    sort of relation field or related object.\n    \"\"\"\n    return field.is_relation and field.one_to_one and not field.concrete\n\n\nclass JoinPromoter:\n    \"\"\"\n    A class to abstract away join promotion problems for complex filter\n    conditions.\n    \"\"\"\n\n    def __init__(self, connector, num_children, negated):\n        self.connector = connector\n        self.negated = negated\n        if self.negated:\n            if connector == AND:\n                self.effective_connector = OR\n            else:\n                self.effective_connector = AND\n        else:\n            self.effective_connector = self.connector\n        self.num_children = num_children\n        # Maps of table alias to how many times it is seen as required for\n        # inner and/or outer joins.\n        self.votes = Counter()\n\n    def __repr__(self):\n        return (\n            f\"{self.__class__.__qualname__}(connector={self.connector!r}, \"\n            f\"num_children={self.num_children!r}, negated={self.negated!r})\"\n        )\n\n    def add_votes(self, votes):\n        \"\"\"\n        Add single vote per item to self.votes. Parameter can be any\n        iterable.\n        \"\"\"\n        self.votes.update(votes)\n\n    def update_join_types(self, query):\n        \"\"\"\n        Change join types so that the generated query is as efficient as\n        possible, but still correct. So, change as many joins as possible\n        to INNER, but don't make OUTER joins INNER if that could remove\n        results from the query.\n        \"\"\"\n        to_promote = set()\n        to_demote = set()\n        # The effective_connector is used so that NOT (a AND b) is treated\n        # similarly to (a OR b) for join promotion.\n        for table, votes in self.votes.items():\n            # We must use outer joins in OR case when the join isn't contained\n            # in all of the joins. Otherwise the INNER JOIN itself could remove\n            # valid results. Consider the case where a model with rel_a and\n            # rel_b relations is queried with rel_a__col=1 | rel_b__col=2. Now,\n            # if rel_a join doesn't produce any results is null (for example\n            # reverse foreign key or null value in direct foreign key), and\n            # there is a matching row in rel_b with col=2, then an INNER join\n            # to rel_a would remove a valid match from the query. So, we need\n            # to promote any existing INNER to LOUTER (it is possible this\n            # promotion in turn will be demoted later on).\n            if self.effective_connector == \"OR\" and votes < self.num_children:\n                to_promote.add(table)\n            # If connector is AND and there is a filter that can match only\n            # when there is a joinable row, then use INNER. For example, in\n            # rel_a__col=1 & rel_b__col=2, if either of the rels produce NULL\n            # as join output, then the col=1 or col=2 can't match (as\n            # NULL=anything is always false).\n            # For the OR case, if all children voted for a join to be inner,\n            # then we can use INNER for the join. For example:\n            #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)\n            # then if rel_a doesn't produce any rows, the whole condition\n            # can't match. Hence we can safely use INNER join.\n            if self.effective_connector == \"AND\" or (\n                self.effective_connector == \"OR\" and votes == self.num_children\n            ):\n                to_demote.add(table)\n            # Finally, what happens in cases where we have:\n            #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0\n            # Now, we first generate the OR clause, and promote joins for it\n            # in the first if branch above. Both rel_a and rel_b are promoted\n            # to LOUTER joins. After that we do the AND case. The OR case\n            # voted no inner joins but the rel_a__col__gte=0 votes inner join\n            # for rel_a. We demote it back to INNER join (in AND case a single\n            # vote is enough). The demotion is OK, if rel_a doesn't produce\n            # rows, then the rel_a__col__gte=0 clause can't be true, and thus\n            # the whole clause must be false. So, it is safe to use INNER\n            # join.\n            # Note that in this example we could just as well have the __gte\n            # clause and the OR clause swapped. Or we could replace the __gte\n            # clause with an OR clause containing rel_a__col=1|rel_a__col=2,\n            # and again we could safely demote to INNER.\n        query.promote_joins(to_promote)\n        query.demote_joins(to_demote)\n        return to_demote\n"
  },
  {
    "patch": "diff --git a/django/http/multipartparser.py b/django/http/multipartparser.py\nindex c3cb90e639..ef0b339d1b 100644\n--- a/django/http/multipartparser.py\n+++ b/django/http/multipartparser.py\n@@ -248,6 +248,8 @@ class MultiPartParser:\n                                 remaining = len(stripped_chunk) % 4\n                                 while remaining != 0:\n                                     over_chunk = field_stream.read(4 - remaining)\n+                                    if not over_chunk:\n+                                        break\n                                     stripped_chunk += b\"\".join(over_chunk.split())\n                                     remaining = len(stripped_chunk) % 4\n \n",
    "commit_message": "Fixed CVE-2022-23833 -- Fixed DoS possiblity in file uploads.\n\nThanks Alan Ryan for the report and initial patch.\n\n",
    "code_before": "\"\"\"\nMulti-part parsing for file uploads.\n\nExposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to\nfile upload handlers for processing.\n\"\"\"\nimport base64\nimport binascii\nimport cgi\nimport collections\nimport html\nfrom urllib.parse import unquote\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    RequestDataTooBig, SuspiciousMultipartForm, TooManyFieldsSent,\n)\nfrom django.core.files.uploadhandler import (\n    SkipFile, StopFutureHandlers, StopUpload,\n)\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_str\n\n__all__ = ('MultiPartParser', 'MultiPartParserError', 'InputStreamExhausted')\n\n\nclass MultiPartParserError(Exception):\n    pass\n\n\nclass InputStreamExhausted(Exception):\n    \"\"\"\n    No more reads are allowed from this device.\n    \"\"\"\n    pass\n\n\nRAW = \"raw\"\nFILE = \"file\"\nFIELD = \"field\"\n\n\nclass MultiPartParser:\n    \"\"\"\n    A rfc2388 multipart/form-data parser.\n\n    ``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks\n    and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``.\n    \"\"\"\n    def __init__(self, META, input_data, upload_handlers, encoding=None):\n        \"\"\"\n        Initialize the MultiPartParser object.\n\n        :META:\n            The standard ``META`` dictionary in Django request objects.\n        :input_data:\n            The raw post data, as a file-like object.\n        :upload_handlers:\n            A list of UploadHandler instances that perform operations on the\n            uploaded data.\n        :encoding:\n            The encoding with which to treat the incoming data.\n        \"\"\"\n        # Content-Type should contain multipart and the boundary information.\n        content_type = META.get('CONTENT_TYPE', '')\n        if not content_type.startswith('multipart/'):\n            raise MultiPartParserError('Invalid Content-Type: %s' % content_type)\n\n        # Parse the header to get the boundary to split the parts.\n        try:\n            ctypes, opts = parse_header(content_type.encode('ascii'))\n        except UnicodeEncodeError:\n            raise MultiPartParserError('Invalid non-ASCII Content-Type in multipart: %s' % force_str(content_type))\n        boundary = opts.get('boundary')\n        if not boundary or not cgi.valid_boundary(boundary):\n            raise MultiPartParserError('Invalid boundary in multipart: %s' % force_str(boundary))\n\n        # Content-Length should contain the length of the body we are about\n        # to receive.\n        try:\n            content_length = int(META.get('CONTENT_LENGTH', 0))\n        except (ValueError, TypeError):\n            content_length = 0\n\n        if content_length < 0:\n            # This means we shouldn't continue...raise an error.\n            raise MultiPartParserError(\"Invalid content length: %r\" % content_length)\n\n        if isinstance(boundary, str):\n            boundary = boundary.encode('ascii')\n        self._boundary = boundary\n        self._input_data = input_data\n\n        # For compatibility with low-level network APIs (with 32-bit integers),\n        # the chunk size should be < 2^31, but still divisible by 4.\n        possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size]\n        self._chunk_size = min([2 ** 31 - 4] + possible_sizes)\n\n        self._meta = META\n        self._encoding = encoding or settings.DEFAULT_CHARSET\n        self._content_length = content_length\n        self._upload_handlers = upload_handlers\n\n    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n\n    def handle_file_complete(self, old_field_name, counters):\n        \"\"\"\n        Handle all the signaling that takes place when a file is complete.\n        \"\"\"\n        for i, handler in enumerate(self._upload_handlers):\n            file_obj = handler.file_complete(counters[i])\n            if file_obj:\n                # If it returns a file object, then set the files dict.\n                self._files.appendlist(force_str(old_field_name, self._encoding, errors='replace'), file_obj)\n                break\n\n    def sanitize_file_name(self, file_name):\n        \"\"\"\n        Sanitize the filename of an upload.\n\n        Remove all possible path separators, even though that might remove more\n        than actually required by the target system. Filenames that could\n        potentially cause problems (current/parent dir) are also discarded.\n\n        It should be noted that this function could still return a \"filepath\"\n        like \"C:some_file.txt\" which is handled later on by the storage layer.\n        So while this function does sanitize filenames to some extent, the\n        resulting filename should still be considered as untrusted user input.\n        \"\"\"\n        file_name = html.unescape(file_name)\n        file_name = file_name.rsplit('/')[-1]\n        file_name = file_name.rsplit('\\\\')[-1]\n        # Remove non-printable characters.\n        file_name = ''.join([char for char in file_name if char.isprintable()])\n\n        if file_name in {'', '.', '..'}:\n            return None\n        return file_name\n\n    IE_sanitize = sanitize_file_name\n\n    def _close_files(self):\n        # Free up all file handles.\n        # FIXME: this currently assumes that upload handlers store the file as 'file'\n        # We should document that... (Maybe add handler.free_file to complement new_file)\n        for handler in self._upload_handlers:\n            if hasattr(handler, 'file'):\n                handler.file.close()\n\n\nclass LazyStream:\n    \"\"\"\n    The LazyStream wrapper allows one to get and \"unget\" bytes from a stream.\n\n    Given a producer object (an iterator that yields bytestrings), the\n    LazyStream object will support iteration, reading, and keeping a \"look-back\"\n    variable in case you need to \"unget\" some bytes.\n    \"\"\"\n    def __init__(self, producer, length=None):\n        \"\"\"\n        Every LazyStream must have a producer when instantiated.\n\n        A producer is an iterable that returns a string each time it\n        is called.\n        \"\"\"\n        self._producer = producer\n        self._empty = False\n        self._leftover = b''\n        self.length = length\n        self.position = 0\n        self._remaining = length\n        self._unget_history = []\n\n    def tell(self):\n        return self.position\n\n    def read(self, size=None):\n        def parts():\n            remaining = self._remaining if size is None else size\n            # do the whole thing in one shot if no limit was provided.\n            if remaining is None:\n                yield b''.join(self)\n                return\n\n            # otherwise do some bookkeeping to return exactly enough\n            # of the stream and stashing any extra content we get from\n            # the producer\n            while remaining != 0:\n                assert remaining > 0, 'remaining bytes to read should never go negative'\n\n                try:\n                    chunk = next(self)\n                except StopIteration:\n                    return\n                else:\n                    emitting = chunk[:remaining]\n                    self.unget(chunk[remaining:])\n                    remaining -= len(emitting)\n                    yield emitting\n\n        return b''.join(parts())\n\n    def __next__(self):\n        \"\"\"\n        Used when the exact number of bytes to read is unimportant.\n\n        Return whatever chunk is conveniently returned from the iterator.\n        Useful to avoid unnecessary bookkeeping if performance is an issue.\n        \"\"\"\n        if self._leftover:\n            output = self._leftover\n            self._leftover = b''\n        else:\n            output = next(self._producer)\n            self._unget_history = []\n        self.position += len(output)\n        return output\n\n    def close(self):\n        \"\"\"\n        Used to invalidate/disable this lazy stream.\n\n        Replace the producer with an empty list. Any leftover bytes that have\n        already been read will still be reported upon read() and/or next().\n        \"\"\"\n        self._producer = []\n\n    def __iter__(self):\n        return self\n\n    def unget(self, bytes):\n        \"\"\"\n        Place bytes back onto the front of the lazy stream.\n\n        Future calls to read() will return those bytes first. The\n        stream position and thus tell() will be rewound.\n        \"\"\"\n        if not bytes:\n            return\n        self._update_unget_history(len(bytes))\n        self.position -= len(bytes)\n        self._leftover = bytes + self._leftover\n\n    def _update_unget_history(self, num_bytes):\n        \"\"\"\n        Update the unget history as a sanity check to see if we've pushed\n        back the same number of bytes in one chunk. If we keep ungetting the\n        same number of bytes many times (here, 50), we're mostly likely in an\n        infinite loop of some sort. This is usually caused by a\n        maliciously-malformed MIME request.\n        \"\"\"\n        self._unget_history = [num_bytes] + self._unget_history[:49]\n        number_equal = len([\n            current_number for current_number in self._unget_history\n            if current_number == num_bytes\n        ])\n\n        if number_equal > 40:\n            raise SuspiciousMultipartForm(\n                \"The multipart parser got stuck, which shouldn't happen with\"\n                \" normal uploaded files. Check for malicious upload activity;\"\n                \" if there is none, report this to the Django developers.\"\n            )\n\n\nclass ChunkIter:\n    \"\"\"\n    An iterable that will yield chunks of data. Given a file-like object as the\n    constructor, yield chunks of read operations from that object.\n    \"\"\"\n    def __init__(self, flo, chunk_size=64 * 1024):\n        self.flo = flo\n        self.chunk_size = chunk_size\n\n    def __next__(self):\n        try:\n            data = self.flo.read(self.chunk_size)\n        except InputStreamExhausted:\n            raise StopIteration()\n        if data:\n            return data\n        else:\n            raise StopIteration()\n\n    def __iter__(self):\n        return self\n\n\nclass InterBoundaryIter:\n    \"\"\"\n    A Producer that will iterate over boundaries.\n    \"\"\"\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return LazyStream(BoundaryIter(self._stream, self._boundary))\n        except InputStreamExhausted:\n            raise StopIteration()\n\n\nclass BoundaryIter:\n    \"\"\"\n    A Producer that is sensitive to boundaries.\n\n    Will happily yield bytes until a boundary is found. Will yield the bytes\n    before the boundary, throw away the boundary bytes themselves, and push the\n    post-boundary bytes back on the stream.\n\n    The future calls to next() after locating the boundary will raise a\n    StopIteration exception.\n    \"\"\"\n\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n        self._done = False\n        # rollback an additional six bytes because the format is like\n        # this: CRLF<boundary>[--CRLF]\n        self._rollback = len(boundary) + 6\n\n        # Try to use mx fast string search if available. Otherwise\n        # use Python find. Wrap the latter for consistency.\n        unused_char = self._stream.read(1)\n        if not unused_char:\n            raise InputStreamExhausted()\n        self._stream.unget(unused_char)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._done:\n            raise StopIteration()\n\n        stream = self._stream\n        rollback = self._rollback\n\n        bytes_read = 0\n        chunks = []\n        for bytes in stream:\n            bytes_read += len(bytes)\n            chunks.append(bytes)\n            if bytes_read > rollback:\n                break\n            if not bytes:\n                break\n        else:\n            self._done = True\n\n        if not chunks:\n            raise StopIteration()\n\n        chunk = b''.join(chunks)\n        boundary = self._find_boundary(chunk)\n\n        if boundary:\n            end, next = boundary\n            stream.unget(chunk[next:])\n            self._done = True\n            return chunk[:end]\n        else:\n            # make sure we don't treat a partial boundary (and\n            # its separators) as data\n            if not chunk[:-rollback]:  # and len(chunk) >= (len(self._boundary) + 6):\n                # There's nothing left, we should just return and mark as done.\n                self._done = True\n                return chunk\n            else:\n                stream.unget(chunk[-rollback:])\n                return chunk[:-rollback]\n\n    def _find_boundary(self, data):\n        \"\"\"\n        Find a multipart boundary in data.\n\n        Should no boundary exist in the data, return None. Otherwise, return\n        a tuple containing the indices of the following:\n         * the end of current encapsulation\n         * the start of the next encapsulation\n        \"\"\"\n        index = data.find(self._boundary)\n        if index < 0:\n            return None\n        else:\n            end = index\n            next = index + len(self._boundary)\n            # backup over CRLF\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\n':\n                end -= 1\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\r':\n                end -= 1\n            return end, next\n\n\ndef exhaust(stream_or_iterable):\n    \"\"\"Exhaust an iterator or stream.\"\"\"\n    try:\n        iterator = iter(stream_or_iterable)\n    except TypeError:\n        iterator = ChunkIter(stream_or_iterable, 16384)\n    collections.deque(iterator, maxlen=0)  # consume iterator quickly.\n\n\ndef parse_boundary_stream(stream, max_header_size):\n    \"\"\"\n    Parse one and exactly one stream that encapsulates a boundary.\n    \"\"\"\n    # Stream at beginning of header, look for end of header\n    # and parse it if found. The header must fit within one\n    # chunk.\n    chunk = stream.read(max_header_size)\n\n    # 'find' returns the top of these four bytes, so we'll\n    # need to munch them later to prevent them from polluting\n    # the payload.\n    header_end = chunk.find(b'\\r\\n\\r\\n')\n\n    def _parse_header(line):\n        main_value_pair, params = parse_header(line)\n        try:\n            name, value = main_value_pair.split(':', 1)\n        except ValueError:\n            raise ValueError(\"Invalid header: %r\" % line)\n        return name, (value, params)\n\n    if header_end == -1:\n        # we find no header, so we just mark this fact and pass on\n        # the stream verbatim\n        stream.unget(chunk)\n        return (RAW, {}, stream)\n\n    header = chunk[:header_end]\n\n    # here we place any excess chunk back onto the stream, as\n    # well as throwing away the CRLFCRLF bytes from above.\n    stream.unget(chunk[header_end + 4:])\n\n    TYPE = RAW\n    outdict = {}\n\n    # Eliminate blank lines\n    for line in header.split(b'\\r\\n'):\n        # This terminology (\"main value\" and \"dictionary of\n        # parameters\") is from the Python docs.\n        try:\n            name, (value, params) = _parse_header(line)\n        except ValueError:\n            continue\n\n        if name == 'content-disposition':\n            TYPE = FIELD\n            if params.get('filename'):\n                TYPE = FILE\n\n        outdict[name] = value, params\n\n    if TYPE == RAW:\n        stream.unget(chunk)\n\n    return (TYPE, outdict, stream)\n\n\nclass Parser:\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._separator = b'--' + boundary\n\n    def __iter__(self):\n        boundarystream = InterBoundaryIter(self._stream, self._separator)\n        for sub_stream in boundarystream:\n            # Iterate over each part\n            yield parse_boundary_stream(sub_stream, 1024)\n\n\ndef parse_header(line):\n    \"\"\"\n    Parse the header into a key-value.\n\n    Input (line): bytes, output: str for key/name, bytes for values which\n    will be decoded later.\n    \"\"\"\n    plist = _parse_header_params(b';' + line)\n    key = plist.pop(0).lower().decode('ascii')\n    pdict = {}\n    for p in plist:\n        i = p.find(b'=')\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower().decode('ascii')\n            if name.endswith('*'):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # https://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(b\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1:].strip()\n            if len(value) >= 2 and value[:1] == value[-1:] == b'\"':\n                value = value[1:-1]\n                value = value.replace(b'\\\\\\\\', b'\\\\').replace(b'\\\\\"', b'\"')\n            if has_encoding:\n                encoding, lang, value = value.split(b\"'\")\n                value = unquote(value.decode(), encoding=encoding.decode())\n            pdict[name] = value\n    return key, pdict\n\n\ndef _parse_header_params(s):\n    plist = []\n    while s[:1] == b';':\n        s = s[1:]\n        end = s.find(b';')\n        while end > 0 and s.count(b'\"', 0, end) % 2:\n            end = s.find(b';', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        plist.append(f.strip())\n        s = s[end:]\n    return plist\n",
    "code_after": "\"\"\"\nMulti-part parsing for file uploads.\n\nExposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to\nfile upload handlers for processing.\n\"\"\"\nimport base64\nimport binascii\nimport cgi\nimport collections\nimport html\nfrom urllib.parse import unquote\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    RequestDataTooBig, SuspiciousMultipartForm, TooManyFieldsSent,\n)\nfrom django.core.files.uploadhandler import (\n    SkipFile, StopFutureHandlers, StopUpload,\n)\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_str\n\n__all__ = ('MultiPartParser', 'MultiPartParserError', 'InputStreamExhausted')\n\n\nclass MultiPartParserError(Exception):\n    pass\n\n\nclass InputStreamExhausted(Exception):\n    \"\"\"\n    No more reads are allowed from this device.\n    \"\"\"\n    pass\n\n\nRAW = \"raw\"\nFILE = \"file\"\nFIELD = \"field\"\n\n\nclass MultiPartParser:\n    \"\"\"\n    A rfc2388 multipart/form-data parser.\n\n    ``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks\n    and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``.\n    \"\"\"\n    def __init__(self, META, input_data, upload_handlers, encoding=None):\n        \"\"\"\n        Initialize the MultiPartParser object.\n\n        :META:\n            The standard ``META`` dictionary in Django request objects.\n        :input_data:\n            The raw post data, as a file-like object.\n        :upload_handlers:\n            A list of UploadHandler instances that perform operations on the\n            uploaded data.\n        :encoding:\n            The encoding with which to treat the incoming data.\n        \"\"\"\n        # Content-Type should contain multipart and the boundary information.\n        content_type = META.get('CONTENT_TYPE', '')\n        if not content_type.startswith('multipart/'):\n            raise MultiPartParserError('Invalid Content-Type: %s' % content_type)\n\n        # Parse the header to get the boundary to split the parts.\n        try:\n            ctypes, opts = parse_header(content_type.encode('ascii'))\n        except UnicodeEncodeError:\n            raise MultiPartParserError('Invalid non-ASCII Content-Type in multipart: %s' % force_str(content_type))\n        boundary = opts.get('boundary')\n        if not boundary or not cgi.valid_boundary(boundary):\n            raise MultiPartParserError('Invalid boundary in multipart: %s' % force_str(boundary))\n\n        # Content-Length should contain the length of the body we are about\n        # to receive.\n        try:\n            content_length = int(META.get('CONTENT_LENGTH', 0))\n        except (ValueError, TypeError):\n            content_length = 0\n\n        if content_length < 0:\n            # This means we shouldn't continue...raise an error.\n            raise MultiPartParserError(\"Invalid content length: %r\" % content_length)\n\n        if isinstance(boundary, str):\n            boundary = boundary.encode('ascii')\n        self._boundary = boundary\n        self._input_data = input_data\n\n        # For compatibility with low-level network APIs (with 32-bit integers),\n        # the chunk size should be < 2^31, but still divisible by 4.\n        possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size]\n        self._chunk_size = min([2 ** 31 - 4] + possible_sizes)\n\n        self._meta = META\n        self._encoding = encoding or settings.DEFAULT_CHARSET\n        self._content_length = content_length\n        self._upload_handlers = upload_handlers\n\n    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    if not over_chunk:\n                                        break\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n\n    def handle_file_complete(self, old_field_name, counters):\n        \"\"\"\n        Handle all the signaling that takes place when a file is complete.\n        \"\"\"\n        for i, handler in enumerate(self._upload_handlers):\n            file_obj = handler.file_complete(counters[i])\n            if file_obj:\n                # If it returns a file object, then set the files dict.\n                self._files.appendlist(force_str(old_field_name, self._encoding, errors='replace'), file_obj)\n                break\n\n    def sanitize_file_name(self, file_name):\n        \"\"\"\n        Sanitize the filename of an upload.\n\n        Remove all possible path separators, even though that might remove more\n        than actually required by the target system. Filenames that could\n        potentially cause problems (current/parent dir) are also discarded.\n\n        It should be noted that this function could still return a \"filepath\"\n        like \"C:some_file.txt\" which is handled later on by the storage layer.\n        So while this function does sanitize filenames to some extent, the\n        resulting filename should still be considered as untrusted user input.\n        \"\"\"\n        file_name = html.unescape(file_name)\n        file_name = file_name.rsplit('/')[-1]\n        file_name = file_name.rsplit('\\\\')[-1]\n        # Remove non-printable characters.\n        file_name = ''.join([char for char in file_name if char.isprintable()])\n\n        if file_name in {'', '.', '..'}:\n            return None\n        return file_name\n\n    IE_sanitize = sanitize_file_name\n\n    def _close_files(self):\n        # Free up all file handles.\n        # FIXME: this currently assumes that upload handlers store the file as 'file'\n        # We should document that... (Maybe add handler.free_file to complement new_file)\n        for handler in self._upload_handlers:\n            if hasattr(handler, 'file'):\n                handler.file.close()\n\n\nclass LazyStream:\n    \"\"\"\n    The LazyStream wrapper allows one to get and \"unget\" bytes from a stream.\n\n    Given a producer object (an iterator that yields bytestrings), the\n    LazyStream object will support iteration, reading, and keeping a \"look-back\"\n    variable in case you need to \"unget\" some bytes.\n    \"\"\"\n    def __init__(self, producer, length=None):\n        \"\"\"\n        Every LazyStream must have a producer when instantiated.\n\n        A producer is an iterable that returns a string each time it\n        is called.\n        \"\"\"\n        self._producer = producer\n        self._empty = False\n        self._leftover = b''\n        self.length = length\n        self.position = 0\n        self._remaining = length\n        self._unget_history = []\n\n    def tell(self):\n        return self.position\n\n    def read(self, size=None):\n        def parts():\n            remaining = self._remaining if size is None else size\n            # do the whole thing in one shot if no limit was provided.\n            if remaining is None:\n                yield b''.join(self)\n                return\n\n            # otherwise do some bookkeeping to return exactly enough\n            # of the stream and stashing any extra content we get from\n            # the producer\n            while remaining != 0:\n                assert remaining > 0, 'remaining bytes to read should never go negative'\n\n                try:\n                    chunk = next(self)\n                except StopIteration:\n                    return\n                else:\n                    emitting = chunk[:remaining]\n                    self.unget(chunk[remaining:])\n                    remaining -= len(emitting)\n                    yield emitting\n\n        return b''.join(parts())\n\n    def __next__(self):\n        \"\"\"\n        Used when the exact number of bytes to read is unimportant.\n\n        Return whatever chunk is conveniently returned from the iterator.\n        Useful to avoid unnecessary bookkeeping if performance is an issue.\n        \"\"\"\n        if self._leftover:\n            output = self._leftover\n            self._leftover = b''\n        else:\n            output = next(self._producer)\n            self._unget_history = []\n        self.position += len(output)\n        return output\n\n    def close(self):\n        \"\"\"\n        Used to invalidate/disable this lazy stream.\n\n        Replace the producer with an empty list. Any leftover bytes that have\n        already been read will still be reported upon read() and/or next().\n        \"\"\"\n        self._producer = []\n\n    def __iter__(self):\n        return self\n\n    def unget(self, bytes):\n        \"\"\"\n        Place bytes back onto the front of the lazy stream.\n\n        Future calls to read() will return those bytes first. The\n        stream position and thus tell() will be rewound.\n        \"\"\"\n        if not bytes:\n            return\n        self._update_unget_history(len(bytes))\n        self.position -= len(bytes)\n        self._leftover = bytes + self._leftover\n\n    def _update_unget_history(self, num_bytes):\n        \"\"\"\n        Update the unget history as a sanity check to see if we've pushed\n        back the same number of bytes in one chunk. If we keep ungetting the\n        same number of bytes many times (here, 50), we're mostly likely in an\n        infinite loop of some sort. This is usually caused by a\n        maliciously-malformed MIME request.\n        \"\"\"\n        self._unget_history = [num_bytes] + self._unget_history[:49]\n        number_equal = len([\n            current_number for current_number in self._unget_history\n            if current_number == num_bytes\n        ])\n\n        if number_equal > 40:\n            raise SuspiciousMultipartForm(\n                \"The multipart parser got stuck, which shouldn't happen with\"\n                \" normal uploaded files. Check for malicious upload activity;\"\n                \" if there is none, report this to the Django developers.\"\n            )\n\n\nclass ChunkIter:\n    \"\"\"\n    An iterable that will yield chunks of data. Given a file-like object as the\n    constructor, yield chunks of read operations from that object.\n    \"\"\"\n    def __init__(self, flo, chunk_size=64 * 1024):\n        self.flo = flo\n        self.chunk_size = chunk_size\n\n    def __next__(self):\n        try:\n            data = self.flo.read(self.chunk_size)\n        except InputStreamExhausted:\n            raise StopIteration()\n        if data:\n            return data\n        else:\n            raise StopIteration()\n\n    def __iter__(self):\n        return self\n\n\nclass InterBoundaryIter:\n    \"\"\"\n    A Producer that will iterate over boundaries.\n    \"\"\"\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return LazyStream(BoundaryIter(self._stream, self._boundary))\n        except InputStreamExhausted:\n            raise StopIteration()\n\n\nclass BoundaryIter:\n    \"\"\"\n    A Producer that is sensitive to boundaries.\n\n    Will happily yield bytes until a boundary is found. Will yield the bytes\n    before the boundary, throw away the boundary bytes themselves, and push the\n    post-boundary bytes back on the stream.\n\n    The future calls to next() after locating the boundary will raise a\n    StopIteration exception.\n    \"\"\"\n\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n        self._done = False\n        # rollback an additional six bytes because the format is like\n        # this: CRLF<boundary>[--CRLF]\n        self._rollback = len(boundary) + 6\n\n        # Try to use mx fast string search if available. Otherwise\n        # use Python find. Wrap the latter for consistency.\n        unused_char = self._stream.read(1)\n        if not unused_char:\n            raise InputStreamExhausted()\n        self._stream.unget(unused_char)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._done:\n            raise StopIteration()\n\n        stream = self._stream\n        rollback = self._rollback\n\n        bytes_read = 0\n        chunks = []\n        for bytes in stream:\n            bytes_read += len(bytes)\n            chunks.append(bytes)\n            if bytes_read > rollback:\n                break\n            if not bytes:\n                break\n        else:\n            self._done = True\n\n        if not chunks:\n            raise StopIteration()\n\n        chunk = b''.join(chunks)\n        boundary = self._find_boundary(chunk)\n\n        if boundary:\n            end, next = boundary\n            stream.unget(chunk[next:])\n            self._done = True\n            return chunk[:end]\n        else:\n            # make sure we don't treat a partial boundary (and\n            # its separators) as data\n            if not chunk[:-rollback]:  # and len(chunk) >= (len(self._boundary) + 6):\n                # There's nothing left, we should just return and mark as done.\n                self._done = True\n                return chunk\n            else:\n                stream.unget(chunk[-rollback:])\n                return chunk[:-rollback]\n\n    def _find_boundary(self, data):\n        \"\"\"\n        Find a multipart boundary in data.\n\n        Should no boundary exist in the data, return None. Otherwise, return\n        a tuple containing the indices of the following:\n         * the end of current encapsulation\n         * the start of the next encapsulation\n        \"\"\"\n        index = data.find(self._boundary)\n        if index < 0:\n            return None\n        else:\n            end = index\n            next = index + len(self._boundary)\n            # backup over CRLF\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\n':\n                end -= 1\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\r':\n                end -= 1\n            return end, next\n\n\ndef exhaust(stream_or_iterable):\n    \"\"\"Exhaust an iterator or stream.\"\"\"\n    try:\n        iterator = iter(stream_or_iterable)\n    except TypeError:\n        iterator = ChunkIter(stream_or_iterable, 16384)\n    collections.deque(iterator, maxlen=0)  # consume iterator quickly.\n\n\ndef parse_boundary_stream(stream, max_header_size):\n    \"\"\"\n    Parse one and exactly one stream that encapsulates a boundary.\n    \"\"\"\n    # Stream at beginning of header, look for end of header\n    # and parse it if found. The header must fit within one\n    # chunk.\n    chunk = stream.read(max_header_size)\n\n    # 'find' returns the top of these four bytes, so we'll\n    # need to munch them later to prevent them from polluting\n    # the payload.\n    header_end = chunk.find(b'\\r\\n\\r\\n')\n\n    def _parse_header(line):\n        main_value_pair, params = parse_header(line)\n        try:\n            name, value = main_value_pair.split(':', 1)\n        except ValueError:\n            raise ValueError(\"Invalid header: %r\" % line)\n        return name, (value, params)\n\n    if header_end == -1:\n        # we find no header, so we just mark this fact and pass on\n        # the stream verbatim\n        stream.unget(chunk)\n        return (RAW, {}, stream)\n\n    header = chunk[:header_end]\n\n    # here we place any excess chunk back onto the stream, as\n    # well as throwing away the CRLFCRLF bytes from above.\n    stream.unget(chunk[header_end + 4:])\n\n    TYPE = RAW\n    outdict = {}\n\n    # Eliminate blank lines\n    for line in header.split(b'\\r\\n'):\n        # This terminology (\"main value\" and \"dictionary of\n        # parameters\") is from the Python docs.\n        try:\n            name, (value, params) = _parse_header(line)\n        except ValueError:\n            continue\n\n        if name == 'content-disposition':\n            TYPE = FIELD\n            if params.get('filename'):\n                TYPE = FILE\n\n        outdict[name] = value, params\n\n    if TYPE == RAW:\n        stream.unget(chunk)\n\n    return (TYPE, outdict, stream)\n\n\nclass Parser:\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._separator = b'--' + boundary\n\n    def __iter__(self):\n        boundarystream = InterBoundaryIter(self._stream, self._separator)\n        for sub_stream in boundarystream:\n            # Iterate over each part\n            yield parse_boundary_stream(sub_stream, 1024)\n\n\ndef parse_header(line):\n    \"\"\"\n    Parse the header into a key-value.\n\n    Input (line): bytes, output: str for key/name, bytes for values which\n    will be decoded later.\n    \"\"\"\n    plist = _parse_header_params(b';' + line)\n    key = plist.pop(0).lower().decode('ascii')\n    pdict = {}\n    for p in plist:\n        i = p.find(b'=')\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower().decode('ascii')\n            if name.endswith('*'):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # https://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(b\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1:].strip()\n            if len(value) >= 2 and value[:1] == value[-1:] == b'\"':\n                value = value[1:-1]\n                value = value.replace(b'\\\\\\\\', b'\\\\').replace(b'\\\\\"', b'\"')\n            if has_encoding:\n                encoding, lang, value = value.split(b\"'\")\n                value = unquote(value.decode(), encoding=encoding.decode())\n            pdict[name] = value\n    return key, pdict\n\n\ndef _parse_header_params(s):\n    plist = []\n    while s[:1] == b';':\n        s = s[1:]\n        end = s.find(b';')\n        while end > 0 and s.count(b'\"', 0, end) % 2:\n            end = s.find(b';', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        plist.append(f.strip())\n        s = s[end:]\n    return plist\n"
  },
  {
    "patch": "diff --git a/django/template/defaulttags.py b/django/template/defaulttags.py\nindex bc401853a4..99c09a483a 100644\n--- a/django/template/defaulttags.py\n+++ b/django/template/defaulttags.py\n@@ -8,7 +8,7 @@ from itertools import cycle as itertools_cycle, groupby\n \n from django.conf import settings\n from django.utils import timezone\n-from django.utils.html import conditional_escape, format_html\n+from django.utils.html import conditional_escape, escape, format_html\n from django.utils.lorem_ipsum import paragraphs, words\n from django.utils.safestring import mark_safe\n \n@@ -99,10 +99,13 @@ class CycleNode(Node):\n \n class DebugNode(Node):\n     def render(self, context):\n+        if not settings.DEBUG:\n+            return ''\n+\n         from pprint import pformat\n-        output = [pformat(val) for val in context]\n+        output = [escape(pformat(val)) for val in context]\n         output.append('\\n\\n')\n-        output.append(pformat(sys.modules))\n+        output.append(escape(pformat(sys.modules)))\n         return ''.join(output)\n \n \n",
    "commit_message": "Fixed CVE-2022-22818 -- Fixed possible XSS via {% debug %} template tag.\n\nThanks Keryn Knight for the report.\n\nCo-authored-by: Adam Johnson <me@adamj.eu>\n\n",
    "code_before": "\"\"\"Default tags used by the template system, available to all templates.\"\"\"\nimport re\nimport sys\nimport warnings\nfrom collections import namedtuple\nfrom datetime import datetime\nfrom itertools import cycle as itertools_cycle, groupby\n\nfrom django.conf import settings\nfrom django.utils import timezone\nfrom django.utils.html import conditional_escape, format_html\nfrom django.utils.lorem_ipsum import paragraphs, words\nfrom django.utils.safestring import mark_safe\n\nfrom .base import (\n    BLOCK_TAG_END, BLOCK_TAG_START, COMMENT_TAG_END, COMMENT_TAG_START,\n    FILTER_SEPARATOR, SINGLE_BRACE_END, SINGLE_BRACE_START,\n    VARIABLE_ATTRIBUTE_SEPARATOR, VARIABLE_TAG_END, VARIABLE_TAG_START, Node,\n    NodeList, TemplateSyntaxError, VariableDoesNotExist, kwarg_re,\n    render_value_in_context, token_kwargs,\n)\nfrom .context import Context\nfrom .defaultfilters import date\nfrom .library import Library\nfrom .smartif import IfParser, Literal\n\nregister = Library()\n\n\nclass AutoEscapeControlNode(Node):\n    \"\"\"Implement the actions of the autoescape tag.\"\"\"\n    def __init__(self, setting, nodelist):\n        self.setting, self.nodelist = setting, nodelist\n\n    def render(self, context):\n        old_setting = context.autoescape\n        context.autoescape = self.setting\n        output = self.nodelist.render(context)\n        context.autoescape = old_setting\n        if self.setting:\n            return mark_safe(output)\n        else:\n            return output\n\n\nclass CommentNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        return ''\n\n\nclass CsrfTokenNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        csrf_token = context.get('csrf_token')\n        if csrf_token:\n            if csrf_token == 'NOTPROVIDED':\n                return format_html(\"\")\n            else:\n                return format_html('<input type=\"hidden\" name=\"csrfmiddlewaretoken\" value=\"{}\">', csrf_token)\n        else:\n            # It's very probable that the token is missing because of\n            # misconfiguration, so we raise a warning\n            if settings.DEBUG:\n                warnings.warn(\n                    \"A {% csrf_token %} was used in a template, but the context \"\n                    \"did not provide the value.  This is usually caused by not \"\n                    \"using RequestContext.\"\n                )\n            return ''\n\n\nclass CycleNode(Node):\n    def __init__(self, cyclevars, variable_name=None, silent=False):\n        self.cyclevars = cyclevars\n        self.variable_name = variable_name\n        self.silent = silent\n\n    def render(self, context):\n        if self not in context.render_context:\n            # First time the node is rendered in template\n            context.render_context[self] = itertools_cycle(self.cyclevars)\n        cycle_iter = context.render_context[self]\n        value = next(cycle_iter).resolve(context)\n        if self.variable_name:\n            context.set_upward(self.variable_name, value)\n        if self.silent:\n            return ''\n        return render_value_in_context(value, context)\n\n    def reset(self, context):\n        \"\"\"\n        Reset the cycle iteration back to the beginning.\n        \"\"\"\n        context.render_context[self] = itertools_cycle(self.cyclevars)\n\n\nclass DebugNode(Node):\n    def render(self, context):\n        from pprint import pformat\n        output = [pformat(val) for val in context]\n        output.append('\\n\\n')\n        output.append(pformat(sys.modules))\n        return ''.join(output)\n\n\nclass FilterNode(Node):\n    def __init__(self, filter_expr, nodelist):\n        self.filter_expr, self.nodelist = filter_expr, nodelist\n\n    def render(self, context):\n        output = self.nodelist.render(context)\n        # Apply filters.\n        with context.push(var=output):\n            return self.filter_expr.resolve(context)\n\n\nclass FirstOfNode(Node):\n    def __init__(self, variables, asvar=None):\n        self.vars = variables\n        self.asvar = asvar\n\n    def render(self, context):\n        first = ''\n        for var in self.vars:\n            value = var.resolve(context, ignore_failures=True)\n            if value:\n                first = render_value_in_context(value, context)\n                break\n        if self.asvar:\n            context[self.asvar] = first\n            return ''\n        return first\n\n\nclass ForNode(Node):\n    child_nodelists = ('nodelist_loop', 'nodelist_empty')\n\n    def __init__(self, loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty=None):\n        self.loopvars, self.sequence = loopvars, sequence\n        self.is_reversed = is_reversed\n        self.nodelist_loop = nodelist_loop\n        if nodelist_empty is None:\n            self.nodelist_empty = NodeList()\n        else:\n            self.nodelist_empty = nodelist_empty\n\n    def __repr__(self):\n        reversed_text = ' reversed' if self.is_reversed else ''\n        return '<%s: for %s in %s, tail_len: %d%s>' % (\n            self.__class__.__name__,\n            ', '.join(self.loopvars),\n            self.sequence,\n            len(self.nodelist_loop),\n            reversed_text,\n        )\n\n    def render(self, context):\n        if 'forloop' in context:\n            parentloop = context['forloop']\n        else:\n            parentloop = {}\n        with context.push():\n            values = self.sequence.resolve(context, ignore_failures=True)\n            if values is None:\n                values = []\n            if not hasattr(values, '__len__'):\n                values = list(values)\n            len_values = len(values)\n            if len_values < 1:\n                return self.nodelist_empty.render(context)\n            nodelist = []\n            if self.is_reversed:\n                values = reversed(values)\n            num_loopvars = len(self.loopvars)\n            unpack = num_loopvars > 1\n            # Create a forloop value in the context.  We'll update counters on each\n            # iteration just below.\n            loop_dict = context['forloop'] = {'parentloop': parentloop}\n            for i, item in enumerate(values):\n                # Shortcuts for current loop iteration number.\n                loop_dict['counter0'] = i\n                loop_dict['counter'] = i + 1\n                # Reverse counter iteration numbers.\n                loop_dict['revcounter'] = len_values - i\n                loop_dict['revcounter0'] = len_values - i - 1\n                # Boolean values designating first and last times through loop.\n                loop_dict['first'] = (i == 0)\n                loop_dict['last'] = (i == len_values - 1)\n\n                pop_context = False\n                if unpack:\n                    # If there are multiple loop variables, unpack the item into\n                    # them.\n                    try:\n                        len_item = len(item)\n                    except TypeError:  # not an iterable\n                        len_item = 1\n                    # Check loop variable count before unpacking\n                    if num_loopvars != len_item:\n                        raise ValueError(\n                            \"Need {} values to unpack in for loop; got {}. \"\n                            .format(num_loopvars, len_item),\n                        )\n                    unpacked_vars = dict(zip(self.loopvars, item))\n                    pop_context = True\n                    context.update(unpacked_vars)\n                else:\n                    context[self.loopvars[0]] = item\n\n                for node in self.nodelist_loop:\n                    nodelist.append(node.render_annotated(context))\n\n                if pop_context:\n                    # Pop the loop variables pushed on to the context to avoid\n                    # the context ending up in an inconsistent state when other\n                    # tags (e.g., include and with) push data to context.\n                    context.pop()\n        return mark_safe(''.join(nodelist))\n\n\nclass IfChangedNode(Node):\n    child_nodelists = ('nodelist_true', 'nodelist_false')\n\n    def __init__(self, nodelist_true, nodelist_false, *varlist):\n        self.nodelist_true, self.nodelist_false = nodelist_true, nodelist_false\n        self._varlist = varlist\n\n    def render(self, context):\n        # Init state storage\n        state_frame = self._get_context_stack_frame(context)\n        state_frame.setdefault(self)\n\n        nodelist_true_output = None\n        if self._varlist:\n            # Consider multiple parameters. This behaves like an OR evaluation\n            # of the multiple variables.\n            compare_to = [var.resolve(context, ignore_failures=True) for var in self._varlist]\n        else:\n            # The \"{% ifchanged %}\" syntax (without any variables) compares\n            # the rendered output.\n            compare_to = nodelist_true_output = self.nodelist_true.render(context)\n\n        if compare_to != state_frame[self]:\n            state_frame[self] = compare_to\n            # render true block if not already rendered\n            return nodelist_true_output or self.nodelist_true.render(context)\n        elif self.nodelist_false:\n            return self.nodelist_false.render(context)\n        return ''\n\n    def _get_context_stack_frame(self, context):\n        # The Context object behaves like a stack where each template tag can create a new scope.\n        # Find the place where to store the state to detect changes.\n        if 'forloop' in context:\n            # Ifchanged is bound to the local for loop.\n            # When there is a loop-in-loop, the state is bound to the inner loop,\n            # so it resets when the outer loop continues.\n            return context['forloop']\n        else:\n            # Using ifchanged outside loops. Effectively this is a no-op because the state is associated with 'self'.\n            return context.render_context\n\n\nclass IfNode(Node):\n\n    def __init__(self, conditions_nodelists):\n        self.conditions_nodelists = conditions_nodelists\n\n    def __repr__(self):\n        return '<%s>' % self.__class__.__name__\n\n    def __iter__(self):\n        for _, nodelist in self.conditions_nodelists:\n            yield from nodelist\n\n    @property\n    def nodelist(self):\n        return NodeList(self)\n\n    def render(self, context):\n        for condition, nodelist in self.conditions_nodelists:\n\n            if condition is not None:           # if / elif clause\n                try:\n                    match = condition.eval(context)\n                except VariableDoesNotExist:\n                    match = None\n            else:                               # else clause\n                match = True\n\n            if match:\n                return nodelist.render(context)\n\n        return ''\n\n\nclass LoremNode(Node):\n    def __init__(self, count, method, common):\n        self.count, self.method, self.common = count, method, common\n\n    def render(self, context):\n        try:\n            count = int(self.count.resolve(context))\n        except (ValueError, TypeError):\n            count = 1\n        if self.method == 'w':\n            return words(count, common=self.common)\n        else:\n            paras = paragraphs(count, common=self.common)\n        if self.method == 'p':\n            paras = ['<p>%s</p>' % p for p in paras]\n        return '\\n\\n'.join(paras)\n\n\nGroupedResult = namedtuple('GroupedResult', ['grouper', 'list'])\n\n\nclass RegroupNode(Node):\n    def __init__(self, target, expression, var_name):\n        self.target, self.expression = target, expression\n        self.var_name = var_name\n\n    def resolve_expression(self, obj, context):\n        # This method is called for each object in self.target. See regroup()\n        # for the reason why we temporarily put the object in the context.\n        context[self.var_name] = obj\n        return self.expression.resolve(context, ignore_failures=True)\n\n    def render(self, context):\n        obj_list = self.target.resolve(context, ignore_failures=True)\n        if obj_list is None:\n            # target variable wasn't found in context; fail silently.\n            context[self.var_name] = []\n            return ''\n        # List of dictionaries in the format:\n        # {'grouper': 'key', 'list': [list of contents]}.\n        context[self.var_name] = [\n            GroupedResult(grouper=key, list=list(val))\n            for key, val in\n            groupby(obj_list, lambda obj: self.resolve_expression(obj, context))\n        ]\n        return ''\n\n\nclass LoadNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        return ''\n\n\nclass NowNode(Node):\n    def __init__(self, format_string, asvar=None):\n        self.format_string = format_string\n        self.asvar = asvar\n\n    def render(self, context):\n        tzinfo = timezone.get_current_timezone() if settings.USE_TZ else None\n        formatted = date(datetime.now(tz=tzinfo), self.format_string)\n\n        if self.asvar:\n            context[self.asvar] = formatted\n            return ''\n        else:\n            return formatted\n\n\nclass ResetCycleNode(Node):\n    def __init__(self, node):\n        self.node = node\n\n    def render(self, context):\n        self.node.reset(context)\n        return ''\n\n\nclass SpacelessNode(Node):\n    def __init__(self, nodelist):\n        self.nodelist = nodelist\n\n    def render(self, context):\n        from django.utils.html import strip_spaces_between_tags\n        return strip_spaces_between_tags(self.nodelist.render(context).strip())\n\n\nclass TemplateTagNode(Node):\n    mapping = {\n        'openblock': BLOCK_TAG_START,\n        'closeblock': BLOCK_TAG_END,\n        'openvariable': VARIABLE_TAG_START,\n        'closevariable': VARIABLE_TAG_END,\n        'openbrace': SINGLE_BRACE_START,\n        'closebrace': SINGLE_BRACE_END,\n        'opencomment': COMMENT_TAG_START,\n        'closecomment': COMMENT_TAG_END,\n    }\n\n    def __init__(self, tagtype):\n        self.tagtype = tagtype\n\n    def render(self, context):\n        return self.mapping.get(self.tagtype, '')\n\n\nclass URLNode(Node):\n    child_nodelists = ()\n\n    def __init__(self, view_name, args, kwargs, asvar):\n        self.view_name = view_name\n        self.args = args\n        self.kwargs = kwargs\n        self.asvar = asvar\n\n    def __repr__(self):\n        return \"<%s view_name='%s' args=%s kwargs=%s as=%s>\" % (\n            self.__class__.__qualname__,\n            self.view_name,\n            repr(self.args),\n            repr(self.kwargs),\n            repr(self.asvar),\n        )\n\n    def render(self, context):\n        from django.urls import NoReverseMatch, reverse\n        args = [arg.resolve(context) for arg in self.args]\n        kwargs = {k: v.resolve(context) for k, v in self.kwargs.items()}\n        view_name = self.view_name.resolve(context)\n        try:\n            current_app = context.request.current_app\n        except AttributeError:\n            try:\n                current_app = context.request.resolver_match.namespace\n            except AttributeError:\n                current_app = None\n        # Try to look up the URL. If it fails, raise NoReverseMatch unless the\n        # {% url ... as var %} construct is used, in which case return nothing.\n        url = ''\n        try:\n            url = reverse(view_name, args=args, kwargs=kwargs, current_app=current_app)\n        except NoReverseMatch:\n            if self.asvar is None:\n                raise\n\n        if self.asvar:\n            context[self.asvar] = url\n            return ''\n        else:\n            if context.autoescape:\n                url = conditional_escape(url)\n            return url\n\n\nclass VerbatimNode(Node):\n    def __init__(self, content):\n        self.content = content\n\n    def render(self, context):\n        return self.content\n\n\nclass WidthRatioNode(Node):\n    def __init__(self, val_expr, max_expr, max_width, asvar=None):\n        self.val_expr = val_expr\n        self.max_expr = max_expr\n        self.max_width = max_width\n        self.asvar = asvar\n\n    def render(self, context):\n        try:\n            value = self.val_expr.resolve(context)\n            max_value = self.max_expr.resolve(context)\n            max_width = int(self.max_width.resolve(context))\n        except VariableDoesNotExist:\n            return ''\n        except (ValueError, TypeError):\n            raise TemplateSyntaxError(\"widthratio final argument must be a number\")\n        try:\n            value = float(value)\n            max_value = float(max_value)\n            ratio = (value / max_value) * max_width\n            result = str(round(ratio))\n        except ZeroDivisionError:\n            result = '0'\n        except (ValueError, TypeError, OverflowError):\n            result = ''\n\n        if self.asvar:\n            context[self.asvar] = result\n            return ''\n        else:\n            return result\n\n\nclass WithNode(Node):\n    def __init__(self, var, name, nodelist, extra_context=None):\n        self.nodelist = nodelist\n        # var and name are legacy attributes, being left in case they are used\n        # by third-party subclasses of this Node.\n        self.extra_context = extra_context or {}\n        if name:\n            self.extra_context[name] = var\n\n    def __repr__(self):\n        return '<%s>' % self.__class__.__name__\n\n    def render(self, context):\n        values = {key: val.resolve(context) for key, val in self.extra_context.items()}\n        with context.push(**values):\n            return self.nodelist.render(context)\n\n\n@register.tag\ndef autoescape(parser, token):\n    \"\"\"\n    Force autoescape behavior for this block.\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    args = token.contents.split()\n    if len(args) != 2:\n        raise TemplateSyntaxError(\"'autoescape' tag requires exactly one argument.\")\n    arg = args[1]\n    if arg not in ('on', 'off'):\n        raise TemplateSyntaxError(\"'autoescape' argument should be 'on' or 'off'\")\n    nodelist = parser.parse(('endautoescape',))\n    parser.delete_first_token()\n    return AutoEscapeControlNode((arg == 'on'), nodelist)\n\n\n@register.tag\ndef comment(parser, token):\n    \"\"\"\n    Ignore everything between ``{% comment %}`` and ``{% endcomment %}``.\n    \"\"\"\n    parser.skip_past('endcomment')\n    return CommentNode()\n\n\n@register.tag\ndef cycle(parser, token):\n    \"\"\"\n    Cycle among the given strings each time this tag is encountered.\n\n    Within a loop, cycles among the given strings each time through\n    the loop::\n\n        {% for o in some_list %}\n            <tr class=\"{% cycle 'row1' 'row2' %}\">\n                ...\n            </tr>\n        {% endfor %}\n\n    Outside of a loop, give the values a unique name the first time you call\n    it, then use that name each successive time through::\n\n            <tr class=\"{% cycle 'row1' 'row2' 'row3' as rowcolors %}\">...</tr>\n            <tr class=\"{% cycle rowcolors %}\">...</tr>\n            <tr class=\"{% cycle rowcolors %}\">...</tr>\n\n    You can use any number of values, separated by spaces. Commas can also\n    be used to separate values; if a comma is used, the cycle values are\n    interpreted as literal strings.\n\n    The optional flag \"silent\" can be used to prevent the cycle declaration\n    from returning any value::\n\n        {% for o in some_list %}\n            {% cycle 'row1' 'row2' as rowcolors silent %}\n            <tr class=\"{{ rowcolors }}\">{% include \"subtemplate.html \" %}</tr>\n        {% endfor %}\n    \"\"\"\n    # Note: This returns the exact same node on each {% cycle name %} call;\n    # that is, the node object returned from {% cycle a b c as name %} and the\n    # one returned from {% cycle name %} are the exact same object. This\n    # shouldn't cause problems (heh), but if it does, now you know.\n    #\n    # Ugly hack warning: This stuffs the named template dict into parser so\n    # that names are only unique within each template (as opposed to using\n    # a global variable, which would make cycle names have to be unique across\n    # *all* templates.\n    #\n    # It keeps the last node in the parser to be able to reset it with\n    # {% resetcycle %}.\n\n    args = token.split_contents()\n\n    if len(args) < 2:\n        raise TemplateSyntaxError(\"'cycle' tag requires at least two arguments\")\n\n    if len(args) == 2:\n        # {% cycle foo %} case.\n        name = args[1]\n        if not hasattr(parser, '_named_cycle_nodes'):\n            raise TemplateSyntaxError(\"No named cycles in template. '%s' is not defined\" % name)\n        if name not in parser._named_cycle_nodes:\n            raise TemplateSyntaxError(\"Named cycle '%s' does not exist\" % name)\n        return parser._named_cycle_nodes[name]\n\n    as_form = False\n\n    if len(args) > 4:\n        # {% cycle ... as foo [silent] %} case.\n        if args[-3] == \"as\":\n            if args[-1] != \"silent\":\n                raise TemplateSyntaxError(\"Only 'silent' flag is allowed after cycle's name, not '%s'.\" % args[-1])\n            as_form = True\n            silent = True\n            args = args[:-1]\n        elif args[-2] == \"as\":\n            as_form = True\n            silent = False\n\n    if as_form:\n        name = args[-1]\n        values = [parser.compile_filter(arg) for arg in args[1:-2]]\n        node = CycleNode(values, name, silent=silent)\n        if not hasattr(parser, '_named_cycle_nodes'):\n            parser._named_cycle_nodes = {}\n        parser._named_cycle_nodes[name] = node\n    else:\n        values = [parser.compile_filter(arg) for arg in args[1:]]\n        node = CycleNode(values)\n    parser._last_cycle_node = node\n    return node\n\n\n@register.tag\ndef csrf_token(parser, token):\n    return CsrfTokenNode()\n\n\n@register.tag\ndef debug(parser, token):\n    \"\"\"\n    Output a whole load of debugging information, including the current\n    context and imported modules.\n\n    Sample usage::\n\n        <pre>\n            {% debug %}\n        </pre>\n    \"\"\"\n    return DebugNode()\n\n\n@register.tag('filter')\ndef do_filter(parser, token):\n    \"\"\"\n    Filter the contents of the block through variable filters.\n\n    Filters can also be piped through each other, and they can have\n    arguments -- just like in variable syntax.\n\n    Sample usage::\n\n        {% filter force_escape|lower %}\n            This text will be HTML-escaped, and will appear in lowercase.\n        {% endfilter %}\n\n    Note that the ``escape`` and ``safe`` filters are not acceptable arguments.\n    Instead, use the ``autoescape`` tag to manage autoescaping for blocks of\n    template code.\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    _, rest = token.contents.split(None, 1)\n    filter_expr = parser.compile_filter(\"var|%s\" % (rest))\n    for func, unused in filter_expr.filters:\n        filter_name = getattr(func, '_filter_name', None)\n        if filter_name in ('escape', 'safe'):\n            raise TemplateSyntaxError('\"filter %s\" is not permitted.  Use the \"autoescape\" tag instead.' % filter_name)\n    nodelist = parser.parse(('endfilter',))\n    parser.delete_first_token()\n    return FilterNode(filter_expr, nodelist)\n\n\n@register.tag\ndef firstof(parser, token):\n    \"\"\"\n    Output the first variable passed that is not False.\n\n    Output nothing if all the passed variables are False.\n\n    Sample usage::\n\n        {% firstof var1 var2 var3 as myvar %}\n\n    This is equivalent to::\n\n        {% if var1 %}\n            {{ var1 }}\n        {% elif var2 %}\n            {{ var2 }}\n        {% elif var3 %}\n            {{ var3 }}\n        {% endif %}\n\n    but much cleaner!\n\n    You can also use a literal string as a fallback value in case all\n    passed variables are False::\n\n        {% firstof var1 var2 var3 \"fallback value\" %}\n\n    If you want to disable auto-escaping of variables you can use::\n\n        {% autoescape off %}\n            {% firstof var1 var2 var3 \"<strong>fallback value</strong>\" %}\n        {% autoescape %}\n\n    Or if only some variables should be escaped, you can use::\n\n        {% firstof var1 var2|safe var3 \"<strong>fallback value</strong>\"|safe %}\n    \"\"\"\n    bits = token.split_contents()[1:]\n    asvar = None\n    if not bits:\n        raise TemplateSyntaxError(\"'firstof' statement requires at least one argument\")\n\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n    return FirstOfNode([parser.compile_filter(bit) for bit in bits], asvar)\n\n\n@register.tag('for')\ndef do_for(parser, token):\n    \"\"\"\n    Loop over each item in an array.\n\n    For example, to display a list of athletes given ``athlete_list``::\n\n        <ul>\n        {% for athlete in athlete_list %}\n            <li>{{ athlete.name }}</li>\n        {% endfor %}\n        </ul>\n\n    You can loop over a list in reverse by using\n    ``{% for obj in list reversed %}``.\n\n    You can also unpack multiple values from a two-dimensional array::\n\n        {% for key,value in dict.items %}\n            {{ key }}: {{ value }}\n        {% endfor %}\n\n    The ``for`` tag can take an optional ``{% empty %}`` clause that will\n    be displayed if the given array is empty or could not be found::\n\n        <ul>\n          {% for athlete in athlete_list %}\n            <li>{{ athlete.name }}</li>\n          {% empty %}\n            <li>Sorry, no athletes in this list.</li>\n          {% endfor %}\n        <ul>\n\n    The above is equivalent to -- but shorter, cleaner, and possibly faster\n    than -- the following::\n\n        <ul>\n          {% if athlete_list %}\n            {% for athlete in athlete_list %}\n              <li>{{ athlete.name }}</li>\n            {% endfor %}\n          {% else %}\n            <li>Sorry, no athletes in this list.</li>\n          {% endif %}\n        </ul>\n\n    The for loop sets a number of variables available within the loop:\n\n        ==========================  ================================================\n        Variable                    Description\n        ==========================  ================================================\n        ``forloop.counter``         The current iteration of the loop (1-indexed)\n        ``forloop.counter0``        The current iteration of the loop (0-indexed)\n        ``forloop.revcounter``      The number of iterations from the end of the\n                                    loop (1-indexed)\n        ``forloop.revcounter0``     The number of iterations from the end of the\n                                    loop (0-indexed)\n        ``forloop.first``           True if this is the first time through the loop\n        ``forloop.last``            True if this is the last time through the loop\n        ``forloop.parentloop``      For nested loops, this is the loop \"above\" the\n                                    current one\n        ==========================  ================================================\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) < 4:\n        raise TemplateSyntaxError(\"'for' statements should have at least four\"\n                                  \" words: %s\" % token.contents)\n\n    is_reversed = bits[-1] == 'reversed'\n    in_index = -3 if is_reversed else -2\n    if bits[in_index] != 'in':\n        raise TemplateSyntaxError(\"'for' statements should use the format\"\n                                  \" 'for x in y': %s\" % token.contents)\n\n    invalid_chars = frozenset((' ', '\"', \"'\", FILTER_SEPARATOR))\n    loopvars = re.split(r' *, *', ' '.join(bits[1:in_index]))\n    for var in loopvars:\n        if not var or not invalid_chars.isdisjoint(var):\n            raise TemplateSyntaxError(\"'for' tag received an invalid argument:\"\n                                      \" %s\" % token.contents)\n\n    sequence = parser.compile_filter(bits[in_index + 1])\n    nodelist_loop = parser.parse(('empty', 'endfor',))\n    token = parser.next_token()\n    if token.contents == 'empty':\n        nodelist_empty = parser.parse(('endfor',))\n        parser.delete_first_token()\n    else:\n        nodelist_empty = None\n    return ForNode(loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty)\n\n\nclass TemplateLiteral(Literal):\n    def __init__(self, value, text):\n        self.value = value\n        self.text = text  # for better error messages\n\n    def display(self):\n        return self.text\n\n    def eval(self, context):\n        return self.value.resolve(context, ignore_failures=True)\n\n\nclass TemplateIfParser(IfParser):\n    error_class = TemplateSyntaxError\n\n    def __init__(self, parser, *args, **kwargs):\n        self.template_parser = parser\n        super().__init__(*args, **kwargs)\n\n    def create_var(self, value):\n        return TemplateLiteral(self.template_parser.compile_filter(value), value)\n\n\n@register.tag('if')\ndef do_if(parser, token):\n    \"\"\"\n    Evaluate a variable, and if that variable is \"true\" (i.e., exists, is not\n    empty, and is not a false boolean value), output the contents of the block:\n\n    ::\n\n        {% if athlete_list %}\n            Number of athletes: {{ athlete_list|count }}\n        {% elif athlete_in_locker_room_list %}\n            Athletes should be out of the locker room soon!\n        {% else %}\n            No athletes.\n        {% endif %}\n\n    In the above, if ``athlete_list`` is not empty, the number of athletes will\n    be displayed by the ``{{ athlete_list|count }}`` variable.\n\n    The ``if`` tag may take one or several `` {% elif %}`` clauses, as well as\n    an ``{% else %}`` clause that will be displayed if all previous conditions\n    fail. These clauses are optional.\n\n    ``if`` tags may use ``or``, ``and`` or ``not`` to test a number of\n    variables or to negate a given variable::\n\n        {% if not athlete_list %}\n            There are no athletes.\n        {% endif %}\n\n        {% if athlete_list or coach_list %}\n            There are some athletes or some coaches.\n        {% endif %}\n\n        {% if athlete_list and coach_list %}\n            Both athletes and coaches are available.\n        {% endif %}\n\n        {% if not athlete_list or coach_list %}\n            There are no athletes, or there are some coaches.\n        {% endif %}\n\n        {% if athlete_list and not coach_list %}\n            There are some athletes and absolutely no coaches.\n        {% endif %}\n\n    Comparison operators are also available, and the use of filters is also\n    allowed, for example::\n\n        {% if articles|length >= 5 %}...{% endif %}\n\n    Arguments and operators _must_ have a space between them, so\n    ``{% if 1>2 %}`` is not a valid if tag.\n\n    All supported operators are: ``or``, ``and``, ``in``, ``not in``\n    ``==``, ``!=``, ``>``, ``>=``, ``<`` and ``<=``.\n\n    Operator precedence follows Python.\n    \"\"\"\n    # {% if ... %}\n    bits = token.split_contents()[1:]\n    condition = TemplateIfParser(parser, bits).parse()\n    nodelist = parser.parse(('elif', 'else', 'endif'))\n    conditions_nodelists = [(condition, nodelist)]\n    token = parser.next_token()\n\n    # {% elif ... %} (repeatable)\n    while token.contents.startswith('elif'):\n        bits = token.split_contents()[1:]\n        condition = TemplateIfParser(parser, bits).parse()\n        nodelist = parser.parse(('elif', 'else', 'endif'))\n        conditions_nodelists.append((condition, nodelist))\n        token = parser.next_token()\n\n    # {% else %} (optional)\n    if token.contents == 'else':\n        nodelist = parser.parse(('endif',))\n        conditions_nodelists.append((None, nodelist))\n        token = parser.next_token()\n\n    # {% endif %}\n    if token.contents != 'endif':\n        raise TemplateSyntaxError('Malformed template tag at line {}: \"{}\"'.format(token.lineno, token.contents))\n\n    return IfNode(conditions_nodelists)\n\n\n@register.tag\ndef ifchanged(parser, token):\n    \"\"\"\n    Check if a value has changed from the last iteration of a loop.\n\n    The ``{% ifchanged %}`` block tag is used within a loop. It has two\n    possible uses.\n\n    1. Check its own rendered contents against its previous state and only\n       displays the content if it has changed. For example, this displays a\n       list of days, only displaying the month if it changes::\n\n            <h1>Archive for {{ year }}</h1>\n\n            {% for date in days %}\n                {% ifchanged %}<h3>{{ date|date:\"F\" }}</h3>{% endifchanged %}\n                <a href=\"{{ date|date:\"M/d\"|lower }}/\">{{ date|date:\"j\" }}</a>\n            {% endfor %}\n\n    2. If given one or more variables, check whether any variable has changed.\n       For example, the following shows the date every time it changes, while\n       showing the hour if either the hour or the date has changed::\n\n            {% for date in days %}\n                {% ifchanged date.date %} {{ date.date }} {% endifchanged %}\n                {% ifchanged date.hour date.date %}\n                    {{ date.hour }}\n                {% endifchanged %}\n            {% endfor %}\n    \"\"\"\n    bits = token.split_contents()\n    nodelist_true = parser.parse(('else', 'endifchanged'))\n    token = parser.next_token()\n    if token.contents == 'else':\n        nodelist_false = parser.parse(('endifchanged',))\n        parser.delete_first_token()\n    else:\n        nodelist_false = NodeList()\n    values = [parser.compile_filter(bit) for bit in bits[1:]]\n    return IfChangedNode(nodelist_true, nodelist_false, *values)\n\n\ndef find_library(parser, name):\n    try:\n        return parser.libraries[name]\n    except KeyError:\n        raise TemplateSyntaxError(\n            \"'%s' is not a registered tag library. Must be one of:\\n%s\" % (\n                name, \"\\n\".join(sorted(parser.libraries)),\n            ),\n        )\n\n\ndef load_from_library(library, label, names):\n    \"\"\"\n    Return a subset of tags and filters from a library.\n    \"\"\"\n    subset = Library()\n    for name in names:\n        found = False\n        if name in library.tags:\n            found = True\n            subset.tags[name] = library.tags[name]\n        if name in library.filters:\n            found = True\n            subset.filters[name] = library.filters[name]\n        if found is False:\n            raise TemplateSyntaxError(\n                \"'%s' is not a valid tag or filter in tag library '%s'\" % (\n                    name, label,\n                ),\n            )\n    return subset\n\n\n@register.tag\ndef load(parser, token):\n    \"\"\"\n    Load a custom template tag library into the parser.\n\n    For example, to load the template tags in\n    ``django/templatetags/news/photos.py``::\n\n        {% load news.photos %}\n\n    Can also be used to load an individual tag/filter from\n    a library::\n\n        {% load byline from news %}\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    bits = token.contents.split()\n    if len(bits) >= 4 and bits[-2] == \"from\":\n        # from syntax is used; load individual tags from the library\n        name = bits[-1]\n        lib = find_library(parser, name)\n        subset = load_from_library(lib, name, bits[1:-2])\n        parser.add_library(subset)\n    else:\n        # one or more libraries are specified; load and add them to the parser\n        for name in bits[1:]:\n            lib = find_library(parser, name)\n            parser.add_library(lib)\n    return LoadNode()\n\n\n@register.tag\ndef lorem(parser, token):\n    \"\"\"\n    Create random Latin text useful for providing test data in templates.\n\n    Usage format::\n\n        {% lorem [count] [method] [random] %}\n\n    ``count`` is a number (or variable) containing the number of paragraphs or\n    words to generate (default is 1).\n\n    ``method`` is either ``w`` for words, ``p`` for HTML paragraphs, ``b`` for\n    plain-text paragraph blocks (default is ``b``).\n\n    ``random`` is the word ``random``, which if given, does not use the common\n    paragraph (starting \"Lorem ipsum dolor sit amet, consectetuer...\").\n\n    Examples:\n\n    * ``{% lorem %}`` outputs the common \"lorem ipsum\" paragraph\n    * ``{% lorem 3 p %}`` outputs the common \"lorem ipsum\" paragraph\n      and two random paragraphs each wrapped in HTML ``<p>`` tags\n    * ``{% lorem 2 w random %}`` outputs two random latin words\n    \"\"\"\n    bits = list(token.split_contents())\n    tagname = bits[0]\n    # Random bit\n    common = bits[-1] != 'random'\n    if not common:\n        bits.pop()\n    # Method bit\n    if bits[-1] in ('w', 'p', 'b'):\n        method = bits.pop()\n    else:\n        method = 'b'\n    # Count bit\n    if len(bits) > 1:\n        count = bits.pop()\n    else:\n        count = '1'\n    count = parser.compile_filter(count)\n    if len(bits) != 1:\n        raise TemplateSyntaxError(\"Incorrect format for %r tag\" % tagname)\n    return LoremNode(count, method, common)\n\n\n@register.tag\ndef now(parser, token):\n    \"\"\"\n    Display the date, formatted according to the given string.\n\n    Use the same format as PHP's ``date()`` function; see https://php.net/date\n    for all the possible values.\n\n    Sample usage::\n\n        It is {% now \"jS F Y H:i\" %}\n    \"\"\"\n    bits = token.split_contents()\n    asvar = None\n    if len(bits) == 4 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n    if len(bits) != 2:\n        raise TemplateSyntaxError(\"'now' statement takes one argument\")\n    format_string = bits[1][1:-1]\n    return NowNode(format_string, asvar)\n\n\n@register.tag\ndef regroup(parser, token):\n    \"\"\"\n    Regroup a list of alike objects by a common attribute.\n\n    This complex tag is best illustrated by use of an example: say that\n    ``musicians`` is a list of ``Musician`` objects that have ``name`` and\n    ``instrument`` attributes, and you'd like to display a list that\n    looks like:\n\n        * Guitar:\n            * Django Reinhardt\n            * Emily Remler\n        * Piano:\n            * Lovie Austin\n            * Bud Powell\n        * Trumpet:\n            * Duke Ellington\n\n    The following snippet of template code would accomplish this dubious task::\n\n        {% regroup musicians by instrument as grouped %}\n        <ul>\n        {% for group in grouped %}\n            <li>{{ group.grouper }}\n            <ul>\n                {% for musician in group.list %}\n                <li>{{ musician.name }}</li>\n                {% endfor %}\n            </ul>\n        {% endfor %}\n        </ul>\n\n    As you can see, ``{% regroup %}`` populates a variable with a list of\n    objects with ``grouper`` and ``list`` attributes. ``grouper`` contains the\n    item that was grouped by; ``list`` contains the list of objects that share\n    that ``grouper``. In this case, ``grouper`` would be ``Guitar``, ``Piano``\n    and ``Trumpet``, and ``list`` is the list of musicians who play this\n    instrument.\n\n    Note that ``{% regroup %}`` does not work when the list to be grouped is not\n    sorted by the key you are grouping by! This means that if your list of\n    musicians was not sorted by instrument, you'd need to make sure it is sorted\n    before using it, i.e.::\n\n        {% regroup musicians|dictsort:\"instrument\" by instrument as grouped %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) != 6:\n        raise TemplateSyntaxError(\"'regroup' tag takes five arguments\")\n    target = parser.compile_filter(bits[1])\n    if bits[2] != 'by':\n        raise TemplateSyntaxError(\"second argument to 'regroup' tag must be 'by'\")\n    if bits[4] != 'as':\n        raise TemplateSyntaxError(\"next-to-last argument to 'regroup' tag must\"\n                                  \" be 'as'\")\n    var_name = bits[5]\n    # RegroupNode will take each item in 'target', put it in the context under\n    # 'var_name', evaluate 'var_name'.'expression' in the current context, and\n    # group by the resulting value. After all items are processed, it will\n    # save the final result in the context under 'var_name', thus clearing the\n    # temporary values. This hack is necessary because the template engine\n    # doesn't provide a context-aware equivalent of Python's getattr.\n    expression = parser.compile_filter(var_name +\n                                       VARIABLE_ATTRIBUTE_SEPARATOR +\n                                       bits[3])\n    return RegroupNode(target, expression, var_name)\n\n\n@register.tag\ndef resetcycle(parser, token):\n    \"\"\"\n    Reset a cycle tag.\n\n    If an argument is given, reset the last rendered cycle tag whose name\n    matches the argument, else reset the last rendered cycle tag (named or\n    unnamed).\n    \"\"\"\n    args = token.split_contents()\n\n    if len(args) > 2:\n        raise TemplateSyntaxError(\"%r tag accepts at most one argument.\" % args[0])\n\n    if len(args) == 2:\n        name = args[1]\n        try:\n            return ResetCycleNode(parser._named_cycle_nodes[name])\n        except (AttributeError, KeyError):\n            raise TemplateSyntaxError(\"Named cycle '%s' does not exist.\" % name)\n    try:\n        return ResetCycleNode(parser._last_cycle_node)\n    except AttributeError:\n        raise TemplateSyntaxError(\"No cycles in template.\")\n\n\n@register.tag\ndef spaceless(parser, token):\n    \"\"\"\n    Remove whitespace between HTML tags, including tab and newline characters.\n\n    Example usage::\n\n        {% spaceless %}\n            <p>\n                <a href=\"foo/\">Foo</a>\n            </p>\n        {% endspaceless %}\n\n    This example returns this HTML::\n\n        <p><a href=\"foo/\">Foo</a></p>\n\n    Only space between *tags* is normalized -- not space between tags and text.\n    In this example, the space around ``Hello`` isn't stripped::\n\n        {% spaceless %}\n            <strong>\n                Hello\n            </strong>\n        {% endspaceless %}\n    \"\"\"\n    nodelist = parser.parse(('endspaceless',))\n    parser.delete_first_token()\n    return SpacelessNode(nodelist)\n\n\n@register.tag\ndef templatetag(parser, token):\n    \"\"\"\n    Output one of the bits used to compose template tags.\n\n    Since the template system has no concept of \"escaping\", to display one of\n    the bits used in template tags, you must use the ``{% templatetag %}`` tag.\n\n    The argument tells which template bit to output:\n\n        ==================  =======\n        Argument            Outputs\n        ==================  =======\n        ``openblock``       ``{%``\n        ``closeblock``      ``%}``\n        ``openvariable``    ``{{``\n        ``closevariable``   ``}}``\n        ``openbrace``       ``{``\n        ``closebrace``      ``}``\n        ``opencomment``     ``{#``\n        ``closecomment``    ``#}``\n        ==================  =======\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    bits = token.contents.split()\n    if len(bits) != 2:\n        raise TemplateSyntaxError(\"'templatetag' statement takes one argument\")\n    tag = bits[1]\n    if tag not in TemplateTagNode.mapping:\n        raise TemplateSyntaxError(\"Invalid templatetag argument: '%s'.\"\n                                  \" Must be one of: %s\" %\n                                  (tag, list(TemplateTagNode.mapping)))\n    return TemplateTagNode(tag)\n\n\n@register.tag\ndef url(parser, token):\n    r\"\"\"\n    Return an absolute URL matching the given view with its parameters.\n\n    This is a way to define links that aren't tied to a particular URL\n    configuration::\n\n        {% url \"url_name\" arg1 arg2 %}\n\n        or\n\n        {% url \"url_name\" name1=value1 name2=value2 %}\n\n    The first argument is a URL pattern name. Other arguments are\n    space-separated values that will be filled in place of positional and\n    keyword arguments in the URL. Don't mix positional and keyword arguments.\n    All arguments for the URL must be present.\n\n    For example, if you have a view ``app_name.views.client_details`` taking\n    the client's id and the corresponding line in a URLconf looks like this::\n\n        path('client/<int:id>/', views.client_details, name='client-detail-view')\n\n    and this app's URLconf is included into the project's URLconf under some\n    path::\n\n        path('clients/', include('app_name.urls'))\n\n    then in a template you can create a link for a certain client like this::\n\n        {% url \"client-detail-view\" client.id %}\n\n    The URL will look like ``/clients/client/123/``.\n\n    The first argument may also be the name of a template variable that will be\n    evaluated to obtain the view name or the URL name, e.g.::\n\n        {% with url_name=\"client-detail-view\" %}\n        {% url url_name client.id %}\n        {% endwith %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) < 2:\n        raise TemplateSyntaxError(\"'%s' takes at least one argument, a URL pattern name.\" % bits[0])\n    viewname = parser.compile_filter(bits[1])\n    args = []\n    kwargs = {}\n    asvar = None\n    bits = bits[2:]\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n\n    for bit in bits:\n        match = kwarg_re.match(bit)\n        if not match:\n            raise TemplateSyntaxError(\"Malformed arguments to url tag\")\n        name, value = match.groups()\n        if name:\n            kwargs[name] = parser.compile_filter(value)\n        else:\n            args.append(parser.compile_filter(value))\n\n    return URLNode(viewname, args, kwargs, asvar)\n\n\n@register.tag\ndef verbatim(parser, token):\n    \"\"\"\n    Stop the template engine from rendering the contents of this block tag.\n\n    Usage::\n\n        {% verbatim %}\n            {% don't process this %}\n        {% endverbatim %}\n\n    You can also designate a specific closing tag block (allowing the\n    unrendered use of ``{% endverbatim %}``)::\n\n        {% verbatim myblock %}\n            ...\n        {% endverbatim myblock %}\n    \"\"\"\n    nodelist = parser.parse(('endverbatim',))\n    parser.delete_first_token()\n    return VerbatimNode(nodelist.render(Context()))\n\n\n@register.tag\ndef widthratio(parser, token):\n    \"\"\"\n    For creating bar charts and such. Calculate the ratio of a given value to a\n    maximum value, and then apply that ratio to a constant.\n\n    For example::\n\n        <img src=\"bar.png\" alt=\"Bar\"\n             height=\"10\" width=\"{% widthratio this_value max_value max_width %}\">\n\n    If ``this_value`` is 175, ``max_value`` is 200, and ``max_width`` is 100,\n    the image in the above example will be 88 pixels wide\n    (because 175/200 = .875; .875 * 100 = 87.5 which is rounded up to 88).\n\n    In some cases you might want to capture the result of widthratio in a\n    variable. It can be useful for instance in a blocktranslate like this::\n\n        {% widthratio this_value max_value max_width as width %}\n        {% blocktranslate %}The width is: {{ width }}{% endblocktranslate %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) == 4:\n        tag, this_value_expr, max_value_expr, max_width = bits\n        asvar = None\n    elif len(bits) == 6:\n        tag, this_value_expr, max_value_expr, max_width, as_, asvar = bits\n        if as_ != 'as':\n            raise TemplateSyntaxError(\"Invalid syntax in widthratio tag. Expecting 'as' keyword\")\n    else:\n        raise TemplateSyntaxError(\"widthratio takes at least three arguments\")\n\n    return WidthRatioNode(parser.compile_filter(this_value_expr),\n                          parser.compile_filter(max_value_expr),\n                          parser.compile_filter(max_width),\n                          asvar=asvar)\n\n\n@register.tag('with')\ndef do_with(parser, token):\n    \"\"\"\n    Add one or more values to the context (inside of this block) for caching\n    and easy access.\n\n    For example::\n\n        {% with total=person.some_sql_method %}\n            {{ total }} object{{ total|pluralize }}\n        {% endwith %}\n\n    Multiple values can be added to the context::\n\n        {% with foo=1 bar=2 %}\n            ...\n        {% endwith %}\n\n    The legacy format of ``{% with person.some_sql_method as total %}`` is\n    still accepted.\n    \"\"\"\n    bits = token.split_contents()\n    remaining_bits = bits[1:]\n    extra_context = token_kwargs(remaining_bits, parser, support_legacy=True)\n    if not extra_context:\n        raise TemplateSyntaxError(\"%r expected at least one variable \"\n                                  \"assignment\" % bits[0])\n    if remaining_bits:\n        raise TemplateSyntaxError(\"%r received an invalid token: %r\" %\n                                  (bits[0], remaining_bits[0]))\n    nodelist = parser.parse(('endwith',))\n    parser.delete_first_token()\n    return WithNode(None, None, nodelist, extra_context=extra_context)\n",
    "code_after": "\"\"\"Default tags used by the template system, available to all templates.\"\"\"\nimport re\nimport sys\nimport warnings\nfrom collections import namedtuple\nfrom datetime import datetime\nfrom itertools import cycle as itertools_cycle, groupby\n\nfrom django.conf import settings\nfrom django.utils import timezone\nfrom django.utils.html import conditional_escape, escape, format_html\nfrom django.utils.lorem_ipsum import paragraphs, words\nfrom django.utils.safestring import mark_safe\n\nfrom .base import (\n    BLOCK_TAG_END, BLOCK_TAG_START, COMMENT_TAG_END, COMMENT_TAG_START,\n    FILTER_SEPARATOR, SINGLE_BRACE_END, SINGLE_BRACE_START,\n    VARIABLE_ATTRIBUTE_SEPARATOR, VARIABLE_TAG_END, VARIABLE_TAG_START, Node,\n    NodeList, TemplateSyntaxError, VariableDoesNotExist, kwarg_re,\n    render_value_in_context, token_kwargs,\n)\nfrom .context import Context\nfrom .defaultfilters import date\nfrom .library import Library\nfrom .smartif import IfParser, Literal\n\nregister = Library()\n\n\nclass AutoEscapeControlNode(Node):\n    \"\"\"Implement the actions of the autoescape tag.\"\"\"\n    def __init__(self, setting, nodelist):\n        self.setting, self.nodelist = setting, nodelist\n\n    def render(self, context):\n        old_setting = context.autoescape\n        context.autoescape = self.setting\n        output = self.nodelist.render(context)\n        context.autoescape = old_setting\n        if self.setting:\n            return mark_safe(output)\n        else:\n            return output\n\n\nclass CommentNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        return ''\n\n\nclass CsrfTokenNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        csrf_token = context.get('csrf_token')\n        if csrf_token:\n            if csrf_token == 'NOTPROVIDED':\n                return format_html(\"\")\n            else:\n                return format_html('<input type=\"hidden\" name=\"csrfmiddlewaretoken\" value=\"{}\">', csrf_token)\n        else:\n            # It's very probable that the token is missing because of\n            # misconfiguration, so we raise a warning\n            if settings.DEBUG:\n                warnings.warn(\n                    \"A {% csrf_token %} was used in a template, but the context \"\n                    \"did not provide the value.  This is usually caused by not \"\n                    \"using RequestContext.\"\n                )\n            return ''\n\n\nclass CycleNode(Node):\n    def __init__(self, cyclevars, variable_name=None, silent=False):\n        self.cyclevars = cyclevars\n        self.variable_name = variable_name\n        self.silent = silent\n\n    def render(self, context):\n        if self not in context.render_context:\n            # First time the node is rendered in template\n            context.render_context[self] = itertools_cycle(self.cyclevars)\n        cycle_iter = context.render_context[self]\n        value = next(cycle_iter).resolve(context)\n        if self.variable_name:\n            context.set_upward(self.variable_name, value)\n        if self.silent:\n            return ''\n        return render_value_in_context(value, context)\n\n    def reset(self, context):\n        \"\"\"\n        Reset the cycle iteration back to the beginning.\n        \"\"\"\n        context.render_context[self] = itertools_cycle(self.cyclevars)\n\n\nclass DebugNode(Node):\n    def render(self, context):\n        if not settings.DEBUG:\n            return ''\n\n        from pprint import pformat\n        output = [escape(pformat(val)) for val in context]\n        output.append('\\n\\n')\n        output.append(escape(pformat(sys.modules)))\n        return ''.join(output)\n\n\nclass FilterNode(Node):\n    def __init__(self, filter_expr, nodelist):\n        self.filter_expr, self.nodelist = filter_expr, nodelist\n\n    def render(self, context):\n        output = self.nodelist.render(context)\n        # Apply filters.\n        with context.push(var=output):\n            return self.filter_expr.resolve(context)\n\n\nclass FirstOfNode(Node):\n    def __init__(self, variables, asvar=None):\n        self.vars = variables\n        self.asvar = asvar\n\n    def render(self, context):\n        first = ''\n        for var in self.vars:\n            value = var.resolve(context, ignore_failures=True)\n            if value:\n                first = render_value_in_context(value, context)\n                break\n        if self.asvar:\n            context[self.asvar] = first\n            return ''\n        return first\n\n\nclass ForNode(Node):\n    child_nodelists = ('nodelist_loop', 'nodelist_empty')\n\n    def __init__(self, loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty=None):\n        self.loopvars, self.sequence = loopvars, sequence\n        self.is_reversed = is_reversed\n        self.nodelist_loop = nodelist_loop\n        if nodelist_empty is None:\n            self.nodelist_empty = NodeList()\n        else:\n            self.nodelist_empty = nodelist_empty\n\n    def __repr__(self):\n        reversed_text = ' reversed' if self.is_reversed else ''\n        return '<%s: for %s in %s, tail_len: %d%s>' % (\n            self.__class__.__name__,\n            ', '.join(self.loopvars),\n            self.sequence,\n            len(self.nodelist_loop),\n            reversed_text,\n        )\n\n    def render(self, context):\n        if 'forloop' in context:\n            parentloop = context['forloop']\n        else:\n            parentloop = {}\n        with context.push():\n            values = self.sequence.resolve(context, ignore_failures=True)\n            if values is None:\n                values = []\n            if not hasattr(values, '__len__'):\n                values = list(values)\n            len_values = len(values)\n            if len_values < 1:\n                return self.nodelist_empty.render(context)\n            nodelist = []\n            if self.is_reversed:\n                values = reversed(values)\n            num_loopvars = len(self.loopvars)\n            unpack = num_loopvars > 1\n            # Create a forloop value in the context.  We'll update counters on each\n            # iteration just below.\n            loop_dict = context['forloop'] = {'parentloop': parentloop}\n            for i, item in enumerate(values):\n                # Shortcuts for current loop iteration number.\n                loop_dict['counter0'] = i\n                loop_dict['counter'] = i + 1\n                # Reverse counter iteration numbers.\n                loop_dict['revcounter'] = len_values - i\n                loop_dict['revcounter0'] = len_values - i - 1\n                # Boolean values designating first and last times through loop.\n                loop_dict['first'] = (i == 0)\n                loop_dict['last'] = (i == len_values - 1)\n\n                pop_context = False\n                if unpack:\n                    # If there are multiple loop variables, unpack the item into\n                    # them.\n                    try:\n                        len_item = len(item)\n                    except TypeError:  # not an iterable\n                        len_item = 1\n                    # Check loop variable count before unpacking\n                    if num_loopvars != len_item:\n                        raise ValueError(\n                            \"Need {} values to unpack in for loop; got {}. \"\n                            .format(num_loopvars, len_item),\n                        )\n                    unpacked_vars = dict(zip(self.loopvars, item))\n                    pop_context = True\n                    context.update(unpacked_vars)\n                else:\n                    context[self.loopvars[0]] = item\n\n                for node in self.nodelist_loop:\n                    nodelist.append(node.render_annotated(context))\n\n                if pop_context:\n                    # Pop the loop variables pushed on to the context to avoid\n                    # the context ending up in an inconsistent state when other\n                    # tags (e.g., include and with) push data to context.\n                    context.pop()\n        return mark_safe(''.join(nodelist))\n\n\nclass IfChangedNode(Node):\n    child_nodelists = ('nodelist_true', 'nodelist_false')\n\n    def __init__(self, nodelist_true, nodelist_false, *varlist):\n        self.nodelist_true, self.nodelist_false = nodelist_true, nodelist_false\n        self._varlist = varlist\n\n    def render(self, context):\n        # Init state storage\n        state_frame = self._get_context_stack_frame(context)\n        state_frame.setdefault(self)\n\n        nodelist_true_output = None\n        if self._varlist:\n            # Consider multiple parameters. This behaves like an OR evaluation\n            # of the multiple variables.\n            compare_to = [var.resolve(context, ignore_failures=True) for var in self._varlist]\n        else:\n            # The \"{% ifchanged %}\" syntax (without any variables) compares\n            # the rendered output.\n            compare_to = nodelist_true_output = self.nodelist_true.render(context)\n\n        if compare_to != state_frame[self]:\n            state_frame[self] = compare_to\n            # render true block if not already rendered\n            return nodelist_true_output or self.nodelist_true.render(context)\n        elif self.nodelist_false:\n            return self.nodelist_false.render(context)\n        return ''\n\n    def _get_context_stack_frame(self, context):\n        # The Context object behaves like a stack where each template tag can create a new scope.\n        # Find the place where to store the state to detect changes.\n        if 'forloop' in context:\n            # Ifchanged is bound to the local for loop.\n            # When there is a loop-in-loop, the state is bound to the inner loop,\n            # so it resets when the outer loop continues.\n            return context['forloop']\n        else:\n            # Using ifchanged outside loops. Effectively this is a no-op because the state is associated with 'self'.\n            return context.render_context\n\n\nclass IfNode(Node):\n\n    def __init__(self, conditions_nodelists):\n        self.conditions_nodelists = conditions_nodelists\n\n    def __repr__(self):\n        return '<%s>' % self.__class__.__name__\n\n    def __iter__(self):\n        for _, nodelist in self.conditions_nodelists:\n            yield from nodelist\n\n    @property\n    def nodelist(self):\n        return NodeList(self)\n\n    def render(self, context):\n        for condition, nodelist in self.conditions_nodelists:\n\n            if condition is not None:           # if / elif clause\n                try:\n                    match = condition.eval(context)\n                except VariableDoesNotExist:\n                    match = None\n            else:                               # else clause\n                match = True\n\n            if match:\n                return nodelist.render(context)\n\n        return ''\n\n\nclass LoremNode(Node):\n    def __init__(self, count, method, common):\n        self.count, self.method, self.common = count, method, common\n\n    def render(self, context):\n        try:\n            count = int(self.count.resolve(context))\n        except (ValueError, TypeError):\n            count = 1\n        if self.method == 'w':\n            return words(count, common=self.common)\n        else:\n            paras = paragraphs(count, common=self.common)\n        if self.method == 'p':\n            paras = ['<p>%s</p>' % p for p in paras]\n        return '\\n\\n'.join(paras)\n\n\nGroupedResult = namedtuple('GroupedResult', ['grouper', 'list'])\n\n\nclass RegroupNode(Node):\n    def __init__(self, target, expression, var_name):\n        self.target, self.expression = target, expression\n        self.var_name = var_name\n\n    def resolve_expression(self, obj, context):\n        # This method is called for each object in self.target. See regroup()\n        # for the reason why we temporarily put the object in the context.\n        context[self.var_name] = obj\n        return self.expression.resolve(context, ignore_failures=True)\n\n    def render(self, context):\n        obj_list = self.target.resolve(context, ignore_failures=True)\n        if obj_list is None:\n            # target variable wasn't found in context; fail silently.\n            context[self.var_name] = []\n            return ''\n        # List of dictionaries in the format:\n        # {'grouper': 'key', 'list': [list of contents]}.\n        context[self.var_name] = [\n            GroupedResult(grouper=key, list=list(val))\n            for key, val in\n            groupby(obj_list, lambda obj: self.resolve_expression(obj, context))\n        ]\n        return ''\n\n\nclass LoadNode(Node):\n    child_nodelists = ()\n\n    def render(self, context):\n        return ''\n\n\nclass NowNode(Node):\n    def __init__(self, format_string, asvar=None):\n        self.format_string = format_string\n        self.asvar = asvar\n\n    def render(self, context):\n        tzinfo = timezone.get_current_timezone() if settings.USE_TZ else None\n        formatted = date(datetime.now(tz=tzinfo), self.format_string)\n\n        if self.asvar:\n            context[self.asvar] = formatted\n            return ''\n        else:\n            return formatted\n\n\nclass ResetCycleNode(Node):\n    def __init__(self, node):\n        self.node = node\n\n    def render(self, context):\n        self.node.reset(context)\n        return ''\n\n\nclass SpacelessNode(Node):\n    def __init__(self, nodelist):\n        self.nodelist = nodelist\n\n    def render(self, context):\n        from django.utils.html import strip_spaces_between_tags\n        return strip_spaces_between_tags(self.nodelist.render(context).strip())\n\n\nclass TemplateTagNode(Node):\n    mapping = {\n        'openblock': BLOCK_TAG_START,\n        'closeblock': BLOCK_TAG_END,\n        'openvariable': VARIABLE_TAG_START,\n        'closevariable': VARIABLE_TAG_END,\n        'openbrace': SINGLE_BRACE_START,\n        'closebrace': SINGLE_BRACE_END,\n        'opencomment': COMMENT_TAG_START,\n        'closecomment': COMMENT_TAG_END,\n    }\n\n    def __init__(self, tagtype):\n        self.tagtype = tagtype\n\n    def render(self, context):\n        return self.mapping.get(self.tagtype, '')\n\n\nclass URLNode(Node):\n    child_nodelists = ()\n\n    def __init__(self, view_name, args, kwargs, asvar):\n        self.view_name = view_name\n        self.args = args\n        self.kwargs = kwargs\n        self.asvar = asvar\n\n    def __repr__(self):\n        return \"<%s view_name='%s' args=%s kwargs=%s as=%s>\" % (\n            self.__class__.__qualname__,\n            self.view_name,\n            repr(self.args),\n            repr(self.kwargs),\n            repr(self.asvar),\n        )\n\n    def render(self, context):\n        from django.urls import NoReverseMatch, reverse\n        args = [arg.resolve(context) for arg in self.args]\n        kwargs = {k: v.resolve(context) for k, v in self.kwargs.items()}\n        view_name = self.view_name.resolve(context)\n        try:\n            current_app = context.request.current_app\n        except AttributeError:\n            try:\n                current_app = context.request.resolver_match.namespace\n            except AttributeError:\n                current_app = None\n        # Try to look up the URL. If it fails, raise NoReverseMatch unless the\n        # {% url ... as var %} construct is used, in which case return nothing.\n        url = ''\n        try:\n            url = reverse(view_name, args=args, kwargs=kwargs, current_app=current_app)\n        except NoReverseMatch:\n            if self.asvar is None:\n                raise\n\n        if self.asvar:\n            context[self.asvar] = url\n            return ''\n        else:\n            if context.autoescape:\n                url = conditional_escape(url)\n            return url\n\n\nclass VerbatimNode(Node):\n    def __init__(self, content):\n        self.content = content\n\n    def render(self, context):\n        return self.content\n\n\nclass WidthRatioNode(Node):\n    def __init__(self, val_expr, max_expr, max_width, asvar=None):\n        self.val_expr = val_expr\n        self.max_expr = max_expr\n        self.max_width = max_width\n        self.asvar = asvar\n\n    def render(self, context):\n        try:\n            value = self.val_expr.resolve(context)\n            max_value = self.max_expr.resolve(context)\n            max_width = int(self.max_width.resolve(context))\n        except VariableDoesNotExist:\n            return ''\n        except (ValueError, TypeError):\n            raise TemplateSyntaxError(\"widthratio final argument must be a number\")\n        try:\n            value = float(value)\n            max_value = float(max_value)\n            ratio = (value / max_value) * max_width\n            result = str(round(ratio))\n        except ZeroDivisionError:\n            result = '0'\n        except (ValueError, TypeError, OverflowError):\n            result = ''\n\n        if self.asvar:\n            context[self.asvar] = result\n            return ''\n        else:\n            return result\n\n\nclass WithNode(Node):\n    def __init__(self, var, name, nodelist, extra_context=None):\n        self.nodelist = nodelist\n        # var and name are legacy attributes, being left in case they are used\n        # by third-party subclasses of this Node.\n        self.extra_context = extra_context or {}\n        if name:\n            self.extra_context[name] = var\n\n    def __repr__(self):\n        return '<%s>' % self.__class__.__name__\n\n    def render(self, context):\n        values = {key: val.resolve(context) for key, val in self.extra_context.items()}\n        with context.push(**values):\n            return self.nodelist.render(context)\n\n\n@register.tag\ndef autoescape(parser, token):\n    \"\"\"\n    Force autoescape behavior for this block.\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    args = token.contents.split()\n    if len(args) != 2:\n        raise TemplateSyntaxError(\"'autoescape' tag requires exactly one argument.\")\n    arg = args[1]\n    if arg not in ('on', 'off'):\n        raise TemplateSyntaxError(\"'autoescape' argument should be 'on' or 'off'\")\n    nodelist = parser.parse(('endautoescape',))\n    parser.delete_first_token()\n    return AutoEscapeControlNode((arg == 'on'), nodelist)\n\n\n@register.tag\ndef comment(parser, token):\n    \"\"\"\n    Ignore everything between ``{% comment %}`` and ``{% endcomment %}``.\n    \"\"\"\n    parser.skip_past('endcomment')\n    return CommentNode()\n\n\n@register.tag\ndef cycle(parser, token):\n    \"\"\"\n    Cycle among the given strings each time this tag is encountered.\n\n    Within a loop, cycles among the given strings each time through\n    the loop::\n\n        {% for o in some_list %}\n            <tr class=\"{% cycle 'row1' 'row2' %}\">\n                ...\n            </tr>\n        {% endfor %}\n\n    Outside of a loop, give the values a unique name the first time you call\n    it, then use that name each successive time through::\n\n            <tr class=\"{% cycle 'row1' 'row2' 'row3' as rowcolors %}\">...</tr>\n            <tr class=\"{% cycle rowcolors %}\">...</tr>\n            <tr class=\"{% cycle rowcolors %}\">...</tr>\n\n    You can use any number of values, separated by spaces. Commas can also\n    be used to separate values; if a comma is used, the cycle values are\n    interpreted as literal strings.\n\n    The optional flag \"silent\" can be used to prevent the cycle declaration\n    from returning any value::\n\n        {% for o in some_list %}\n            {% cycle 'row1' 'row2' as rowcolors silent %}\n            <tr class=\"{{ rowcolors }}\">{% include \"subtemplate.html \" %}</tr>\n        {% endfor %}\n    \"\"\"\n    # Note: This returns the exact same node on each {% cycle name %} call;\n    # that is, the node object returned from {% cycle a b c as name %} and the\n    # one returned from {% cycle name %} are the exact same object. This\n    # shouldn't cause problems (heh), but if it does, now you know.\n    #\n    # Ugly hack warning: This stuffs the named template dict into parser so\n    # that names are only unique within each template (as opposed to using\n    # a global variable, which would make cycle names have to be unique across\n    # *all* templates.\n    #\n    # It keeps the last node in the parser to be able to reset it with\n    # {% resetcycle %}.\n\n    args = token.split_contents()\n\n    if len(args) < 2:\n        raise TemplateSyntaxError(\"'cycle' tag requires at least two arguments\")\n\n    if len(args) == 2:\n        # {% cycle foo %} case.\n        name = args[1]\n        if not hasattr(parser, '_named_cycle_nodes'):\n            raise TemplateSyntaxError(\"No named cycles in template. '%s' is not defined\" % name)\n        if name not in parser._named_cycle_nodes:\n            raise TemplateSyntaxError(\"Named cycle '%s' does not exist\" % name)\n        return parser._named_cycle_nodes[name]\n\n    as_form = False\n\n    if len(args) > 4:\n        # {% cycle ... as foo [silent] %} case.\n        if args[-3] == \"as\":\n            if args[-1] != \"silent\":\n                raise TemplateSyntaxError(\"Only 'silent' flag is allowed after cycle's name, not '%s'.\" % args[-1])\n            as_form = True\n            silent = True\n            args = args[:-1]\n        elif args[-2] == \"as\":\n            as_form = True\n            silent = False\n\n    if as_form:\n        name = args[-1]\n        values = [parser.compile_filter(arg) for arg in args[1:-2]]\n        node = CycleNode(values, name, silent=silent)\n        if not hasattr(parser, '_named_cycle_nodes'):\n            parser._named_cycle_nodes = {}\n        parser._named_cycle_nodes[name] = node\n    else:\n        values = [parser.compile_filter(arg) for arg in args[1:]]\n        node = CycleNode(values)\n    parser._last_cycle_node = node\n    return node\n\n\n@register.tag\ndef csrf_token(parser, token):\n    return CsrfTokenNode()\n\n\n@register.tag\ndef debug(parser, token):\n    \"\"\"\n    Output a whole load of debugging information, including the current\n    context and imported modules.\n\n    Sample usage::\n\n        <pre>\n            {% debug %}\n        </pre>\n    \"\"\"\n    return DebugNode()\n\n\n@register.tag('filter')\ndef do_filter(parser, token):\n    \"\"\"\n    Filter the contents of the block through variable filters.\n\n    Filters can also be piped through each other, and they can have\n    arguments -- just like in variable syntax.\n\n    Sample usage::\n\n        {% filter force_escape|lower %}\n            This text will be HTML-escaped, and will appear in lowercase.\n        {% endfilter %}\n\n    Note that the ``escape`` and ``safe`` filters are not acceptable arguments.\n    Instead, use the ``autoescape`` tag to manage autoescaping for blocks of\n    template code.\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    _, rest = token.contents.split(None, 1)\n    filter_expr = parser.compile_filter(\"var|%s\" % (rest))\n    for func, unused in filter_expr.filters:\n        filter_name = getattr(func, '_filter_name', None)\n        if filter_name in ('escape', 'safe'):\n            raise TemplateSyntaxError('\"filter %s\" is not permitted.  Use the \"autoescape\" tag instead.' % filter_name)\n    nodelist = parser.parse(('endfilter',))\n    parser.delete_first_token()\n    return FilterNode(filter_expr, nodelist)\n\n\n@register.tag\ndef firstof(parser, token):\n    \"\"\"\n    Output the first variable passed that is not False.\n\n    Output nothing if all the passed variables are False.\n\n    Sample usage::\n\n        {% firstof var1 var2 var3 as myvar %}\n\n    This is equivalent to::\n\n        {% if var1 %}\n            {{ var1 }}\n        {% elif var2 %}\n            {{ var2 }}\n        {% elif var3 %}\n            {{ var3 }}\n        {% endif %}\n\n    but much cleaner!\n\n    You can also use a literal string as a fallback value in case all\n    passed variables are False::\n\n        {% firstof var1 var2 var3 \"fallback value\" %}\n\n    If you want to disable auto-escaping of variables you can use::\n\n        {% autoescape off %}\n            {% firstof var1 var2 var3 \"<strong>fallback value</strong>\" %}\n        {% autoescape %}\n\n    Or if only some variables should be escaped, you can use::\n\n        {% firstof var1 var2|safe var3 \"<strong>fallback value</strong>\"|safe %}\n    \"\"\"\n    bits = token.split_contents()[1:]\n    asvar = None\n    if not bits:\n        raise TemplateSyntaxError(\"'firstof' statement requires at least one argument\")\n\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n    return FirstOfNode([parser.compile_filter(bit) for bit in bits], asvar)\n\n\n@register.tag('for')\ndef do_for(parser, token):\n    \"\"\"\n    Loop over each item in an array.\n\n    For example, to display a list of athletes given ``athlete_list``::\n\n        <ul>\n        {% for athlete in athlete_list %}\n            <li>{{ athlete.name }}</li>\n        {% endfor %}\n        </ul>\n\n    You can loop over a list in reverse by using\n    ``{% for obj in list reversed %}``.\n\n    You can also unpack multiple values from a two-dimensional array::\n\n        {% for key,value in dict.items %}\n            {{ key }}: {{ value }}\n        {% endfor %}\n\n    The ``for`` tag can take an optional ``{% empty %}`` clause that will\n    be displayed if the given array is empty or could not be found::\n\n        <ul>\n          {% for athlete in athlete_list %}\n            <li>{{ athlete.name }}</li>\n          {% empty %}\n            <li>Sorry, no athletes in this list.</li>\n          {% endfor %}\n        <ul>\n\n    The above is equivalent to -- but shorter, cleaner, and possibly faster\n    than -- the following::\n\n        <ul>\n          {% if athlete_list %}\n            {% for athlete in athlete_list %}\n              <li>{{ athlete.name }}</li>\n            {% endfor %}\n          {% else %}\n            <li>Sorry, no athletes in this list.</li>\n          {% endif %}\n        </ul>\n\n    The for loop sets a number of variables available within the loop:\n\n        ==========================  ================================================\n        Variable                    Description\n        ==========================  ================================================\n        ``forloop.counter``         The current iteration of the loop (1-indexed)\n        ``forloop.counter0``        The current iteration of the loop (0-indexed)\n        ``forloop.revcounter``      The number of iterations from the end of the\n                                    loop (1-indexed)\n        ``forloop.revcounter0``     The number of iterations from the end of the\n                                    loop (0-indexed)\n        ``forloop.first``           True if this is the first time through the loop\n        ``forloop.last``            True if this is the last time through the loop\n        ``forloop.parentloop``      For nested loops, this is the loop \"above\" the\n                                    current one\n        ==========================  ================================================\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) < 4:\n        raise TemplateSyntaxError(\"'for' statements should have at least four\"\n                                  \" words: %s\" % token.contents)\n\n    is_reversed = bits[-1] == 'reversed'\n    in_index = -3 if is_reversed else -2\n    if bits[in_index] != 'in':\n        raise TemplateSyntaxError(\"'for' statements should use the format\"\n                                  \" 'for x in y': %s\" % token.contents)\n\n    invalid_chars = frozenset((' ', '\"', \"'\", FILTER_SEPARATOR))\n    loopvars = re.split(r' *, *', ' '.join(bits[1:in_index]))\n    for var in loopvars:\n        if not var or not invalid_chars.isdisjoint(var):\n            raise TemplateSyntaxError(\"'for' tag received an invalid argument:\"\n                                      \" %s\" % token.contents)\n\n    sequence = parser.compile_filter(bits[in_index + 1])\n    nodelist_loop = parser.parse(('empty', 'endfor',))\n    token = parser.next_token()\n    if token.contents == 'empty':\n        nodelist_empty = parser.parse(('endfor',))\n        parser.delete_first_token()\n    else:\n        nodelist_empty = None\n    return ForNode(loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty)\n\n\nclass TemplateLiteral(Literal):\n    def __init__(self, value, text):\n        self.value = value\n        self.text = text  # for better error messages\n\n    def display(self):\n        return self.text\n\n    def eval(self, context):\n        return self.value.resolve(context, ignore_failures=True)\n\n\nclass TemplateIfParser(IfParser):\n    error_class = TemplateSyntaxError\n\n    def __init__(self, parser, *args, **kwargs):\n        self.template_parser = parser\n        super().__init__(*args, **kwargs)\n\n    def create_var(self, value):\n        return TemplateLiteral(self.template_parser.compile_filter(value), value)\n\n\n@register.tag('if')\ndef do_if(parser, token):\n    \"\"\"\n    Evaluate a variable, and if that variable is \"true\" (i.e., exists, is not\n    empty, and is not a false boolean value), output the contents of the block:\n\n    ::\n\n        {% if athlete_list %}\n            Number of athletes: {{ athlete_list|count }}\n        {% elif athlete_in_locker_room_list %}\n            Athletes should be out of the locker room soon!\n        {% else %}\n            No athletes.\n        {% endif %}\n\n    In the above, if ``athlete_list`` is not empty, the number of athletes will\n    be displayed by the ``{{ athlete_list|count }}`` variable.\n\n    The ``if`` tag may take one or several `` {% elif %}`` clauses, as well as\n    an ``{% else %}`` clause that will be displayed if all previous conditions\n    fail. These clauses are optional.\n\n    ``if`` tags may use ``or``, ``and`` or ``not`` to test a number of\n    variables or to negate a given variable::\n\n        {% if not athlete_list %}\n            There are no athletes.\n        {% endif %}\n\n        {% if athlete_list or coach_list %}\n            There are some athletes or some coaches.\n        {% endif %}\n\n        {% if athlete_list and coach_list %}\n            Both athletes and coaches are available.\n        {% endif %}\n\n        {% if not athlete_list or coach_list %}\n            There are no athletes, or there are some coaches.\n        {% endif %}\n\n        {% if athlete_list and not coach_list %}\n            There are some athletes and absolutely no coaches.\n        {% endif %}\n\n    Comparison operators are also available, and the use of filters is also\n    allowed, for example::\n\n        {% if articles|length >= 5 %}...{% endif %}\n\n    Arguments and operators _must_ have a space between them, so\n    ``{% if 1>2 %}`` is not a valid if tag.\n\n    All supported operators are: ``or``, ``and``, ``in``, ``not in``\n    ``==``, ``!=``, ``>``, ``>=``, ``<`` and ``<=``.\n\n    Operator precedence follows Python.\n    \"\"\"\n    # {% if ... %}\n    bits = token.split_contents()[1:]\n    condition = TemplateIfParser(parser, bits).parse()\n    nodelist = parser.parse(('elif', 'else', 'endif'))\n    conditions_nodelists = [(condition, nodelist)]\n    token = parser.next_token()\n\n    # {% elif ... %} (repeatable)\n    while token.contents.startswith('elif'):\n        bits = token.split_contents()[1:]\n        condition = TemplateIfParser(parser, bits).parse()\n        nodelist = parser.parse(('elif', 'else', 'endif'))\n        conditions_nodelists.append((condition, nodelist))\n        token = parser.next_token()\n\n    # {% else %} (optional)\n    if token.contents == 'else':\n        nodelist = parser.parse(('endif',))\n        conditions_nodelists.append((None, nodelist))\n        token = parser.next_token()\n\n    # {% endif %}\n    if token.contents != 'endif':\n        raise TemplateSyntaxError('Malformed template tag at line {}: \"{}\"'.format(token.lineno, token.contents))\n\n    return IfNode(conditions_nodelists)\n\n\n@register.tag\ndef ifchanged(parser, token):\n    \"\"\"\n    Check if a value has changed from the last iteration of a loop.\n\n    The ``{% ifchanged %}`` block tag is used within a loop. It has two\n    possible uses.\n\n    1. Check its own rendered contents against its previous state and only\n       displays the content if it has changed. For example, this displays a\n       list of days, only displaying the month if it changes::\n\n            <h1>Archive for {{ year }}</h1>\n\n            {% for date in days %}\n                {% ifchanged %}<h3>{{ date|date:\"F\" }}</h3>{% endifchanged %}\n                <a href=\"{{ date|date:\"M/d\"|lower }}/\">{{ date|date:\"j\" }}</a>\n            {% endfor %}\n\n    2. If given one or more variables, check whether any variable has changed.\n       For example, the following shows the date every time it changes, while\n       showing the hour if either the hour or the date has changed::\n\n            {% for date in days %}\n                {% ifchanged date.date %} {{ date.date }} {% endifchanged %}\n                {% ifchanged date.hour date.date %}\n                    {{ date.hour }}\n                {% endifchanged %}\n            {% endfor %}\n    \"\"\"\n    bits = token.split_contents()\n    nodelist_true = parser.parse(('else', 'endifchanged'))\n    token = parser.next_token()\n    if token.contents == 'else':\n        nodelist_false = parser.parse(('endifchanged',))\n        parser.delete_first_token()\n    else:\n        nodelist_false = NodeList()\n    values = [parser.compile_filter(bit) for bit in bits[1:]]\n    return IfChangedNode(nodelist_true, nodelist_false, *values)\n\n\ndef find_library(parser, name):\n    try:\n        return parser.libraries[name]\n    except KeyError:\n        raise TemplateSyntaxError(\n            \"'%s' is not a registered tag library. Must be one of:\\n%s\" % (\n                name, \"\\n\".join(sorted(parser.libraries)),\n            ),\n        )\n\n\ndef load_from_library(library, label, names):\n    \"\"\"\n    Return a subset of tags and filters from a library.\n    \"\"\"\n    subset = Library()\n    for name in names:\n        found = False\n        if name in library.tags:\n            found = True\n            subset.tags[name] = library.tags[name]\n        if name in library.filters:\n            found = True\n            subset.filters[name] = library.filters[name]\n        if found is False:\n            raise TemplateSyntaxError(\n                \"'%s' is not a valid tag or filter in tag library '%s'\" % (\n                    name, label,\n                ),\n            )\n    return subset\n\n\n@register.tag\ndef load(parser, token):\n    \"\"\"\n    Load a custom template tag library into the parser.\n\n    For example, to load the template tags in\n    ``django/templatetags/news/photos.py``::\n\n        {% load news.photos %}\n\n    Can also be used to load an individual tag/filter from\n    a library::\n\n        {% load byline from news %}\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    bits = token.contents.split()\n    if len(bits) >= 4 and bits[-2] == \"from\":\n        # from syntax is used; load individual tags from the library\n        name = bits[-1]\n        lib = find_library(parser, name)\n        subset = load_from_library(lib, name, bits[1:-2])\n        parser.add_library(subset)\n    else:\n        # one or more libraries are specified; load and add them to the parser\n        for name in bits[1:]:\n            lib = find_library(parser, name)\n            parser.add_library(lib)\n    return LoadNode()\n\n\n@register.tag\ndef lorem(parser, token):\n    \"\"\"\n    Create random Latin text useful for providing test data in templates.\n\n    Usage format::\n\n        {% lorem [count] [method] [random] %}\n\n    ``count`` is a number (or variable) containing the number of paragraphs or\n    words to generate (default is 1).\n\n    ``method`` is either ``w`` for words, ``p`` for HTML paragraphs, ``b`` for\n    plain-text paragraph blocks (default is ``b``).\n\n    ``random`` is the word ``random``, which if given, does not use the common\n    paragraph (starting \"Lorem ipsum dolor sit amet, consectetuer...\").\n\n    Examples:\n\n    * ``{% lorem %}`` outputs the common \"lorem ipsum\" paragraph\n    * ``{% lorem 3 p %}`` outputs the common \"lorem ipsum\" paragraph\n      and two random paragraphs each wrapped in HTML ``<p>`` tags\n    * ``{% lorem 2 w random %}`` outputs two random latin words\n    \"\"\"\n    bits = list(token.split_contents())\n    tagname = bits[0]\n    # Random bit\n    common = bits[-1] != 'random'\n    if not common:\n        bits.pop()\n    # Method bit\n    if bits[-1] in ('w', 'p', 'b'):\n        method = bits.pop()\n    else:\n        method = 'b'\n    # Count bit\n    if len(bits) > 1:\n        count = bits.pop()\n    else:\n        count = '1'\n    count = parser.compile_filter(count)\n    if len(bits) != 1:\n        raise TemplateSyntaxError(\"Incorrect format for %r tag\" % tagname)\n    return LoremNode(count, method, common)\n\n\n@register.tag\ndef now(parser, token):\n    \"\"\"\n    Display the date, formatted according to the given string.\n\n    Use the same format as PHP's ``date()`` function; see https://php.net/date\n    for all the possible values.\n\n    Sample usage::\n\n        It is {% now \"jS F Y H:i\" %}\n    \"\"\"\n    bits = token.split_contents()\n    asvar = None\n    if len(bits) == 4 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n    if len(bits) != 2:\n        raise TemplateSyntaxError(\"'now' statement takes one argument\")\n    format_string = bits[1][1:-1]\n    return NowNode(format_string, asvar)\n\n\n@register.tag\ndef regroup(parser, token):\n    \"\"\"\n    Regroup a list of alike objects by a common attribute.\n\n    This complex tag is best illustrated by use of an example: say that\n    ``musicians`` is a list of ``Musician`` objects that have ``name`` and\n    ``instrument`` attributes, and you'd like to display a list that\n    looks like:\n\n        * Guitar:\n            * Django Reinhardt\n            * Emily Remler\n        * Piano:\n            * Lovie Austin\n            * Bud Powell\n        * Trumpet:\n            * Duke Ellington\n\n    The following snippet of template code would accomplish this dubious task::\n\n        {% regroup musicians by instrument as grouped %}\n        <ul>\n        {% for group in grouped %}\n            <li>{{ group.grouper }}\n            <ul>\n                {% for musician in group.list %}\n                <li>{{ musician.name }}</li>\n                {% endfor %}\n            </ul>\n        {% endfor %}\n        </ul>\n\n    As you can see, ``{% regroup %}`` populates a variable with a list of\n    objects with ``grouper`` and ``list`` attributes. ``grouper`` contains the\n    item that was grouped by; ``list`` contains the list of objects that share\n    that ``grouper``. In this case, ``grouper`` would be ``Guitar``, ``Piano``\n    and ``Trumpet``, and ``list`` is the list of musicians who play this\n    instrument.\n\n    Note that ``{% regroup %}`` does not work when the list to be grouped is not\n    sorted by the key you are grouping by! This means that if your list of\n    musicians was not sorted by instrument, you'd need to make sure it is sorted\n    before using it, i.e.::\n\n        {% regroup musicians|dictsort:\"instrument\" by instrument as grouped %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) != 6:\n        raise TemplateSyntaxError(\"'regroup' tag takes five arguments\")\n    target = parser.compile_filter(bits[1])\n    if bits[2] != 'by':\n        raise TemplateSyntaxError(\"second argument to 'regroup' tag must be 'by'\")\n    if bits[4] != 'as':\n        raise TemplateSyntaxError(\"next-to-last argument to 'regroup' tag must\"\n                                  \" be 'as'\")\n    var_name = bits[5]\n    # RegroupNode will take each item in 'target', put it in the context under\n    # 'var_name', evaluate 'var_name'.'expression' in the current context, and\n    # group by the resulting value. After all items are processed, it will\n    # save the final result in the context under 'var_name', thus clearing the\n    # temporary values. This hack is necessary because the template engine\n    # doesn't provide a context-aware equivalent of Python's getattr.\n    expression = parser.compile_filter(var_name +\n                                       VARIABLE_ATTRIBUTE_SEPARATOR +\n                                       bits[3])\n    return RegroupNode(target, expression, var_name)\n\n\n@register.tag\ndef resetcycle(parser, token):\n    \"\"\"\n    Reset a cycle tag.\n\n    If an argument is given, reset the last rendered cycle tag whose name\n    matches the argument, else reset the last rendered cycle tag (named or\n    unnamed).\n    \"\"\"\n    args = token.split_contents()\n\n    if len(args) > 2:\n        raise TemplateSyntaxError(\"%r tag accepts at most one argument.\" % args[0])\n\n    if len(args) == 2:\n        name = args[1]\n        try:\n            return ResetCycleNode(parser._named_cycle_nodes[name])\n        except (AttributeError, KeyError):\n            raise TemplateSyntaxError(\"Named cycle '%s' does not exist.\" % name)\n    try:\n        return ResetCycleNode(parser._last_cycle_node)\n    except AttributeError:\n        raise TemplateSyntaxError(\"No cycles in template.\")\n\n\n@register.tag\ndef spaceless(parser, token):\n    \"\"\"\n    Remove whitespace between HTML tags, including tab and newline characters.\n\n    Example usage::\n\n        {% spaceless %}\n            <p>\n                <a href=\"foo/\">Foo</a>\n            </p>\n        {% endspaceless %}\n\n    This example returns this HTML::\n\n        <p><a href=\"foo/\">Foo</a></p>\n\n    Only space between *tags* is normalized -- not space between tags and text.\n    In this example, the space around ``Hello`` isn't stripped::\n\n        {% spaceless %}\n            <strong>\n                Hello\n            </strong>\n        {% endspaceless %}\n    \"\"\"\n    nodelist = parser.parse(('endspaceless',))\n    parser.delete_first_token()\n    return SpacelessNode(nodelist)\n\n\n@register.tag\ndef templatetag(parser, token):\n    \"\"\"\n    Output one of the bits used to compose template tags.\n\n    Since the template system has no concept of \"escaping\", to display one of\n    the bits used in template tags, you must use the ``{% templatetag %}`` tag.\n\n    The argument tells which template bit to output:\n\n        ==================  =======\n        Argument            Outputs\n        ==================  =======\n        ``openblock``       ``{%``\n        ``closeblock``      ``%}``\n        ``openvariable``    ``{{``\n        ``closevariable``   ``}}``\n        ``openbrace``       ``{``\n        ``closebrace``      ``}``\n        ``opencomment``     ``{#``\n        ``closecomment``    ``#}``\n        ==================  =======\n    \"\"\"\n    # token.split_contents() isn't useful here because this tag doesn't accept variable as arguments\n    bits = token.contents.split()\n    if len(bits) != 2:\n        raise TemplateSyntaxError(\"'templatetag' statement takes one argument\")\n    tag = bits[1]\n    if tag not in TemplateTagNode.mapping:\n        raise TemplateSyntaxError(\"Invalid templatetag argument: '%s'.\"\n                                  \" Must be one of: %s\" %\n                                  (tag, list(TemplateTagNode.mapping)))\n    return TemplateTagNode(tag)\n\n\n@register.tag\ndef url(parser, token):\n    r\"\"\"\n    Return an absolute URL matching the given view with its parameters.\n\n    This is a way to define links that aren't tied to a particular URL\n    configuration::\n\n        {% url \"url_name\" arg1 arg2 %}\n\n        or\n\n        {% url \"url_name\" name1=value1 name2=value2 %}\n\n    The first argument is a URL pattern name. Other arguments are\n    space-separated values that will be filled in place of positional and\n    keyword arguments in the URL. Don't mix positional and keyword arguments.\n    All arguments for the URL must be present.\n\n    For example, if you have a view ``app_name.views.client_details`` taking\n    the client's id and the corresponding line in a URLconf looks like this::\n\n        path('client/<int:id>/', views.client_details, name='client-detail-view')\n\n    and this app's URLconf is included into the project's URLconf under some\n    path::\n\n        path('clients/', include('app_name.urls'))\n\n    then in a template you can create a link for a certain client like this::\n\n        {% url \"client-detail-view\" client.id %}\n\n    The URL will look like ``/clients/client/123/``.\n\n    The first argument may also be the name of a template variable that will be\n    evaluated to obtain the view name or the URL name, e.g.::\n\n        {% with url_name=\"client-detail-view\" %}\n        {% url url_name client.id %}\n        {% endwith %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) < 2:\n        raise TemplateSyntaxError(\"'%s' takes at least one argument, a URL pattern name.\" % bits[0])\n    viewname = parser.compile_filter(bits[1])\n    args = []\n    kwargs = {}\n    asvar = None\n    bits = bits[2:]\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n\n    for bit in bits:\n        match = kwarg_re.match(bit)\n        if not match:\n            raise TemplateSyntaxError(\"Malformed arguments to url tag\")\n        name, value = match.groups()\n        if name:\n            kwargs[name] = parser.compile_filter(value)\n        else:\n            args.append(parser.compile_filter(value))\n\n    return URLNode(viewname, args, kwargs, asvar)\n\n\n@register.tag\ndef verbatim(parser, token):\n    \"\"\"\n    Stop the template engine from rendering the contents of this block tag.\n\n    Usage::\n\n        {% verbatim %}\n            {% don't process this %}\n        {% endverbatim %}\n\n    You can also designate a specific closing tag block (allowing the\n    unrendered use of ``{% endverbatim %}``)::\n\n        {% verbatim myblock %}\n            ...\n        {% endverbatim myblock %}\n    \"\"\"\n    nodelist = parser.parse(('endverbatim',))\n    parser.delete_first_token()\n    return VerbatimNode(nodelist.render(Context()))\n\n\n@register.tag\ndef widthratio(parser, token):\n    \"\"\"\n    For creating bar charts and such. Calculate the ratio of a given value to a\n    maximum value, and then apply that ratio to a constant.\n\n    For example::\n\n        <img src=\"bar.png\" alt=\"Bar\"\n             height=\"10\" width=\"{% widthratio this_value max_value max_width %}\">\n\n    If ``this_value`` is 175, ``max_value`` is 200, and ``max_width`` is 100,\n    the image in the above example will be 88 pixels wide\n    (because 175/200 = .875; .875 * 100 = 87.5 which is rounded up to 88).\n\n    In some cases you might want to capture the result of widthratio in a\n    variable. It can be useful for instance in a blocktranslate like this::\n\n        {% widthratio this_value max_value max_width as width %}\n        {% blocktranslate %}The width is: {{ width }}{% endblocktranslate %}\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) == 4:\n        tag, this_value_expr, max_value_expr, max_width = bits\n        asvar = None\n    elif len(bits) == 6:\n        tag, this_value_expr, max_value_expr, max_width, as_, asvar = bits\n        if as_ != 'as':\n            raise TemplateSyntaxError(\"Invalid syntax in widthratio tag. Expecting 'as' keyword\")\n    else:\n        raise TemplateSyntaxError(\"widthratio takes at least three arguments\")\n\n    return WidthRatioNode(parser.compile_filter(this_value_expr),\n                          parser.compile_filter(max_value_expr),\n                          parser.compile_filter(max_width),\n                          asvar=asvar)\n\n\n@register.tag('with')\ndef do_with(parser, token):\n    \"\"\"\n    Add one or more values to the context (inside of this block) for caching\n    and easy access.\n\n    For example::\n\n        {% with total=person.some_sql_method %}\n            {{ total }} object{{ total|pluralize }}\n        {% endwith %}\n\n    Multiple values can be added to the context::\n\n        {% with foo=1 bar=2 %}\n            ...\n        {% endwith %}\n\n    The legacy format of ``{% with person.some_sql_method as total %}`` is\n    still accepted.\n    \"\"\"\n    bits = token.split_contents()\n    remaining_bits = bits[1:]\n    extra_context = token_kwargs(remaining_bits, parser, support_legacy=True)\n    if not extra_context:\n        raise TemplateSyntaxError(\"%r expected at least one variable \"\n                                  \"assignment\" % bits[0])\n    if remaining_bits:\n        raise TemplateSyntaxError(\"%r received an invalid token: %r\" %\n                                  (bits[0], remaining_bits[0]))\n    nodelist = parser.parse(('endwith',))\n    parser.delete_first_token()\n    return WithNode(None, None, nodelist, extra_context=extra_context)\n"
  },
  {
    "patch": "diff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 8ee6443d2b..bbb3e8b21d 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -51,7 +51,10 @@ class Storage:\n             content = File(content, name)\n \n         name = self.get_available_name(name, max_length=max_length)\n-        return self._save(name, content)\n+        name = self._save(name, content)\n+        # Ensure that the name returned from the storage system is still valid.\n+        validate_file_name(name, allow_relative_path=True)\n+        return name\n \n     # These methods are part of the public API, with default implementations.\n \n@@ -75,6 +78,7 @@ class Storage:\n         Return a filename that's free on the target storage system and\n         available for new content to be written to.\n         \"\"\"\n+        name = str(name).replace('\\\\', '/')\n         dir_name, file_name = os.path.split(name)\n         if '..' in pathlib.PurePath(dir_name).parts:\n             raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n@@ -108,6 +112,7 @@ class Storage:\n         Validate the filename by calling get_valid_name() and return a filename\n         to be passed to the save() method.\n         \"\"\"\n+        filename = str(filename).replace('\\\\', '/')\n         # `filename` may include a path as returned by FileField.upload_to.\n         dirname, filename = os.path.split(filename)\n         if '..' in pathlib.PurePath(dirname).parts:\n@@ -297,6 +302,8 @@ class FileSystemStorage(Storage):\n         if self.file_permissions_mode is not None:\n             os.chmod(full_path, self.file_permissions_mode)\n \n+        # Ensure the saved path is always relative to the storage root.\n+        name = os.path.relpath(full_path, self.location)\n         # Store filenames with forward slashes, even on Windows.\n         return str(name).replace('\\\\', '/')\n \n",
    "commit_message": "Fixed CVE-2021-45452 -- Fixed potential path traversal in storage subsystem.\n\nThanks to Dennis Brinkrolf for the report.\n\n",
    "code_before": "import os\nimport pathlib\nfrom datetime import datetime\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.core.exceptions import SuspiciousFileOperation\nfrom django.core.files import File, locks\nfrom django.core.files.move import file_move_safe\nfrom django.core.files.utils import validate_file_name\nfrom django.core.signals import setting_changed\nfrom django.utils import timezone\nfrom django.utils._os import safe_join\nfrom django.utils.crypto import get_random_string\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.encoding import filepath_to_uri\nfrom django.utils.functional import LazyObject, cached_property\nfrom django.utils.module_loading import import_string\nfrom django.utils.text import get_valid_filename\n\n__all__ = (\n    'Storage', 'FileSystemStorage', 'DefaultStorage', 'default_storage',\n    'get_storage_class',\n)\n\n\nclass Storage:\n    \"\"\"\n    A base storage class, providing some default behaviors that all other\n    storage systems can inherit or override, as necessary.\n    \"\"\"\n\n    # The following methods represent a public interface to private methods.\n    # These shouldn't be overridden by subclasses unless absolutely necessary.\n\n    def open(self, name, mode='rb'):\n        \"\"\"Retrieve the specified file from storage.\"\"\"\n        return self._open(name, mode)\n\n    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        return self._save(name, content)\n\n    # These methods are part of the public API, with default implementations.\n\n    def get_valid_name(self, name):\n        \"\"\"\n        Return a filename, based on the provided filename, that's suitable for\n        use in the target storage system.\n        \"\"\"\n        return get_valid_filename(name)\n\n    def get_alternative_name(self, file_root, file_ext):\n        \"\"\"\n        Return an alternative filename, by adding an underscore and a random 7\n        character alphanumeric string (before the file extension, if one\n        exists) to the filename.\n        \"\"\"\n        return '%s_%s%s' % (file_root, get_random_string(7), file_ext)\n\n    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n\n    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n\n    def path(self, name):\n        \"\"\"\n        Return a local filesystem path where the file can be retrieved using\n        Python's built-in open() function. Storage systems that can't be\n        accessed using open() should *not* implement this method.\n        \"\"\"\n        raise NotImplementedError(\"This backend doesn't support absolute paths.\")\n\n    # The following methods form the public API for storage systems, but with\n    # no default implementations. Subclasses must implement *all* of these.\n\n    def delete(self, name):\n        \"\"\"\n        Delete the specified file from the storage system.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a delete() method')\n\n    def exists(self, name):\n        \"\"\"\n        Return True if a file referenced by the given name already exists in the\n        storage system, or False if the name is available for a new file.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide an exists() method')\n\n    def listdir(self, path):\n        \"\"\"\n        List the contents of the specified path. Return a 2-tuple of lists:\n        the first item being directories, the second item being files.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a listdir() method')\n\n    def size(self, name):\n        \"\"\"\n        Return the total size, in bytes, of the file specified by name.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a size() method')\n\n    def url(self, name):\n        \"\"\"\n        Return an absolute URL where the file's contents can be accessed\n        directly by a web browser.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a url() method')\n\n    def get_accessed_time(self, name):\n        \"\"\"\n        Return the last accessed time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_accessed_time() method')\n\n    def get_created_time(self, name):\n        \"\"\"\n        Return the creation time (as a datetime) of the file specified by name.\n        The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_created_time() method')\n\n    def get_modified_time(self, name):\n        \"\"\"\n        Return the last modified time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_modified_time() method')\n\n\n@deconstructible\nclass FileSystemStorage(Storage):\n    \"\"\"\n    Standard filesystem storage\n    \"\"\"\n    # The combination of O_CREAT and O_EXCL makes os.open() raise OSError if\n    # the file already exists before it's opened.\n    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)\n\n    def __init__(self, location=None, base_url=None, file_permissions_mode=None,\n                 directory_permissions_mode=None):\n        self._location = location\n        self._base_url = base_url\n        self._file_permissions_mode = file_permissions_mode\n        self._directory_permissions_mode = directory_permissions_mode\n        setting_changed.connect(self._clear_cached_properties)\n\n    def _clear_cached_properties(self, setting, **kwargs):\n        \"\"\"Reset setting based property values.\"\"\"\n        if setting == 'MEDIA_ROOT':\n            self.__dict__.pop('base_location', None)\n            self.__dict__.pop('location', None)\n        elif setting == 'MEDIA_URL':\n            self.__dict__.pop('base_url', None)\n        elif setting == 'FILE_UPLOAD_PERMISSIONS':\n            self.__dict__.pop('file_permissions_mode', None)\n        elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS':\n            self.__dict__.pop('directory_permissions_mode', None)\n\n    def _value_or_setting(self, value, setting):\n        return setting if value is None else value\n\n    @cached_property\n    def base_location(self):\n        return self._value_or_setting(self._location, settings.MEDIA_ROOT)\n\n    @cached_property\n    def location(self):\n        return os.path.abspath(self.base_location)\n\n    @cached_property\n    def base_url(self):\n        if self._base_url is not None and not self._base_url.endswith('/'):\n            self._base_url += '/'\n        return self._value_or_setting(self._base_url, settings.MEDIA_URL)\n\n    @cached_property\n    def file_permissions_mode(self):\n        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n\n    @cached_property\n    def directory_permissions_mode(self):\n        return self._value_or_setting(self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS)\n\n    def _open(self, name, mode='rb'):\n        return File(open(self.path(name), mode))\n\n    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n\n    def delete(self, name):\n        if not name:\n            raise ValueError('The name must be given to delete().')\n        name = self.path(name)\n        # If the file or directory exists, delete it from the filesystem.\n        try:\n            if os.path.isdir(name):\n                os.rmdir(name)\n            else:\n                os.remove(name)\n        except FileNotFoundError:\n            # FileNotFoundError is raised if the file or directory was removed\n            # concurrently.\n            pass\n\n    def exists(self, name):\n        return os.path.lexists(self.path(name))\n\n    def listdir(self, path):\n        path = self.path(path)\n        directories, files = [], []\n        with os.scandir(path) as entries:\n            for entry in entries:\n                if entry.is_dir():\n                    directories.append(entry.name)\n                else:\n                    files.append(entry.name)\n        return directories, files\n\n    def path(self, name):\n        return safe_join(self.location, name)\n\n    def size(self, name):\n        return os.path.getsize(self.path(name))\n\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        return urljoin(self.base_url, url)\n\n    def _datetime_from_timestamp(self, ts):\n        \"\"\"\n        If timezone support is enabled, make an aware datetime object in UTC;\n        otherwise make a naive one in the local timezone.\n        \"\"\"\n        tz = timezone.utc if settings.USE_TZ else None\n        return datetime.fromtimestamp(ts, tz=tz)\n\n    def get_accessed_time(self, name):\n        return self._datetime_from_timestamp(os.path.getatime(self.path(name)))\n\n    def get_created_time(self, name):\n        return self._datetime_from_timestamp(os.path.getctime(self.path(name)))\n\n    def get_modified_time(self, name):\n        return self._datetime_from_timestamp(os.path.getmtime(self.path(name)))\n\n\ndef get_storage_class(import_path=None):\n    return import_string(import_path or settings.DEFAULT_FILE_STORAGE)\n\n\nclass DefaultStorage(LazyObject):\n    def _setup(self):\n        self._wrapped = get_storage_class()()\n\n\ndefault_storage = DefaultStorage()\n",
    "code_after": "import os\nimport pathlib\nfrom datetime import datetime\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.core.exceptions import SuspiciousFileOperation\nfrom django.core.files import File, locks\nfrom django.core.files.move import file_move_safe\nfrom django.core.files.utils import validate_file_name\nfrom django.core.signals import setting_changed\nfrom django.utils import timezone\nfrom django.utils._os import safe_join\nfrom django.utils.crypto import get_random_string\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.encoding import filepath_to_uri\nfrom django.utils.functional import LazyObject, cached_property\nfrom django.utils.module_loading import import_string\nfrom django.utils.text import get_valid_filename\n\n__all__ = (\n    'Storage', 'FileSystemStorage', 'DefaultStorage', 'default_storage',\n    'get_storage_class',\n)\n\n\nclass Storage:\n    \"\"\"\n    A base storage class, providing some default behaviors that all other\n    storage systems can inherit or override, as necessary.\n    \"\"\"\n\n    # The following methods represent a public interface to private methods.\n    # These shouldn't be overridden by subclasses unless absolutely necessary.\n\n    def open(self, name, mode='rb'):\n        \"\"\"Retrieve the specified file from storage.\"\"\"\n        return self._open(name, mode)\n\n    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        name = self._save(name, content)\n        # Ensure that the name returned from the storage system is still valid.\n        validate_file_name(name, allow_relative_path=True)\n        return name\n\n    # These methods are part of the public API, with default implementations.\n\n    def get_valid_name(self, name):\n        \"\"\"\n        Return a filename, based on the provided filename, that's suitable for\n        use in the target storage system.\n        \"\"\"\n        return get_valid_filename(name)\n\n    def get_alternative_name(self, file_root, file_ext):\n        \"\"\"\n        Return an alternative filename, by adding an underscore and a random 7\n        character alphanumeric string (before the file extension, if one\n        exists) to the filename.\n        \"\"\"\n        return '%s_%s%s' % (file_root, get_random_string(7), file_ext)\n\n    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        name = str(name).replace('\\\\', '/')\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n\n    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        filename = str(filename).replace('\\\\', '/')\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n\n    def path(self, name):\n        \"\"\"\n        Return a local filesystem path where the file can be retrieved using\n        Python's built-in open() function. Storage systems that can't be\n        accessed using open() should *not* implement this method.\n        \"\"\"\n        raise NotImplementedError(\"This backend doesn't support absolute paths.\")\n\n    # The following methods form the public API for storage systems, but with\n    # no default implementations. Subclasses must implement *all* of these.\n\n    def delete(self, name):\n        \"\"\"\n        Delete the specified file from the storage system.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a delete() method')\n\n    def exists(self, name):\n        \"\"\"\n        Return True if a file referenced by the given name already exists in the\n        storage system, or False if the name is available for a new file.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide an exists() method')\n\n    def listdir(self, path):\n        \"\"\"\n        List the contents of the specified path. Return a 2-tuple of lists:\n        the first item being directories, the second item being files.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a listdir() method')\n\n    def size(self, name):\n        \"\"\"\n        Return the total size, in bytes, of the file specified by name.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a size() method')\n\n    def url(self, name):\n        \"\"\"\n        Return an absolute URL where the file's contents can be accessed\n        directly by a web browser.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a url() method')\n\n    def get_accessed_time(self, name):\n        \"\"\"\n        Return the last accessed time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_accessed_time() method')\n\n    def get_created_time(self, name):\n        \"\"\"\n        Return the creation time (as a datetime) of the file specified by name.\n        The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_created_time() method')\n\n    def get_modified_time(self, name):\n        \"\"\"\n        Return the last modified time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_modified_time() method')\n\n\n@deconstructible\nclass FileSystemStorage(Storage):\n    \"\"\"\n    Standard filesystem storage\n    \"\"\"\n    # The combination of O_CREAT and O_EXCL makes os.open() raise OSError if\n    # the file already exists before it's opened.\n    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)\n\n    def __init__(self, location=None, base_url=None, file_permissions_mode=None,\n                 directory_permissions_mode=None):\n        self._location = location\n        self._base_url = base_url\n        self._file_permissions_mode = file_permissions_mode\n        self._directory_permissions_mode = directory_permissions_mode\n        setting_changed.connect(self._clear_cached_properties)\n\n    def _clear_cached_properties(self, setting, **kwargs):\n        \"\"\"Reset setting based property values.\"\"\"\n        if setting == 'MEDIA_ROOT':\n            self.__dict__.pop('base_location', None)\n            self.__dict__.pop('location', None)\n        elif setting == 'MEDIA_URL':\n            self.__dict__.pop('base_url', None)\n        elif setting == 'FILE_UPLOAD_PERMISSIONS':\n            self.__dict__.pop('file_permissions_mode', None)\n        elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS':\n            self.__dict__.pop('directory_permissions_mode', None)\n\n    def _value_or_setting(self, value, setting):\n        return setting if value is None else value\n\n    @cached_property\n    def base_location(self):\n        return self._value_or_setting(self._location, settings.MEDIA_ROOT)\n\n    @cached_property\n    def location(self):\n        return os.path.abspath(self.base_location)\n\n    @cached_property\n    def base_url(self):\n        if self._base_url is not None and not self._base_url.endswith('/'):\n            self._base_url += '/'\n        return self._value_or_setting(self._base_url, settings.MEDIA_URL)\n\n    @cached_property\n    def file_permissions_mode(self):\n        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n\n    @cached_property\n    def directory_permissions_mode(self):\n        return self._value_or_setting(self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS)\n\n    def _open(self, name, mode='rb'):\n        return File(open(self.path(name), mode))\n\n    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Ensure the saved path is always relative to the storage root.\n        name = os.path.relpath(full_path, self.location)\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n\n    def delete(self, name):\n        if not name:\n            raise ValueError('The name must be given to delete().')\n        name = self.path(name)\n        # If the file or directory exists, delete it from the filesystem.\n        try:\n            if os.path.isdir(name):\n                os.rmdir(name)\n            else:\n                os.remove(name)\n        except FileNotFoundError:\n            # FileNotFoundError is raised if the file or directory was removed\n            # concurrently.\n            pass\n\n    def exists(self, name):\n        return os.path.lexists(self.path(name))\n\n    def listdir(self, path):\n        path = self.path(path)\n        directories, files = [], []\n        with os.scandir(path) as entries:\n            for entry in entries:\n                if entry.is_dir():\n                    directories.append(entry.name)\n                else:\n                    files.append(entry.name)\n        return directories, files\n\n    def path(self, name):\n        return safe_join(self.location, name)\n\n    def size(self, name):\n        return os.path.getsize(self.path(name))\n\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        return urljoin(self.base_url, url)\n\n    def _datetime_from_timestamp(self, ts):\n        \"\"\"\n        If timezone support is enabled, make an aware datetime object in UTC;\n        otherwise make a naive one in the local timezone.\n        \"\"\"\n        tz = timezone.utc if settings.USE_TZ else None\n        return datetime.fromtimestamp(ts, tz=tz)\n\n    def get_accessed_time(self, name):\n        return self._datetime_from_timestamp(os.path.getatime(self.path(name)))\n\n    def get_created_time(self, name):\n        return self._datetime_from_timestamp(os.path.getctime(self.path(name)))\n\n    def get_modified_time(self, name):\n        return self._datetime_from_timestamp(os.path.getmtime(self.path(name)))\n\n\ndef get_storage_class(import_path=None):\n    return import_string(import_path or settings.DEFAULT_FILE_STORAGE)\n\n\nclass DefaultStorage(LazyObject):\n    def _setup(self):\n        self._wrapped = get_storage_class()()\n\n\ndefault_storage = DefaultStorage()\n"
  },
  {
    "patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 13070b303b..0813cc9dad 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -22,7 +22,7 @@ from django.utils.text import (\n from django.utils.timesince import timesince, timeuntil\n from django.utils.translation import gettext, ngettext\n \n-from .base import Variable, VariableDoesNotExist\n+from .base import VARIABLE_ATTRIBUTE_SEPARATOR\n from .library import Library\n \n register = Library()\n@@ -503,7 +503,7 @@ def striptags(value):\n def _property_resolver(arg):\n     \"\"\"\n     When arg is convertible to float, behave like operator.itemgetter(arg)\n-    Otherwise, behave like Variable(arg).resolve\n+    Otherwise, chain __getitem__() and getattr().\n \n     >>> _property_resolver(1)('abc')\n     'b'\n@@ -521,7 +521,19 @@ def _property_resolver(arg):\n     try:\n         float(arg)\n     except ValueError:\n-        return Variable(arg).resolve\n+        if VARIABLE_ATTRIBUTE_SEPARATOR + '_' in arg or arg[0] == '_':\n+            raise AttributeError('Access to private variables is forbidden.')\n+        parts = arg.split(VARIABLE_ATTRIBUTE_SEPARATOR)\n+\n+        def resolve(value):\n+            for part in parts:\n+                try:\n+                    value = value[part]\n+                except (AttributeError, IndexError, KeyError, TypeError, ValueError):\n+                    value = getattr(value, part)\n+            return value\n+\n+        return resolve\n     else:\n         return itemgetter(arg)\n \n@@ -534,7 +546,7 @@ def dictsort(value, arg):\n     \"\"\"\n     try:\n         return sorted(value, key=_property_resolver(arg))\n-    except (TypeError, VariableDoesNotExist):\n+    except (AttributeError, TypeError):\n         return ''\n \n \n@@ -546,7 +558,7 @@ def dictsortreversed(value, arg):\n     \"\"\"\n     try:\n         return sorted(value, key=_property_resolver(arg), reverse=True)\n-    except (TypeError, VariableDoesNotExist):\n+    except (AttributeError, TypeError):\n         return ''\n \n \n",
    "commit_message": "Fixed CVE-2021-45116 -- Fixed potential information disclosure in dictsort template filter.\n\nThanks to Dennis Brinkrolf for the report.\n\nCo-authored-by: Adam Johnson <me@adamj.eu>\n\n",
    "code_before": "\"\"\"Default variable filters.\"\"\"\nimport random as random_module\nimport re\nimport types\nfrom decimal import ROUND_HALF_UP, Context, Decimal, InvalidOperation\nfrom functools import wraps\nfrom operator import itemgetter\nfrom pprint import pformat\nfrom urllib.parse import quote\n\nfrom django.utils import formats\nfrom django.utils.dateformat import format, time_format\nfrom django.utils.encoding import iri_to_uri\nfrom django.utils.html import (\n    avoid_wrapping, conditional_escape, escape, escapejs,\n    json_script as _json_script, linebreaks, strip_tags, urlize as _urlize,\n)\nfrom django.utils.safestring import SafeData, mark_safe\nfrom django.utils.text import (\n    Truncator, normalize_newlines, phone2numeric, slugify as _slugify, wrap,\n)\nfrom django.utils.timesince import timesince, timeuntil\nfrom django.utils.translation import gettext, ngettext\n\nfrom .base import Variable, VariableDoesNotExist\nfrom .library import Library\n\nregister = Library()\n\n\n#######################\n# STRING DECORATOR    #\n#######################\n\ndef stringfilter(func):\n    \"\"\"\n    Decorator for filters which should only receive strings. The object\n    passed as the first positional argument will be converted to a string.\n    \"\"\"\n    def _dec(*args, **kwargs):\n        args = list(args)\n        args[0] = str(args[0])\n        if (isinstance(args[0], SafeData) and\n                getattr(_dec._decorated_function, 'is_safe', False)):\n            return mark_safe(func(*args, **kwargs))\n        return func(*args, **kwargs)\n\n    # Include a reference to the real function (used to check original\n    # arguments by the template parser, and to bear the 'is_safe' attribute\n    # when multiple decorators are applied).\n    _dec._decorated_function = getattr(func, '_decorated_function', func)\n\n    return wraps(func)(_dec)\n\n\n###################\n# STRINGS         #\n###################\n\n@register.filter(is_safe=True)\n@stringfilter\ndef addslashes(value):\n    \"\"\"\n    Add slashes before quotes. Useful for escaping strings in CSV, for\n    example. Less useful for escaping JavaScript; use the ``escapejs``\n    filter instead.\n    \"\"\"\n    return value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\")\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef capfirst(value):\n    \"\"\"Capitalize the first character of the value.\"\"\"\n    return value and value[0].upper() + value[1:]\n\n\n@register.filter(\"escapejs\")\n@stringfilter\ndef escapejs_filter(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return escapejs(value)\n\n\n@register.filter(is_safe=True)\ndef json_script(value, element_id=None):\n    \"\"\"\n    Output value JSON-encoded, wrapped in a <script type=\"application/json\">\n    tag (with an optional id).\n    \"\"\"\n    return _json_script(value, element_id)\n\n\n@register.filter(is_safe=True)\ndef floatformat(text, arg=-1):\n    \"\"\"\n    Display a float to a specified number of decimal places.\n\n    If called without an argument, display the floating point number with one\n    decimal place -- but only if there's a decimal place to be displayed:\n\n    * num1 = 34.23234\n    * num2 = 34.00000\n    * num3 = 34.26000\n    * {{ num1|floatformat }} displays \"34.2\"\n    * {{ num2|floatformat }} displays \"34\"\n    * {{ num3|floatformat }} displays \"34.3\"\n\n    If arg is positive, always display exactly arg number of decimal places:\n\n    * {{ num1|floatformat:3 }} displays \"34.232\"\n    * {{ num2|floatformat:3 }} displays \"34.000\"\n    * {{ num3|floatformat:3 }} displays \"34.260\"\n\n    If arg is negative, display arg number of decimal places -- but only if\n    there are places to be displayed:\n\n    * {{ num1|floatformat:\"-3\" }} displays \"34.232\"\n    * {{ num2|floatformat:\"-3\" }} displays \"34\"\n    * {{ num3|floatformat:\"-3\" }} displays \"34.260\"\n\n    If arg has the 'g' suffix, force the result to be grouped by the\n    THOUSAND_SEPARATOR for the active locale. When the active locale is\n    en (English):\n\n    * {{ 6666.6666|floatformat:\"2g\" }} displays \"6,666.67\"\n    * {{ 10000|floatformat:\"g\" }} displays \"10,000\"\n\n    If arg has the 'u' suffix, force the result to be unlocalized. When the\n    active locale is pl (Polish):\n\n    * {{ 66666.6666|floatformat:\"2\" }} displays \"66666,67\"\n    * {{ 66666.6666|floatformat:\"2u\" }} displays \"66666.67\"\n\n    If the input float is infinity or NaN, display the string representation\n    of that value.\n    \"\"\"\n    force_grouping = False\n    use_l10n = True\n    if isinstance(arg, str):\n        last_char = arg[-1]\n        if arg[-2:] in {'gu', 'ug'}:\n            force_grouping = True\n            use_l10n = False\n            arg = arg[:-2] or -1\n        elif last_char == 'g':\n            force_grouping = True\n            arg = arg[:-1] or -1\n        elif last_char == 'u':\n            use_l10n = False\n            arg = arg[:-1] or -1\n    try:\n        input_val = repr(text)\n        d = Decimal(input_val)\n    except InvalidOperation:\n        try:\n            d = Decimal(str(float(text)))\n        except (ValueError, InvalidOperation, TypeError):\n            return ''\n    try:\n        p = int(arg)\n    except ValueError:\n        return input_val\n\n    try:\n        m = int(d) - d\n    except (ValueError, OverflowError, InvalidOperation):\n        return input_val\n\n    if not m and p < 0:\n        return mark_safe(formats.number_format(\n            '%d' % (int(d)),\n            0,\n            use_l10n=use_l10n,\n            force_grouping=force_grouping,\n        ))\n\n    exp = Decimal(1).scaleb(-abs(p))\n    # Set the precision high enough to avoid an exception (#15789).\n    tupl = d.as_tuple()\n    units = len(tupl[1])\n    units += -tupl[2] if m else tupl[2]\n    prec = abs(p) + units + 1\n\n    # Avoid conversion to scientific notation by accessing `sign`, `digits`,\n    # and `exponent` from Decimal.as_tuple() directly.\n    rounded_d = d.quantize(exp, ROUND_HALF_UP, Context(prec=prec))\n    sign, digits, exponent = rounded_d.as_tuple()\n    digits = [str(digit) for digit in reversed(digits)]\n    while len(digits) <= abs(exponent):\n        digits.append('0')\n    digits.insert(-exponent, '.')\n    if sign and rounded_d:\n        digits.append('-')\n    number = ''.join(reversed(digits))\n    return mark_safe(formats.number_format(\n        number,\n        abs(p),\n        use_l10n=use_l10n,\n        force_grouping=force_grouping,\n    ))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef iriencode(value):\n    \"\"\"Escape an IRI value for use in a URL.\"\"\"\n    return iri_to_uri(value)\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linenumbers(value, autoescape=True):\n    \"\"\"Display text with line numbers.\"\"\"\n    lines = value.split('\\n')\n    # Find the maximum width of the line count, for use with zero padding\n    # string format command\n    width = str(len(str(len(lines))))\n    if not autoescape or isinstance(value, SafeData):\n        for i, line in enumerate(lines):\n            lines[i] = (\"%0\" + width + \"d. %s\") % (i + 1, line)\n    else:\n        for i, line in enumerate(lines):\n            lines[i] = (\"%0\" + width + \"d. %s\") % (i + 1, escape(line))\n    return mark_safe('\\n'.join(lines))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef lower(value):\n    \"\"\"Convert a string into all lowercase.\"\"\"\n    return value.lower()\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef make_list(value):\n    \"\"\"\n    Return the value turned into a list.\n\n    For an integer, it's a list of digits.\n    For a string, it's a list of characters.\n    \"\"\"\n    return list(value)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef slugify(value):\n    \"\"\"\n    Convert to ASCII. Convert spaces to hyphens. Remove characters that aren't\n    alphanumerics, underscores, or hyphens. Convert to lowercase. Also strip\n    leading and trailing whitespace.\n    \"\"\"\n    return _slugify(value)\n\n\n@register.filter(is_safe=True)\ndef stringformat(value, arg):\n    \"\"\"\n    Format the variable according to the arg, a string formatting specifier.\n\n    This specifier uses Python string formatting syntax, with the exception\n    that the leading \"%\" is dropped.\n\n    See https://docs.python.org/library/stdtypes.html#printf-style-string-formatting\n    for documentation of Python string formatting.\n    \"\"\"\n    if isinstance(value, tuple):\n        value = str(value)\n    try:\n        return (\"%\" + str(arg)) % value\n    except (ValueError, TypeError):\n        return \"\"\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef title(value):\n    \"\"\"Convert a string into titlecase.\"\"\"\n    t = re.sub(\"([a-z])'([A-Z])\", lambda m: m[0].lower(), value.title())\n    return re.sub(r'\\d([A-Z])', lambda m: m[0].lower(), t)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatechars(value, arg):\n    \"\"\"Truncate a string after `arg` number of characters.\"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # Invalid literal for int().\n        return value  # Fail silently.\n    return Truncator(value).chars(length)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatechars_html(value, arg):\n    \"\"\"\n    Truncate HTML after `arg` number of chars.\n    Preserve newlines in the HTML.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # invalid literal for int()\n        return value  # Fail silently.\n    return Truncator(value).chars(length, html=True)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatewords(value, arg):\n    \"\"\"\n    Truncate a string after `arg` number of words.\n    Remove newlines within the string.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # Invalid literal for int().\n        return value  # Fail silently.\n    return Truncator(value).words(length, truncate=' \u2026')\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatewords_html(value, arg):\n    \"\"\"\n    Truncate HTML after `arg` number of words.\n    Preserve newlines in the HTML.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # invalid literal for int()\n        return value  # Fail silently.\n    return Truncator(value).words(length, html=True, truncate=' \u2026')\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef upper(value):\n    \"\"\"Convert a string into all uppercase.\"\"\"\n    return value.upper()\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef urlencode(value, safe=None):\n    \"\"\"\n    Escape a value for use in a URL.\n\n    The ``safe`` parameter determines the characters which should not be\n    escaped by Python's quote() function. If not provided, use the default safe\n    characters (but an empty string can be provided when *all* characters\n    should be escaped).\n    \"\"\"\n    kwargs = {}\n    if safe is not None:\n        kwargs['safe'] = safe\n    return quote(value, **kwargs)\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef urlize(value, autoescape=True):\n    \"\"\"Convert URLs in plain text into clickable links.\"\"\"\n    return mark_safe(_urlize(value, nofollow=True, autoescape=autoescape))\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef urlizetrunc(value, limit, autoescape=True):\n    \"\"\"\n    Convert URLs into clickable links, truncating URLs to the given character\n    limit, and adding 'rel=nofollow' attribute to discourage spamming.\n\n    Argument: Length to truncate URLs to.\n    \"\"\"\n    return mark_safe(_urlize(value, trim_url_limit=int(limit), nofollow=True, autoescape=autoescape))\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef wordcount(value):\n    \"\"\"Return the number of words.\"\"\"\n    return len(value.split())\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef wordwrap(value, arg):\n    \"\"\"Wrap words at `arg` line length.\"\"\"\n    return wrap(value, int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef ljust(value, arg):\n    \"\"\"Left-align the value in a field of a given width.\"\"\"\n    return value.ljust(int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef rjust(value, arg):\n    \"\"\"Right-align the value in a field of a given width.\"\"\"\n    return value.rjust(int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef center(value, arg):\n    \"\"\"Center the value in a field of a given width.\"\"\"\n    return value.center(int(arg))\n\n\n@register.filter\n@stringfilter\ndef cut(value, arg):\n    \"\"\"Remove all values of arg from the given string.\"\"\"\n    safe = isinstance(value, SafeData)\n    value = value.replace(arg, '')\n    if safe and arg != ';':\n        return mark_safe(value)\n    return value\n\n\n###################\n# HTML STRINGS    #\n###################\n\n@register.filter(\"escape\", is_safe=True)\n@stringfilter\ndef escape_filter(value):\n    \"\"\"Mark the value as a string that should be auto-escaped.\"\"\"\n    return conditional_escape(value)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef force_escape(value):\n    \"\"\"\n    Escape a string's HTML. Return a new string containing the escaped\n    characters (as opposed to \"escape\", which marks the content for later\n    possible escaping).\n    \"\"\"\n    return escape(value)\n\n\n@register.filter(\"linebreaks\", is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linebreaks_filter(value, autoescape=True):\n    \"\"\"\n    Replace line breaks in plain text with appropriate HTML; a single\n    newline becomes an HTML line break (``<br>``) and a new line\n    followed by a blank line becomes a paragraph break (``</p>``).\n    \"\"\"\n    autoescape = autoescape and not isinstance(value, SafeData)\n    return mark_safe(linebreaks(value, autoescape))\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linebreaksbr(value, autoescape=True):\n    \"\"\"\n    Convert all newlines in a piece of plain text to HTML line breaks\n    (``<br>``).\n    \"\"\"\n    autoescape = autoescape and not isinstance(value, SafeData)\n    value = normalize_newlines(value)\n    if autoescape:\n        value = escape(value)\n    return mark_safe(value.replace('\\n', '<br>'))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef safe(value):\n    \"\"\"Mark the value as a string that should not be auto-escaped.\"\"\"\n    return mark_safe(value)\n\n\n@register.filter(is_safe=True)\ndef safeseq(value):\n    \"\"\"\n    A \"safe\" filter for sequences. Mark each element in the sequence,\n    individually, as safe, after converting them to strings. Return a list\n    with the results.\n    \"\"\"\n    return [mark_safe(obj) for obj in value]\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef striptags(value):\n    \"\"\"Strip all [X]HTML tags.\"\"\"\n    return strip_tags(value)\n\n\n###################\n# LISTS           #\n###################\n\ndef _property_resolver(arg):\n    \"\"\"\n    When arg is convertible to float, behave like operator.itemgetter(arg)\n    Otherwise, behave like Variable(arg).resolve\n\n    >>> _property_resolver(1)('abc')\n    'b'\n    >>> _property_resolver('1')('abc')\n    Traceback (most recent call last):\n    ...\n    TypeError: string indices must be integers\n    >>> class Foo:\n    ...     a = 42\n    ...     b = 3.14\n    ...     c = 'Hey!'\n    >>> _property_resolver('b')(Foo())\n    3.14\n    \"\"\"\n    try:\n        float(arg)\n    except ValueError:\n        return Variable(arg).resolve\n    else:\n        return itemgetter(arg)\n\n\n@register.filter(is_safe=False)\ndef dictsort(value, arg):\n    \"\"\"\n    Given a list of dicts, return that list sorted by the property given in\n    the argument.\n    \"\"\"\n    try:\n        return sorted(value, key=_property_resolver(arg))\n    except (TypeError, VariableDoesNotExist):\n        return ''\n\n\n@register.filter(is_safe=False)\ndef dictsortreversed(value, arg):\n    \"\"\"\n    Given a list of dicts, return that list sorted in reverse order by the\n    property given in the argument.\n    \"\"\"\n    try:\n        return sorted(value, key=_property_resolver(arg), reverse=True)\n    except (TypeError, VariableDoesNotExist):\n        return ''\n\n\n@register.filter(is_safe=False)\ndef first(value):\n    \"\"\"Return the first item in a list.\"\"\"\n    try:\n        return value[0]\n    except IndexError:\n        return ''\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\ndef join(value, arg, autoescape=True):\n    \"\"\"Join a list with a string, like Python's ``str.join(list)``.\"\"\"\n    try:\n        if autoescape:\n            value = [conditional_escape(v) for v in value]\n        data = conditional_escape(arg).join(value)\n    except TypeError:  # Fail silently if arg isn't iterable.\n        return value\n    return mark_safe(data)\n\n\n@register.filter(is_safe=True)\ndef last(value):\n    \"\"\"Return the last item in a list.\"\"\"\n    try:\n        return value[-1]\n    except IndexError:\n        return ''\n\n\n@register.filter(is_safe=False)\ndef length(value):\n    \"\"\"Return the length of the value - useful for lists.\"\"\"\n    try:\n        return len(value)\n    except (ValueError, TypeError):\n        return 0\n\n\n@register.filter(is_safe=False)\ndef length_is(value, arg):\n    \"\"\"Return a boolean of whether the value's length is the argument.\"\"\"\n    try:\n        return len(value) == int(arg)\n    except (ValueError, TypeError):\n        return ''\n\n\n@register.filter(is_safe=True)\ndef random(value):\n    \"\"\"Return a random item from the list.\"\"\"\n    return random_module.choice(value)\n\n\n@register.filter(\"slice\", is_safe=True)\ndef slice_filter(value, arg):\n    \"\"\"\n    Return a slice of the list using the same syntax as Python's list slicing.\n    \"\"\"\n    try:\n        bits = []\n        for x in str(arg).split(':'):\n            if not x:\n                bits.append(None)\n            else:\n                bits.append(int(x))\n        return value[slice(*bits)]\n\n    except (ValueError, TypeError):\n        return value  # Fail silently.\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\ndef unordered_list(value, autoescape=True):\n    \"\"\"\n    Recursively take a self-nested list and return an HTML unordered list --\n    WITHOUT opening and closing <ul> tags.\n\n    Assume the list is in the proper format. For example, if ``var`` contains:\n    ``['States', ['Kansas', ['Lawrence', 'Topeka'], 'Illinois']]``, then\n    ``{{ var|unordered_list }}`` returns::\n\n        <li>States\n        <ul>\n                <li>Kansas\n                <ul>\n                        <li>Lawrence</li>\n                        <li>Topeka</li>\n                </ul>\n                </li>\n                <li>Illinois</li>\n        </ul>\n        </li>\n    \"\"\"\n    if autoescape:\n        escaper = conditional_escape\n    else:\n        def escaper(x):\n            return x\n\n    def walk_items(item_list):\n        item_iterator = iter(item_list)\n        try:\n            item = next(item_iterator)\n            while True:\n                try:\n                    next_item = next(item_iterator)\n                except StopIteration:\n                    yield item, None\n                    break\n                if isinstance(next_item, (list, tuple, types.GeneratorType)):\n                    try:\n                        iter(next_item)\n                    except TypeError:\n                        pass\n                    else:\n                        yield item, next_item\n                        item = next(item_iterator)\n                        continue\n                yield item, None\n                item = next_item\n        except StopIteration:\n            pass\n\n    def list_formatter(item_list, tabs=1):\n        indent = '\\t' * tabs\n        output = []\n        for item, children in walk_items(item_list):\n            sublist = ''\n            if children:\n                sublist = '\\n%s<ul>\\n%s\\n%s</ul>\\n%s' % (\n                    indent, list_formatter(children, tabs + 1), indent, indent)\n            output.append('%s<li>%s%s</li>' % (\n                indent, escaper(item), sublist))\n        return '\\n'.join(output)\n\n    return mark_safe(list_formatter(value))\n\n\n###################\n# INTEGERS        #\n###################\n\n@register.filter(is_safe=False)\ndef add(value, arg):\n    \"\"\"Add the arg to the value.\"\"\"\n    try:\n        return int(value) + int(arg)\n    except (ValueError, TypeError):\n        try:\n            return value + arg\n        except Exception:\n            return ''\n\n\n@register.filter(is_safe=False)\ndef get_digit(value, arg):\n    \"\"\"\n    Given a whole number, return the requested digit of it, where 1 is the\n    right-most digit, 2 is the second-right-most digit, etc. Return the\n    original value for invalid input (if input or argument is not an integer,\n    or if argument is less than 1). Otherwise, output is always an integer.\n    \"\"\"\n    try:\n        arg = int(arg)\n        value = int(value)\n    except ValueError:\n        return value  # Fail silently for an invalid argument\n    if arg < 1:\n        return value\n    try:\n        return int(str(value)[-arg])\n    except IndexError:\n        return 0\n\n\n###################\n# DATES           #\n###################\n\n@register.filter(expects_localtime=True, is_safe=False)\ndef date(value, arg=None):\n    \"\"\"Format a date according to the given format.\"\"\"\n    if value in (None, ''):\n        return ''\n    try:\n        return formats.date_format(value, arg)\n    except AttributeError:\n        try:\n            return format(value, arg)\n        except AttributeError:\n            return ''\n\n\n@register.filter(expects_localtime=True, is_safe=False)\ndef time(value, arg=None):\n    \"\"\"Format a time according to the given format.\"\"\"\n    if value in (None, ''):\n        return ''\n    try:\n        return formats.time_format(value, arg)\n    except (AttributeError, TypeError):\n        try:\n            return time_format(value, arg)\n        except (AttributeError, TypeError):\n            return ''\n\n\n@register.filter(\"timesince\", is_safe=False)\ndef timesince_filter(value, arg=None):\n    \"\"\"Format a date as the time since that date (i.e. \"4 days, 6 hours\").\"\"\"\n    if not value:\n        return ''\n    try:\n        if arg:\n            return timesince(value, arg)\n        return timesince(value)\n    except (ValueError, TypeError):\n        return ''\n\n\n@register.filter(\"timeuntil\", is_safe=False)\ndef timeuntil_filter(value, arg=None):\n    \"\"\"Format a date as the time until that date (i.e. \"4 days, 6 hours\").\"\"\"\n    if not value:\n        return ''\n    try:\n        return timeuntil(value, arg)\n    except (ValueError, TypeError):\n        return ''\n\n\n###################\n# LOGIC           #\n###################\n\n@register.filter(is_safe=False)\ndef default(value, arg):\n    \"\"\"If value is unavailable, use given default.\"\"\"\n    return value or arg\n\n\n@register.filter(is_safe=False)\ndef default_if_none(value, arg):\n    \"\"\"If value is None, use given default.\"\"\"\n    if value is None:\n        return arg\n    return value\n\n\n@register.filter(is_safe=False)\ndef divisibleby(value, arg):\n    \"\"\"Return True if the value is divisible by the argument.\"\"\"\n    return int(value) % int(arg) == 0\n\n\n@register.filter(is_safe=False)\ndef yesno(value, arg=None):\n    \"\"\"\n    Given a string mapping values for true, false, and (optionally) None,\n    return one of those strings according to the value:\n\n    ==========  ======================  ==================================\n    Value       Argument                Outputs\n    ==========  ======================  ==================================\n    ``True``    ``\"yeah,no,maybe\"``     ``yeah``\n    ``False``   ``\"yeah,no,maybe\"``     ``no``\n    ``None``    ``\"yeah,no,maybe\"``     ``maybe``\n    ``None``    ``\"yeah,no\"``           ``\"no\"`` (converts None to False\n                                        if no mapping for None is given.\n    ==========  ======================  ==================================\n    \"\"\"\n    if arg is None:\n        # Translators: Please do not add spaces around commas.\n        arg = gettext('yes,no,maybe')\n    bits = arg.split(',')\n    if len(bits) < 2:\n        return value  # Invalid arg.\n    try:\n        yes, no, maybe = bits\n    except ValueError:\n        # Unpack list of wrong size (no \"maybe\" value provided).\n        yes, no, maybe = bits[0], bits[1], bits[1]\n    if value is None:\n        return maybe\n    if value:\n        return yes\n    return no\n\n\n###################\n# MISC            #\n###################\n\n@register.filter(is_safe=True)\ndef filesizeformat(bytes_):\n    \"\"\"\n    Format the value like a 'human-readable' file size (i.e. 13 KB, 4.1 MB,\n    102 bytes, etc.).\n    \"\"\"\n    try:\n        bytes_ = int(bytes_)\n    except (TypeError, ValueError, UnicodeDecodeError):\n        value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", 0) % {'size': 0}\n        return avoid_wrapping(value)\n\n    def filesize_number_format(value):\n        return formats.number_format(round(value, 1), 1)\n\n    KB = 1 << 10\n    MB = 1 << 20\n    GB = 1 << 30\n    TB = 1 << 40\n    PB = 1 << 50\n\n    negative = bytes_ < 0\n    if negative:\n        bytes_ = -bytes_  # Allow formatting of negative numbers.\n\n    if bytes_ < KB:\n        value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", bytes_) % {'size': bytes_}\n    elif bytes_ < MB:\n        value = gettext(\"%s KB\") % filesize_number_format(bytes_ / KB)\n    elif bytes_ < GB:\n        value = gettext(\"%s MB\") % filesize_number_format(bytes_ / MB)\n    elif bytes_ < TB:\n        value = gettext(\"%s GB\") % filesize_number_format(bytes_ / GB)\n    elif bytes_ < PB:\n        value = gettext(\"%s TB\") % filesize_number_format(bytes_ / TB)\n    else:\n        value = gettext(\"%s PB\") % filesize_number_format(bytes_ / PB)\n\n    if negative:\n        value = \"-%s\" % value\n    return avoid_wrapping(value)\n\n\n@register.filter(is_safe=False)\ndef pluralize(value, arg='s'):\n    \"\"\"\n    Return a plural suffix if the value is not 1, '1', or an object of\n    length 1. By default, use 's' as the suffix:\n\n    * If value is 0, vote{{ value|pluralize }} display \"votes\".\n    * If value is 1, vote{{ value|pluralize }} display \"vote\".\n    * If value is 2, vote{{ value|pluralize }} display \"votes\".\n\n    If an argument is provided, use that string instead:\n\n    * If value is 0, class{{ value|pluralize:\"es\" }} display \"classes\".\n    * If value is 1, class{{ value|pluralize:\"es\" }} display \"class\".\n    * If value is 2, class{{ value|pluralize:\"es\" }} display \"classes\".\n\n    If the provided argument contains a comma, use the text before the comma\n    for the singular case and the text after the comma for the plural case:\n\n    * If value is 0, cand{{ value|pluralize:\"y,ies\" }} display \"candies\".\n    * If value is 1, cand{{ value|pluralize:\"y,ies\" }} display \"candy\".\n    * If value is 2, cand{{ value|pluralize:\"y,ies\" }} display \"candies\".\n    \"\"\"\n    if ',' not in arg:\n        arg = ',' + arg\n    bits = arg.split(',')\n    if len(bits) > 2:\n        return ''\n    singular_suffix, plural_suffix = bits[:2]\n\n    try:\n        return singular_suffix if float(value) == 1 else plural_suffix\n    except ValueError:  # Invalid string that's not a number.\n        pass\n    except TypeError:  # Value isn't a string or a number; maybe it's a list?\n        try:\n            return singular_suffix if len(value) == 1 else plural_suffix\n        except TypeError:  # len() of unsized object.\n            pass\n    return ''\n\n\n@register.filter(\"phone2numeric\", is_safe=True)\ndef phone2numeric_filter(value):\n    \"\"\"Take a phone number and converts it in to its numerical equivalent.\"\"\"\n    return phone2numeric(value)\n\n\n@register.filter(is_safe=True)\ndef pprint(value):\n    \"\"\"A wrapper around pprint.pprint -- for debugging, really.\"\"\"\n    try:\n        return pformat(value)\n    except Exception as e:\n        return \"Error in formatting: %s: %s\" % (e.__class__.__name__, e)\n",
    "code_after": "\"\"\"Default variable filters.\"\"\"\nimport random as random_module\nimport re\nimport types\nfrom decimal import ROUND_HALF_UP, Context, Decimal, InvalidOperation\nfrom functools import wraps\nfrom operator import itemgetter\nfrom pprint import pformat\nfrom urllib.parse import quote\n\nfrom django.utils import formats\nfrom django.utils.dateformat import format, time_format\nfrom django.utils.encoding import iri_to_uri\nfrom django.utils.html import (\n    avoid_wrapping, conditional_escape, escape, escapejs,\n    json_script as _json_script, linebreaks, strip_tags, urlize as _urlize,\n)\nfrom django.utils.safestring import SafeData, mark_safe\nfrom django.utils.text import (\n    Truncator, normalize_newlines, phone2numeric, slugify as _slugify, wrap,\n)\nfrom django.utils.timesince import timesince, timeuntil\nfrom django.utils.translation import gettext, ngettext\n\nfrom .base import VARIABLE_ATTRIBUTE_SEPARATOR\nfrom .library import Library\n\nregister = Library()\n\n\n#######################\n# STRING DECORATOR    #\n#######################\n\ndef stringfilter(func):\n    \"\"\"\n    Decorator for filters which should only receive strings. The object\n    passed as the first positional argument will be converted to a string.\n    \"\"\"\n    def _dec(*args, **kwargs):\n        args = list(args)\n        args[0] = str(args[0])\n        if (isinstance(args[0], SafeData) and\n                getattr(_dec._decorated_function, 'is_safe', False)):\n            return mark_safe(func(*args, **kwargs))\n        return func(*args, **kwargs)\n\n    # Include a reference to the real function (used to check original\n    # arguments by the template parser, and to bear the 'is_safe' attribute\n    # when multiple decorators are applied).\n    _dec._decorated_function = getattr(func, '_decorated_function', func)\n\n    return wraps(func)(_dec)\n\n\n###################\n# STRINGS         #\n###################\n\n@register.filter(is_safe=True)\n@stringfilter\ndef addslashes(value):\n    \"\"\"\n    Add slashes before quotes. Useful for escaping strings in CSV, for\n    example. Less useful for escaping JavaScript; use the ``escapejs``\n    filter instead.\n    \"\"\"\n    return value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\")\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef capfirst(value):\n    \"\"\"Capitalize the first character of the value.\"\"\"\n    return value and value[0].upper() + value[1:]\n\n\n@register.filter(\"escapejs\")\n@stringfilter\ndef escapejs_filter(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return escapejs(value)\n\n\n@register.filter(is_safe=True)\ndef json_script(value, element_id=None):\n    \"\"\"\n    Output value JSON-encoded, wrapped in a <script type=\"application/json\">\n    tag (with an optional id).\n    \"\"\"\n    return _json_script(value, element_id)\n\n\n@register.filter(is_safe=True)\ndef floatformat(text, arg=-1):\n    \"\"\"\n    Display a float to a specified number of decimal places.\n\n    If called without an argument, display the floating point number with one\n    decimal place -- but only if there's a decimal place to be displayed:\n\n    * num1 = 34.23234\n    * num2 = 34.00000\n    * num3 = 34.26000\n    * {{ num1|floatformat }} displays \"34.2\"\n    * {{ num2|floatformat }} displays \"34\"\n    * {{ num3|floatformat }} displays \"34.3\"\n\n    If arg is positive, always display exactly arg number of decimal places:\n\n    * {{ num1|floatformat:3 }} displays \"34.232\"\n    * {{ num2|floatformat:3 }} displays \"34.000\"\n    * {{ num3|floatformat:3 }} displays \"34.260\"\n\n    If arg is negative, display arg number of decimal places -- but only if\n    there are places to be displayed:\n\n    * {{ num1|floatformat:\"-3\" }} displays \"34.232\"\n    * {{ num2|floatformat:\"-3\" }} displays \"34\"\n    * {{ num3|floatformat:\"-3\" }} displays \"34.260\"\n\n    If arg has the 'g' suffix, force the result to be grouped by the\n    THOUSAND_SEPARATOR for the active locale. When the active locale is\n    en (English):\n\n    * {{ 6666.6666|floatformat:\"2g\" }} displays \"6,666.67\"\n    * {{ 10000|floatformat:\"g\" }} displays \"10,000\"\n\n    If arg has the 'u' suffix, force the result to be unlocalized. When the\n    active locale is pl (Polish):\n\n    * {{ 66666.6666|floatformat:\"2\" }} displays \"66666,67\"\n    * {{ 66666.6666|floatformat:\"2u\" }} displays \"66666.67\"\n\n    If the input float is infinity or NaN, display the string representation\n    of that value.\n    \"\"\"\n    force_grouping = False\n    use_l10n = True\n    if isinstance(arg, str):\n        last_char = arg[-1]\n        if arg[-2:] in {'gu', 'ug'}:\n            force_grouping = True\n            use_l10n = False\n            arg = arg[:-2] or -1\n        elif last_char == 'g':\n            force_grouping = True\n            arg = arg[:-1] or -1\n        elif last_char == 'u':\n            use_l10n = False\n            arg = arg[:-1] or -1\n    try:\n        input_val = repr(text)\n        d = Decimal(input_val)\n    except InvalidOperation:\n        try:\n            d = Decimal(str(float(text)))\n        except (ValueError, InvalidOperation, TypeError):\n            return ''\n    try:\n        p = int(arg)\n    except ValueError:\n        return input_val\n\n    try:\n        m = int(d) - d\n    except (ValueError, OverflowError, InvalidOperation):\n        return input_val\n\n    if not m and p < 0:\n        return mark_safe(formats.number_format(\n            '%d' % (int(d)),\n            0,\n            use_l10n=use_l10n,\n            force_grouping=force_grouping,\n        ))\n\n    exp = Decimal(1).scaleb(-abs(p))\n    # Set the precision high enough to avoid an exception (#15789).\n    tupl = d.as_tuple()\n    units = len(tupl[1])\n    units += -tupl[2] if m else tupl[2]\n    prec = abs(p) + units + 1\n\n    # Avoid conversion to scientific notation by accessing `sign`, `digits`,\n    # and `exponent` from Decimal.as_tuple() directly.\n    rounded_d = d.quantize(exp, ROUND_HALF_UP, Context(prec=prec))\n    sign, digits, exponent = rounded_d.as_tuple()\n    digits = [str(digit) for digit in reversed(digits)]\n    while len(digits) <= abs(exponent):\n        digits.append('0')\n    digits.insert(-exponent, '.')\n    if sign and rounded_d:\n        digits.append('-')\n    number = ''.join(reversed(digits))\n    return mark_safe(formats.number_format(\n        number,\n        abs(p),\n        use_l10n=use_l10n,\n        force_grouping=force_grouping,\n    ))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef iriencode(value):\n    \"\"\"Escape an IRI value for use in a URL.\"\"\"\n    return iri_to_uri(value)\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linenumbers(value, autoescape=True):\n    \"\"\"Display text with line numbers.\"\"\"\n    lines = value.split('\\n')\n    # Find the maximum width of the line count, for use with zero padding\n    # string format command\n    width = str(len(str(len(lines))))\n    if not autoescape or isinstance(value, SafeData):\n        for i, line in enumerate(lines):\n            lines[i] = (\"%0\" + width + \"d. %s\") % (i + 1, line)\n    else:\n        for i, line in enumerate(lines):\n            lines[i] = (\"%0\" + width + \"d. %s\") % (i + 1, escape(line))\n    return mark_safe('\\n'.join(lines))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef lower(value):\n    \"\"\"Convert a string into all lowercase.\"\"\"\n    return value.lower()\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef make_list(value):\n    \"\"\"\n    Return the value turned into a list.\n\n    For an integer, it's a list of digits.\n    For a string, it's a list of characters.\n    \"\"\"\n    return list(value)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef slugify(value):\n    \"\"\"\n    Convert to ASCII. Convert spaces to hyphens. Remove characters that aren't\n    alphanumerics, underscores, or hyphens. Convert to lowercase. Also strip\n    leading and trailing whitespace.\n    \"\"\"\n    return _slugify(value)\n\n\n@register.filter(is_safe=True)\ndef stringformat(value, arg):\n    \"\"\"\n    Format the variable according to the arg, a string formatting specifier.\n\n    This specifier uses Python string formatting syntax, with the exception\n    that the leading \"%\" is dropped.\n\n    See https://docs.python.org/library/stdtypes.html#printf-style-string-formatting\n    for documentation of Python string formatting.\n    \"\"\"\n    if isinstance(value, tuple):\n        value = str(value)\n    try:\n        return (\"%\" + str(arg)) % value\n    except (ValueError, TypeError):\n        return \"\"\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef title(value):\n    \"\"\"Convert a string into titlecase.\"\"\"\n    t = re.sub(\"([a-z])'([A-Z])\", lambda m: m[0].lower(), value.title())\n    return re.sub(r'\\d([A-Z])', lambda m: m[0].lower(), t)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatechars(value, arg):\n    \"\"\"Truncate a string after `arg` number of characters.\"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # Invalid literal for int().\n        return value  # Fail silently.\n    return Truncator(value).chars(length)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatechars_html(value, arg):\n    \"\"\"\n    Truncate HTML after `arg` number of chars.\n    Preserve newlines in the HTML.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # invalid literal for int()\n        return value  # Fail silently.\n    return Truncator(value).chars(length, html=True)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatewords(value, arg):\n    \"\"\"\n    Truncate a string after `arg` number of words.\n    Remove newlines within the string.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # Invalid literal for int().\n        return value  # Fail silently.\n    return Truncator(value).words(length, truncate=' \u2026')\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef truncatewords_html(value, arg):\n    \"\"\"\n    Truncate HTML after `arg` number of words.\n    Preserve newlines in the HTML.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # invalid literal for int()\n        return value  # Fail silently.\n    return Truncator(value).words(length, html=True, truncate=' \u2026')\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef upper(value):\n    \"\"\"Convert a string into all uppercase.\"\"\"\n    return value.upper()\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef urlencode(value, safe=None):\n    \"\"\"\n    Escape a value for use in a URL.\n\n    The ``safe`` parameter determines the characters which should not be\n    escaped by Python's quote() function. If not provided, use the default safe\n    characters (but an empty string can be provided when *all* characters\n    should be escaped).\n    \"\"\"\n    kwargs = {}\n    if safe is not None:\n        kwargs['safe'] = safe\n    return quote(value, **kwargs)\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef urlize(value, autoescape=True):\n    \"\"\"Convert URLs in plain text into clickable links.\"\"\"\n    return mark_safe(_urlize(value, nofollow=True, autoescape=autoescape))\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef urlizetrunc(value, limit, autoescape=True):\n    \"\"\"\n    Convert URLs into clickable links, truncating URLs to the given character\n    limit, and adding 'rel=nofollow' attribute to discourage spamming.\n\n    Argument: Length to truncate URLs to.\n    \"\"\"\n    return mark_safe(_urlize(value, trim_url_limit=int(limit), nofollow=True, autoescape=autoescape))\n\n\n@register.filter(is_safe=False)\n@stringfilter\ndef wordcount(value):\n    \"\"\"Return the number of words.\"\"\"\n    return len(value.split())\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef wordwrap(value, arg):\n    \"\"\"Wrap words at `arg` line length.\"\"\"\n    return wrap(value, int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef ljust(value, arg):\n    \"\"\"Left-align the value in a field of a given width.\"\"\"\n    return value.ljust(int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef rjust(value, arg):\n    \"\"\"Right-align the value in a field of a given width.\"\"\"\n    return value.rjust(int(arg))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef center(value, arg):\n    \"\"\"Center the value in a field of a given width.\"\"\"\n    return value.center(int(arg))\n\n\n@register.filter\n@stringfilter\ndef cut(value, arg):\n    \"\"\"Remove all values of arg from the given string.\"\"\"\n    safe = isinstance(value, SafeData)\n    value = value.replace(arg, '')\n    if safe and arg != ';':\n        return mark_safe(value)\n    return value\n\n\n###################\n# HTML STRINGS    #\n###################\n\n@register.filter(\"escape\", is_safe=True)\n@stringfilter\ndef escape_filter(value):\n    \"\"\"Mark the value as a string that should be auto-escaped.\"\"\"\n    return conditional_escape(value)\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef force_escape(value):\n    \"\"\"\n    Escape a string's HTML. Return a new string containing the escaped\n    characters (as opposed to \"escape\", which marks the content for later\n    possible escaping).\n    \"\"\"\n    return escape(value)\n\n\n@register.filter(\"linebreaks\", is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linebreaks_filter(value, autoescape=True):\n    \"\"\"\n    Replace line breaks in plain text with appropriate HTML; a single\n    newline becomes an HTML line break (``<br>``) and a new line\n    followed by a blank line becomes a paragraph break (``</p>``).\n    \"\"\"\n    autoescape = autoescape and not isinstance(value, SafeData)\n    return mark_safe(linebreaks(value, autoescape))\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\n@stringfilter\ndef linebreaksbr(value, autoescape=True):\n    \"\"\"\n    Convert all newlines in a piece of plain text to HTML line breaks\n    (``<br>``).\n    \"\"\"\n    autoescape = autoescape and not isinstance(value, SafeData)\n    value = normalize_newlines(value)\n    if autoescape:\n        value = escape(value)\n    return mark_safe(value.replace('\\n', '<br>'))\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef safe(value):\n    \"\"\"Mark the value as a string that should not be auto-escaped.\"\"\"\n    return mark_safe(value)\n\n\n@register.filter(is_safe=True)\ndef safeseq(value):\n    \"\"\"\n    A \"safe\" filter for sequences. Mark each element in the sequence,\n    individually, as safe, after converting them to strings. Return a list\n    with the results.\n    \"\"\"\n    return [mark_safe(obj) for obj in value]\n\n\n@register.filter(is_safe=True)\n@stringfilter\ndef striptags(value):\n    \"\"\"Strip all [X]HTML tags.\"\"\"\n    return strip_tags(value)\n\n\n###################\n# LISTS           #\n###################\n\ndef _property_resolver(arg):\n    \"\"\"\n    When arg is convertible to float, behave like operator.itemgetter(arg)\n    Otherwise, chain __getitem__() and getattr().\n\n    >>> _property_resolver(1)('abc')\n    'b'\n    >>> _property_resolver('1')('abc')\n    Traceback (most recent call last):\n    ...\n    TypeError: string indices must be integers\n    >>> class Foo:\n    ...     a = 42\n    ...     b = 3.14\n    ...     c = 'Hey!'\n    >>> _property_resolver('b')(Foo())\n    3.14\n    \"\"\"\n    try:\n        float(arg)\n    except ValueError:\n        if VARIABLE_ATTRIBUTE_SEPARATOR + '_' in arg or arg[0] == '_':\n            raise AttributeError('Access to private variables is forbidden.')\n        parts = arg.split(VARIABLE_ATTRIBUTE_SEPARATOR)\n\n        def resolve(value):\n            for part in parts:\n                try:\n                    value = value[part]\n                except (AttributeError, IndexError, KeyError, TypeError, ValueError):\n                    value = getattr(value, part)\n            return value\n\n        return resolve\n    else:\n        return itemgetter(arg)\n\n\n@register.filter(is_safe=False)\ndef dictsort(value, arg):\n    \"\"\"\n    Given a list of dicts, return that list sorted by the property given in\n    the argument.\n    \"\"\"\n    try:\n        return sorted(value, key=_property_resolver(arg))\n    except (AttributeError, TypeError):\n        return ''\n\n\n@register.filter(is_safe=False)\ndef dictsortreversed(value, arg):\n    \"\"\"\n    Given a list of dicts, return that list sorted in reverse order by the\n    property given in the argument.\n    \"\"\"\n    try:\n        return sorted(value, key=_property_resolver(arg), reverse=True)\n    except (AttributeError, TypeError):\n        return ''\n\n\n@register.filter(is_safe=False)\ndef first(value):\n    \"\"\"Return the first item in a list.\"\"\"\n    try:\n        return value[0]\n    except IndexError:\n        return ''\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\ndef join(value, arg, autoescape=True):\n    \"\"\"Join a list with a string, like Python's ``str.join(list)``.\"\"\"\n    try:\n        if autoescape:\n            value = [conditional_escape(v) for v in value]\n        data = conditional_escape(arg).join(value)\n    except TypeError:  # Fail silently if arg isn't iterable.\n        return value\n    return mark_safe(data)\n\n\n@register.filter(is_safe=True)\ndef last(value):\n    \"\"\"Return the last item in a list.\"\"\"\n    try:\n        return value[-1]\n    except IndexError:\n        return ''\n\n\n@register.filter(is_safe=False)\ndef length(value):\n    \"\"\"Return the length of the value - useful for lists.\"\"\"\n    try:\n        return len(value)\n    except (ValueError, TypeError):\n        return 0\n\n\n@register.filter(is_safe=False)\ndef length_is(value, arg):\n    \"\"\"Return a boolean of whether the value's length is the argument.\"\"\"\n    try:\n        return len(value) == int(arg)\n    except (ValueError, TypeError):\n        return ''\n\n\n@register.filter(is_safe=True)\ndef random(value):\n    \"\"\"Return a random item from the list.\"\"\"\n    return random_module.choice(value)\n\n\n@register.filter(\"slice\", is_safe=True)\ndef slice_filter(value, arg):\n    \"\"\"\n    Return a slice of the list using the same syntax as Python's list slicing.\n    \"\"\"\n    try:\n        bits = []\n        for x in str(arg).split(':'):\n            if not x:\n                bits.append(None)\n            else:\n                bits.append(int(x))\n        return value[slice(*bits)]\n\n    except (ValueError, TypeError):\n        return value  # Fail silently.\n\n\n@register.filter(is_safe=True, needs_autoescape=True)\ndef unordered_list(value, autoescape=True):\n    \"\"\"\n    Recursively take a self-nested list and return an HTML unordered list --\n    WITHOUT opening and closing <ul> tags.\n\n    Assume the list is in the proper format. For example, if ``var`` contains:\n    ``['States', ['Kansas', ['Lawrence', 'Topeka'], 'Illinois']]``, then\n    ``{{ var|unordered_list }}`` returns::\n\n        <li>States\n        <ul>\n                <li>Kansas\n                <ul>\n                        <li>Lawrence</li>\n                        <li>Topeka</li>\n                </ul>\n                </li>\n                <li>Illinois</li>\n        </ul>\n        </li>\n    \"\"\"\n    if autoescape:\n        escaper = conditional_escape\n    else:\n        def escaper(x):\n            return x\n\n    def walk_items(item_list):\n        item_iterator = iter(item_list)\n        try:\n            item = next(item_iterator)\n            while True:\n                try:\n                    next_item = next(item_iterator)\n                except StopIteration:\n                    yield item, None\n                    break\n                if isinstance(next_item, (list, tuple, types.GeneratorType)):\n                    try:\n                        iter(next_item)\n                    except TypeError:\n                        pass\n                    else:\n                        yield item, next_item\n                        item = next(item_iterator)\n                        continue\n                yield item, None\n                item = next_item\n        except StopIteration:\n            pass\n\n    def list_formatter(item_list, tabs=1):\n        indent = '\\t' * tabs\n        output = []\n        for item, children in walk_items(item_list):\n            sublist = ''\n            if children:\n                sublist = '\\n%s<ul>\\n%s\\n%s</ul>\\n%s' % (\n                    indent, list_formatter(children, tabs + 1), indent, indent)\n            output.append('%s<li>%s%s</li>' % (\n                indent, escaper(item), sublist))\n        return '\\n'.join(output)\n\n    return mark_safe(list_formatter(value))\n\n\n###################\n# INTEGERS        #\n###################\n\n@register.filter(is_safe=False)\ndef add(value, arg):\n    \"\"\"Add the arg to the value.\"\"\"\n    try:\n        return int(value) + int(arg)\n    except (ValueError, TypeError):\n        try:\n            return value + arg\n        except Exception:\n            return ''\n\n\n@register.filter(is_safe=False)\ndef get_digit(value, arg):\n    \"\"\"\n    Given a whole number, return the requested digit of it, where 1 is the\n    right-most digit, 2 is the second-right-most digit, etc. Return the\n    original value for invalid input (if input or argument is not an integer,\n    or if argument is less than 1). Otherwise, output is always an integer.\n    \"\"\"\n    try:\n        arg = int(arg)\n        value = int(value)\n    except ValueError:\n        return value  # Fail silently for an invalid argument\n    if arg < 1:\n        return value\n    try:\n        return int(str(value)[-arg])\n    except IndexError:\n        return 0\n\n\n###################\n# DATES           #\n###################\n\n@register.filter(expects_localtime=True, is_safe=False)\ndef date(value, arg=None):\n    \"\"\"Format a date according to the given format.\"\"\"\n    if value in (None, ''):\n        return ''\n    try:\n        return formats.date_format(value, arg)\n    except AttributeError:\n        try:\n            return format(value, arg)\n        except AttributeError:\n            return ''\n\n\n@register.filter(expects_localtime=True, is_safe=False)\ndef time(value, arg=None):\n    \"\"\"Format a time according to the given format.\"\"\"\n    if value in (None, ''):\n        return ''\n    try:\n        return formats.time_format(value, arg)\n    except (AttributeError, TypeError):\n        try:\n            return time_format(value, arg)\n        except (AttributeError, TypeError):\n            return ''\n\n\n@register.filter(\"timesince\", is_safe=False)\ndef timesince_filter(value, arg=None):\n    \"\"\"Format a date as the time since that date (i.e. \"4 days, 6 hours\").\"\"\"\n    if not value:\n        return ''\n    try:\n        if arg:\n            return timesince(value, arg)\n        return timesince(value)\n    except (ValueError, TypeError):\n        return ''\n\n\n@register.filter(\"timeuntil\", is_safe=False)\ndef timeuntil_filter(value, arg=None):\n    \"\"\"Format a date as the time until that date (i.e. \"4 days, 6 hours\").\"\"\"\n    if not value:\n        return ''\n    try:\n        return timeuntil(value, arg)\n    except (ValueError, TypeError):\n        return ''\n\n\n###################\n# LOGIC           #\n###################\n\n@register.filter(is_safe=False)\ndef default(value, arg):\n    \"\"\"If value is unavailable, use given default.\"\"\"\n    return value or arg\n\n\n@register.filter(is_safe=False)\ndef default_if_none(value, arg):\n    \"\"\"If value is None, use given default.\"\"\"\n    if value is None:\n        return arg\n    return value\n\n\n@register.filter(is_safe=False)\ndef divisibleby(value, arg):\n    \"\"\"Return True if the value is divisible by the argument.\"\"\"\n    return int(value) % int(arg) == 0\n\n\n@register.filter(is_safe=False)\ndef yesno(value, arg=None):\n    \"\"\"\n    Given a string mapping values for true, false, and (optionally) None,\n    return one of those strings according to the value:\n\n    ==========  ======================  ==================================\n    Value       Argument                Outputs\n    ==========  ======================  ==================================\n    ``True``    ``\"yeah,no,maybe\"``     ``yeah``\n    ``False``   ``\"yeah,no,maybe\"``     ``no``\n    ``None``    ``\"yeah,no,maybe\"``     ``maybe``\n    ``None``    ``\"yeah,no\"``           ``\"no\"`` (converts None to False\n                                        if no mapping for None is given.\n    ==========  ======================  ==================================\n    \"\"\"\n    if arg is None:\n        # Translators: Please do not add spaces around commas.\n        arg = gettext('yes,no,maybe')\n    bits = arg.split(',')\n    if len(bits) < 2:\n        return value  # Invalid arg.\n    try:\n        yes, no, maybe = bits\n    except ValueError:\n        # Unpack list of wrong size (no \"maybe\" value provided).\n        yes, no, maybe = bits[0], bits[1], bits[1]\n    if value is None:\n        return maybe\n    if value:\n        return yes\n    return no\n\n\n###################\n# MISC            #\n###################\n\n@register.filter(is_safe=True)\ndef filesizeformat(bytes_):\n    \"\"\"\n    Format the value like a 'human-readable' file size (i.e. 13 KB, 4.1 MB,\n    102 bytes, etc.).\n    \"\"\"\n    try:\n        bytes_ = int(bytes_)\n    except (TypeError, ValueError, UnicodeDecodeError):\n        value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", 0) % {'size': 0}\n        return avoid_wrapping(value)\n\n    def filesize_number_format(value):\n        return formats.number_format(round(value, 1), 1)\n\n    KB = 1 << 10\n    MB = 1 << 20\n    GB = 1 << 30\n    TB = 1 << 40\n    PB = 1 << 50\n\n    negative = bytes_ < 0\n    if negative:\n        bytes_ = -bytes_  # Allow formatting of negative numbers.\n\n    if bytes_ < KB:\n        value = ngettext(\"%(size)d byte\", \"%(size)d bytes\", bytes_) % {'size': bytes_}\n    elif bytes_ < MB:\n        value = gettext(\"%s KB\") % filesize_number_format(bytes_ / KB)\n    elif bytes_ < GB:\n        value = gettext(\"%s MB\") % filesize_number_format(bytes_ / MB)\n    elif bytes_ < TB:\n        value = gettext(\"%s GB\") % filesize_number_format(bytes_ / GB)\n    elif bytes_ < PB:\n        value = gettext(\"%s TB\") % filesize_number_format(bytes_ / TB)\n    else:\n        value = gettext(\"%s PB\") % filesize_number_format(bytes_ / PB)\n\n    if negative:\n        value = \"-%s\" % value\n    return avoid_wrapping(value)\n\n\n@register.filter(is_safe=False)\ndef pluralize(value, arg='s'):\n    \"\"\"\n    Return a plural suffix if the value is not 1, '1', or an object of\n    length 1. By default, use 's' as the suffix:\n\n    * If value is 0, vote{{ value|pluralize }} display \"votes\".\n    * If value is 1, vote{{ value|pluralize }} display \"vote\".\n    * If value is 2, vote{{ value|pluralize }} display \"votes\".\n\n    If an argument is provided, use that string instead:\n\n    * If value is 0, class{{ value|pluralize:\"es\" }} display \"classes\".\n    * If value is 1, class{{ value|pluralize:\"es\" }} display \"class\".\n    * If value is 2, class{{ value|pluralize:\"es\" }} display \"classes\".\n\n    If the provided argument contains a comma, use the text before the comma\n    for the singular case and the text after the comma for the plural case:\n\n    * If value is 0, cand{{ value|pluralize:\"y,ies\" }} display \"candies\".\n    * If value is 1, cand{{ value|pluralize:\"y,ies\" }} display \"candy\".\n    * If value is 2, cand{{ value|pluralize:\"y,ies\" }} display \"candies\".\n    \"\"\"\n    if ',' not in arg:\n        arg = ',' + arg\n    bits = arg.split(',')\n    if len(bits) > 2:\n        return ''\n    singular_suffix, plural_suffix = bits[:2]\n\n    try:\n        return singular_suffix if float(value) == 1 else plural_suffix\n    except ValueError:  # Invalid string that's not a number.\n        pass\n    except TypeError:  # Value isn't a string or a number; maybe it's a list?\n        try:\n            return singular_suffix if len(value) == 1 else plural_suffix\n        except TypeError:  # len() of unsized object.\n            pass\n    return ''\n\n\n@register.filter(\"phone2numeric\", is_safe=True)\ndef phone2numeric_filter(value):\n    \"\"\"Take a phone number and converts it in to its numerical equivalent.\"\"\"\n    return phone2numeric(value)\n\n\n@register.filter(is_safe=True)\ndef pprint(value):\n    \"\"\"A wrapper around pprint.pprint -- for debugging, really.\"\"\"\n    try:\n        return pformat(value)\n    except Exception as e:\n        return \"Error in formatting: %s: %s\" % (e.__class__.__name__, e)\n"
  },
  {
    "patch": "diff --git a/django/contrib/auth/password_validation.py b/django/contrib/auth/password_validation.py\nindex bc70a84543..2e64bf1586 100644\n--- a/django/contrib/auth/password_validation.py\n+++ b/django/contrib/auth/password_validation.py\n@@ -115,6 +115,36 @@ class MinimumLengthValidator:\n         ) % {'min_length': self.min_length}\n \n \n+def exceeds_maximum_length_ratio(password, max_similarity, value):\n+    \"\"\"\n+    Test that value is within a reasonable range of password.\n+\n+    The following ratio calculations are based on testing SequenceMatcher like\n+    this:\n+\n+    for i in range(0,6):\n+      print(10**i, SequenceMatcher(a='A', b='A'*(10**i)).quick_ratio())\n+\n+    which yields:\n+\n+    1 1.0\n+    10 0.18181818181818182\n+    100 0.019801980198019802\n+    1000 0.001998001998001998\n+    10000 0.00019998000199980003\n+    100000 1.999980000199998e-05\n+\n+    This means a length_ratio of 10 should never yield a similarity higher than\n+    0.2, for 100 this is down to 0.02 and for 1000 it is 0.002. This can be\n+    calculated via 2 / length_ratio. As a result we avoid the potentially\n+    expensive sequence matching.\n+    \"\"\"\n+    pwd_len = len(password)\n+    length_bound_similarity = max_similarity / 2 * pwd_len\n+    value_len = len(value)\n+    return pwd_len >= 10 * value_len and value_len < length_bound_similarity\n+\n+\n class UserAttributeSimilarityValidator:\n     \"\"\"\n     Validate that the password is sufficiently different from the user's\n@@ -130,19 +160,25 @@ class UserAttributeSimilarityValidator:\n \n     def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7):\n         self.user_attributes = user_attributes\n+        if max_similarity < 0.1:\n+            raise ValueError('max_similarity must be at least 0.1')\n         self.max_similarity = max_similarity\n \n     def validate(self, password, user=None):\n         if not user:\n             return\n \n+        password = password.lower()\n         for attribute_name in self.user_attributes:\n             value = getattr(user, attribute_name, None)\n             if not value or not isinstance(value, str):\n                 continue\n-            value_parts = re.split(r'\\W+', value) + [value]\n+            value_lower = value.lower()\n+            value_parts = re.split(r'\\W+', value_lower) + [value_lower]\n             for value_part in value_parts:\n-                if SequenceMatcher(a=password.lower(), b=value_part.lower()).quick_ratio() >= self.max_similarity:\n+                if exceeds_maximum_length_ratio(password, self.max_similarity, value_part):\n+                    continue\n+                if SequenceMatcher(a=password, b=value_part).quick_ratio() >= self.max_similarity:\n                     try:\n                         verbose_name = str(user._meta.get_field(attribute_name).verbose_name)\n                     except FieldDoesNotExist:\n",
    "commit_message": "Fixed CVE-2021-45115 -- Prevented DoS vector in UserAttributeSimilarityValidator.\n\nThanks Chris Bailey for the report.\n\nCo-authored-by: Adam Johnson <me@adamj.eu>\n\n",
    "code_before": "import functools\nimport gzip\nimport re\nfrom difflib import SequenceMatcher\nfrom pathlib import Path\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    FieldDoesNotExist, ImproperlyConfigured, ValidationError,\n)\nfrom django.utils.functional import cached_property, lazy\nfrom django.utils.html import format_html, format_html_join\nfrom django.utils.module_loading import import_string\nfrom django.utils.translation import gettext as _, ngettext\n\n\n@functools.lru_cache(maxsize=None)\ndef get_default_password_validators():\n    return get_password_validators(settings.AUTH_PASSWORD_VALIDATORS)\n\n\ndef get_password_validators(validator_config):\n    validators = []\n    for validator in validator_config:\n        try:\n            klass = import_string(validator['NAME'])\n        except ImportError:\n            msg = \"The module in NAME could not be imported: %s. Check your AUTH_PASSWORD_VALIDATORS setting.\"\n            raise ImproperlyConfigured(msg % validator['NAME'])\n        validators.append(klass(**validator.get('OPTIONS', {})))\n\n    return validators\n\n\ndef validate_password(password, user=None, password_validators=None):\n    \"\"\"\n    Validate that the password meets all validator requirements.\n\n    If the password is valid, return ``None``.\n    If the password is invalid, raise ValidationError with all error messages.\n    \"\"\"\n    errors = []\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        try:\n            validator.validate(password, user)\n        except ValidationError as error:\n            errors.append(error)\n    if errors:\n        raise ValidationError(errors)\n\n\ndef password_changed(password, user=None, password_validators=None):\n    \"\"\"\n    Inform all validators that have implemented a password_changed() method\n    that the password has been changed.\n    \"\"\"\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        password_changed = getattr(validator, 'password_changed', lambda *a: None)\n        password_changed(password, user)\n\n\ndef password_validators_help_texts(password_validators=None):\n    \"\"\"\n    Return a list of all help texts of all configured validators.\n    \"\"\"\n    help_texts = []\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        help_texts.append(validator.get_help_text())\n    return help_texts\n\n\ndef _password_validators_help_text_html(password_validators=None):\n    \"\"\"\n    Return an HTML string with all help texts of all configured validators\n    in an <ul>.\n    \"\"\"\n    help_texts = password_validators_help_texts(password_validators)\n    help_items = format_html_join('', '<li>{}</li>', ((help_text,) for help_text in help_texts))\n    return format_html('<ul>{}</ul>', help_items) if help_items else ''\n\n\npassword_validators_help_text_html = lazy(_password_validators_help_text_html, str)\n\n\nclass MinimumLengthValidator:\n    \"\"\"\n    Validate that the password is of a minimum length.\n    \"\"\"\n    def __init__(self, min_length=8):\n        self.min_length = min_length\n\n    def validate(self, password, user=None):\n        if len(password) < self.min_length:\n            raise ValidationError(\n                ngettext(\n                    \"This password is too short. It must contain at least %(min_length)d character.\",\n                    \"This password is too short. It must contain at least %(min_length)d characters.\",\n                    self.min_length\n                ),\n                code='password_too_short',\n                params={'min_length': self.min_length},\n            )\n\n    def get_help_text(self):\n        return ngettext(\n            \"Your password must contain at least %(min_length)d character.\",\n            \"Your password must contain at least %(min_length)d characters.\",\n            self.min_length\n        ) % {'min_length': self.min_length}\n\n\nclass UserAttributeSimilarityValidator:\n    \"\"\"\n    Validate that the password is sufficiently different from the user's\n    attributes.\n\n    If no specific attributes are provided, look at a sensible list of\n    defaults. Attributes that don't exist are ignored. Comparison is made to\n    not only the full attribute value, but also its components, so that, for\n    example, a password is validated against either part of an email address,\n    as well as the full address.\n    \"\"\"\n    DEFAULT_USER_ATTRIBUTES = ('username', 'first_name', 'last_name', 'email')\n\n    def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7):\n        self.user_attributes = user_attributes\n        self.max_similarity = max_similarity\n\n    def validate(self, password, user=None):\n        if not user:\n            return\n\n        for attribute_name in self.user_attributes:\n            value = getattr(user, attribute_name, None)\n            if not value or not isinstance(value, str):\n                continue\n            value_parts = re.split(r'\\W+', value) + [value]\n            for value_part in value_parts:\n                if SequenceMatcher(a=password.lower(), b=value_part.lower()).quick_ratio() >= self.max_similarity:\n                    try:\n                        verbose_name = str(user._meta.get_field(attribute_name).verbose_name)\n                    except FieldDoesNotExist:\n                        verbose_name = attribute_name\n                    raise ValidationError(\n                        _(\"The password is too similar to the %(verbose_name)s.\"),\n                        code='password_too_similar',\n                        params={'verbose_name': verbose_name},\n                    )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be too similar to your other personal information.')\n\n\nclass CommonPasswordValidator:\n    \"\"\"\n    Validate that the password is not a common password.\n\n    The password is rejected if it occurs in a provided list of passwords,\n    which may be gzipped. The list Django ships with contains 20000 common\n    passwords (lowercased and deduplicated), created by Royce Williams:\n    https://gist.github.com/roycewilliams/281ce539915a947a23db17137d91aeb7\n    The password list must be lowercased to match the comparison in validate().\n    \"\"\"\n\n    @cached_property\n    def DEFAULT_PASSWORD_LIST_PATH(self):\n        return Path(__file__).resolve().parent / 'common-passwords.txt.gz'\n\n    def __init__(self, password_list_path=DEFAULT_PASSWORD_LIST_PATH):\n        if password_list_path is CommonPasswordValidator.DEFAULT_PASSWORD_LIST_PATH:\n            password_list_path = self.DEFAULT_PASSWORD_LIST_PATH\n        try:\n            with gzip.open(password_list_path, 'rt', encoding='utf-8') as f:\n                self.passwords = {x.strip() for x in f}\n        except OSError:\n            with open(password_list_path) as f:\n                self.passwords = {x.strip() for x in f}\n\n    def validate(self, password, user=None):\n        if password.lower().strip() in self.passwords:\n            raise ValidationError(\n                _(\"This password is too common.\"),\n                code='password_too_common',\n            )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be a commonly used password.')\n\n\nclass NumericPasswordValidator:\n    \"\"\"\n    Validate that the password is not entirely numeric.\n    \"\"\"\n    def validate(self, password, user=None):\n        if password.isdigit():\n            raise ValidationError(\n                _(\"This password is entirely numeric.\"),\n                code='password_entirely_numeric',\n            )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be entirely numeric.')\n",
    "code_after": "import functools\nimport gzip\nimport re\nfrom difflib import SequenceMatcher\nfrom pathlib import Path\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    FieldDoesNotExist, ImproperlyConfigured, ValidationError,\n)\nfrom django.utils.functional import cached_property, lazy\nfrom django.utils.html import format_html, format_html_join\nfrom django.utils.module_loading import import_string\nfrom django.utils.translation import gettext as _, ngettext\n\n\n@functools.lru_cache(maxsize=None)\ndef get_default_password_validators():\n    return get_password_validators(settings.AUTH_PASSWORD_VALIDATORS)\n\n\ndef get_password_validators(validator_config):\n    validators = []\n    for validator in validator_config:\n        try:\n            klass = import_string(validator['NAME'])\n        except ImportError:\n            msg = \"The module in NAME could not be imported: %s. Check your AUTH_PASSWORD_VALIDATORS setting.\"\n            raise ImproperlyConfigured(msg % validator['NAME'])\n        validators.append(klass(**validator.get('OPTIONS', {})))\n\n    return validators\n\n\ndef validate_password(password, user=None, password_validators=None):\n    \"\"\"\n    Validate that the password meets all validator requirements.\n\n    If the password is valid, return ``None``.\n    If the password is invalid, raise ValidationError with all error messages.\n    \"\"\"\n    errors = []\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        try:\n            validator.validate(password, user)\n        except ValidationError as error:\n            errors.append(error)\n    if errors:\n        raise ValidationError(errors)\n\n\ndef password_changed(password, user=None, password_validators=None):\n    \"\"\"\n    Inform all validators that have implemented a password_changed() method\n    that the password has been changed.\n    \"\"\"\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        password_changed = getattr(validator, 'password_changed', lambda *a: None)\n        password_changed(password, user)\n\n\ndef password_validators_help_texts(password_validators=None):\n    \"\"\"\n    Return a list of all help texts of all configured validators.\n    \"\"\"\n    help_texts = []\n    if password_validators is None:\n        password_validators = get_default_password_validators()\n    for validator in password_validators:\n        help_texts.append(validator.get_help_text())\n    return help_texts\n\n\ndef _password_validators_help_text_html(password_validators=None):\n    \"\"\"\n    Return an HTML string with all help texts of all configured validators\n    in an <ul>.\n    \"\"\"\n    help_texts = password_validators_help_texts(password_validators)\n    help_items = format_html_join('', '<li>{}</li>', ((help_text,) for help_text in help_texts))\n    return format_html('<ul>{}</ul>', help_items) if help_items else ''\n\n\npassword_validators_help_text_html = lazy(_password_validators_help_text_html, str)\n\n\nclass MinimumLengthValidator:\n    \"\"\"\n    Validate that the password is of a minimum length.\n    \"\"\"\n    def __init__(self, min_length=8):\n        self.min_length = min_length\n\n    def validate(self, password, user=None):\n        if len(password) < self.min_length:\n            raise ValidationError(\n                ngettext(\n                    \"This password is too short. It must contain at least %(min_length)d character.\",\n                    \"This password is too short. It must contain at least %(min_length)d characters.\",\n                    self.min_length\n                ),\n                code='password_too_short',\n                params={'min_length': self.min_length},\n            )\n\n    def get_help_text(self):\n        return ngettext(\n            \"Your password must contain at least %(min_length)d character.\",\n            \"Your password must contain at least %(min_length)d characters.\",\n            self.min_length\n        ) % {'min_length': self.min_length}\n\n\ndef exceeds_maximum_length_ratio(password, max_similarity, value):\n    \"\"\"\n    Test that value is within a reasonable range of password.\n\n    The following ratio calculations are based on testing SequenceMatcher like\n    this:\n\n    for i in range(0,6):\n      print(10**i, SequenceMatcher(a='A', b='A'*(10**i)).quick_ratio())\n\n    which yields:\n\n    1 1.0\n    10 0.18181818181818182\n    100 0.019801980198019802\n    1000 0.001998001998001998\n    10000 0.00019998000199980003\n    100000 1.999980000199998e-05\n\n    This means a length_ratio of 10 should never yield a similarity higher than\n    0.2, for 100 this is down to 0.02 and for 1000 it is 0.002. This can be\n    calculated via 2 / length_ratio. As a result we avoid the potentially\n    expensive sequence matching.\n    \"\"\"\n    pwd_len = len(password)\n    length_bound_similarity = max_similarity / 2 * pwd_len\n    value_len = len(value)\n    return pwd_len >= 10 * value_len and value_len < length_bound_similarity\n\n\nclass UserAttributeSimilarityValidator:\n    \"\"\"\n    Validate that the password is sufficiently different from the user's\n    attributes.\n\n    If no specific attributes are provided, look at a sensible list of\n    defaults. Attributes that don't exist are ignored. Comparison is made to\n    not only the full attribute value, but also its components, so that, for\n    example, a password is validated against either part of an email address,\n    as well as the full address.\n    \"\"\"\n    DEFAULT_USER_ATTRIBUTES = ('username', 'first_name', 'last_name', 'email')\n\n    def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7):\n        self.user_attributes = user_attributes\n        if max_similarity < 0.1:\n            raise ValueError('max_similarity must be at least 0.1')\n        self.max_similarity = max_similarity\n\n    def validate(self, password, user=None):\n        if not user:\n            return\n\n        password = password.lower()\n        for attribute_name in self.user_attributes:\n            value = getattr(user, attribute_name, None)\n            if not value or not isinstance(value, str):\n                continue\n            value_lower = value.lower()\n            value_parts = re.split(r'\\W+', value_lower) + [value_lower]\n            for value_part in value_parts:\n                if exceeds_maximum_length_ratio(password, self.max_similarity, value_part):\n                    continue\n                if SequenceMatcher(a=password, b=value_part).quick_ratio() >= self.max_similarity:\n                    try:\n                        verbose_name = str(user._meta.get_field(attribute_name).verbose_name)\n                    except FieldDoesNotExist:\n                        verbose_name = attribute_name\n                    raise ValidationError(\n                        _(\"The password is too similar to the %(verbose_name)s.\"),\n                        code='password_too_similar',\n                        params={'verbose_name': verbose_name},\n                    )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be too similar to your other personal information.')\n\n\nclass CommonPasswordValidator:\n    \"\"\"\n    Validate that the password is not a common password.\n\n    The password is rejected if it occurs in a provided list of passwords,\n    which may be gzipped. The list Django ships with contains 20000 common\n    passwords (lowercased and deduplicated), created by Royce Williams:\n    https://gist.github.com/roycewilliams/281ce539915a947a23db17137d91aeb7\n    The password list must be lowercased to match the comparison in validate().\n    \"\"\"\n\n    @cached_property\n    def DEFAULT_PASSWORD_LIST_PATH(self):\n        return Path(__file__).resolve().parent / 'common-passwords.txt.gz'\n\n    def __init__(self, password_list_path=DEFAULT_PASSWORD_LIST_PATH):\n        if password_list_path is CommonPasswordValidator.DEFAULT_PASSWORD_LIST_PATH:\n            password_list_path = self.DEFAULT_PASSWORD_LIST_PATH\n        try:\n            with gzip.open(password_list_path, 'rt', encoding='utf-8') as f:\n                self.passwords = {x.strip() for x in f}\n        except OSError:\n            with open(password_list_path) as f:\n                self.passwords = {x.strip() for x in f}\n\n    def validate(self, password, user=None):\n        if password.lower().strip() in self.passwords:\n            raise ValidationError(\n                _(\"This password is too common.\"),\n                code='password_too_common',\n            )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be a commonly used password.')\n\n\nclass NumericPasswordValidator:\n    \"\"\"\n    Validate that the password is not entirely numeric.\n    \"\"\"\n    def validate(self, password, user=None):\n        if password.isdigit():\n            raise ValidationError(\n                _(\"This password is entirely numeric.\"),\n                code='password_entirely_numeric',\n            )\n\n    def get_help_text(self):\n        return _('Your password can\u2019t be entirely numeric.')\n"
  },
  {
    "patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 6ea18dd22f..110ad87cdb 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -165,7 +165,11 @@ class RegexPattern(CheckURLMixin):\n         self.converters = {}\n \n     def match(self, path):\n-        match = self.regex.search(path)\n+        match = (\n+            self.regex.fullmatch(path)\n+            if self._is_endpoint and self.regex.pattern.endswith('$')\n+            else self.regex.search(path)\n+        )\n         if match:\n             # If there are any named groups, use those as kwargs, ignoring\n             # non-named groups. Otherwise, pass all non-named arguments as\n@@ -255,7 +259,7 @@ def _route_to_regex(route, is_endpoint=False):\n         converters[parameter] = converter\n         parts.append('(?P<' + parameter + '>' + converter.regex + ')')\n     if is_endpoint:\n-        parts.append('$')\n+        parts.append(r'\\Z')\n     return ''.join(parts), converters\n \n \n",
    "commit_message": "Fixed #30530, CVE-2021-44420 -- Fixed potential bypass of an upstream access control based on URL paths.\n\nThanks Sjoerd Job Postmus and TengMA(@te3t123) for reports.\n\n",
    "code_before": "\"\"\"\nThis module converts requested URLs to callback view functions.\n\nURLResolver is the main class here. Its resolve() method takes a URL (as\na string) and returns a ResolverMatch object which provides access to all\nattributes of the resolved URL match.\n\"\"\"\nimport functools\nimport inspect\nimport re\nimport string\nfrom importlib import import_module\nfrom pickle import PicklingError\nfrom urllib.parse import quote\n\nfrom asgiref.local import Local\n\nfrom django.conf import settings\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.urls import check_resolver\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.functional import cached_property\nfrom django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\nfrom django.utils.regex_helper import _lazy_re_compile, normalize\nfrom django.utils.translation import get_language\n\nfrom .converters import get_converter\nfrom .exceptions import NoReverseMatch, Resolver404\nfrom .utils import get_callable\n\n\nclass ResolverMatch:\n    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n        self.func = func\n        self.args = args\n        self.kwargs = kwargs\n        self.url_name = url_name\n        self.route = route\n        self.tried = tried\n\n        # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n        # in an empty value.\n        self.app_names = [x for x in app_names if x] if app_names else []\n        self.app_name = ':'.join(self.app_names)\n        self.namespaces = [x for x in namespaces if x] if namespaces else []\n        self.namespace = ':'.join(self.namespaces)\n\n        if not hasattr(func, '__name__'):\n            # A class-based view\n            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n        else:\n            # A function-based view\n            self._func_path = func.__module__ + '.' + func.__name__\n\n        view_path = url_name or self._func_path\n        self.view_name = ':'.join(self.namespaces + [view_path])\n\n    def __getitem__(self, index):\n        return (self.func, self.args, self.kwargs)[index]\n\n    def __repr__(self):\n        if isinstance(self.func, functools.partial):\n            func = repr(self.func)\n        else:\n            func = self._func_path\n        return (\n            'ResolverMatch(func=%s, args=%r, kwargs=%r, url_name=%r, '\n            'app_names=%r, namespaces=%r, route=%r)' % (\n                func, self.args, self.kwargs, self.url_name,\n                self.app_names, self.namespaces, self.route,\n            )\n        )\n\n    def __reduce_ex__(self, protocol):\n        raise PicklingError(f'Cannot pickle {self.__class__.__qualname__}.')\n\n\ndef get_resolver(urlconf=None):\n    if urlconf is None:\n        urlconf = settings.ROOT_URLCONF\n    return _get_cached_resolver(urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef _get_cached_resolver(urlconf=None):\n    return URLResolver(RegexPattern(r'^/'), urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef get_ns_resolver(ns_pattern, resolver, converters):\n    # Build a namespaced resolver for the given parent URLconf pattern.\n    # This makes it possible to have captured parameters in the parent\n    # URLconf pattern.\n    pattern = RegexPattern(ns_pattern)\n    pattern.converters = dict(converters)\n    ns_resolver = URLResolver(pattern, resolver.url_patterns)\n    return URLResolver(RegexPattern(r'^/'), [ns_resolver])\n\n\nclass LocaleRegexDescriptor:\n    def __init__(self, attr):\n        self.attr = attr\n\n    def __get__(self, instance, cls=None):\n        \"\"\"\n        Return a compiled regular expression based on the active language.\n        \"\"\"\n        if instance is None:\n            return self\n        # As a performance optimization, if the given regex string is a regular\n        # string (not a lazily-translated string proxy), compile it once and\n        # avoid per-language compilation.\n        pattern = getattr(instance, self.attr)\n        if isinstance(pattern, str):\n            instance.__dict__['regex'] = instance._compile(pattern)\n            return instance.__dict__['regex']\n        language_code = get_language()\n        if language_code not in instance._regex_dict:\n            instance._regex_dict[language_code] = instance._compile(str(pattern))\n        return instance._regex_dict[language_code]\n\n\nclass CheckURLMixin:\n    def describe(self):\n        \"\"\"\n        Format the URL pattern for display in warning messages.\n        \"\"\"\n        description = \"'{}'\".format(self)\n        if self.name:\n            description += \" [name='{}']\".format(self.name)\n        return description\n\n    def _check_pattern_startswith_slash(self):\n        \"\"\"\n        Check that the pattern does not begin with a forward slash.\n        \"\"\"\n        regex_pattern = self.regex.pattern\n        if not settings.APPEND_SLASH:\n            # Skip check as it can be useful to start a URL pattern with a slash\n            # when APPEND_SLASH=False.\n            return []\n        if regex_pattern.startswith(('/', '^/', '^\\\\/')) and not regex_pattern.endswith('/'):\n            warning = Warning(\n                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                \"slash as it is unnecessary. If this pattern is targeted in an \"\n                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n                    self.describe()\n                ),\n                id=\"urls.W002\",\n            )\n            return [warning]\n        else:\n            return []\n\n\nclass RegexPattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor('_regex')\n\n    def __init__(self, regex, name=None, is_endpoint=False):\n        self._regex = regex\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = {}\n\n    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end():], args, kwargs\n        return None\n\n    def check(self):\n        warnings = []\n        warnings.extend(self._check_pattern_startswith_slash())\n        if not self._is_endpoint:\n            warnings.extend(self._check_include_trailing_dollar())\n        return warnings\n\n    def _check_include_trailing_dollar(self):\n        regex_pattern = self.regex.pattern\n        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):\n            return [Warning(\n                \"Your URL pattern {} uses include with a route ending with a '$'. \"\n                \"Remove the dollar from the route to avoid problems including \"\n                \"URLs.\".format(self.describe()),\n                id='urls.W001',\n            )]\n        else:\n            return []\n\n    def _compile(self, regex):\n        \"\"\"Compile and return the given regular expression.\"\"\"\n        try:\n            return re.compile(regex)\n        except re.error as e:\n            raise ImproperlyConfigured(\n                '\"%s\" is not a valid regular expression: %s' % (regex, e)\n            ) from e\n\n    def __str__(self):\n        return str(self._regex)\n\n\n_PATH_PARAMETER_COMPONENT_RE = _lazy_re_compile(\n    r'<(?:(?P<converter>[^>:]+):)?(?P<parameter>[^>]+)>'\n)\n\n\ndef _route_to_regex(route, is_endpoint=False):\n    \"\"\"\n    Convert a path pattern into a regular expression. Return the regular\n    expression and a dictionary mapping the capture names to the converters.\n    For example, 'foo/<int:pk>' returns '^foo\\\\/(?P<pk>[0-9]+)'\n    and {'pk': <django.urls.converters.IntConverter>}.\n    \"\"\"\n    original_route = route\n    parts = ['^']\n    converters = {}\n    while True:\n        match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n        if not match:\n            parts.append(re.escape(route))\n            break\n        elif not set(match.group()).isdisjoint(string.whitespace):\n            raise ImproperlyConfigured(\n                \"URL route '%s' cannot contain whitespace in angle brackets \"\n                \"<\u2026>.\" % original_route\n            )\n        parts.append(re.escape(route[:match.start()]))\n        route = route[match.end():]\n        parameter = match['parameter']\n        if not parameter.isidentifier():\n            raise ImproperlyConfigured(\n                \"URL route '%s' uses parameter name %r which isn't a valid \"\n                \"Python identifier.\" % (original_route, parameter)\n            )\n        raw_converter = match['converter']\n        if raw_converter is None:\n            # If a converter isn't specified, the default is `str`.\n            raw_converter = 'str'\n        try:\n            converter = get_converter(raw_converter)\n        except KeyError as e:\n            raise ImproperlyConfigured(\n                'URL route %r uses invalid converter %r.'\n                % (original_route, raw_converter)\n            ) from e\n        converters[parameter] = converter\n        parts.append('(?P<' + parameter + '>' + converter.regex + ')')\n    if is_endpoint:\n        parts.append('$')\n    return ''.join(parts), converters\n\n\nclass RoutePattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor('_route')\n\n    def __init__(self, route, name=None, is_endpoint=False):\n        self._route = route\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = _route_to_regex(str(route), is_endpoint)[1]\n\n    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # RoutePattern doesn't allow non-named groups so args are ignored.\n            kwargs = match.groupdict()\n            for key, value in kwargs.items():\n                converter = self.converters[key]\n                try:\n                    kwargs[key] = converter.to_python(value)\n                except ValueError:\n                    return None\n            return path[match.end():], (), kwargs\n        return None\n\n    def check(self):\n        warnings = self._check_pattern_startswith_slash()\n        route = self._route\n        if '(?P<' in route or route.startswith('^') or route.endswith('$'):\n            warnings.append(Warning(\n                \"Your URL pattern {} has a route that contains '(?P<', begins \"\n                \"with a '^', or ends with a '$'. This was likely an oversight \"\n                \"when migrating to django.urls.path().\".format(self.describe()),\n                id='2_0.W001',\n            ))\n        return warnings\n\n    def _compile(self, route):\n        return re.compile(_route_to_regex(route, self._is_endpoint)[0])\n\n    def __str__(self):\n        return str(self._route)\n\n\nclass LocalePrefixPattern:\n    def __init__(self, prefix_default_language=True):\n        self.prefix_default_language = prefix_default_language\n        self.converters = {}\n\n    @property\n    def regex(self):\n        # This is only used by reverse() and cached in _reverse_dict.\n        return re.compile(self.language_prefix)\n\n    @property\n    def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n            return ''\n        else:\n            return '%s/' % language_code\n\n    def match(self, path):\n        language_prefix = self.language_prefix\n        if path.startswith(language_prefix):\n            return path[len(language_prefix):], (), {}\n        return None\n\n    def check(self):\n        return []\n\n    def describe(self):\n        return \"'{}'\".format(self)\n\n    def __str__(self):\n        return self.language_prefix\n\n\nclass URLPattern:\n    def __init__(self, pattern, callback, default_args=None, name=None):\n        self.pattern = pattern\n        self.callback = callback  # the view\n        self.default_args = default_args or {}\n        self.name = name\n\n    def __repr__(self):\n        return '<%s %s>' % (self.__class__.__name__, self.pattern.describe())\n\n    def check(self):\n        warnings = self._check_pattern_name()\n        warnings.extend(self.pattern.check())\n        warnings.extend(self._check_callback())\n        return warnings\n\n    def _check_pattern_name(self):\n        \"\"\"\n        Check that the pattern name does not contain a colon.\n        \"\"\"\n        if self.pattern.name is not None and \":\" in self.pattern.name:\n            warning = Warning(\n                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"\n                \"avoid ambiguous namespace references.\".format(self.pattern.describe()),\n                id=\"urls.W003\",\n            )\n            return [warning]\n        else:\n            return []\n\n    def _check_callback(self):\n        from django.views import View\n\n        view = self.callback\n        if inspect.isclass(view) and issubclass(view, View):\n            return [Error(\n                'Your URL pattern %s has an invalid view, pass %s.as_view() '\n                'instead of %s.' % (\n                    self.pattern.describe(),\n                    view.__name__,\n                    view.__name__,\n                ),\n                id='urls.E009',\n            )]\n        return []\n\n    def resolve(self, path):\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            # Pass any extra_kwargs as **kwargs.\n            kwargs.update(self.default_args)\n            return ResolverMatch(self.callback, args, kwargs, self.pattern.name, route=str(self.pattern))\n\n    @cached_property\n    def lookup_str(self):\n        \"\"\"\n        A string that identifies the view (e.g. 'path.to.view_function' or\n        'path.to.ClassBasedView').\n        \"\"\"\n        callback = self.callback\n        if isinstance(callback, functools.partial):\n            callback = callback.func\n        if hasattr(callback, 'view_class'):\n            callback = callback.view_class\n        elif not hasattr(callback, '__name__'):\n            return callback.__module__ + \".\" + callback.__class__.__name__\n        return callback.__module__ + \".\" + callback.__qualname__\n\n\nclass URLResolver:\n    def __init__(self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None):\n        self.pattern = pattern\n        # urlconf_name is the dotted Python path to the module defining\n        # urlpatterns. It may also be an object with an urlpatterns attribute\n        # or urlpatterns itself.\n        self.urlconf_name = urlconf_name\n        self.callback = None\n        self.default_kwargs = default_kwargs or {}\n        self.namespace = namespace\n        self.app_name = app_name\n        self._reverse_dict = {}\n        self._namespace_dict = {}\n        self._app_dict = {}\n        # set of dotted paths to all functions and classes that are used in\n        # urlpatterns\n        self._callback_strs = set()\n        self._populated = False\n        self._local = Local()\n\n    def __repr__(self):\n        if isinstance(self.urlconf_name, list) and self.urlconf_name:\n            # Don't bother to output the whole list, it can be huge\n            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__\n        else:\n            urlconf_repr = repr(self.urlconf_name)\n        return '<%s %s (%s:%s) %s>' % (\n            self.__class__.__name__, urlconf_repr, self.app_name,\n            self.namespace, self.pattern.describe(),\n        )\n\n    def check(self):\n        messages = []\n        for pattern in self.url_patterns:\n            messages.extend(check_resolver(pattern))\n        messages.extend(self._check_custom_error_handlers())\n        return messages or self.pattern.check()\n\n    def _check_custom_error_handlers(self):\n        messages = []\n        # All handlers take (request, exception) arguments except handler500\n        # which takes (request).\n        for status_code, num_parameters in [(400, 2), (403, 2), (404, 2), (500, 1)]:\n            try:\n                handler = self.resolve_error_handler(status_code)\n            except (ImportError, ViewDoesNotExist) as e:\n                path = getattr(self.urlconf_module, 'handler%s' % status_code)\n                msg = (\n                    \"The custom handler{status_code} view '{path}' could not be imported.\"\n                ).format(status_code=status_code, path=path)\n                messages.append(Error(msg, hint=str(e), id='urls.E008'))\n                continue\n            signature = inspect.signature(handler)\n            args = [None] * num_parameters\n            try:\n                signature.bind(*args)\n            except TypeError:\n                msg = (\n                    \"The custom handler{status_code} view '{path}' does not \"\n                    \"take the correct number of arguments ({args}).\"\n                ).format(\n                    status_code=status_code,\n                    path=handler.__module__ + '.' + handler.__qualname__,\n                    args='request, exception' if num_parameters == 2 else 'request',\n                )\n                messages.append(Error(msg, id='urls.E007'))\n        return messages\n\n    def _populate(self):\n        # Short-circuit if called recursively in this thread to prevent\n        # infinite recursion. Concurrent threads may call this at the same\n        # time and will need to continue, so set 'populating' on a\n        # thread-local variable.\n        if getattr(self._local, 'populating', False):\n            return\n        try:\n            self._local.populating = True\n            lookups = MultiValueDict()\n            namespaces = {}\n            apps = {}\n            language_code = get_language()\n            for url_pattern in reversed(self.url_patterns):\n                p_pattern = url_pattern.pattern.regex.pattern\n                if p_pattern.startswith('^'):\n                    p_pattern = p_pattern[1:]\n                if isinstance(url_pattern, URLPattern):\n                    self._callback_strs.add(url_pattern.lookup_str)\n                    bits = normalize(url_pattern.pattern.regex.pattern)\n                    lookups.appendlist(\n                        url_pattern.callback,\n                        (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n                    )\n                    if url_pattern.name is not None:\n                        lookups.appendlist(\n                            url_pattern.name,\n                            (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n                        )\n                else:  # url_pattern is a URLResolver.\n                    url_pattern._populate()\n                    if url_pattern.app_name:\n                        apps.setdefault(url_pattern.app_name, []).append(url_pattern.namespace)\n                        namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                    else:\n                        for name in url_pattern.reverse_dict:\n                            for matches, pat, defaults, converters in url_pattern.reverse_dict.getlist(name):\n                                new_matches = normalize(p_pattern + pat)\n                                lookups.appendlist(\n                                    name,\n                                    (\n                                        new_matches,\n                                        p_pattern + pat,\n                                        {**defaults, **url_pattern.default_kwargs},\n                                        {**self.pattern.converters, **url_pattern.pattern.converters, **converters}\n                                    )\n                                )\n                        for namespace, (prefix, sub_pattern) in url_pattern.namespace_dict.items():\n                            current_converters = url_pattern.pattern.converters\n                            sub_pattern.pattern.converters.update(current_converters)\n                            namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n                        for app_name, namespace_list in url_pattern.app_dict.items():\n                            apps.setdefault(app_name, []).extend(namespace_list)\n                    self._callback_strs.update(url_pattern._callback_strs)\n            self._namespace_dict[language_code] = namespaces\n            self._app_dict[language_code] = apps\n            self._reverse_dict[language_code] = lookups\n            self._populated = True\n        finally:\n            self._local.populating = False\n\n    @property\n    def reverse_dict(self):\n        language_code = get_language()\n        if language_code not in self._reverse_dict:\n            self._populate()\n        return self._reverse_dict[language_code]\n\n    @property\n    def namespace_dict(self):\n        language_code = get_language()\n        if language_code not in self._namespace_dict:\n            self._populate()\n        return self._namespace_dict[language_code]\n\n    @property\n    def app_dict(self):\n        language_code = get_language()\n        if language_code not in self._app_dict:\n            self._populate()\n        return self._app_dict[language_code]\n\n    @staticmethod\n    def _extend_tried(tried, pattern, sub_tried=None):\n        if sub_tried is None:\n            tried.append([pattern])\n        else:\n            tried.extend([pattern, *t] for t in sub_tried)\n\n    @staticmethod\n    def _join_route(route1, route2):\n        \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n        if not route1:\n            return route2\n        if route2.startswith('^'):\n            route2 = route2[1:]\n        return route1 + route2\n\n    def _is_callback(self, name):\n        if not self._populated:\n            self._populate()\n        return name in self._callback_strs\n\n    def resolve(self, path):\n        path = str(path)  # path may be a reverse_lazy object\n        tried = []\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            for pattern in self.url_patterns:\n                try:\n                    sub_match = pattern.resolve(new_path)\n                except Resolver404 as e:\n                    self._extend_tried(tried, pattern, e.args[0].get('tried'))\n                else:\n                    if sub_match:\n                        # Merge captured arguments in match with submatch\n                        sub_match_dict = {**kwargs, **self.default_kwargs}\n                        # Update the sub_match_dict with the kwargs from the sub_match.\n                        sub_match_dict.update(sub_match.kwargs)\n                        # If there are *any* named groups, ignore all non-named groups.\n                        # Otherwise, pass all non-named arguments as positional arguments.\n                        sub_match_args = sub_match.args\n                        if not sub_match_dict:\n                            sub_match_args = args + sub_match.args\n                        current_route = '' if isinstance(pattern, URLPattern) else str(pattern.pattern)\n                        self._extend_tried(tried, pattern, sub_match.tried)\n                        return ResolverMatch(\n                            sub_match.func,\n                            sub_match_args,\n                            sub_match_dict,\n                            sub_match.url_name,\n                            [self.app_name] + sub_match.app_names,\n                            [self.namespace] + sub_match.namespaces,\n                            self._join_route(current_route, sub_match.route),\n                            tried,\n                        )\n                    tried.append([pattern])\n            raise Resolver404({'tried': tried, 'path': new_path})\n        raise Resolver404({'path': path})\n\n    @cached_property\n    def urlconf_module(self):\n        if isinstance(self.urlconf_name, str):\n            return import_module(self.urlconf_name)\n        else:\n            return self.urlconf_name\n\n    @cached_property\n    def url_patterns(self):\n        # urlconf_module might be a valid set of patterns, so we default to it\n        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\n        try:\n            iter(patterns)\n        except TypeError as e:\n            msg = (\n                \"The included URLconf '{name}' does not appear to have \"\n                \"any patterns in it. If you see the 'urlpatterns' variable \"\n                \"with valid patterns in the file then the issue is probably \"\n                \"caused by a circular import.\"\n            )\n            raise ImproperlyConfigured(msg.format(name=self.urlconf_name)) from e\n        return patterns\n\n    def resolve_error_handler(self, view_type):\n        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)\n        if not callback:\n            # No handler specified in file; use lazy import, since\n            # django.conf.urls imports this file.\n            from django.conf import urls\n            callback = getattr(urls, 'handler%s' % view_type)\n        return get_callable(callback)\n\n    def reverse(self, lookup_view, *args, **kwargs):\n        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)\n\n    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n        if args and kwargs:\n            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")\n\n        if not self._populated:\n            self._populate()\n\n        possibilities = self.reverse_dict.getlist(lookup_view)\n\n        for possibility, pattern, defaults, converters in possibilities:\n            for result, params in possibility:\n                if args:\n                    if len(args) != len(params):\n                        continue\n                    candidate_subs = dict(zip(params, args))\n                else:\n                    if set(kwargs).symmetric_difference(params).difference(defaults):\n                        continue\n                    if any(kwargs.get(k, v) != v for k, v in defaults.items()):\n                        continue\n                    candidate_subs = kwargs\n                # Convert the candidate subs to text using Converter.to_url().\n                text_candidate_subs = {}\n                match = True\n                for k, v in candidate_subs.items():\n                    if k in converters:\n                        try:\n                            text_candidate_subs[k] = converters[k].to_url(v)\n                        except ValueError:\n                            match = False\n                            break\n                    else:\n                        text_candidate_subs[k] = str(v)\n                if not match:\n                    continue\n                # WSGI provides decoded URLs, without %xx escapes, and the URL\n                # resolver operates on such URLs. First substitute arguments\n                # without quoting to build a decoded URL and look for a match.\n                # Then, if we have a match, redo the substitution with quoted\n                # arguments in order to return a properly encoded URL.\n                candidate_pat = _prefix.replace('%', '%%') + result\n                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % text_candidate_subs):\n                    # safe characters from `pchar` definition of RFC 3986\n                    url = quote(candidate_pat % text_candidate_subs, safe=RFC3986_SUBDELIMS + '/~:@')\n                    # Don't allow construction of scheme relative urls.\n                    return escape_leading_slashes(url)\n        # lookup_view can be URL name or callable, but callables are not\n        # friendly in error messages.\n        m = getattr(lookup_view, '__module__', None)\n        n = getattr(lookup_view, '__name__', None)\n        if m is not None and n is not None:\n            lookup_view_s = \"%s.%s\" % (m, n)\n        else:\n            lookup_view_s = lookup_view\n\n        patterns = [pattern for (_, pattern, _, _) in possibilities]\n        if patterns:\n            if args:\n                arg_msg = \"arguments '%s'\" % (args,)\n            elif kwargs:\n                arg_msg = \"keyword arguments '%s'\" % kwargs\n            else:\n                arg_msg = \"no arguments\"\n            msg = (\n                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %\n                (lookup_view_s, arg_msg, len(patterns), patterns)\n            )\n        else:\n            msg = (\n                \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n                \"a valid view function or pattern name.\" % {'view': lookup_view_s}\n            )\n        raise NoReverseMatch(msg)\n",
    "code_after": "\"\"\"\nThis module converts requested URLs to callback view functions.\n\nURLResolver is the main class here. Its resolve() method takes a URL (as\na string) and returns a ResolverMatch object which provides access to all\nattributes of the resolved URL match.\n\"\"\"\nimport functools\nimport inspect\nimport re\nimport string\nfrom importlib import import_module\nfrom pickle import PicklingError\nfrom urllib.parse import quote\n\nfrom asgiref.local import Local\n\nfrom django.conf import settings\nfrom django.core.checks import Error, Warning\nfrom django.core.checks.urls import check_resolver\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.functional import cached_property\nfrom django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\nfrom django.utils.regex_helper import _lazy_re_compile, normalize\nfrom django.utils.translation import get_language\n\nfrom .converters import get_converter\nfrom .exceptions import NoReverseMatch, Resolver404\nfrom .utils import get_callable\n\n\nclass ResolverMatch:\n    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n        self.func = func\n        self.args = args\n        self.kwargs = kwargs\n        self.url_name = url_name\n        self.route = route\n        self.tried = tried\n\n        # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n        # in an empty value.\n        self.app_names = [x for x in app_names if x] if app_names else []\n        self.app_name = ':'.join(self.app_names)\n        self.namespaces = [x for x in namespaces if x] if namespaces else []\n        self.namespace = ':'.join(self.namespaces)\n\n        if not hasattr(func, '__name__'):\n            # A class-based view\n            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n        else:\n            # A function-based view\n            self._func_path = func.__module__ + '.' + func.__name__\n\n        view_path = url_name or self._func_path\n        self.view_name = ':'.join(self.namespaces + [view_path])\n\n    def __getitem__(self, index):\n        return (self.func, self.args, self.kwargs)[index]\n\n    def __repr__(self):\n        if isinstance(self.func, functools.partial):\n            func = repr(self.func)\n        else:\n            func = self._func_path\n        return (\n            'ResolverMatch(func=%s, args=%r, kwargs=%r, url_name=%r, '\n            'app_names=%r, namespaces=%r, route=%r)' % (\n                func, self.args, self.kwargs, self.url_name,\n                self.app_names, self.namespaces, self.route,\n            )\n        )\n\n    def __reduce_ex__(self, protocol):\n        raise PicklingError(f'Cannot pickle {self.__class__.__qualname__}.')\n\n\ndef get_resolver(urlconf=None):\n    if urlconf is None:\n        urlconf = settings.ROOT_URLCONF\n    return _get_cached_resolver(urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef _get_cached_resolver(urlconf=None):\n    return URLResolver(RegexPattern(r'^/'), urlconf)\n\n\n@functools.lru_cache(maxsize=None)\ndef get_ns_resolver(ns_pattern, resolver, converters):\n    # Build a namespaced resolver for the given parent URLconf pattern.\n    # This makes it possible to have captured parameters in the parent\n    # URLconf pattern.\n    pattern = RegexPattern(ns_pattern)\n    pattern.converters = dict(converters)\n    ns_resolver = URLResolver(pattern, resolver.url_patterns)\n    return URLResolver(RegexPattern(r'^/'), [ns_resolver])\n\n\nclass LocaleRegexDescriptor:\n    def __init__(self, attr):\n        self.attr = attr\n\n    def __get__(self, instance, cls=None):\n        \"\"\"\n        Return a compiled regular expression based on the active language.\n        \"\"\"\n        if instance is None:\n            return self\n        # As a performance optimization, if the given regex string is a regular\n        # string (not a lazily-translated string proxy), compile it once and\n        # avoid per-language compilation.\n        pattern = getattr(instance, self.attr)\n        if isinstance(pattern, str):\n            instance.__dict__['regex'] = instance._compile(pattern)\n            return instance.__dict__['regex']\n        language_code = get_language()\n        if language_code not in instance._regex_dict:\n            instance._regex_dict[language_code] = instance._compile(str(pattern))\n        return instance._regex_dict[language_code]\n\n\nclass CheckURLMixin:\n    def describe(self):\n        \"\"\"\n        Format the URL pattern for display in warning messages.\n        \"\"\"\n        description = \"'{}'\".format(self)\n        if self.name:\n            description += \" [name='{}']\".format(self.name)\n        return description\n\n    def _check_pattern_startswith_slash(self):\n        \"\"\"\n        Check that the pattern does not begin with a forward slash.\n        \"\"\"\n        regex_pattern = self.regex.pattern\n        if not settings.APPEND_SLASH:\n            # Skip check as it can be useful to start a URL pattern with a slash\n            # when APPEND_SLASH=False.\n            return []\n        if regex_pattern.startswith(('/', '^/', '^\\\\/')) and not regex_pattern.endswith('/'):\n            warning = Warning(\n                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                \"slash as it is unnecessary. If this pattern is targeted in an \"\n                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n                    self.describe()\n                ),\n                id=\"urls.W002\",\n            )\n            return [warning]\n        else:\n            return []\n\n\nclass RegexPattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor('_regex')\n\n    def __init__(self, regex, name=None, is_endpoint=False):\n        self._regex = regex\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = {}\n\n    def match(self, path):\n        match = (\n            self.regex.fullmatch(path)\n            if self._is_endpoint and self.regex.pattern.endswith('$')\n            else self.regex.search(path)\n        )\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end():], args, kwargs\n        return None\n\n    def check(self):\n        warnings = []\n        warnings.extend(self._check_pattern_startswith_slash())\n        if not self._is_endpoint:\n            warnings.extend(self._check_include_trailing_dollar())\n        return warnings\n\n    def _check_include_trailing_dollar(self):\n        regex_pattern = self.regex.pattern\n        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):\n            return [Warning(\n                \"Your URL pattern {} uses include with a route ending with a '$'. \"\n                \"Remove the dollar from the route to avoid problems including \"\n                \"URLs.\".format(self.describe()),\n                id='urls.W001',\n            )]\n        else:\n            return []\n\n    def _compile(self, regex):\n        \"\"\"Compile and return the given regular expression.\"\"\"\n        try:\n            return re.compile(regex)\n        except re.error as e:\n            raise ImproperlyConfigured(\n                '\"%s\" is not a valid regular expression: %s' % (regex, e)\n            ) from e\n\n    def __str__(self):\n        return str(self._regex)\n\n\n_PATH_PARAMETER_COMPONENT_RE = _lazy_re_compile(\n    r'<(?:(?P<converter>[^>:]+):)?(?P<parameter>[^>]+)>'\n)\n\n\ndef _route_to_regex(route, is_endpoint=False):\n    \"\"\"\n    Convert a path pattern into a regular expression. Return the regular\n    expression and a dictionary mapping the capture names to the converters.\n    For example, 'foo/<int:pk>' returns '^foo\\\\/(?P<pk>[0-9]+)'\n    and {'pk': <django.urls.converters.IntConverter>}.\n    \"\"\"\n    original_route = route\n    parts = ['^']\n    converters = {}\n    while True:\n        match = _PATH_PARAMETER_COMPONENT_RE.search(route)\n        if not match:\n            parts.append(re.escape(route))\n            break\n        elif not set(match.group()).isdisjoint(string.whitespace):\n            raise ImproperlyConfigured(\n                \"URL route '%s' cannot contain whitespace in angle brackets \"\n                \"<\u2026>.\" % original_route\n            )\n        parts.append(re.escape(route[:match.start()]))\n        route = route[match.end():]\n        parameter = match['parameter']\n        if not parameter.isidentifier():\n            raise ImproperlyConfigured(\n                \"URL route '%s' uses parameter name %r which isn't a valid \"\n                \"Python identifier.\" % (original_route, parameter)\n            )\n        raw_converter = match['converter']\n        if raw_converter is None:\n            # If a converter isn't specified, the default is `str`.\n            raw_converter = 'str'\n        try:\n            converter = get_converter(raw_converter)\n        except KeyError as e:\n            raise ImproperlyConfigured(\n                'URL route %r uses invalid converter %r.'\n                % (original_route, raw_converter)\n            ) from e\n        converters[parameter] = converter\n        parts.append('(?P<' + parameter + '>' + converter.regex + ')')\n    if is_endpoint:\n        parts.append(r'\\Z')\n    return ''.join(parts), converters\n\n\nclass RoutePattern(CheckURLMixin):\n    regex = LocaleRegexDescriptor('_route')\n\n    def __init__(self, route, name=None, is_endpoint=False):\n        self._route = route\n        self._regex_dict = {}\n        self._is_endpoint = is_endpoint\n        self.name = name\n        self.converters = _route_to_regex(str(route), is_endpoint)[1]\n\n    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # RoutePattern doesn't allow non-named groups so args are ignored.\n            kwargs = match.groupdict()\n            for key, value in kwargs.items():\n                converter = self.converters[key]\n                try:\n                    kwargs[key] = converter.to_python(value)\n                except ValueError:\n                    return None\n            return path[match.end():], (), kwargs\n        return None\n\n    def check(self):\n        warnings = self._check_pattern_startswith_slash()\n        route = self._route\n        if '(?P<' in route or route.startswith('^') or route.endswith('$'):\n            warnings.append(Warning(\n                \"Your URL pattern {} has a route that contains '(?P<', begins \"\n                \"with a '^', or ends with a '$'. This was likely an oversight \"\n                \"when migrating to django.urls.path().\".format(self.describe()),\n                id='2_0.W001',\n            ))\n        return warnings\n\n    def _compile(self, route):\n        return re.compile(_route_to_regex(route, self._is_endpoint)[0])\n\n    def __str__(self):\n        return str(self._route)\n\n\nclass LocalePrefixPattern:\n    def __init__(self, prefix_default_language=True):\n        self.prefix_default_language = prefix_default_language\n        self.converters = {}\n\n    @property\n    def regex(self):\n        # This is only used by reverse() and cached in _reverse_dict.\n        return re.compile(self.language_prefix)\n\n    @property\n    def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n            return ''\n        else:\n            return '%s/' % language_code\n\n    def match(self, path):\n        language_prefix = self.language_prefix\n        if path.startswith(language_prefix):\n            return path[len(language_prefix):], (), {}\n        return None\n\n    def check(self):\n        return []\n\n    def describe(self):\n        return \"'{}'\".format(self)\n\n    def __str__(self):\n        return self.language_prefix\n\n\nclass URLPattern:\n    def __init__(self, pattern, callback, default_args=None, name=None):\n        self.pattern = pattern\n        self.callback = callback  # the view\n        self.default_args = default_args or {}\n        self.name = name\n\n    def __repr__(self):\n        return '<%s %s>' % (self.__class__.__name__, self.pattern.describe())\n\n    def check(self):\n        warnings = self._check_pattern_name()\n        warnings.extend(self.pattern.check())\n        warnings.extend(self._check_callback())\n        return warnings\n\n    def _check_pattern_name(self):\n        \"\"\"\n        Check that the pattern name does not contain a colon.\n        \"\"\"\n        if self.pattern.name is not None and \":\" in self.pattern.name:\n            warning = Warning(\n                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"\n                \"avoid ambiguous namespace references.\".format(self.pattern.describe()),\n                id=\"urls.W003\",\n            )\n            return [warning]\n        else:\n            return []\n\n    def _check_callback(self):\n        from django.views import View\n\n        view = self.callback\n        if inspect.isclass(view) and issubclass(view, View):\n            return [Error(\n                'Your URL pattern %s has an invalid view, pass %s.as_view() '\n                'instead of %s.' % (\n                    self.pattern.describe(),\n                    view.__name__,\n                    view.__name__,\n                ),\n                id='urls.E009',\n            )]\n        return []\n\n    def resolve(self, path):\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            # Pass any extra_kwargs as **kwargs.\n            kwargs.update(self.default_args)\n            return ResolverMatch(self.callback, args, kwargs, self.pattern.name, route=str(self.pattern))\n\n    @cached_property\n    def lookup_str(self):\n        \"\"\"\n        A string that identifies the view (e.g. 'path.to.view_function' or\n        'path.to.ClassBasedView').\n        \"\"\"\n        callback = self.callback\n        if isinstance(callback, functools.partial):\n            callback = callback.func\n        if hasattr(callback, 'view_class'):\n            callback = callback.view_class\n        elif not hasattr(callback, '__name__'):\n            return callback.__module__ + \".\" + callback.__class__.__name__\n        return callback.__module__ + \".\" + callback.__qualname__\n\n\nclass URLResolver:\n    def __init__(self, pattern, urlconf_name, default_kwargs=None, app_name=None, namespace=None):\n        self.pattern = pattern\n        # urlconf_name is the dotted Python path to the module defining\n        # urlpatterns. It may also be an object with an urlpatterns attribute\n        # or urlpatterns itself.\n        self.urlconf_name = urlconf_name\n        self.callback = None\n        self.default_kwargs = default_kwargs or {}\n        self.namespace = namespace\n        self.app_name = app_name\n        self._reverse_dict = {}\n        self._namespace_dict = {}\n        self._app_dict = {}\n        # set of dotted paths to all functions and classes that are used in\n        # urlpatterns\n        self._callback_strs = set()\n        self._populated = False\n        self._local = Local()\n\n    def __repr__(self):\n        if isinstance(self.urlconf_name, list) and self.urlconf_name:\n            # Don't bother to output the whole list, it can be huge\n            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__\n        else:\n            urlconf_repr = repr(self.urlconf_name)\n        return '<%s %s (%s:%s) %s>' % (\n            self.__class__.__name__, urlconf_repr, self.app_name,\n            self.namespace, self.pattern.describe(),\n        )\n\n    def check(self):\n        messages = []\n        for pattern in self.url_patterns:\n            messages.extend(check_resolver(pattern))\n        messages.extend(self._check_custom_error_handlers())\n        return messages or self.pattern.check()\n\n    def _check_custom_error_handlers(self):\n        messages = []\n        # All handlers take (request, exception) arguments except handler500\n        # which takes (request).\n        for status_code, num_parameters in [(400, 2), (403, 2), (404, 2), (500, 1)]:\n            try:\n                handler = self.resolve_error_handler(status_code)\n            except (ImportError, ViewDoesNotExist) as e:\n                path = getattr(self.urlconf_module, 'handler%s' % status_code)\n                msg = (\n                    \"The custom handler{status_code} view '{path}' could not be imported.\"\n                ).format(status_code=status_code, path=path)\n                messages.append(Error(msg, hint=str(e), id='urls.E008'))\n                continue\n            signature = inspect.signature(handler)\n            args = [None] * num_parameters\n            try:\n                signature.bind(*args)\n            except TypeError:\n                msg = (\n                    \"The custom handler{status_code} view '{path}' does not \"\n                    \"take the correct number of arguments ({args}).\"\n                ).format(\n                    status_code=status_code,\n                    path=handler.__module__ + '.' + handler.__qualname__,\n                    args='request, exception' if num_parameters == 2 else 'request',\n                )\n                messages.append(Error(msg, id='urls.E007'))\n        return messages\n\n    def _populate(self):\n        # Short-circuit if called recursively in this thread to prevent\n        # infinite recursion. Concurrent threads may call this at the same\n        # time and will need to continue, so set 'populating' on a\n        # thread-local variable.\n        if getattr(self._local, 'populating', False):\n            return\n        try:\n            self._local.populating = True\n            lookups = MultiValueDict()\n            namespaces = {}\n            apps = {}\n            language_code = get_language()\n            for url_pattern in reversed(self.url_patterns):\n                p_pattern = url_pattern.pattern.regex.pattern\n                if p_pattern.startswith('^'):\n                    p_pattern = p_pattern[1:]\n                if isinstance(url_pattern, URLPattern):\n                    self._callback_strs.add(url_pattern.lookup_str)\n                    bits = normalize(url_pattern.pattern.regex.pattern)\n                    lookups.appendlist(\n                        url_pattern.callback,\n                        (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n                    )\n                    if url_pattern.name is not None:\n                        lookups.appendlist(\n                            url_pattern.name,\n                            (bits, p_pattern, url_pattern.default_args, url_pattern.pattern.converters)\n                        )\n                else:  # url_pattern is a URLResolver.\n                    url_pattern._populate()\n                    if url_pattern.app_name:\n                        apps.setdefault(url_pattern.app_name, []).append(url_pattern.namespace)\n                        namespaces[url_pattern.namespace] = (p_pattern, url_pattern)\n                    else:\n                        for name in url_pattern.reverse_dict:\n                            for matches, pat, defaults, converters in url_pattern.reverse_dict.getlist(name):\n                                new_matches = normalize(p_pattern + pat)\n                                lookups.appendlist(\n                                    name,\n                                    (\n                                        new_matches,\n                                        p_pattern + pat,\n                                        {**defaults, **url_pattern.default_kwargs},\n                                        {**self.pattern.converters, **url_pattern.pattern.converters, **converters}\n                                    )\n                                )\n                        for namespace, (prefix, sub_pattern) in url_pattern.namespace_dict.items():\n                            current_converters = url_pattern.pattern.converters\n                            sub_pattern.pattern.converters.update(current_converters)\n                            namespaces[namespace] = (p_pattern + prefix, sub_pattern)\n                        for app_name, namespace_list in url_pattern.app_dict.items():\n                            apps.setdefault(app_name, []).extend(namespace_list)\n                    self._callback_strs.update(url_pattern._callback_strs)\n            self._namespace_dict[language_code] = namespaces\n            self._app_dict[language_code] = apps\n            self._reverse_dict[language_code] = lookups\n            self._populated = True\n        finally:\n            self._local.populating = False\n\n    @property\n    def reverse_dict(self):\n        language_code = get_language()\n        if language_code not in self._reverse_dict:\n            self._populate()\n        return self._reverse_dict[language_code]\n\n    @property\n    def namespace_dict(self):\n        language_code = get_language()\n        if language_code not in self._namespace_dict:\n            self._populate()\n        return self._namespace_dict[language_code]\n\n    @property\n    def app_dict(self):\n        language_code = get_language()\n        if language_code not in self._app_dict:\n            self._populate()\n        return self._app_dict[language_code]\n\n    @staticmethod\n    def _extend_tried(tried, pattern, sub_tried=None):\n        if sub_tried is None:\n            tried.append([pattern])\n        else:\n            tried.extend([pattern, *t] for t in sub_tried)\n\n    @staticmethod\n    def _join_route(route1, route2):\n        \"\"\"Join two routes, without the starting ^ in the second route.\"\"\"\n        if not route1:\n            return route2\n        if route2.startswith('^'):\n            route2 = route2[1:]\n        return route1 + route2\n\n    def _is_callback(self, name):\n        if not self._populated:\n            self._populate()\n        return name in self._callback_strs\n\n    def resolve(self, path):\n        path = str(path)  # path may be a reverse_lazy object\n        tried = []\n        match = self.pattern.match(path)\n        if match:\n            new_path, args, kwargs = match\n            for pattern in self.url_patterns:\n                try:\n                    sub_match = pattern.resolve(new_path)\n                except Resolver404 as e:\n                    self._extend_tried(tried, pattern, e.args[0].get('tried'))\n                else:\n                    if sub_match:\n                        # Merge captured arguments in match with submatch\n                        sub_match_dict = {**kwargs, **self.default_kwargs}\n                        # Update the sub_match_dict with the kwargs from the sub_match.\n                        sub_match_dict.update(sub_match.kwargs)\n                        # If there are *any* named groups, ignore all non-named groups.\n                        # Otherwise, pass all non-named arguments as positional arguments.\n                        sub_match_args = sub_match.args\n                        if not sub_match_dict:\n                            sub_match_args = args + sub_match.args\n                        current_route = '' if isinstance(pattern, URLPattern) else str(pattern.pattern)\n                        self._extend_tried(tried, pattern, sub_match.tried)\n                        return ResolverMatch(\n                            sub_match.func,\n                            sub_match_args,\n                            sub_match_dict,\n                            sub_match.url_name,\n                            [self.app_name] + sub_match.app_names,\n                            [self.namespace] + sub_match.namespaces,\n                            self._join_route(current_route, sub_match.route),\n                            tried,\n                        )\n                    tried.append([pattern])\n            raise Resolver404({'tried': tried, 'path': new_path})\n        raise Resolver404({'path': path})\n\n    @cached_property\n    def urlconf_module(self):\n        if isinstance(self.urlconf_name, str):\n            return import_module(self.urlconf_name)\n        else:\n            return self.urlconf_name\n\n    @cached_property\n    def url_patterns(self):\n        # urlconf_module might be a valid set of patterns, so we default to it\n        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\n        try:\n            iter(patterns)\n        except TypeError as e:\n            msg = (\n                \"The included URLconf '{name}' does not appear to have \"\n                \"any patterns in it. If you see the 'urlpatterns' variable \"\n                \"with valid patterns in the file then the issue is probably \"\n                \"caused by a circular import.\"\n            )\n            raise ImproperlyConfigured(msg.format(name=self.urlconf_name)) from e\n        return patterns\n\n    def resolve_error_handler(self, view_type):\n        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)\n        if not callback:\n            # No handler specified in file; use lazy import, since\n            # django.conf.urls imports this file.\n            from django.conf import urls\n            callback = getattr(urls, 'handler%s' % view_type)\n        return get_callable(callback)\n\n    def reverse(self, lookup_view, *args, **kwargs):\n        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)\n\n    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):\n        if args and kwargs:\n            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")\n\n        if not self._populated:\n            self._populate()\n\n        possibilities = self.reverse_dict.getlist(lookup_view)\n\n        for possibility, pattern, defaults, converters in possibilities:\n            for result, params in possibility:\n                if args:\n                    if len(args) != len(params):\n                        continue\n                    candidate_subs = dict(zip(params, args))\n                else:\n                    if set(kwargs).symmetric_difference(params).difference(defaults):\n                        continue\n                    if any(kwargs.get(k, v) != v for k, v in defaults.items()):\n                        continue\n                    candidate_subs = kwargs\n                # Convert the candidate subs to text using Converter.to_url().\n                text_candidate_subs = {}\n                match = True\n                for k, v in candidate_subs.items():\n                    if k in converters:\n                        try:\n                            text_candidate_subs[k] = converters[k].to_url(v)\n                        except ValueError:\n                            match = False\n                            break\n                    else:\n                        text_candidate_subs[k] = str(v)\n                if not match:\n                    continue\n                # WSGI provides decoded URLs, without %xx escapes, and the URL\n                # resolver operates on such URLs. First substitute arguments\n                # without quoting to build a decoded URL and look for a match.\n                # Then, if we have a match, redo the substitution with quoted\n                # arguments in order to return a properly encoded URL.\n                candidate_pat = _prefix.replace('%', '%%') + result\n                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % text_candidate_subs):\n                    # safe characters from `pchar` definition of RFC 3986\n                    url = quote(candidate_pat % text_candidate_subs, safe=RFC3986_SUBDELIMS + '/~:@')\n                    # Don't allow construction of scheme relative urls.\n                    return escape_leading_slashes(url)\n        # lookup_view can be URL name or callable, but callables are not\n        # friendly in error messages.\n        m = getattr(lookup_view, '__module__', None)\n        n = getattr(lookup_view, '__name__', None)\n        if m is not None and n is not None:\n            lookup_view_s = \"%s.%s\" % (m, n)\n        else:\n            lookup_view_s = lookup_view\n\n        patterns = [pattern for (_, pattern, _, _) in possibilities]\n        if patterns:\n            if args:\n                arg_msg = \"arguments '%s'\" % (args,)\n            elif kwargs:\n                arg_msg = \"keyword arguments '%s'\" % kwargs\n            else:\n                arg_msg = \"no arguments\"\n            msg = (\n                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %\n                (lookup_view_s, arg_msg, len(patterns), patterns)\n            )\n        else:\n            msg = (\n                \"Reverse for '%(view)s' not found. '%(view)s' is not \"\n                \"a valid view function or pattern name.\" % {'view': lookup_view_s}\n            )\n        raise NoReverseMatch(msg)\n"
  },
  {
    "patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex f9abec602c..731ccf2d46 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -66,7 +66,7 @@ class URLValidator(RegexValidator):\n     ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n \n     # IP patterns\n-    ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'\n+    ipv4_re = r'(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)(?:\\.(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)){3}'\n     ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n \n     # Host patterns\n@@ -276,6 +276,19 @@ def validate_ipv4_address(value):\n         ipaddress.IPv4Address(value)\n     except ValueError:\n         raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n+    else:\n+        # Leading zeros are forbidden to avoid ambiguity with the octal\n+        # notation. This restriction is included in Python 3.9.5+.\n+        # TODO: Remove when dropping support for PY39.\n+        if any(\n+            octet != '0' and octet[0] == '0'\n+            for octet in value.split('.')\n+        ):\n+            raise ValidationError(\n+                _('Enter a valid IPv4 address.'),\n+                code='invalid',\n+                params={'value': value},\n+            )\n \n \n def validate_ipv6_address(value):\n",
    "commit_message": "Fixed CVE-2021-33571 -- Prevented leading zeros in IPv4 addresses.\n\nvalidate_ipv4_address() was affected only on Python < 3.9.5, see [1].\nURLValidator() uses a regular expressions and it was affected on all\nPython versions.\n\n[1] https://bugs.python.org/issue36384\n\n",
    "code_before": "import ipaddress\nimport re\nimport warnings\nfrom pathlib import Path\nfrom urllib.parse import urlsplit, urlunsplit\n\nfrom django.core.exceptions import ValidationError\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.deprecation import RemovedInDjango41Warning\nfrom django.utils.encoding import punycode\nfrom django.utils.ipv6 import is_valid_ipv6_address\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.translation import gettext_lazy as _, ngettext_lazy\n\n# These values, if given to validate(), will trigger the self.required check.\nEMPTY_VALUES = (None, '', [], (), {})\n\n\n@deconstructible\nclass RegexValidator:\n    regex = ''\n    message = _('Enter a valid value.')\n    code = 'invalid'\n    inverse_match = False\n    flags = 0\n\n    def __init__(self, regex=None, message=None, code=None, inverse_match=None, flags=None):\n        if regex is not None:\n            self.regex = regex\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if inverse_match is not None:\n            self.inverse_match = inverse_match\n        if flags is not None:\n            self.flags = flags\n        if self.flags and not isinstance(self.regex, str):\n            raise TypeError(\"If the flags are set, regex must be a regular expression string.\")\n\n        self.regex = _lazy_re_compile(self.regex, self.flags)\n\n    def __call__(self, value):\n        \"\"\"\n        Validate that the input contains (or does *not* contain, if\n        inverse_match is True) a match for the regular expression.\n        \"\"\"\n        regex_matches = self.regex.search(str(value))\n        invalid_input = regex_matches if self.inverse_match else not regex_matches\n        if invalid_input:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, RegexValidator) and\n            self.regex.pattern == other.regex.pattern and\n            self.regex.flags == other.regex.flags and\n            (self.message == other.message) and\n            (self.code == other.code) and\n            (self.inverse_match == other.inverse_match)\n        )\n\n\n@deconstructible\nclass URLValidator(RegexValidator):\n    ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n\n    # IP patterns\n    ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'\n    ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n\n    # Host patterns\n    hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n    # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1\n    domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n    tld_re = (\n        r'\\.'                                # dot\n        r'(?!-)'                             # can't start with a dash\n        r'(?:[a-z' + ul + '-]{2,63}'         # domain label\n        r'|xn--[a-z0-9]{1,59})'              # or punycode label\n        r'(?<!-)'                            # can't end with a dash\n        r'\\.?'                               # may have a trailing dot\n    )\n    host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n\n    regex = _lazy_re_compile(\n        r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n        r'(?::\\d{2,5})?'  # port\n        r'(?:[/?#][^\\s]*)?'  # resource path\n        r'\\Z', re.IGNORECASE)\n    message = _('Enter a valid URL.')\n    schemes = ['http', 'https', 'ftp', 'ftps']\n    unsafe_chars = frozenset('\\t\\r\\n')\n\n    def __init__(self, schemes=None, **kwargs):\n        super().__init__(**kwargs)\n        if schemes is not None:\n            self.schemes = schemes\n\n    def __call__(self, value):\n        if not isinstance(value, str):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        if self.unsafe_chars.intersection(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        # Check if the scheme is valid.\n        scheme = value.split('://')[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # Then check full URL\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                try:\n                    scheme, netloc, path, query, fragment = urlsplit(value)\n                except ValueError:  # for example, \"Invalid IPv6 URL\"\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r'^\\[(.+)\\](?::\\d{2,5})?$', urlsplit(value).netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if len(urlsplit(value).hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n\ninteger_validator = RegexValidator(\n    _lazy_re_compile(r'^-?\\d+\\Z'),\n    message=_('Enter a valid integer.'),\n    code='invalid',\n)\n\n\ndef validate_integer(value):\n    return integer_validator(value)\n\n\n@deconstructible\nclass EmailValidator:\n    message = _('Enter a valid email address.')\n    code = 'invalid'\n    user_regex = _lazy_re_compile(\n        r\"(^[-!#$%&'*+/=?^_`{}|~0-9A-Z]+(\\.[-!#$%&'*+/=?^_`{}|~0-9A-Z]+)*\\Z\"  # dot-atom\n        r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',  # quoted-string\n        re.IGNORECASE)\n    domain_regex = _lazy_re_compile(\n        # max length for domain name labels is 63 characters per RFC 1034\n        r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z',\n        re.IGNORECASE)\n    literal_regex = _lazy_re_compile(\n        # literal form, ipv4 or ipv6 address (SMTP 4.1.3)\n        r'\\[([A-f0-9:.]+)\\]\\Z',\n        re.IGNORECASE)\n    domain_allowlist = ['localhost']\n\n    @property\n    def domain_whitelist(self):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        return self.domain_allowlist\n\n    @domain_whitelist.setter\n    def domain_whitelist(self, allowlist):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        self.domain_allowlist = allowlist\n\n    def __init__(self, message=None, code=None, allowlist=None, *, whitelist=None):\n        if whitelist is not None:\n            allowlist = whitelist\n            warnings.warn(\n                'The whitelist argument is deprecated in favor of allowlist.',\n                RemovedInDjango41Warning,\n                stacklevel=2,\n            )\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if allowlist is not None:\n            self.domain_allowlist = allowlist\n\n    def __call__(self, value):\n        if not value or '@' not in value:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        user_part, domain_part = value.rsplit('@', 1)\n\n        if not self.user_regex.match(user_part):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        if (domain_part not in self.domain_allowlist and\n                not self.validate_domain_part(domain_part)):\n            # Try for possible IDN domain-part\n            try:\n                domain_part = punycode(domain_part)\n            except UnicodeError:\n                pass\n            else:\n                if self.validate_domain_part(domain_part):\n                    return\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def validate_domain_part(self, domain_part):\n        if self.domain_regex.match(domain_part):\n            return True\n\n        literal_match = self.literal_regex.match(domain_part)\n        if literal_match:\n            ip_address = literal_match[1]\n            try:\n                validate_ipv46_address(ip_address)\n                return True\n            except ValidationError:\n                pass\n        return False\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, EmailValidator) and\n            (self.domain_allowlist == other.domain_allowlist) and\n            (self.message == other.message) and\n            (self.code == other.code)\n        )\n\n\nvalidate_email = EmailValidator()\n\nslug_re = _lazy_re_compile(r'^[-a-zA-Z0-9_]+\\Z')\nvalidate_slug = RegexValidator(\n    slug_re,\n    # Translators: \"letters\" means latin letters: a-z and A-Z.\n    _('Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.'),\n    'invalid'\n)\n\nslug_unicode_re = _lazy_re_compile(r'^[-\\w]+\\Z')\nvalidate_unicode_slug = RegexValidator(\n    slug_unicode_re,\n    _('Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.'),\n    'invalid'\n)\n\n\ndef validate_ipv4_address(value):\n    try:\n        ipaddress.IPv4Address(value)\n    except ValueError:\n        raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv6_address(value):\n    if not is_valid_ipv6_address(value):\n        raise ValidationError(_('Enter a valid IPv6 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv46_address(value):\n    try:\n        validate_ipv4_address(value)\n    except ValidationError:\n        try:\n            validate_ipv6_address(value)\n        except ValidationError:\n            raise ValidationError(_('Enter a valid IPv4 or IPv6 address.'), code='invalid', params={'value': value})\n\n\nip_address_validator_map = {\n    'both': ([validate_ipv46_address], _('Enter a valid IPv4 or IPv6 address.')),\n    'ipv4': ([validate_ipv4_address], _('Enter a valid IPv4 address.')),\n    'ipv6': ([validate_ipv6_address], _('Enter a valid IPv6 address.')),\n}\n\n\ndef ip_address_validators(protocol, unpack_ipv4):\n    \"\"\"\n    Depending on the given parameters, return the appropriate validators for\n    the GenericIPAddressField.\n    \"\"\"\n    if protocol != 'both' and unpack_ipv4:\n        raise ValueError(\n            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\")\n    try:\n        return ip_address_validator_map[protocol.lower()]\n    except KeyError:\n        raise ValueError(\"The protocol '%s' is unknown. Supported: %s\"\n                         % (protocol, list(ip_address_validator_map)))\n\n\ndef int_list_validator(sep=',', message=None, code='invalid', allow_negative=False):\n    regexp = _lazy_re_compile(r'^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z' % {\n        'neg': '(-)?' if allow_negative else '',\n        'sep': re.escape(sep),\n    })\n    return RegexValidator(regexp, message=message, code=code)\n\n\nvalidate_comma_separated_integer_list = int_list_validator(\n    message=_('Enter only digits separated by commas.'),\n)\n\n\n@deconstructible\nclass BaseValidator:\n    message = _('Ensure this value is %(limit_value)s (it is %(show_value)s).')\n    code = 'limit_value'\n\n    def __init__(self, limit_value, message=None):\n        self.limit_value = limit_value\n        if message:\n            self.message = message\n\n    def __call__(self, value):\n        cleaned = self.clean(value)\n        limit_value = self.limit_value() if callable(self.limit_value) else self.limit_value\n        params = {'limit_value': limit_value, 'show_value': cleaned, 'value': value}\n        if self.compare(cleaned, limit_value):\n            raise ValidationError(self.message, code=self.code, params=params)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return (\n            self.limit_value == other.limit_value and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n    def compare(self, a, b):\n        return a is not b\n\n    def clean(self, x):\n        return x\n\n\n@deconstructible\nclass MaxValueValidator(BaseValidator):\n    message = _('Ensure this value is less than or equal to %(limit_value)s.')\n    code = 'max_value'\n\n    def compare(self, a, b):\n        return a > b\n\n\n@deconstructible\nclass MinValueValidator(BaseValidator):\n    message = _('Ensure this value is greater than or equal to %(limit_value)s.')\n    code = 'min_value'\n\n    def compare(self, a, b):\n        return a < b\n\n\n@deconstructible\nclass MinLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at least %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'min_length'\n\n    def compare(self, a, b):\n        return a < b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass MaxLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at most %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'max_length'\n\n    def compare(self, a, b):\n        return a > b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass DecimalValidator:\n    \"\"\"\n    Validate that the input does not exceed the maximum number of digits\n    expected, otherwise raise ValidationError.\n    \"\"\"\n    messages = {\n        'invalid': _('Enter a number.'),\n        'max_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit in total.',\n            'Ensure that there are no more than %(max)s digits in total.',\n            'max'\n        ),\n        'max_decimal_places': ngettext_lazy(\n            'Ensure that there are no more than %(max)s decimal place.',\n            'Ensure that there are no more than %(max)s decimal places.',\n            'max'\n        ),\n        'max_whole_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit before the decimal point.',\n            'Ensure that there are no more than %(max)s digits before the decimal point.',\n            'max'\n        ),\n    }\n\n    def __init__(self, max_digits, decimal_places):\n        self.max_digits = max_digits\n        self.decimal_places = decimal_places\n\n    def __call__(self, value):\n        digit_tuple, exponent = value.as_tuple()[1:]\n        if exponent in {'F', 'n', 'N'}:\n            raise ValidationError(self.messages['invalid'], code='invalid', params={'value': value})\n        if exponent >= 0:\n            # A positive exponent adds that many trailing zeros.\n            digits = len(digit_tuple) + exponent\n            decimals = 0\n        else:\n            # If the absolute value of the negative exponent is larger than the\n            # number of digits, then it's the same as the number of digits,\n            # because it'll consume all of the digits in digit_tuple and then\n            # add abs(exponent) - len(digit_tuple) leading zeros after the\n            # decimal point.\n            if abs(exponent) > len(digit_tuple):\n                digits = decimals = abs(exponent)\n            else:\n                digits = len(digit_tuple)\n                decimals = abs(exponent)\n        whole_digits = digits - decimals\n\n        if self.max_digits is not None and digits > self.max_digits:\n            raise ValidationError(\n                self.messages['max_digits'],\n                code='max_digits',\n                params={'max': self.max_digits, 'value': value},\n            )\n        if self.decimal_places is not None and decimals > self.decimal_places:\n            raise ValidationError(\n                self.messages['max_decimal_places'],\n                code='max_decimal_places',\n                params={'max': self.decimal_places, 'value': value},\n            )\n        if (self.max_digits is not None and self.decimal_places is not None and\n                whole_digits > (self.max_digits - self.decimal_places)):\n            raise ValidationError(\n                self.messages['max_whole_digits'],\n                code='max_whole_digits',\n                params={'max': (self.max_digits - self.decimal_places), 'value': value},\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.max_digits == other.max_digits and\n            self.decimal_places == other.decimal_places\n        )\n\n\n@deconstructible\nclass FileExtensionValidator:\n    message = _(\n        'File extension \u201c%(extension)s\u201d is not allowed. '\n        'Allowed extensions are: %(allowed_extensions)s.'\n    )\n    code = 'invalid_extension'\n\n    def __init__(self, allowed_extensions=None, message=None, code=None):\n        if allowed_extensions is not None:\n            allowed_extensions = [allowed_extension.lower() for allowed_extension in allowed_extensions]\n        self.allowed_extensions = allowed_extensions\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        extension = Path(value.name).suffix[1:].lower()\n        if self.allowed_extensions is not None and extension not in self.allowed_extensions:\n            raise ValidationError(\n                self.message,\n                code=self.code,\n                params={\n                    'extension': extension,\n                    'allowed_extensions': ', '.join(self.allowed_extensions),\n                    'value': value,\n                }\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.allowed_extensions == other.allowed_extensions and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n\ndef get_available_image_extensions():\n    try:\n        from PIL import Image\n    except ImportError:\n        return []\n    else:\n        Image.init()\n        return [ext.lower()[1:] for ext in Image.EXTENSION]\n\n\ndef validate_image_file_extension(value):\n    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(value)\n\n\n@deconstructible\nclass ProhibitNullCharactersValidator:\n    \"\"\"Validate that the string doesn't contain the null character.\"\"\"\n    message = _('Null characters are not allowed.')\n    code = 'null_characters_not_allowed'\n\n    def __init__(self, message=None, code=None):\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        if '\\x00' in str(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.message == other.message and\n            self.code == other.code\n        )\n",
    "code_after": "import ipaddress\nimport re\nimport warnings\nfrom pathlib import Path\nfrom urllib.parse import urlsplit, urlunsplit\n\nfrom django.core.exceptions import ValidationError\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.deprecation import RemovedInDjango41Warning\nfrom django.utils.encoding import punycode\nfrom django.utils.ipv6 import is_valid_ipv6_address\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.translation import gettext_lazy as _, ngettext_lazy\n\n# These values, if given to validate(), will trigger the self.required check.\nEMPTY_VALUES = (None, '', [], (), {})\n\n\n@deconstructible\nclass RegexValidator:\n    regex = ''\n    message = _('Enter a valid value.')\n    code = 'invalid'\n    inverse_match = False\n    flags = 0\n\n    def __init__(self, regex=None, message=None, code=None, inverse_match=None, flags=None):\n        if regex is not None:\n            self.regex = regex\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if inverse_match is not None:\n            self.inverse_match = inverse_match\n        if flags is not None:\n            self.flags = flags\n        if self.flags and not isinstance(self.regex, str):\n            raise TypeError(\"If the flags are set, regex must be a regular expression string.\")\n\n        self.regex = _lazy_re_compile(self.regex, self.flags)\n\n    def __call__(self, value):\n        \"\"\"\n        Validate that the input contains (or does *not* contain, if\n        inverse_match is True) a match for the regular expression.\n        \"\"\"\n        regex_matches = self.regex.search(str(value))\n        invalid_input = regex_matches if self.inverse_match else not regex_matches\n        if invalid_input:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, RegexValidator) and\n            self.regex.pattern == other.regex.pattern and\n            self.regex.flags == other.regex.flags and\n            (self.message == other.message) and\n            (self.code == other.code) and\n            (self.inverse_match == other.inverse_match)\n        )\n\n\n@deconstructible\nclass URLValidator(RegexValidator):\n    ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n\n    # IP patterns\n    ipv4_re = r'(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)(?:\\.(?:0|25[0-5]|2[0-4]\\d|1\\d?\\d?|[1-9]\\d?)){3}'\n    ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n\n    # Host patterns\n    hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n    # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1\n    domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n    tld_re = (\n        r'\\.'                                # dot\n        r'(?!-)'                             # can't start with a dash\n        r'(?:[a-z' + ul + '-]{2,63}'         # domain label\n        r'|xn--[a-z0-9]{1,59})'              # or punycode label\n        r'(?<!-)'                            # can't end with a dash\n        r'\\.?'                               # may have a trailing dot\n    )\n    host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n\n    regex = _lazy_re_compile(\n        r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n        r'(?::\\d{2,5})?'  # port\n        r'(?:[/?#][^\\s]*)?'  # resource path\n        r'\\Z', re.IGNORECASE)\n    message = _('Enter a valid URL.')\n    schemes = ['http', 'https', 'ftp', 'ftps']\n    unsafe_chars = frozenset('\\t\\r\\n')\n\n    def __init__(self, schemes=None, **kwargs):\n        super().__init__(**kwargs)\n        if schemes is not None:\n            self.schemes = schemes\n\n    def __call__(self, value):\n        if not isinstance(value, str):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        if self.unsafe_chars.intersection(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        # Check if the scheme is valid.\n        scheme = value.split('://')[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # Then check full URL\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                try:\n                    scheme, netloc, path, query, fragment = urlsplit(value)\n                except ValueError:  # for example, \"Invalid IPv6 URL\"\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r'^\\[(.+)\\](?::\\d{2,5})?$', urlsplit(value).netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if len(urlsplit(value).hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n\ninteger_validator = RegexValidator(\n    _lazy_re_compile(r'^-?\\d+\\Z'),\n    message=_('Enter a valid integer.'),\n    code='invalid',\n)\n\n\ndef validate_integer(value):\n    return integer_validator(value)\n\n\n@deconstructible\nclass EmailValidator:\n    message = _('Enter a valid email address.')\n    code = 'invalid'\n    user_regex = _lazy_re_compile(\n        r\"(^[-!#$%&'*+/=?^_`{}|~0-9A-Z]+(\\.[-!#$%&'*+/=?^_`{}|~0-9A-Z]+)*\\Z\"  # dot-atom\n        r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',  # quoted-string\n        re.IGNORECASE)\n    domain_regex = _lazy_re_compile(\n        # max length for domain name labels is 63 characters per RFC 1034\n        r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z',\n        re.IGNORECASE)\n    literal_regex = _lazy_re_compile(\n        # literal form, ipv4 or ipv6 address (SMTP 4.1.3)\n        r'\\[([A-f0-9:.]+)\\]\\Z',\n        re.IGNORECASE)\n    domain_allowlist = ['localhost']\n\n    @property\n    def domain_whitelist(self):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        return self.domain_allowlist\n\n    @domain_whitelist.setter\n    def domain_whitelist(self, allowlist):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        self.domain_allowlist = allowlist\n\n    def __init__(self, message=None, code=None, allowlist=None, *, whitelist=None):\n        if whitelist is not None:\n            allowlist = whitelist\n            warnings.warn(\n                'The whitelist argument is deprecated in favor of allowlist.',\n                RemovedInDjango41Warning,\n                stacklevel=2,\n            )\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if allowlist is not None:\n            self.domain_allowlist = allowlist\n\n    def __call__(self, value):\n        if not value or '@' not in value:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        user_part, domain_part = value.rsplit('@', 1)\n\n        if not self.user_regex.match(user_part):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        if (domain_part not in self.domain_allowlist and\n                not self.validate_domain_part(domain_part)):\n            # Try for possible IDN domain-part\n            try:\n                domain_part = punycode(domain_part)\n            except UnicodeError:\n                pass\n            else:\n                if self.validate_domain_part(domain_part):\n                    return\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def validate_domain_part(self, domain_part):\n        if self.domain_regex.match(domain_part):\n            return True\n\n        literal_match = self.literal_regex.match(domain_part)\n        if literal_match:\n            ip_address = literal_match[1]\n            try:\n                validate_ipv46_address(ip_address)\n                return True\n            except ValidationError:\n                pass\n        return False\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, EmailValidator) and\n            (self.domain_allowlist == other.domain_allowlist) and\n            (self.message == other.message) and\n            (self.code == other.code)\n        )\n\n\nvalidate_email = EmailValidator()\n\nslug_re = _lazy_re_compile(r'^[-a-zA-Z0-9_]+\\Z')\nvalidate_slug = RegexValidator(\n    slug_re,\n    # Translators: \"letters\" means latin letters: a-z and A-Z.\n    _('Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.'),\n    'invalid'\n)\n\nslug_unicode_re = _lazy_re_compile(r'^[-\\w]+\\Z')\nvalidate_unicode_slug = RegexValidator(\n    slug_unicode_re,\n    _('Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.'),\n    'invalid'\n)\n\n\ndef validate_ipv4_address(value):\n    try:\n        ipaddress.IPv4Address(value)\n    except ValueError:\n        raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n    else:\n        # Leading zeros are forbidden to avoid ambiguity with the octal\n        # notation. This restriction is included in Python 3.9.5+.\n        # TODO: Remove when dropping support for PY39.\n        if any(\n            octet != '0' and octet[0] == '0'\n            for octet in value.split('.')\n        ):\n            raise ValidationError(\n                _('Enter a valid IPv4 address.'),\n                code='invalid',\n                params={'value': value},\n            )\n\n\ndef validate_ipv6_address(value):\n    if not is_valid_ipv6_address(value):\n        raise ValidationError(_('Enter a valid IPv6 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv46_address(value):\n    try:\n        validate_ipv4_address(value)\n    except ValidationError:\n        try:\n            validate_ipv6_address(value)\n        except ValidationError:\n            raise ValidationError(_('Enter a valid IPv4 or IPv6 address.'), code='invalid', params={'value': value})\n\n\nip_address_validator_map = {\n    'both': ([validate_ipv46_address], _('Enter a valid IPv4 or IPv6 address.')),\n    'ipv4': ([validate_ipv4_address], _('Enter a valid IPv4 address.')),\n    'ipv6': ([validate_ipv6_address], _('Enter a valid IPv6 address.')),\n}\n\n\ndef ip_address_validators(protocol, unpack_ipv4):\n    \"\"\"\n    Depending on the given parameters, return the appropriate validators for\n    the GenericIPAddressField.\n    \"\"\"\n    if protocol != 'both' and unpack_ipv4:\n        raise ValueError(\n            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\")\n    try:\n        return ip_address_validator_map[protocol.lower()]\n    except KeyError:\n        raise ValueError(\"The protocol '%s' is unknown. Supported: %s\"\n                         % (protocol, list(ip_address_validator_map)))\n\n\ndef int_list_validator(sep=',', message=None, code='invalid', allow_negative=False):\n    regexp = _lazy_re_compile(r'^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z' % {\n        'neg': '(-)?' if allow_negative else '',\n        'sep': re.escape(sep),\n    })\n    return RegexValidator(regexp, message=message, code=code)\n\n\nvalidate_comma_separated_integer_list = int_list_validator(\n    message=_('Enter only digits separated by commas.'),\n)\n\n\n@deconstructible\nclass BaseValidator:\n    message = _('Ensure this value is %(limit_value)s (it is %(show_value)s).')\n    code = 'limit_value'\n\n    def __init__(self, limit_value, message=None):\n        self.limit_value = limit_value\n        if message:\n            self.message = message\n\n    def __call__(self, value):\n        cleaned = self.clean(value)\n        limit_value = self.limit_value() if callable(self.limit_value) else self.limit_value\n        params = {'limit_value': limit_value, 'show_value': cleaned, 'value': value}\n        if self.compare(cleaned, limit_value):\n            raise ValidationError(self.message, code=self.code, params=params)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return (\n            self.limit_value == other.limit_value and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n    def compare(self, a, b):\n        return a is not b\n\n    def clean(self, x):\n        return x\n\n\n@deconstructible\nclass MaxValueValidator(BaseValidator):\n    message = _('Ensure this value is less than or equal to %(limit_value)s.')\n    code = 'max_value'\n\n    def compare(self, a, b):\n        return a > b\n\n\n@deconstructible\nclass MinValueValidator(BaseValidator):\n    message = _('Ensure this value is greater than or equal to %(limit_value)s.')\n    code = 'min_value'\n\n    def compare(self, a, b):\n        return a < b\n\n\n@deconstructible\nclass MinLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at least %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'min_length'\n\n    def compare(self, a, b):\n        return a < b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass MaxLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at most %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'max_length'\n\n    def compare(self, a, b):\n        return a > b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass DecimalValidator:\n    \"\"\"\n    Validate that the input does not exceed the maximum number of digits\n    expected, otherwise raise ValidationError.\n    \"\"\"\n    messages = {\n        'invalid': _('Enter a number.'),\n        'max_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit in total.',\n            'Ensure that there are no more than %(max)s digits in total.',\n            'max'\n        ),\n        'max_decimal_places': ngettext_lazy(\n            'Ensure that there are no more than %(max)s decimal place.',\n            'Ensure that there are no more than %(max)s decimal places.',\n            'max'\n        ),\n        'max_whole_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit before the decimal point.',\n            'Ensure that there are no more than %(max)s digits before the decimal point.',\n            'max'\n        ),\n    }\n\n    def __init__(self, max_digits, decimal_places):\n        self.max_digits = max_digits\n        self.decimal_places = decimal_places\n\n    def __call__(self, value):\n        digit_tuple, exponent = value.as_tuple()[1:]\n        if exponent in {'F', 'n', 'N'}:\n            raise ValidationError(self.messages['invalid'], code='invalid', params={'value': value})\n        if exponent >= 0:\n            # A positive exponent adds that many trailing zeros.\n            digits = len(digit_tuple) + exponent\n            decimals = 0\n        else:\n            # If the absolute value of the negative exponent is larger than the\n            # number of digits, then it's the same as the number of digits,\n            # because it'll consume all of the digits in digit_tuple and then\n            # add abs(exponent) - len(digit_tuple) leading zeros after the\n            # decimal point.\n            if abs(exponent) > len(digit_tuple):\n                digits = decimals = abs(exponent)\n            else:\n                digits = len(digit_tuple)\n                decimals = abs(exponent)\n        whole_digits = digits - decimals\n\n        if self.max_digits is not None and digits > self.max_digits:\n            raise ValidationError(\n                self.messages['max_digits'],\n                code='max_digits',\n                params={'max': self.max_digits, 'value': value},\n            )\n        if self.decimal_places is not None and decimals > self.decimal_places:\n            raise ValidationError(\n                self.messages['max_decimal_places'],\n                code='max_decimal_places',\n                params={'max': self.decimal_places, 'value': value},\n            )\n        if (self.max_digits is not None and self.decimal_places is not None and\n                whole_digits > (self.max_digits - self.decimal_places)):\n            raise ValidationError(\n                self.messages['max_whole_digits'],\n                code='max_whole_digits',\n                params={'max': (self.max_digits - self.decimal_places), 'value': value},\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.max_digits == other.max_digits and\n            self.decimal_places == other.decimal_places\n        )\n\n\n@deconstructible\nclass FileExtensionValidator:\n    message = _(\n        'File extension \u201c%(extension)s\u201d is not allowed. '\n        'Allowed extensions are: %(allowed_extensions)s.'\n    )\n    code = 'invalid_extension'\n\n    def __init__(self, allowed_extensions=None, message=None, code=None):\n        if allowed_extensions is not None:\n            allowed_extensions = [allowed_extension.lower() for allowed_extension in allowed_extensions]\n        self.allowed_extensions = allowed_extensions\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        extension = Path(value.name).suffix[1:].lower()\n        if self.allowed_extensions is not None and extension not in self.allowed_extensions:\n            raise ValidationError(\n                self.message,\n                code=self.code,\n                params={\n                    'extension': extension,\n                    'allowed_extensions': ', '.join(self.allowed_extensions),\n                    'value': value,\n                }\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.allowed_extensions == other.allowed_extensions and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n\ndef get_available_image_extensions():\n    try:\n        from PIL import Image\n    except ImportError:\n        return []\n    else:\n        Image.init()\n        return [ext.lower()[1:] for ext in Image.EXTENSION]\n\n\ndef validate_image_file_extension(value):\n    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(value)\n\n\n@deconstructible\nclass ProhibitNullCharactersValidator:\n    \"\"\"Validate that the string doesn't contain the null character.\"\"\"\n    message = _('Null characters are not allowed.')\n    code = 'null_characters_not_allowed'\n\n    def __init__(self, message=None, code=None):\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        if '\\x00' in str(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.message == other.message and\n            self.code == other.code\n        )\n"
  },
  {
    "patch": "diff --git a/django/contrib/admindocs/views.py b/django/contrib/admindocs/views.py\nindex 9f66ce8545..ab6e75c811 100644\n--- a/django/contrib/admindocs/views.py\n+++ b/django/contrib/admindocs/views.py\n@@ -15,6 +15,7 @@ from django.db import models\n from django.http import Http404\n from django.template.engine import Engine\n from django.urls import get_mod_func, get_resolver, get_urlconf\n+from django.utils._os import safe_join\n from django.utils.decorators import method_decorator\n from django.utils.functional import cached_property\n from django.utils.inspect import (\n@@ -333,7 +334,7 @@ class TemplateDetailView(BaseAdminDocsView):\n         else:\n             # This doesn't account for template loaders (#24128).\n             for index, directory in enumerate(default_engine.dirs):\n-                template_file = Path(directory) / template\n+                template_file = Path(safe_join(directory, template))\n                 if template_file.exists():\n                     template_contents = template_file.read_text()\n                 else:\n",
    "commit_message": "Fixed CVE-2021-33203 -- Fixed potential path-traversal via admindocs' TemplateDetailView.\n\n",
    "code_before": "import inspect\nfrom importlib import import_module\nfrom inspect import cleandoc\nfrom pathlib import Path\n\nfrom django.apps import apps\nfrom django.contrib import admin\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom django.contrib.admindocs import utils\nfrom django.contrib.admindocs.utils import (\n    replace_named_groups, replace_unnamed_groups,\n)\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.db import models\nfrom django.http import Http404\nfrom django.template.engine import Engine\nfrom django.urls import get_mod_func, get_resolver, get_urlconf\nfrom django.utils.decorators import method_decorator\nfrom django.utils.functional import cached_property\nfrom django.utils.inspect import (\n    func_accepts_kwargs, func_accepts_var_args, get_func_full_args,\n    method_has_no_args,\n)\nfrom django.utils.translation import gettext as _\nfrom django.views.generic import TemplateView\n\nfrom .utils import get_view_name\n\n# Exclude methods starting with these strings from documentation\nMODEL_METHODS_EXCLUDE = ('_', 'add_', 'delete', 'save', 'set_')\n\n\nclass BaseAdminDocsView(TemplateView):\n    \"\"\"\n    Base view for admindocs views.\n    \"\"\"\n    @method_decorator(staff_member_required)\n    def dispatch(self, request, *args, **kwargs):\n        if not utils.docutils_is_available:\n            # Display an error message for people without docutils\n            self.template_name = 'admin_doc/missing_docutils.html'\n            return self.render_to_response(admin.site.each_context(request))\n        return super().dispatch(request, *args, **kwargs)\n\n    def get_context_data(self, **kwargs):\n        return super().get_context_data(**{\n            **kwargs,\n            **admin.site.each_context(self.request),\n        })\n\n\nclass BookmarkletsView(BaseAdminDocsView):\n    template_name = 'admin_doc/bookmarklets.html'\n\n\nclass TemplateTagIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_tag_index.html'\n\n    def get_context_data(self, **kwargs):\n        tags = []\n        try:\n            engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            app_libs = sorted(engine.template_libraries.items())\n            builtin_libs = [('', lib) for lib in engine.template_builtins]\n            for module_name, library in builtin_libs + app_libs:\n                for tag_name, tag_func in library.tags.items():\n                    title, body, metadata = utils.parse_docstring(tag_func.__doc__)\n                    title = title and utils.parse_rst(title, 'tag', _('tag:') + tag_name)\n                    body = body and utils.parse_rst(body, 'tag', _('tag:') + tag_name)\n                    for key in metadata:\n                        metadata[key] = utils.parse_rst(metadata[key], 'tag', _('tag:') + tag_name)\n                    tag_library = module_name.split('.')[-1]\n                    tags.append({\n                        'name': tag_name,\n                        'title': title,\n                        'body': body,\n                        'meta': metadata,\n                        'library': tag_library,\n                    })\n        return super().get_context_data(**{**kwargs, 'tags': tags})\n\n\nclass TemplateFilterIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_filter_index.html'\n\n    def get_context_data(self, **kwargs):\n        filters = []\n        try:\n            engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            app_libs = sorted(engine.template_libraries.items())\n            builtin_libs = [('', lib) for lib in engine.template_builtins]\n            for module_name, library in builtin_libs + app_libs:\n                for filter_name, filter_func in library.filters.items():\n                    title, body, metadata = utils.parse_docstring(filter_func.__doc__)\n                    title = title and utils.parse_rst(title, 'filter', _('filter:') + filter_name)\n                    body = body and utils.parse_rst(body, 'filter', _('filter:') + filter_name)\n                    for key in metadata:\n                        metadata[key] = utils.parse_rst(metadata[key], 'filter', _('filter:') + filter_name)\n                    tag_library = module_name.split('.')[-1]\n                    filters.append({\n                        'name': filter_name,\n                        'title': title,\n                        'body': body,\n                        'meta': metadata,\n                        'library': tag_library,\n                    })\n        return super().get_context_data(**{**kwargs, 'filters': filters})\n\n\nclass ViewIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/view_index.html'\n\n    def get_context_data(self, **kwargs):\n        views = []\n        url_resolver = get_resolver(get_urlconf())\n        try:\n            view_functions = extract_views_from_urlpatterns(url_resolver.url_patterns)\n        except ImproperlyConfigured:\n            view_functions = []\n        for (func, regex, namespace, name) in view_functions:\n            views.append({\n                'full_name': get_view_name(func),\n                'url': simplify_regex(regex),\n                'url_name': ':'.join((namespace or []) + (name and [name] or [])),\n                'namespace': ':'.join(namespace or []),\n                'name': name,\n            })\n        return super().get_context_data(**{**kwargs, 'views': views})\n\n\nclass ViewDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/view_detail.html'\n\n    @staticmethod\n    def _get_view_func(view):\n        urlconf = get_urlconf()\n        if get_resolver(urlconf)._is_callback(view):\n            mod, func = get_mod_func(view)\n            try:\n                # Separate the module and function, e.g.\n                # 'mymodule.views.myview' -> 'mymodule.views', 'myview').\n                return getattr(import_module(mod), func)\n            except ImportError:\n                # Import may fail because view contains a class name, e.g.\n                # 'mymodule.views.ViewContainer.my_view', so mod takes the form\n                # 'mymodule.views.ViewContainer'. Parse it again to separate\n                # the module and class.\n                mod, klass = get_mod_func(mod)\n                return getattr(getattr(import_module(mod), klass), func)\n\n    def get_context_data(self, **kwargs):\n        view = self.kwargs['view']\n        view_func = self._get_view_func(view)\n        if view_func is None:\n            raise Http404\n        title, body, metadata = utils.parse_docstring(view_func.__doc__)\n        title = title and utils.parse_rst(title, 'view', _('view:') + view)\n        body = body and utils.parse_rst(body, 'view', _('view:') + view)\n        for key in metadata:\n            metadata[key] = utils.parse_rst(metadata[key], 'model', _('view:') + view)\n        return super().get_context_data(**{\n            **kwargs,\n            'name': view,\n            'summary': title,\n            'body': body,\n            'meta': metadata,\n        })\n\n\nclass ModelIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/model_index.html'\n\n    def get_context_data(self, **kwargs):\n        m_list = [m._meta for m in apps.get_models()]\n        return super().get_context_data(**{**kwargs, 'models': m_list})\n\n\nclass ModelDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/model_detail.html'\n\n    def get_context_data(self, **kwargs):\n        model_name = self.kwargs['model_name']\n        # Get the model class.\n        try:\n            app_config = apps.get_app_config(self.kwargs['app_label'])\n        except LookupError:\n            raise Http404(_(\"App %(app_label)r not found\") % self.kwargs)\n        try:\n            model = app_config.get_model(model_name)\n        except LookupError:\n            raise Http404(_(\"Model %(model_name)r not found in app %(app_label)r\") % self.kwargs)\n\n        opts = model._meta\n\n        title, body, metadata = utils.parse_docstring(model.__doc__)\n        title = title and utils.parse_rst(title, 'model', _('model:') + model_name)\n        body = body and utils.parse_rst(body, 'model', _('model:') + model_name)\n\n        # Gather fields/field descriptions.\n        fields = []\n        for field in opts.fields:\n            # ForeignKey is a special case since the field will actually be a\n            # descriptor that returns the other object\n            if isinstance(field, models.ForeignKey):\n                data_type = field.remote_field.model.__name__\n                app_label = field.remote_field.model._meta.app_label\n                verbose = utils.parse_rst(\n                    (_(\"the related `%(app_label)s.%(data_type)s` object\") % {\n                        'app_label': app_label, 'data_type': data_type,\n                    }),\n                    'model',\n                    _('model:') + data_type,\n                )\n            else:\n                data_type = get_readable_field_data_type(field)\n                verbose = field.verbose_name\n            fields.append({\n                'name': field.name,\n                'data_type': data_type,\n                'verbose': verbose or '',\n                'help_text': field.help_text,\n            })\n\n        # Gather many-to-many fields.\n        for field in opts.many_to_many:\n            data_type = field.remote_field.model.__name__\n            app_label = field.remote_field.model._meta.app_label\n            verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {\n                'app_label': app_label,\n                'object_name': data_type,\n            }\n            fields.append({\n                'name': \"%s.all\" % field.name,\n                \"data_type\": 'List',\n                'verbose': utils.parse_rst(_(\"all %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n            fields.append({\n                'name': \"%s.count\" % field.name,\n                'data_type': 'Integer',\n                'verbose': utils.parse_rst(_(\"number of %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n\n        methods = []\n        # Gather model methods.\n        for func_name, func in model.__dict__.items():\n            if inspect.isfunction(func) or isinstance(func, (cached_property, property)):\n                try:\n                    for exclude in MODEL_METHODS_EXCLUDE:\n                        if func_name.startswith(exclude):\n                            raise StopIteration\n                except StopIteration:\n                    continue\n                verbose = func.__doc__\n                verbose = verbose and (\n                    utils.parse_rst(cleandoc(verbose), 'model', _('model:') + opts.model_name)\n                )\n                # Show properties, cached_properties, and methods without\n                # arguments as fields. Otherwise, show as a 'method with\n                # arguments'.\n                if isinstance(func, (cached_property, property)):\n                    fields.append({\n                        'name': func_name,\n                        'data_type': get_return_data_type(func_name),\n                        'verbose': verbose or ''\n                    })\n                elif method_has_no_args(func) and not func_accepts_kwargs(func) and not func_accepts_var_args(func):\n                    fields.append({\n                        'name': func_name,\n                        'data_type': get_return_data_type(func_name),\n                        'verbose': verbose or '',\n                    })\n                else:\n                    arguments = get_func_full_args(func)\n                    # Join arguments with ', ' and in case of default value,\n                    # join it with '='. Use repr() so that strings will be\n                    # correctly displayed.\n                    print_arguments = ', '.join([\n                        '='.join([arg_el[0], *map(repr, arg_el[1:])])\n                        for arg_el in arguments\n                    ])\n                    methods.append({\n                        'name': func_name,\n                        'arguments': print_arguments,\n                        'verbose': verbose or '',\n                    })\n\n        # Gather related objects\n        for rel in opts.related_objects:\n            verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {\n                'app_label': rel.related_model._meta.app_label,\n                'object_name': rel.related_model._meta.object_name,\n            }\n            accessor = rel.get_accessor_name()\n            fields.append({\n                'name': \"%s.all\" % accessor,\n                'data_type': 'List',\n                'verbose': utils.parse_rst(_(\"all %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n            fields.append({\n                'name': \"%s.count\" % accessor,\n                'data_type': 'Integer',\n                'verbose': utils.parse_rst(_(\"number of %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': opts.label,\n            'summary': title,\n            'description': body,\n            'fields': fields,\n            'methods': methods,\n        })\n\n\nclass TemplateDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_detail.html'\n\n    def get_context_data(self, **kwargs):\n        template = self.kwargs['template']\n        templates = []\n        try:\n            default_engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            # This doesn't account for template loaders (#24128).\n            for index, directory in enumerate(default_engine.dirs):\n                template_file = Path(directory) / template\n                if template_file.exists():\n                    template_contents = template_file.read_text()\n                else:\n                    template_contents = ''\n                templates.append({\n                    'file': template_file,\n                    'exists': template_file.exists(),\n                    'contents': template_contents,\n                    'order': index,\n                })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': template,\n            'templates': templates,\n        })\n\n\n####################\n# Helper functions #\n####################\n\n\ndef get_return_data_type(func_name):\n    \"\"\"Return a somewhat-helpful data type given a function name\"\"\"\n    if func_name.startswith('get_'):\n        if func_name.endswith('_list'):\n            return 'List'\n        elif func_name.endswith('_count'):\n            return 'Integer'\n    return ''\n\n\ndef get_readable_field_data_type(field):\n    \"\"\"\n    Return the description for a given field type, if it exists. Fields'\n    descriptions can contain format strings, which will be interpolated with\n    the values of field.__dict__ before being output.\n    \"\"\"\n    return field.description % field.__dict__\n\n\ndef extract_views_from_urlpatterns(urlpatterns, base='', namespace=None):\n    \"\"\"\n    Return a list of views from a list of urlpatterns.\n\n    Each object in the returned list is a two-tuple: (view_func, regex)\n    \"\"\"\n    views = []\n    for p in urlpatterns:\n        if hasattr(p, 'url_patterns'):\n            try:\n                patterns = p.url_patterns\n            except ImportError:\n                continue\n            views.extend(extract_views_from_urlpatterns(\n                patterns,\n                base + str(p.pattern),\n                (namespace or []) + (p.namespace and [p.namespace] or [])\n            ))\n        elif hasattr(p, 'callback'):\n            try:\n                views.append((p.callback, base + str(p.pattern), namespace, p.name))\n            except ViewDoesNotExist:\n                continue\n        else:\n            raise TypeError(_(\"%s does not appear to be a urlpattern object\") % p)\n    return views\n\n\ndef simplify_regex(pattern):\n    r\"\"\"\n    Clean up urlpattern regexes into something more readable by humans. For\n    example, turn \"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n    into \"/<sport_slug>/athletes/<athlete_slug>/\".\n    \"\"\"\n    pattern = replace_named_groups(pattern)\n    pattern = replace_unnamed_groups(pattern)\n    # clean up any outstanding regex-y characters.\n    pattern = pattern.replace('^', '').replace('$', '').replace('?', '')\n    if not pattern.startswith('/'):\n        pattern = '/' + pattern\n    return pattern\n",
    "code_after": "import inspect\nfrom importlib import import_module\nfrom inspect import cleandoc\nfrom pathlib import Path\n\nfrom django.apps import apps\nfrom django.contrib import admin\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom django.contrib.admindocs import utils\nfrom django.contrib.admindocs.utils import (\n    replace_named_groups, replace_unnamed_groups,\n)\nfrom django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\nfrom django.db import models\nfrom django.http import Http404\nfrom django.template.engine import Engine\nfrom django.urls import get_mod_func, get_resolver, get_urlconf\nfrom django.utils._os import safe_join\nfrom django.utils.decorators import method_decorator\nfrom django.utils.functional import cached_property\nfrom django.utils.inspect import (\n    func_accepts_kwargs, func_accepts_var_args, get_func_full_args,\n    method_has_no_args,\n)\nfrom django.utils.translation import gettext as _\nfrom django.views.generic import TemplateView\n\nfrom .utils import get_view_name\n\n# Exclude methods starting with these strings from documentation\nMODEL_METHODS_EXCLUDE = ('_', 'add_', 'delete', 'save', 'set_')\n\n\nclass BaseAdminDocsView(TemplateView):\n    \"\"\"\n    Base view for admindocs views.\n    \"\"\"\n    @method_decorator(staff_member_required)\n    def dispatch(self, request, *args, **kwargs):\n        if not utils.docutils_is_available:\n            # Display an error message for people without docutils\n            self.template_name = 'admin_doc/missing_docutils.html'\n            return self.render_to_response(admin.site.each_context(request))\n        return super().dispatch(request, *args, **kwargs)\n\n    def get_context_data(self, **kwargs):\n        return super().get_context_data(**{\n            **kwargs,\n            **admin.site.each_context(self.request),\n        })\n\n\nclass BookmarkletsView(BaseAdminDocsView):\n    template_name = 'admin_doc/bookmarklets.html'\n\n\nclass TemplateTagIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_tag_index.html'\n\n    def get_context_data(self, **kwargs):\n        tags = []\n        try:\n            engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            app_libs = sorted(engine.template_libraries.items())\n            builtin_libs = [('', lib) for lib in engine.template_builtins]\n            for module_name, library in builtin_libs + app_libs:\n                for tag_name, tag_func in library.tags.items():\n                    title, body, metadata = utils.parse_docstring(tag_func.__doc__)\n                    title = title and utils.parse_rst(title, 'tag', _('tag:') + tag_name)\n                    body = body and utils.parse_rst(body, 'tag', _('tag:') + tag_name)\n                    for key in metadata:\n                        metadata[key] = utils.parse_rst(metadata[key], 'tag', _('tag:') + tag_name)\n                    tag_library = module_name.split('.')[-1]\n                    tags.append({\n                        'name': tag_name,\n                        'title': title,\n                        'body': body,\n                        'meta': metadata,\n                        'library': tag_library,\n                    })\n        return super().get_context_data(**{**kwargs, 'tags': tags})\n\n\nclass TemplateFilterIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_filter_index.html'\n\n    def get_context_data(self, **kwargs):\n        filters = []\n        try:\n            engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            app_libs = sorted(engine.template_libraries.items())\n            builtin_libs = [('', lib) for lib in engine.template_builtins]\n            for module_name, library in builtin_libs + app_libs:\n                for filter_name, filter_func in library.filters.items():\n                    title, body, metadata = utils.parse_docstring(filter_func.__doc__)\n                    title = title and utils.parse_rst(title, 'filter', _('filter:') + filter_name)\n                    body = body and utils.parse_rst(body, 'filter', _('filter:') + filter_name)\n                    for key in metadata:\n                        metadata[key] = utils.parse_rst(metadata[key], 'filter', _('filter:') + filter_name)\n                    tag_library = module_name.split('.')[-1]\n                    filters.append({\n                        'name': filter_name,\n                        'title': title,\n                        'body': body,\n                        'meta': metadata,\n                        'library': tag_library,\n                    })\n        return super().get_context_data(**{**kwargs, 'filters': filters})\n\n\nclass ViewIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/view_index.html'\n\n    def get_context_data(self, **kwargs):\n        views = []\n        url_resolver = get_resolver(get_urlconf())\n        try:\n            view_functions = extract_views_from_urlpatterns(url_resolver.url_patterns)\n        except ImproperlyConfigured:\n            view_functions = []\n        for (func, regex, namespace, name) in view_functions:\n            views.append({\n                'full_name': get_view_name(func),\n                'url': simplify_regex(regex),\n                'url_name': ':'.join((namespace or []) + (name and [name] or [])),\n                'namespace': ':'.join(namespace or []),\n                'name': name,\n            })\n        return super().get_context_data(**{**kwargs, 'views': views})\n\n\nclass ViewDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/view_detail.html'\n\n    @staticmethod\n    def _get_view_func(view):\n        urlconf = get_urlconf()\n        if get_resolver(urlconf)._is_callback(view):\n            mod, func = get_mod_func(view)\n            try:\n                # Separate the module and function, e.g.\n                # 'mymodule.views.myview' -> 'mymodule.views', 'myview').\n                return getattr(import_module(mod), func)\n            except ImportError:\n                # Import may fail because view contains a class name, e.g.\n                # 'mymodule.views.ViewContainer.my_view', so mod takes the form\n                # 'mymodule.views.ViewContainer'. Parse it again to separate\n                # the module and class.\n                mod, klass = get_mod_func(mod)\n                return getattr(getattr(import_module(mod), klass), func)\n\n    def get_context_data(self, **kwargs):\n        view = self.kwargs['view']\n        view_func = self._get_view_func(view)\n        if view_func is None:\n            raise Http404\n        title, body, metadata = utils.parse_docstring(view_func.__doc__)\n        title = title and utils.parse_rst(title, 'view', _('view:') + view)\n        body = body and utils.parse_rst(body, 'view', _('view:') + view)\n        for key in metadata:\n            metadata[key] = utils.parse_rst(metadata[key], 'model', _('view:') + view)\n        return super().get_context_data(**{\n            **kwargs,\n            'name': view,\n            'summary': title,\n            'body': body,\n            'meta': metadata,\n        })\n\n\nclass ModelIndexView(BaseAdminDocsView):\n    template_name = 'admin_doc/model_index.html'\n\n    def get_context_data(self, **kwargs):\n        m_list = [m._meta for m in apps.get_models()]\n        return super().get_context_data(**{**kwargs, 'models': m_list})\n\n\nclass ModelDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/model_detail.html'\n\n    def get_context_data(self, **kwargs):\n        model_name = self.kwargs['model_name']\n        # Get the model class.\n        try:\n            app_config = apps.get_app_config(self.kwargs['app_label'])\n        except LookupError:\n            raise Http404(_(\"App %(app_label)r not found\") % self.kwargs)\n        try:\n            model = app_config.get_model(model_name)\n        except LookupError:\n            raise Http404(_(\"Model %(model_name)r not found in app %(app_label)r\") % self.kwargs)\n\n        opts = model._meta\n\n        title, body, metadata = utils.parse_docstring(model.__doc__)\n        title = title and utils.parse_rst(title, 'model', _('model:') + model_name)\n        body = body and utils.parse_rst(body, 'model', _('model:') + model_name)\n\n        # Gather fields/field descriptions.\n        fields = []\n        for field in opts.fields:\n            # ForeignKey is a special case since the field will actually be a\n            # descriptor that returns the other object\n            if isinstance(field, models.ForeignKey):\n                data_type = field.remote_field.model.__name__\n                app_label = field.remote_field.model._meta.app_label\n                verbose = utils.parse_rst(\n                    (_(\"the related `%(app_label)s.%(data_type)s` object\") % {\n                        'app_label': app_label, 'data_type': data_type,\n                    }),\n                    'model',\n                    _('model:') + data_type,\n                )\n            else:\n                data_type = get_readable_field_data_type(field)\n                verbose = field.verbose_name\n            fields.append({\n                'name': field.name,\n                'data_type': data_type,\n                'verbose': verbose or '',\n                'help_text': field.help_text,\n            })\n\n        # Gather many-to-many fields.\n        for field in opts.many_to_many:\n            data_type = field.remote_field.model.__name__\n            app_label = field.remote_field.model._meta.app_label\n            verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {\n                'app_label': app_label,\n                'object_name': data_type,\n            }\n            fields.append({\n                'name': \"%s.all\" % field.name,\n                \"data_type\": 'List',\n                'verbose': utils.parse_rst(_(\"all %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n            fields.append({\n                'name': \"%s.count\" % field.name,\n                'data_type': 'Integer',\n                'verbose': utils.parse_rst(_(\"number of %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n\n        methods = []\n        # Gather model methods.\n        for func_name, func in model.__dict__.items():\n            if inspect.isfunction(func) or isinstance(func, (cached_property, property)):\n                try:\n                    for exclude in MODEL_METHODS_EXCLUDE:\n                        if func_name.startswith(exclude):\n                            raise StopIteration\n                except StopIteration:\n                    continue\n                verbose = func.__doc__\n                verbose = verbose and (\n                    utils.parse_rst(cleandoc(verbose), 'model', _('model:') + opts.model_name)\n                )\n                # Show properties, cached_properties, and methods without\n                # arguments as fields. Otherwise, show as a 'method with\n                # arguments'.\n                if isinstance(func, (cached_property, property)):\n                    fields.append({\n                        'name': func_name,\n                        'data_type': get_return_data_type(func_name),\n                        'verbose': verbose or ''\n                    })\n                elif method_has_no_args(func) and not func_accepts_kwargs(func) and not func_accepts_var_args(func):\n                    fields.append({\n                        'name': func_name,\n                        'data_type': get_return_data_type(func_name),\n                        'verbose': verbose or '',\n                    })\n                else:\n                    arguments = get_func_full_args(func)\n                    # Join arguments with ', ' and in case of default value,\n                    # join it with '='. Use repr() so that strings will be\n                    # correctly displayed.\n                    print_arguments = ', '.join([\n                        '='.join([arg_el[0], *map(repr, arg_el[1:])])\n                        for arg_el in arguments\n                    ])\n                    methods.append({\n                        'name': func_name,\n                        'arguments': print_arguments,\n                        'verbose': verbose or '',\n                    })\n\n        # Gather related objects\n        for rel in opts.related_objects:\n            verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {\n                'app_label': rel.related_model._meta.app_label,\n                'object_name': rel.related_model._meta.object_name,\n            }\n            accessor = rel.get_accessor_name()\n            fields.append({\n                'name': \"%s.all\" % accessor,\n                'data_type': 'List',\n                'verbose': utils.parse_rst(_(\"all %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n            fields.append({\n                'name': \"%s.count\" % accessor,\n                'data_type': 'Integer',\n                'verbose': utils.parse_rst(_(\"number of %s\") % verbose, 'model', _('model:') + opts.model_name),\n            })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': opts.label,\n            'summary': title,\n            'description': body,\n            'fields': fields,\n            'methods': methods,\n        })\n\n\nclass TemplateDetailView(BaseAdminDocsView):\n    template_name = 'admin_doc/template_detail.html'\n\n    def get_context_data(self, **kwargs):\n        template = self.kwargs['template']\n        templates = []\n        try:\n            default_engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            # This doesn't account for template loaders (#24128).\n            for index, directory in enumerate(default_engine.dirs):\n                template_file = Path(safe_join(directory, template))\n                if template_file.exists():\n                    template_contents = template_file.read_text()\n                else:\n                    template_contents = ''\n                templates.append({\n                    'file': template_file,\n                    'exists': template_file.exists(),\n                    'contents': template_contents,\n                    'order': index,\n                })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': template,\n            'templates': templates,\n        })\n\n\n####################\n# Helper functions #\n####################\n\n\ndef get_return_data_type(func_name):\n    \"\"\"Return a somewhat-helpful data type given a function name\"\"\"\n    if func_name.startswith('get_'):\n        if func_name.endswith('_list'):\n            return 'List'\n        elif func_name.endswith('_count'):\n            return 'Integer'\n    return ''\n\n\ndef get_readable_field_data_type(field):\n    \"\"\"\n    Return the description for a given field type, if it exists. Fields'\n    descriptions can contain format strings, which will be interpolated with\n    the values of field.__dict__ before being output.\n    \"\"\"\n    return field.description % field.__dict__\n\n\ndef extract_views_from_urlpatterns(urlpatterns, base='', namespace=None):\n    \"\"\"\n    Return a list of views from a list of urlpatterns.\n\n    Each object in the returned list is a two-tuple: (view_func, regex)\n    \"\"\"\n    views = []\n    for p in urlpatterns:\n        if hasattr(p, 'url_patterns'):\n            try:\n                patterns = p.url_patterns\n            except ImportError:\n                continue\n            views.extend(extract_views_from_urlpatterns(\n                patterns,\n                base + str(p.pattern),\n                (namespace or []) + (p.namespace and [p.namespace] or [])\n            ))\n        elif hasattr(p, 'callback'):\n            try:\n                views.append((p.callback, base + str(p.pattern), namespace, p.name))\n            except ViewDoesNotExist:\n                continue\n        else:\n            raise TypeError(_(\"%s does not appear to be a urlpattern object\") % p)\n    return views\n\n\ndef simplify_regex(pattern):\n    r\"\"\"\n    Clean up urlpattern regexes into something more readable by humans. For\n    example, turn \"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n    into \"/<sport_slug>/athletes/<athlete_slug>/\".\n    \"\"\"\n    pattern = replace_named_groups(pattern)\n    pattern = replace_unnamed_groups(pattern)\n    # clean up any outstanding regex-y characters.\n    pattern = pattern.replace('^', '').replace('$', '').replace('?', '')\n    if not pattern.startswith('/'):\n        pattern = '/' + pattern\n    return pattern\n"
  },
  {
    "patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex a385819510..f9abec602c 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -92,6 +92,7 @@ class URLValidator(RegexValidator):\n         r'\\Z', re.IGNORECASE)\n     message = _('Enter a valid URL.')\n     schemes = ['http', 'https', 'ftp', 'ftps']\n+    unsafe_chars = frozenset('\\t\\r\\n')\n \n     def __init__(self, schemes=None, **kwargs):\n         super().__init__(**kwargs)\n@@ -101,6 +102,8 @@ class URLValidator(RegexValidator):\n     def __call__(self, value):\n         if not isinstance(value, str):\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n+        if self.unsafe_chars.intersection(value):\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n         # Check if the scheme is valid.\n         scheme = value.split('://')[0].lower()\n         if scheme not in self.schemes:\n",
    "commit_message": "Fixed #32713, Fixed CVE-2021-32052 -- Prevented newlines and tabs from being accepted in URLValidator on Python 3.9.5+.\n\nIn Python 3.9.5+ urllib.parse() automatically removes ASCII newlines\nand tabs from URLs [1, 2]. Unfortunately it created an issue in\nthe URLValidator. URLValidator uses urllib.urlsplit() and\nurllib.urlunsplit() for creating a URL variant with Punycode which no\nlonger contains newlines and tabs in Python 3.9.5+. As a consequence,\nthe regular expression matched the URL (without unsafe characters) and\nthe source value (with unsafe characters) was considered valid.\n\n[1] https://bugs.python.org/issue43882 and\n[2] https://github.com/python/cpython/commit/76cd81d60310d65d01f9d7b48a8985d8ab89c8b4\n",
    "code_before": "import ipaddress\nimport re\nimport warnings\nfrom pathlib import Path\nfrom urllib.parse import urlsplit, urlunsplit\n\nfrom django.core.exceptions import ValidationError\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.deprecation import RemovedInDjango41Warning\nfrom django.utils.encoding import punycode\nfrom django.utils.ipv6 import is_valid_ipv6_address\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.translation import gettext_lazy as _, ngettext_lazy\n\n# These values, if given to validate(), will trigger the self.required check.\nEMPTY_VALUES = (None, '', [], (), {})\n\n\n@deconstructible\nclass RegexValidator:\n    regex = ''\n    message = _('Enter a valid value.')\n    code = 'invalid'\n    inverse_match = False\n    flags = 0\n\n    def __init__(self, regex=None, message=None, code=None, inverse_match=None, flags=None):\n        if regex is not None:\n            self.regex = regex\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if inverse_match is not None:\n            self.inverse_match = inverse_match\n        if flags is not None:\n            self.flags = flags\n        if self.flags and not isinstance(self.regex, str):\n            raise TypeError(\"If the flags are set, regex must be a regular expression string.\")\n\n        self.regex = _lazy_re_compile(self.regex, self.flags)\n\n    def __call__(self, value):\n        \"\"\"\n        Validate that the input contains (or does *not* contain, if\n        inverse_match is True) a match for the regular expression.\n        \"\"\"\n        regex_matches = self.regex.search(str(value))\n        invalid_input = regex_matches if self.inverse_match else not regex_matches\n        if invalid_input:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, RegexValidator) and\n            self.regex.pattern == other.regex.pattern and\n            self.regex.flags == other.regex.flags and\n            (self.message == other.message) and\n            (self.code == other.code) and\n            (self.inverse_match == other.inverse_match)\n        )\n\n\n@deconstructible\nclass URLValidator(RegexValidator):\n    ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n\n    # IP patterns\n    ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'\n    ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n\n    # Host patterns\n    hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n    # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1\n    domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n    tld_re = (\n        r'\\.'                                # dot\n        r'(?!-)'                             # can't start with a dash\n        r'(?:[a-z' + ul + '-]{2,63}'         # domain label\n        r'|xn--[a-z0-9]{1,59})'              # or punycode label\n        r'(?<!-)'                            # can't end with a dash\n        r'\\.?'                               # may have a trailing dot\n    )\n    host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n\n    regex = _lazy_re_compile(\n        r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n        r'(?::\\d{2,5})?'  # port\n        r'(?:[/?#][^\\s]*)?'  # resource path\n        r'\\Z', re.IGNORECASE)\n    message = _('Enter a valid URL.')\n    schemes = ['http', 'https', 'ftp', 'ftps']\n\n    def __init__(self, schemes=None, **kwargs):\n        super().__init__(**kwargs)\n        if schemes is not None:\n            self.schemes = schemes\n\n    def __call__(self, value):\n        if not isinstance(value, str):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        # Check if the scheme is valid.\n        scheme = value.split('://')[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # Then check full URL\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                try:\n                    scheme, netloc, path, query, fragment = urlsplit(value)\n                except ValueError:  # for example, \"Invalid IPv6 URL\"\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r'^\\[(.+)\\](?::\\d{2,5})?$', urlsplit(value).netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if len(urlsplit(value).hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n\ninteger_validator = RegexValidator(\n    _lazy_re_compile(r'^-?\\d+\\Z'),\n    message=_('Enter a valid integer.'),\n    code='invalid',\n)\n\n\ndef validate_integer(value):\n    return integer_validator(value)\n\n\n@deconstructible\nclass EmailValidator:\n    message = _('Enter a valid email address.')\n    code = 'invalid'\n    user_regex = _lazy_re_compile(\n        r\"(^[-!#$%&'*+/=?^_`{}|~0-9A-Z]+(\\.[-!#$%&'*+/=?^_`{}|~0-9A-Z]+)*\\Z\"  # dot-atom\n        r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',  # quoted-string\n        re.IGNORECASE)\n    domain_regex = _lazy_re_compile(\n        # max length for domain name labels is 63 characters per RFC 1034\n        r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z',\n        re.IGNORECASE)\n    literal_regex = _lazy_re_compile(\n        # literal form, ipv4 or ipv6 address (SMTP 4.1.3)\n        r'\\[([A-f0-9:.]+)\\]\\Z',\n        re.IGNORECASE)\n    domain_allowlist = ['localhost']\n\n    @property\n    def domain_whitelist(self):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        return self.domain_allowlist\n\n    @domain_whitelist.setter\n    def domain_whitelist(self, allowlist):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        self.domain_allowlist = allowlist\n\n    def __init__(self, message=None, code=None, allowlist=None, *, whitelist=None):\n        if whitelist is not None:\n            allowlist = whitelist\n            warnings.warn(\n                'The whitelist argument is deprecated in favor of allowlist.',\n                RemovedInDjango41Warning,\n                stacklevel=2,\n            )\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if allowlist is not None:\n            self.domain_allowlist = allowlist\n\n    def __call__(self, value):\n        if not value or '@' not in value:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        user_part, domain_part = value.rsplit('@', 1)\n\n        if not self.user_regex.match(user_part):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        if (domain_part not in self.domain_allowlist and\n                not self.validate_domain_part(domain_part)):\n            # Try for possible IDN domain-part\n            try:\n                domain_part = punycode(domain_part)\n            except UnicodeError:\n                pass\n            else:\n                if self.validate_domain_part(domain_part):\n                    return\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def validate_domain_part(self, domain_part):\n        if self.domain_regex.match(domain_part):\n            return True\n\n        literal_match = self.literal_regex.match(domain_part)\n        if literal_match:\n            ip_address = literal_match[1]\n            try:\n                validate_ipv46_address(ip_address)\n                return True\n            except ValidationError:\n                pass\n        return False\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, EmailValidator) and\n            (self.domain_allowlist == other.domain_allowlist) and\n            (self.message == other.message) and\n            (self.code == other.code)\n        )\n\n\nvalidate_email = EmailValidator()\n\nslug_re = _lazy_re_compile(r'^[-a-zA-Z0-9_]+\\Z')\nvalidate_slug = RegexValidator(\n    slug_re,\n    # Translators: \"letters\" means latin letters: a-z and A-Z.\n    _('Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.'),\n    'invalid'\n)\n\nslug_unicode_re = _lazy_re_compile(r'^[-\\w]+\\Z')\nvalidate_unicode_slug = RegexValidator(\n    slug_unicode_re,\n    _('Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.'),\n    'invalid'\n)\n\n\ndef validate_ipv4_address(value):\n    try:\n        ipaddress.IPv4Address(value)\n    except ValueError:\n        raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv6_address(value):\n    if not is_valid_ipv6_address(value):\n        raise ValidationError(_('Enter a valid IPv6 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv46_address(value):\n    try:\n        validate_ipv4_address(value)\n    except ValidationError:\n        try:\n            validate_ipv6_address(value)\n        except ValidationError:\n            raise ValidationError(_('Enter a valid IPv4 or IPv6 address.'), code='invalid', params={'value': value})\n\n\nip_address_validator_map = {\n    'both': ([validate_ipv46_address], _('Enter a valid IPv4 or IPv6 address.')),\n    'ipv4': ([validate_ipv4_address], _('Enter a valid IPv4 address.')),\n    'ipv6': ([validate_ipv6_address], _('Enter a valid IPv6 address.')),\n}\n\n\ndef ip_address_validators(protocol, unpack_ipv4):\n    \"\"\"\n    Depending on the given parameters, return the appropriate validators for\n    the GenericIPAddressField.\n    \"\"\"\n    if protocol != 'both' and unpack_ipv4:\n        raise ValueError(\n            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\")\n    try:\n        return ip_address_validator_map[protocol.lower()]\n    except KeyError:\n        raise ValueError(\"The protocol '%s' is unknown. Supported: %s\"\n                         % (protocol, list(ip_address_validator_map)))\n\n\ndef int_list_validator(sep=',', message=None, code='invalid', allow_negative=False):\n    regexp = _lazy_re_compile(r'^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z' % {\n        'neg': '(-)?' if allow_negative else '',\n        'sep': re.escape(sep),\n    })\n    return RegexValidator(regexp, message=message, code=code)\n\n\nvalidate_comma_separated_integer_list = int_list_validator(\n    message=_('Enter only digits separated by commas.'),\n)\n\n\n@deconstructible\nclass BaseValidator:\n    message = _('Ensure this value is %(limit_value)s (it is %(show_value)s).')\n    code = 'limit_value'\n\n    def __init__(self, limit_value, message=None):\n        self.limit_value = limit_value\n        if message:\n            self.message = message\n\n    def __call__(self, value):\n        cleaned = self.clean(value)\n        limit_value = self.limit_value() if callable(self.limit_value) else self.limit_value\n        params = {'limit_value': limit_value, 'show_value': cleaned, 'value': value}\n        if self.compare(cleaned, limit_value):\n            raise ValidationError(self.message, code=self.code, params=params)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return (\n            self.limit_value == other.limit_value and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n    def compare(self, a, b):\n        return a is not b\n\n    def clean(self, x):\n        return x\n\n\n@deconstructible\nclass MaxValueValidator(BaseValidator):\n    message = _('Ensure this value is less than or equal to %(limit_value)s.')\n    code = 'max_value'\n\n    def compare(self, a, b):\n        return a > b\n\n\n@deconstructible\nclass MinValueValidator(BaseValidator):\n    message = _('Ensure this value is greater than or equal to %(limit_value)s.')\n    code = 'min_value'\n\n    def compare(self, a, b):\n        return a < b\n\n\n@deconstructible\nclass MinLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at least %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'min_length'\n\n    def compare(self, a, b):\n        return a < b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass MaxLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at most %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'max_length'\n\n    def compare(self, a, b):\n        return a > b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass DecimalValidator:\n    \"\"\"\n    Validate that the input does not exceed the maximum number of digits\n    expected, otherwise raise ValidationError.\n    \"\"\"\n    messages = {\n        'invalid': _('Enter a number.'),\n        'max_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit in total.',\n            'Ensure that there are no more than %(max)s digits in total.',\n            'max'\n        ),\n        'max_decimal_places': ngettext_lazy(\n            'Ensure that there are no more than %(max)s decimal place.',\n            'Ensure that there are no more than %(max)s decimal places.',\n            'max'\n        ),\n        'max_whole_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit before the decimal point.',\n            'Ensure that there are no more than %(max)s digits before the decimal point.',\n            'max'\n        ),\n    }\n\n    def __init__(self, max_digits, decimal_places):\n        self.max_digits = max_digits\n        self.decimal_places = decimal_places\n\n    def __call__(self, value):\n        digit_tuple, exponent = value.as_tuple()[1:]\n        if exponent in {'F', 'n', 'N'}:\n            raise ValidationError(self.messages['invalid'], code='invalid', params={'value': value})\n        if exponent >= 0:\n            # A positive exponent adds that many trailing zeros.\n            digits = len(digit_tuple) + exponent\n            decimals = 0\n        else:\n            # If the absolute value of the negative exponent is larger than the\n            # number of digits, then it's the same as the number of digits,\n            # because it'll consume all of the digits in digit_tuple and then\n            # add abs(exponent) - len(digit_tuple) leading zeros after the\n            # decimal point.\n            if abs(exponent) > len(digit_tuple):\n                digits = decimals = abs(exponent)\n            else:\n                digits = len(digit_tuple)\n                decimals = abs(exponent)\n        whole_digits = digits - decimals\n\n        if self.max_digits is not None and digits > self.max_digits:\n            raise ValidationError(\n                self.messages['max_digits'],\n                code='max_digits',\n                params={'max': self.max_digits, 'value': value},\n            )\n        if self.decimal_places is not None and decimals > self.decimal_places:\n            raise ValidationError(\n                self.messages['max_decimal_places'],\n                code='max_decimal_places',\n                params={'max': self.decimal_places, 'value': value},\n            )\n        if (self.max_digits is not None and self.decimal_places is not None and\n                whole_digits > (self.max_digits - self.decimal_places)):\n            raise ValidationError(\n                self.messages['max_whole_digits'],\n                code='max_whole_digits',\n                params={'max': (self.max_digits - self.decimal_places), 'value': value},\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.max_digits == other.max_digits and\n            self.decimal_places == other.decimal_places\n        )\n\n\n@deconstructible\nclass FileExtensionValidator:\n    message = _(\n        'File extension \u201c%(extension)s\u201d is not allowed. '\n        'Allowed extensions are: %(allowed_extensions)s.'\n    )\n    code = 'invalid_extension'\n\n    def __init__(self, allowed_extensions=None, message=None, code=None):\n        if allowed_extensions is not None:\n            allowed_extensions = [allowed_extension.lower() for allowed_extension in allowed_extensions]\n        self.allowed_extensions = allowed_extensions\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        extension = Path(value.name).suffix[1:].lower()\n        if self.allowed_extensions is not None and extension not in self.allowed_extensions:\n            raise ValidationError(\n                self.message,\n                code=self.code,\n                params={\n                    'extension': extension,\n                    'allowed_extensions': ', '.join(self.allowed_extensions),\n                    'value': value,\n                }\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.allowed_extensions == other.allowed_extensions and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n\ndef get_available_image_extensions():\n    try:\n        from PIL import Image\n    except ImportError:\n        return []\n    else:\n        Image.init()\n        return [ext.lower()[1:] for ext in Image.EXTENSION]\n\n\ndef validate_image_file_extension(value):\n    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(value)\n\n\n@deconstructible\nclass ProhibitNullCharactersValidator:\n    \"\"\"Validate that the string doesn't contain the null character.\"\"\"\n    message = _('Null characters are not allowed.')\n    code = 'null_characters_not_allowed'\n\n    def __init__(self, message=None, code=None):\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        if '\\x00' in str(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.message == other.message and\n            self.code == other.code\n        )\n",
    "code_after": "import ipaddress\nimport re\nimport warnings\nfrom pathlib import Path\nfrom urllib.parse import urlsplit, urlunsplit\n\nfrom django.core.exceptions import ValidationError\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.deprecation import RemovedInDjango41Warning\nfrom django.utils.encoding import punycode\nfrom django.utils.ipv6 import is_valid_ipv6_address\nfrom django.utils.regex_helper import _lazy_re_compile\nfrom django.utils.translation import gettext_lazy as _, ngettext_lazy\n\n# These values, if given to validate(), will trigger the self.required check.\nEMPTY_VALUES = (None, '', [], (), {})\n\n\n@deconstructible\nclass RegexValidator:\n    regex = ''\n    message = _('Enter a valid value.')\n    code = 'invalid'\n    inverse_match = False\n    flags = 0\n\n    def __init__(self, regex=None, message=None, code=None, inverse_match=None, flags=None):\n        if regex is not None:\n            self.regex = regex\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if inverse_match is not None:\n            self.inverse_match = inverse_match\n        if flags is not None:\n            self.flags = flags\n        if self.flags and not isinstance(self.regex, str):\n            raise TypeError(\"If the flags are set, regex must be a regular expression string.\")\n\n        self.regex = _lazy_re_compile(self.regex, self.flags)\n\n    def __call__(self, value):\n        \"\"\"\n        Validate that the input contains (or does *not* contain, if\n        inverse_match is True) a match for the regular expression.\n        \"\"\"\n        regex_matches = self.regex.search(str(value))\n        invalid_input = regex_matches if self.inverse_match else not regex_matches\n        if invalid_input:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, RegexValidator) and\n            self.regex.pattern == other.regex.pattern and\n            self.regex.flags == other.regex.flags and\n            (self.message == other.message) and\n            (self.code == other.code) and\n            (self.inverse_match == other.inverse_match)\n        )\n\n\n@deconstructible\nclass URLValidator(RegexValidator):\n    ul = '\\u00a1-\\uffff'  # Unicode letters range (must not be a raw string).\n\n    # IP patterns\n    ipv4_re = r'(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}'\n    ipv6_re = r'\\[[0-9a-f:.]+\\]'  # (simple regex, validated later)\n\n    # Host patterns\n    hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?'\n    # Max length for domain name labels is 63 characters per RFC 1034 sec. 3.1\n    domain_re = r'(?:\\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*'\n    tld_re = (\n        r'\\.'                                # dot\n        r'(?!-)'                             # can't start with a dash\n        r'(?:[a-z' + ul + '-]{2,63}'         # domain label\n        r'|xn--[a-z0-9]{1,59})'              # or punycode label\n        r'(?<!-)'                            # can't end with a dash\n        r'\\.?'                               # may have a trailing dot\n    )\n    host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n\n    regex = _lazy_re_compile(\n        r'^(?:[a-z0-9.+-]*)://'  # scheme is validated separately\n        r'(?:[^\\s:@/]+(?::[^\\s:@/]*)?@)?'  # user:pass authentication\n        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n        r'(?::\\d{2,5})?'  # port\n        r'(?:[/?#][^\\s]*)?'  # resource path\n        r'\\Z', re.IGNORECASE)\n    message = _('Enter a valid URL.')\n    schemes = ['http', 'https', 'ftp', 'ftps']\n    unsafe_chars = frozenset('\\t\\r\\n')\n\n    def __init__(self, schemes=None, **kwargs):\n        super().__init__(**kwargs)\n        if schemes is not None:\n            self.schemes = schemes\n\n    def __call__(self, value):\n        if not isinstance(value, str):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        if self.unsafe_chars.intersection(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n        # Check if the scheme is valid.\n        scheme = value.split('://')[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # Then check full URL\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                try:\n                    scheme, netloc, path, query, fragment = urlsplit(value)\n                except ValueError:  # for example, \"Invalid IPv6 URL\"\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r'^\\[(.+)\\](?::\\d{2,5})?$', urlsplit(value).netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if len(urlsplit(value).hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n\ninteger_validator = RegexValidator(\n    _lazy_re_compile(r'^-?\\d+\\Z'),\n    message=_('Enter a valid integer.'),\n    code='invalid',\n)\n\n\ndef validate_integer(value):\n    return integer_validator(value)\n\n\n@deconstructible\nclass EmailValidator:\n    message = _('Enter a valid email address.')\n    code = 'invalid'\n    user_regex = _lazy_re_compile(\n        r\"(^[-!#$%&'*+/=?^_`{}|~0-9A-Z]+(\\.[-!#$%&'*+/=?^_`{}|~0-9A-Z]+)*\\Z\"  # dot-atom\n        r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',  # quoted-string\n        re.IGNORECASE)\n    domain_regex = _lazy_re_compile(\n        # max length for domain name labels is 63 characters per RFC 1034\n        r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\\Z',\n        re.IGNORECASE)\n    literal_regex = _lazy_re_compile(\n        # literal form, ipv4 or ipv6 address (SMTP 4.1.3)\n        r'\\[([A-f0-9:.]+)\\]\\Z',\n        re.IGNORECASE)\n    domain_allowlist = ['localhost']\n\n    @property\n    def domain_whitelist(self):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        return self.domain_allowlist\n\n    @domain_whitelist.setter\n    def domain_whitelist(self, allowlist):\n        warnings.warn(\n            'The domain_whitelist attribute is deprecated in favor of '\n            'domain_allowlist.',\n            RemovedInDjango41Warning,\n            stacklevel=2,\n        )\n        self.domain_allowlist = allowlist\n\n    def __init__(self, message=None, code=None, allowlist=None, *, whitelist=None):\n        if whitelist is not None:\n            allowlist = whitelist\n            warnings.warn(\n                'The whitelist argument is deprecated in favor of allowlist.',\n                RemovedInDjango41Warning,\n                stacklevel=2,\n            )\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n        if allowlist is not None:\n            self.domain_allowlist = allowlist\n\n    def __call__(self, value):\n        if not value or '@' not in value:\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        user_part, domain_part = value.rsplit('@', 1)\n\n        if not self.user_regex.match(user_part):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n        if (domain_part not in self.domain_allowlist and\n                not self.validate_domain_part(domain_part)):\n            # Try for possible IDN domain-part\n            try:\n                domain_part = punycode(domain_part)\n            except UnicodeError:\n                pass\n            else:\n                if self.validate_domain_part(domain_part):\n                    return\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def validate_domain_part(self, domain_part):\n        if self.domain_regex.match(domain_part):\n            return True\n\n        literal_match = self.literal_regex.match(domain_part)\n        if literal_match:\n            ip_address = literal_match[1]\n            try:\n                validate_ipv46_address(ip_address)\n                return True\n            except ValidationError:\n                pass\n        return False\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, EmailValidator) and\n            (self.domain_allowlist == other.domain_allowlist) and\n            (self.message == other.message) and\n            (self.code == other.code)\n        )\n\n\nvalidate_email = EmailValidator()\n\nslug_re = _lazy_re_compile(r'^[-a-zA-Z0-9_]+\\Z')\nvalidate_slug = RegexValidator(\n    slug_re,\n    # Translators: \"letters\" means latin letters: a-z and A-Z.\n    _('Enter a valid \u201cslug\u201d consisting of letters, numbers, underscores or hyphens.'),\n    'invalid'\n)\n\nslug_unicode_re = _lazy_re_compile(r'^[-\\w]+\\Z')\nvalidate_unicode_slug = RegexValidator(\n    slug_unicode_re,\n    _('Enter a valid \u201cslug\u201d consisting of Unicode letters, numbers, underscores, or hyphens.'),\n    'invalid'\n)\n\n\ndef validate_ipv4_address(value):\n    try:\n        ipaddress.IPv4Address(value)\n    except ValueError:\n        raise ValidationError(_('Enter a valid IPv4 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv6_address(value):\n    if not is_valid_ipv6_address(value):\n        raise ValidationError(_('Enter a valid IPv6 address.'), code='invalid', params={'value': value})\n\n\ndef validate_ipv46_address(value):\n    try:\n        validate_ipv4_address(value)\n    except ValidationError:\n        try:\n            validate_ipv6_address(value)\n        except ValidationError:\n            raise ValidationError(_('Enter a valid IPv4 or IPv6 address.'), code='invalid', params={'value': value})\n\n\nip_address_validator_map = {\n    'both': ([validate_ipv46_address], _('Enter a valid IPv4 or IPv6 address.')),\n    'ipv4': ([validate_ipv4_address], _('Enter a valid IPv4 address.')),\n    'ipv6': ([validate_ipv6_address], _('Enter a valid IPv6 address.')),\n}\n\n\ndef ip_address_validators(protocol, unpack_ipv4):\n    \"\"\"\n    Depending on the given parameters, return the appropriate validators for\n    the GenericIPAddressField.\n    \"\"\"\n    if protocol != 'both' and unpack_ipv4:\n        raise ValueError(\n            \"You can only use `unpack_ipv4` if `protocol` is set to 'both'\")\n    try:\n        return ip_address_validator_map[protocol.lower()]\n    except KeyError:\n        raise ValueError(\"The protocol '%s' is unknown. Supported: %s\"\n                         % (protocol, list(ip_address_validator_map)))\n\n\ndef int_list_validator(sep=',', message=None, code='invalid', allow_negative=False):\n    regexp = _lazy_re_compile(r'^%(neg)s\\d+(?:%(sep)s%(neg)s\\d+)*\\Z' % {\n        'neg': '(-)?' if allow_negative else '',\n        'sep': re.escape(sep),\n    })\n    return RegexValidator(regexp, message=message, code=code)\n\n\nvalidate_comma_separated_integer_list = int_list_validator(\n    message=_('Enter only digits separated by commas.'),\n)\n\n\n@deconstructible\nclass BaseValidator:\n    message = _('Ensure this value is %(limit_value)s (it is %(show_value)s).')\n    code = 'limit_value'\n\n    def __init__(self, limit_value, message=None):\n        self.limit_value = limit_value\n        if message:\n            self.message = message\n\n    def __call__(self, value):\n        cleaned = self.clean(value)\n        limit_value = self.limit_value() if callable(self.limit_value) else self.limit_value\n        params = {'limit_value': limit_value, 'show_value': cleaned, 'value': value}\n        if self.compare(cleaned, limit_value):\n            raise ValidationError(self.message, code=self.code, params=params)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return (\n            self.limit_value == other.limit_value and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n    def compare(self, a, b):\n        return a is not b\n\n    def clean(self, x):\n        return x\n\n\n@deconstructible\nclass MaxValueValidator(BaseValidator):\n    message = _('Ensure this value is less than or equal to %(limit_value)s.')\n    code = 'max_value'\n\n    def compare(self, a, b):\n        return a > b\n\n\n@deconstructible\nclass MinValueValidator(BaseValidator):\n    message = _('Ensure this value is greater than or equal to %(limit_value)s.')\n    code = 'min_value'\n\n    def compare(self, a, b):\n        return a < b\n\n\n@deconstructible\nclass MinLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at least %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at least %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'min_length'\n\n    def compare(self, a, b):\n        return a < b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass MaxLengthValidator(BaseValidator):\n    message = ngettext_lazy(\n        'Ensure this value has at most %(limit_value)d character (it has %(show_value)d).',\n        'Ensure this value has at most %(limit_value)d characters (it has %(show_value)d).',\n        'limit_value')\n    code = 'max_length'\n\n    def compare(self, a, b):\n        return a > b\n\n    def clean(self, x):\n        return len(x)\n\n\n@deconstructible\nclass DecimalValidator:\n    \"\"\"\n    Validate that the input does not exceed the maximum number of digits\n    expected, otherwise raise ValidationError.\n    \"\"\"\n    messages = {\n        'invalid': _('Enter a number.'),\n        'max_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit in total.',\n            'Ensure that there are no more than %(max)s digits in total.',\n            'max'\n        ),\n        'max_decimal_places': ngettext_lazy(\n            'Ensure that there are no more than %(max)s decimal place.',\n            'Ensure that there are no more than %(max)s decimal places.',\n            'max'\n        ),\n        'max_whole_digits': ngettext_lazy(\n            'Ensure that there are no more than %(max)s digit before the decimal point.',\n            'Ensure that there are no more than %(max)s digits before the decimal point.',\n            'max'\n        ),\n    }\n\n    def __init__(self, max_digits, decimal_places):\n        self.max_digits = max_digits\n        self.decimal_places = decimal_places\n\n    def __call__(self, value):\n        digit_tuple, exponent = value.as_tuple()[1:]\n        if exponent in {'F', 'n', 'N'}:\n            raise ValidationError(self.messages['invalid'], code='invalid', params={'value': value})\n        if exponent >= 0:\n            # A positive exponent adds that many trailing zeros.\n            digits = len(digit_tuple) + exponent\n            decimals = 0\n        else:\n            # If the absolute value of the negative exponent is larger than the\n            # number of digits, then it's the same as the number of digits,\n            # because it'll consume all of the digits in digit_tuple and then\n            # add abs(exponent) - len(digit_tuple) leading zeros after the\n            # decimal point.\n            if abs(exponent) > len(digit_tuple):\n                digits = decimals = abs(exponent)\n            else:\n                digits = len(digit_tuple)\n                decimals = abs(exponent)\n        whole_digits = digits - decimals\n\n        if self.max_digits is not None and digits > self.max_digits:\n            raise ValidationError(\n                self.messages['max_digits'],\n                code='max_digits',\n                params={'max': self.max_digits, 'value': value},\n            )\n        if self.decimal_places is not None and decimals > self.decimal_places:\n            raise ValidationError(\n                self.messages['max_decimal_places'],\n                code='max_decimal_places',\n                params={'max': self.decimal_places, 'value': value},\n            )\n        if (self.max_digits is not None and self.decimal_places is not None and\n                whole_digits > (self.max_digits - self.decimal_places)):\n            raise ValidationError(\n                self.messages['max_whole_digits'],\n                code='max_whole_digits',\n                params={'max': (self.max_digits - self.decimal_places), 'value': value},\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.max_digits == other.max_digits and\n            self.decimal_places == other.decimal_places\n        )\n\n\n@deconstructible\nclass FileExtensionValidator:\n    message = _(\n        'File extension \u201c%(extension)s\u201d is not allowed. '\n        'Allowed extensions are: %(allowed_extensions)s.'\n    )\n    code = 'invalid_extension'\n\n    def __init__(self, allowed_extensions=None, message=None, code=None):\n        if allowed_extensions is not None:\n            allowed_extensions = [allowed_extension.lower() for allowed_extension in allowed_extensions]\n        self.allowed_extensions = allowed_extensions\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        extension = Path(value.name).suffix[1:].lower()\n        if self.allowed_extensions is not None and extension not in self.allowed_extensions:\n            raise ValidationError(\n                self.message,\n                code=self.code,\n                params={\n                    'extension': extension,\n                    'allowed_extensions': ', '.join(self.allowed_extensions),\n                    'value': value,\n                }\n            )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.allowed_extensions == other.allowed_extensions and\n            self.message == other.message and\n            self.code == other.code\n        )\n\n\ndef get_available_image_extensions():\n    try:\n        from PIL import Image\n    except ImportError:\n        return []\n    else:\n        Image.init()\n        return [ext.lower()[1:] for ext in Image.EXTENSION]\n\n\ndef validate_image_file_extension(value):\n    return FileExtensionValidator(allowed_extensions=get_available_image_extensions())(value)\n\n\n@deconstructible\nclass ProhibitNullCharactersValidator:\n    \"\"\"Validate that the string doesn't contain the null character.\"\"\"\n    message = _('Null characters are not allowed.')\n    code = 'null_characters_not_allowed'\n\n    def __init__(self, message=None, code=None):\n        if message is not None:\n            self.message = message\n        if code is not None:\n            self.code = code\n\n    def __call__(self, value):\n        if '\\x00' in str(value):\n            raise ValidationError(self.message, code=self.code, params={'value': value})\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, self.__class__) and\n            self.message == other.message and\n            self.code == other.code\n        )\n"
  },
  {
    "patch": "diff --git a/django/http/multipartparser.py b/django/http/multipartparser.py\nindex 8078393a66..180a533bb6 100644\n--- a/django/http/multipartparser.py\n+++ b/django/http/multipartparser.py\n@@ -212,9 +212,8 @@ class MultiPartParser:\n                     # This is a file, use the handler...\n                     file_name = disposition.get('filename')\n                     if file_name:\n-                        file_name = os.path.basename(file_name)\n                         file_name = force_str(file_name, encoding, errors='replace')\n-                        file_name = self.IE_sanitize(html.unescape(file_name))\n+                        file_name = self.sanitize_file_name(file_name)\n                     if not file_name:\n                         continue\n \n@@ -306,9 +305,13 @@ class MultiPartParser:\n                 self._files.appendlist(force_str(old_field_name, self._encoding, errors='replace'), file_obj)\n                 break\n \n-    def IE_sanitize(self, filename):\n-        \"\"\"Cleanup filename from Internet Explorer full paths.\"\"\"\n-        return filename and filename[filename.rfind(\"\\\\\") + 1:].strip()\n+    def sanitize_file_name(self, file_name):\n+        file_name = html.unescape(file_name)\n+        # Cleanup Windows-style path separators.\n+        file_name = file_name[file_name.rfind('\\\\') + 1:].strip()\n+        return os.path.basename(file_name)\n+\n+    IE_sanitize = sanitize_file_name\n \n     def _close_files(self):\n         # Free up all file handles.\n",
    "commit_message": "Fixed CVE-2021-28658 -- Fixed potential directory-traversal via uploaded files.\n\nThanks Claude Paroz for the initial patch.\nThanks Dennis Brinkrolf for the report.\n\n",
    "code_before": "\"\"\"\nMulti-part parsing for file uploads.\n\nExposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to\nfile upload handlers for processing.\n\"\"\"\nimport base64\nimport binascii\nimport cgi\nimport collections\nimport html\nimport os\nfrom urllib.parse import unquote\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    RequestDataTooBig, SuspiciousMultipartForm, TooManyFieldsSent,\n)\nfrom django.core.files.uploadhandler import (\n    SkipFile, StopFutureHandlers, StopUpload,\n)\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_str\n\n__all__ = ('MultiPartParser', 'MultiPartParserError', 'InputStreamExhausted')\n\n\nclass MultiPartParserError(Exception):\n    pass\n\n\nclass InputStreamExhausted(Exception):\n    \"\"\"\n    No more reads are allowed from this device.\n    \"\"\"\n    pass\n\n\nRAW = \"raw\"\nFILE = \"file\"\nFIELD = \"field\"\n\n\nclass MultiPartParser:\n    \"\"\"\n    A rfc2388 multipart/form-data parser.\n\n    ``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks\n    and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``.\n    \"\"\"\n    def __init__(self, META, input_data, upload_handlers, encoding=None):\n        \"\"\"\n        Initialize the MultiPartParser object.\n\n        :META:\n            The standard ``META`` dictionary in Django request objects.\n        :input_data:\n            The raw post data, as a file-like object.\n        :upload_handlers:\n            A list of UploadHandler instances that perform operations on the\n            uploaded data.\n        :encoding:\n            The encoding with which to treat the incoming data.\n        \"\"\"\n        # Content-Type should contain multipart and the boundary information.\n        content_type = META.get('CONTENT_TYPE', '')\n        if not content_type.startswith('multipart/'):\n            raise MultiPartParserError('Invalid Content-Type: %s' % content_type)\n\n        # Parse the header to get the boundary to split the parts.\n        try:\n            ctypes, opts = parse_header(content_type.encode('ascii'))\n        except UnicodeEncodeError:\n            raise MultiPartParserError('Invalid non-ASCII Content-Type in multipart: %s' % force_str(content_type))\n        boundary = opts.get('boundary')\n        if not boundary or not cgi.valid_boundary(boundary):\n            raise MultiPartParserError('Invalid boundary in multipart: %s' % force_str(boundary))\n\n        # Content-Length should contain the length of the body we are about\n        # to receive.\n        try:\n            content_length = int(META.get('CONTENT_LENGTH', 0))\n        except (ValueError, TypeError):\n            content_length = 0\n\n        if content_length < 0:\n            # This means we shouldn't continue...raise an error.\n            raise MultiPartParserError(\"Invalid content length: %r\" % content_length)\n\n        if isinstance(boundary, str):\n            boundary = boundary.encode('ascii')\n        self._boundary = boundary\n        self._input_data = input_data\n\n        # For compatibility with low-level network APIs (with 32-bit integers),\n        # the chunk size should be < 2^31, but still divisible by 4.\n        possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size]\n        self._chunk_size = min([2 ** 31 - 4] + possible_sizes)\n\n        self._meta = META\n        self._encoding = encoding or settings.DEFAULT_CHARSET\n        self._content_length = content_length\n        self._upload_handlers = upload_handlers\n\n    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = os.path.basename(file_name)\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.IE_sanitize(html.unescape(file_name))\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n\n    def handle_file_complete(self, old_field_name, counters):\n        \"\"\"\n        Handle all the signaling that takes place when a file is complete.\n        \"\"\"\n        for i, handler in enumerate(self._upload_handlers):\n            file_obj = handler.file_complete(counters[i])\n            if file_obj:\n                # If it returns a file object, then set the files dict.\n                self._files.appendlist(force_str(old_field_name, self._encoding, errors='replace'), file_obj)\n                break\n\n    def IE_sanitize(self, filename):\n        \"\"\"Cleanup filename from Internet Explorer full paths.\"\"\"\n        return filename and filename[filename.rfind(\"\\\\\") + 1:].strip()\n\n    def _close_files(self):\n        # Free up all file handles.\n        # FIXME: this currently assumes that upload handlers store the file as 'file'\n        # We should document that... (Maybe add handler.free_file to complement new_file)\n        for handler in self._upload_handlers:\n            if hasattr(handler, 'file'):\n                handler.file.close()\n\n\nclass LazyStream:\n    \"\"\"\n    The LazyStream wrapper allows one to get and \"unget\" bytes from a stream.\n\n    Given a producer object (an iterator that yields bytestrings), the\n    LazyStream object will support iteration, reading, and keeping a \"look-back\"\n    variable in case you need to \"unget\" some bytes.\n    \"\"\"\n    def __init__(self, producer, length=None):\n        \"\"\"\n        Every LazyStream must have a producer when instantiated.\n\n        A producer is an iterable that returns a string each time it\n        is called.\n        \"\"\"\n        self._producer = producer\n        self._empty = False\n        self._leftover = b''\n        self.length = length\n        self.position = 0\n        self._remaining = length\n        self._unget_history = []\n\n    def tell(self):\n        return self.position\n\n    def read(self, size=None):\n        def parts():\n            remaining = self._remaining if size is None else size\n            # do the whole thing in one shot if no limit was provided.\n            if remaining is None:\n                yield b''.join(self)\n                return\n\n            # otherwise do some bookkeeping to return exactly enough\n            # of the stream and stashing any extra content we get from\n            # the producer\n            while remaining != 0:\n                assert remaining > 0, 'remaining bytes to read should never go negative'\n\n                try:\n                    chunk = next(self)\n                except StopIteration:\n                    return\n                else:\n                    emitting = chunk[:remaining]\n                    self.unget(chunk[remaining:])\n                    remaining -= len(emitting)\n                    yield emitting\n\n        return b''.join(parts())\n\n    def __next__(self):\n        \"\"\"\n        Used when the exact number of bytes to read is unimportant.\n\n        Return whatever chunk is conveniently returned from the iterator.\n        Useful to avoid unnecessary bookkeeping if performance is an issue.\n        \"\"\"\n        if self._leftover:\n            output = self._leftover\n            self._leftover = b''\n        else:\n            output = next(self._producer)\n            self._unget_history = []\n        self.position += len(output)\n        return output\n\n    def close(self):\n        \"\"\"\n        Used to invalidate/disable this lazy stream.\n\n        Replace the producer with an empty list. Any leftover bytes that have\n        already been read will still be reported upon read() and/or next().\n        \"\"\"\n        self._producer = []\n\n    def __iter__(self):\n        return self\n\n    def unget(self, bytes):\n        \"\"\"\n        Place bytes back onto the front of the lazy stream.\n\n        Future calls to read() will return those bytes first. The\n        stream position and thus tell() will be rewound.\n        \"\"\"\n        if not bytes:\n            return\n        self._update_unget_history(len(bytes))\n        self.position -= len(bytes)\n        self._leftover = bytes + self._leftover\n\n    def _update_unget_history(self, num_bytes):\n        \"\"\"\n        Update the unget history as a sanity check to see if we've pushed\n        back the same number of bytes in one chunk. If we keep ungetting the\n        same number of bytes many times (here, 50), we're mostly likely in an\n        infinite loop of some sort. This is usually caused by a\n        maliciously-malformed MIME request.\n        \"\"\"\n        self._unget_history = [num_bytes] + self._unget_history[:49]\n        number_equal = len([\n            current_number for current_number in self._unget_history\n            if current_number == num_bytes\n        ])\n\n        if number_equal > 40:\n            raise SuspiciousMultipartForm(\n                \"The multipart parser got stuck, which shouldn't happen with\"\n                \" normal uploaded files. Check for malicious upload activity;\"\n                \" if there is none, report this to the Django developers.\"\n            )\n\n\nclass ChunkIter:\n    \"\"\"\n    An iterable that will yield chunks of data. Given a file-like object as the\n    constructor, yield chunks of read operations from that object.\n    \"\"\"\n    def __init__(self, flo, chunk_size=64 * 1024):\n        self.flo = flo\n        self.chunk_size = chunk_size\n\n    def __next__(self):\n        try:\n            data = self.flo.read(self.chunk_size)\n        except InputStreamExhausted:\n            raise StopIteration()\n        if data:\n            return data\n        else:\n            raise StopIteration()\n\n    def __iter__(self):\n        return self\n\n\nclass InterBoundaryIter:\n    \"\"\"\n    A Producer that will iterate over boundaries.\n    \"\"\"\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return LazyStream(BoundaryIter(self._stream, self._boundary))\n        except InputStreamExhausted:\n            raise StopIteration()\n\n\nclass BoundaryIter:\n    \"\"\"\n    A Producer that is sensitive to boundaries.\n\n    Will happily yield bytes until a boundary is found. Will yield the bytes\n    before the boundary, throw away the boundary bytes themselves, and push the\n    post-boundary bytes back on the stream.\n\n    The future calls to next() after locating the boundary will raise a\n    StopIteration exception.\n    \"\"\"\n\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n        self._done = False\n        # rollback an additional six bytes because the format is like\n        # this: CRLF<boundary>[--CRLF]\n        self._rollback = len(boundary) + 6\n\n        # Try to use mx fast string search if available. Otherwise\n        # use Python find. Wrap the latter for consistency.\n        unused_char = self._stream.read(1)\n        if not unused_char:\n            raise InputStreamExhausted()\n        self._stream.unget(unused_char)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._done:\n            raise StopIteration()\n\n        stream = self._stream\n        rollback = self._rollback\n\n        bytes_read = 0\n        chunks = []\n        for bytes in stream:\n            bytes_read += len(bytes)\n            chunks.append(bytes)\n            if bytes_read > rollback:\n                break\n            if not bytes:\n                break\n        else:\n            self._done = True\n\n        if not chunks:\n            raise StopIteration()\n\n        chunk = b''.join(chunks)\n        boundary = self._find_boundary(chunk)\n\n        if boundary:\n            end, next = boundary\n            stream.unget(chunk[next:])\n            self._done = True\n            return chunk[:end]\n        else:\n            # make sure we don't treat a partial boundary (and\n            # its separators) as data\n            if not chunk[:-rollback]:  # and len(chunk) >= (len(self._boundary) + 6):\n                # There's nothing left, we should just return and mark as done.\n                self._done = True\n                return chunk\n            else:\n                stream.unget(chunk[-rollback:])\n                return chunk[:-rollback]\n\n    def _find_boundary(self, data):\n        \"\"\"\n        Find a multipart boundary in data.\n\n        Should no boundary exist in the data, return None. Otherwise, return\n        a tuple containing the indices of the following:\n         * the end of current encapsulation\n         * the start of the next encapsulation\n        \"\"\"\n        index = data.find(self._boundary)\n        if index < 0:\n            return None\n        else:\n            end = index\n            next = index + len(self._boundary)\n            # backup over CRLF\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\n':\n                end -= 1\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\r':\n                end -= 1\n            return end, next\n\n\ndef exhaust(stream_or_iterable):\n    \"\"\"Exhaust an iterator or stream.\"\"\"\n    try:\n        iterator = iter(stream_or_iterable)\n    except TypeError:\n        iterator = ChunkIter(stream_or_iterable, 16384)\n    collections.deque(iterator, maxlen=0)  # consume iterator quickly.\n\n\ndef parse_boundary_stream(stream, max_header_size):\n    \"\"\"\n    Parse one and exactly one stream that encapsulates a boundary.\n    \"\"\"\n    # Stream at beginning of header, look for end of header\n    # and parse it if found. The header must fit within one\n    # chunk.\n    chunk = stream.read(max_header_size)\n\n    # 'find' returns the top of these four bytes, so we'll\n    # need to munch them later to prevent them from polluting\n    # the payload.\n    header_end = chunk.find(b'\\r\\n\\r\\n')\n\n    def _parse_header(line):\n        main_value_pair, params = parse_header(line)\n        try:\n            name, value = main_value_pair.split(':', 1)\n        except ValueError:\n            raise ValueError(\"Invalid header: %r\" % line)\n        return name, (value, params)\n\n    if header_end == -1:\n        # we find no header, so we just mark this fact and pass on\n        # the stream verbatim\n        stream.unget(chunk)\n        return (RAW, {}, stream)\n\n    header = chunk[:header_end]\n\n    # here we place any excess chunk back onto the stream, as\n    # well as throwing away the CRLFCRLF bytes from above.\n    stream.unget(chunk[header_end + 4:])\n\n    TYPE = RAW\n    outdict = {}\n\n    # Eliminate blank lines\n    for line in header.split(b'\\r\\n'):\n        # This terminology (\"main value\" and \"dictionary of\n        # parameters\") is from the Python docs.\n        try:\n            name, (value, params) = _parse_header(line)\n        except ValueError:\n            continue\n\n        if name == 'content-disposition':\n            TYPE = FIELD\n            if params.get('filename'):\n                TYPE = FILE\n\n        outdict[name] = value, params\n\n    if TYPE == RAW:\n        stream.unget(chunk)\n\n    return (TYPE, outdict, stream)\n\n\nclass Parser:\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._separator = b'--' + boundary\n\n    def __iter__(self):\n        boundarystream = InterBoundaryIter(self._stream, self._separator)\n        for sub_stream in boundarystream:\n            # Iterate over each part\n            yield parse_boundary_stream(sub_stream, 1024)\n\n\ndef parse_header(line):\n    \"\"\"\n    Parse the header into a key-value.\n\n    Input (line): bytes, output: str for key/name, bytes for values which\n    will be decoded later.\n    \"\"\"\n    plist = _parse_header_params(b';' + line)\n    key = plist.pop(0).lower().decode('ascii')\n    pdict = {}\n    for p in plist:\n        i = p.find(b'=')\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower().decode('ascii')\n            if name.endswith('*'):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # http://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(b\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1:].strip()\n            if len(value) >= 2 and value[:1] == value[-1:] == b'\"':\n                value = value[1:-1]\n                value = value.replace(b'\\\\\\\\', b'\\\\').replace(b'\\\\\"', b'\"')\n            if has_encoding:\n                encoding, lang, value = value.split(b\"'\")\n                value = unquote(value.decode(), encoding=encoding.decode())\n            pdict[name] = value\n    return key, pdict\n\n\ndef _parse_header_params(s):\n    plist = []\n    while s[:1] == b';':\n        s = s[1:]\n        end = s.find(b';')\n        while end > 0 and s.count(b'\"', 0, end) % 2:\n            end = s.find(b';', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        plist.append(f.strip())\n        s = s[end:]\n    return plist\n",
    "code_after": "\"\"\"\nMulti-part parsing for file uploads.\n\nExposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to\nfile upload handlers for processing.\n\"\"\"\nimport base64\nimport binascii\nimport cgi\nimport collections\nimport html\nimport os\nfrom urllib.parse import unquote\n\nfrom django.conf import settings\nfrom django.core.exceptions import (\n    RequestDataTooBig, SuspiciousMultipartForm, TooManyFieldsSent,\n)\nfrom django.core.files.uploadhandler import (\n    SkipFile, StopFutureHandlers, StopUpload,\n)\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_str\n\n__all__ = ('MultiPartParser', 'MultiPartParserError', 'InputStreamExhausted')\n\n\nclass MultiPartParserError(Exception):\n    pass\n\n\nclass InputStreamExhausted(Exception):\n    \"\"\"\n    No more reads are allowed from this device.\n    \"\"\"\n    pass\n\n\nRAW = \"raw\"\nFILE = \"file\"\nFIELD = \"field\"\n\n\nclass MultiPartParser:\n    \"\"\"\n    A rfc2388 multipart/form-data parser.\n\n    ``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks\n    and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``.\n    \"\"\"\n    def __init__(self, META, input_data, upload_handlers, encoding=None):\n        \"\"\"\n        Initialize the MultiPartParser object.\n\n        :META:\n            The standard ``META`` dictionary in Django request objects.\n        :input_data:\n            The raw post data, as a file-like object.\n        :upload_handlers:\n            A list of UploadHandler instances that perform operations on the\n            uploaded data.\n        :encoding:\n            The encoding with which to treat the incoming data.\n        \"\"\"\n        # Content-Type should contain multipart and the boundary information.\n        content_type = META.get('CONTENT_TYPE', '')\n        if not content_type.startswith('multipart/'):\n            raise MultiPartParserError('Invalid Content-Type: %s' % content_type)\n\n        # Parse the header to get the boundary to split the parts.\n        try:\n            ctypes, opts = parse_header(content_type.encode('ascii'))\n        except UnicodeEncodeError:\n            raise MultiPartParserError('Invalid non-ASCII Content-Type in multipart: %s' % force_str(content_type))\n        boundary = opts.get('boundary')\n        if not boundary or not cgi.valid_boundary(boundary):\n            raise MultiPartParserError('Invalid boundary in multipart: %s' % force_str(boundary))\n\n        # Content-Length should contain the length of the body we are about\n        # to receive.\n        try:\n            content_length = int(META.get('CONTENT_LENGTH', 0))\n        except (ValueError, TypeError):\n            content_length = 0\n\n        if content_length < 0:\n            # This means we shouldn't continue...raise an error.\n            raise MultiPartParserError(\"Invalid content length: %r\" % content_length)\n\n        if isinstance(boundary, str):\n            boundary = boundary.encode('ascii')\n        self._boundary = boundary\n        self._input_data = input_data\n\n        # For compatibility with low-level network APIs (with 32-bit integers),\n        # the chunk size should be < 2^31, but still divisible by 4.\n        possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size]\n        self._chunk_size = min([2 ** 31 - 4] + possible_sizes)\n\n        self._meta = META\n        self._encoding = encoding or settings.DEFAULT_CHARSET\n        self._content_length = content_length\n        self._upload_handlers = upload_handlers\n\n    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n\n    def handle_file_complete(self, old_field_name, counters):\n        \"\"\"\n        Handle all the signaling that takes place when a file is complete.\n        \"\"\"\n        for i, handler in enumerate(self._upload_handlers):\n            file_obj = handler.file_complete(counters[i])\n            if file_obj:\n                # If it returns a file object, then set the files dict.\n                self._files.appendlist(force_str(old_field_name, self._encoding, errors='replace'), file_obj)\n                break\n\n    def sanitize_file_name(self, file_name):\n        file_name = html.unescape(file_name)\n        # Cleanup Windows-style path separators.\n        file_name = file_name[file_name.rfind('\\\\') + 1:].strip()\n        return os.path.basename(file_name)\n\n    IE_sanitize = sanitize_file_name\n\n    def _close_files(self):\n        # Free up all file handles.\n        # FIXME: this currently assumes that upload handlers store the file as 'file'\n        # We should document that... (Maybe add handler.free_file to complement new_file)\n        for handler in self._upload_handlers:\n            if hasattr(handler, 'file'):\n                handler.file.close()\n\n\nclass LazyStream:\n    \"\"\"\n    The LazyStream wrapper allows one to get and \"unget\" bytes from a stream.\n\n    Given a producer object (an iterator that yields bytestrings), the\n    LazyStream object will support iteration, reading, and keeping a \"look-back\"\n    variable in case you need to \"unget\" some bytes.\n    \"\"\"\n    def __init__(self, producer, length=None):\n        \"\"\"\n        Every LazyStream must have a producer when instantiated.\n\n        A producer is an iterable that returns a string each time it\n        is called.\n        \"\"\"\n        self._producer = producer\n        self._empty = False\n        self._leftover = b''\n        self.length = length\n        self.position = 0\n        self._remaining = length\n        self._unget_history = []\n\n    def tell(self):\n        return self.position\n\n    def read(self, size=None):\n        def parts():\n            remaining = self._remaining if size is None else size\n            # do the whole thing in one shot if no limit was provided.\n            if remaining is None:\n                yield b''.join(self)\n                return\n\n            # otherwise do some bookkeeping to return exactly enough\n            # of the stream and stashing any extra content we get from\n            # the producer\n            while remaining != 0:\n                assert remaining > 0, 'remaining bytes to read should never go negative'\n\n                try:\n                    chunk = next(self)\n                except StopIteration:\n                    return\n                else:\n                    emitting = chunk[:remaining]\n                    self.unget(chunk[remaining:])\n                    remaining -= len(emitting)\n                    yield emitting\n\n        return b''.join(parts())\n\n    def __next__(self):\n        \"\"\"\n        Used when the exact number of bytes to read is unimportant.\n\n        Return whatever chunk is conveniently returned from the iterator.\n        Useful to avoid unnecessary bookkeeping if performance is an issue.\n        \"\"\"\n        if self._leftover:\n            output = self._leftover\n            self._leftover = b''\n        else:\n            output = next(self._producer)\n            self._unget_history = []\n        self.position += len(output)\n        return output\n\n    def close(self):\n        \"\"\"\n        Used to invalidate/disable this lazy stream.\n\n        Replace the producer with an empty list. Any leftover bytes that have\n        already been read will still be reported upon read() and/or next().\n        \"\"\"\n        self._producer = []\n\n    def __iter__(self):\n        return self\n\n    def unget(self, bytes):\n        \"\"\"\n        Place bytes back onto the front of the lazy stream.\n\n        Future calls to read() will return those bytes first. The\n        stream position and thus tell() will be rewound.\n        \"\"\"\n        if not bytes:\n            return\n        self._update_unget_history(len(bytes))\n        self.position -= len(bytes)\n        self._leftover = bytes + self._leftover\n\n    def _update_unget_history(self, num_bytes):\n        \"\"\"\n        Update the unget history as a sanity check to see if we've pushed\n        back the same number of bytes in one chunk. If we keep ungetting the\n        same number of bytes many times (here, 50), we're mostly likely in an\n        infinite loop of some sort. This is usually caused by a\n        maliciously-malformed MIME request.\n        \"\"\"\n        self._unget_history = [num_bytes] + self._unget_history[:49]\n        number_equal = len([\n            current_number for current_number in self._unget_history\n            if current_number == num_bytes\n        ])\n\n        if number_equal > 40:\n            raise SuspiciousMultipartForm(\n                \"The multipart parser got stuck, which shouldn't happen with\"\n                \" normal uploaded files. Check for malicious upload activity;\"\n                \" if there is none, report this to the Django developers.\"\n            )\n\n\nclass ChunkIter:\n    \"\"\"\n    An iterable that will yield chunks of data. Given a file-like object as the\n    constructor, yield chunks of read operations from that object.\n    \"\"\"\n    def __init__(self, flo, chunk_size=64 * 1024):\n        self.flo = flo\n        self.chunk_size = chunk_size\n\n    def __next__(self):\n        try:\n            data = self.flo.read(self.chunk_size)\n        except InputStreamExhausted:\n            raise StopIteration()\n        if data:\n            return data\n        else:\n            raise StopIteration()\n\n    def __iter__(self):\n        return self\n\n\nclass InterBoundaryIter:\n    \"\"\"\n    A Producer that will iterate over boundaries.\n    \"\"\"\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return LazyStream(BoundaryIter(self._stream, self._boundary))\n        except InputStreamExhausted:\n            raise StopIteration()\n\n\nclass BoundaryIter:\n    \"\"\"\n    A Producer that is sensitive to boundaries.\n\n    Will happily yield bytes until a boundary is found. Will yield the bytes\n    before the boundary, throw away the boundary bytes themselves, and push the\n    post-boundary bytes back on the stream.\n\n    The future calls to next() after locating the boundary will raise a\n    StopIteration exception.\n    \"\"\"\n\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._boundary = boundary\n        self._done = False\n        # rollback an additional six bytes because the format is like\n        # this: CRLF<boundary>[--CRLF]\n        self._rollback = len(boundary) + 6\n\n        # Try to use mx fast string search if available. Otherwise\n        # use Python find. Wrap the latter for consistency.\n        unused_char = self._stream.read(1)\n        if not unused_char:\n            raise InputStreamExhausted()\n        self._stream.unget(unused_char)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._done:\n            raise StopIteration()\n\n        stream = self._stream\n        rollback = self._rollback\n\n        bytes_read = 0\n        chunks = []\n        for bytes in stream:\n            bytes_read += len(bytes)\n            chunks.append(bytes)\n            if bytes_read > rollback:\n                break\n            if not bytes:\n                break\n        else:\n            self._done = True\n\n        if not chunks:\n            raise StopIteration()\n\n        chunk = b''.join(chunks)\n        boundary = self._find_boundary(chunk)\n\n        if boundary:\n            end, next = boundary\n            stream.unget(chunk[next:])\n            self._done = True\n            return chunk[:end]\n        else:\n            # make sure we don't treat a partial boundary (and\n            # its separators) as data\n            if not chunk[:-rollback]:  # and len(chunk) >= (len(self._boundary) + 6):\n                # There's nothing left, we should just return and mark as done.\n                self._done = True\n                return chunk\n            else:\n                stream.unget(chunk[-rollback:])\n                return chunk[:-rollback]\n\n    def _find_boundary(self, data):\n        \"\"\"\n        Find a multipart boundary in data.\n\n        Should no boundary exist in the data, return None. Otherwise, return\n        a tuple containing the indices of the following:\n         * the end of current encapsulation\n         * the start of the next encapsulation\n        \"\"\"\n        index = data.find(self._boundary)\n        if index < 0:\n            return None\n        else:\n            end = index\n            next = index + len(self._boundary)\n            # backup over CRLF\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\n':\n                end -= 1\n            last = max(0, end - 1)\n            if data[last:last + 1] == b'\\r':\n                end -= 1\n            return end, next\n\n\ndef exhaust(stream_or_iterable):\n    \"\"\"Exhaust an iterator or stream.\"\"\"\n    try:\n        iterator = iter(stream_or_iterable)\n    except TypeError:\n        iterator = ChunkIter(stream_or_iterable, 16384)\n    collections.deque(iterator, maxlen=0)  # consume iterator quickly.\n\n\ndef parse_boundary_stream(stream, max_header_size):\n    \"\"\"\n    Parse one and exactly one stream that encapsulates a boundary.\n    \"\"\"\n    # Stream at beginning of header, look for end of header\n    # and parse it if found. The header must fit within one\n    # chunk.\n    chunk = stream.read(max_header_size)\n\n    # 'find' returns the top of these four bytes, so we'll\n    # need to munch them later to prevent them from polluting\n    # the payload.\n    header_end = chunk.find(b'\\r\\n\\r\\n')\n\n    def _parse_header(line):\n        main_value_pair, params = parse_header(line)\n        try:\n            name, value = main_value_pair.split(':', 1)\n        except ValueError:\n            raise ValueError(\"Invalid header: %r\" % line)\n        return name, (value, params)\n\n    if header_end == -1:\n        # we find no header, so we just mark this fact and pass on\n        # the stream verbatim\n        stream.unget(chunk)\n        return (RAW, {}, stream)\n\n    header = chunk[:header_end]\n\n    # here we place any excess chunk back onto the stream, as\n    # well as throwing away the CRLFCRLF bytes from above.\n    stream.unget(chunk[header_end + 4:])\n\n    TYPE = RAW\n    outdict = {}\n\n    # Eliminate blank lines\n    for line in header.split(b'\\r\\n'):\n        # This terminology (\"main value\" and \"dictionary of\n        # parameters\") is from the Python docs.\n        try:\n            name, (value, params) = _parse_header(line)\n        except ValueError:\n            continue\n\n        if name == 'content-disposition':\n            TYPE = FIELD\n            if params.get('filename'):\n                TYPE = FILE\n\n        outdict[name] = value, params\n\n    if TYPE == RAW:\n        stream.unget(chunk)\n\n    return (TYPE, outdict, stream)\n\n\nclass Parser:\n    def __init__(self, stream, boundary):\n        self._stream = stream\n        self._separator = b'--' + boundary\n\n    def __iter__(self):\n        boundarystream = InterBoundaryIter(self._stream, self._separator)\n        for sub_stream in boundarystream:\n            # Iterate over each part\n            yield parse_boundary_stream(sub_stream, 1024)\n\n\ndef parse_header(line):\n    \"\"\"\n    Parse the header into a key-value.\n\n    Input (line): bytes, output: str for key/name, bytes for values which\n    will be decoded later.\n    \"\"\"\n    plist = _parse_header_params(b';' + line)\n    key = plist.pop(0).lower().decode('ascii')\n    pdict = {}\n    for p in plist:\n        i = p.find(b'=')\n        if i >= 0:\n            has_encoding = False\n            name = p[:i].strip().lower().decode('ascii')\n            if name.endswith('*'):\n                # Lang/encoding embedded in the value (like \"filename*=UTF-8''file.ext\")\n                # http://tools.ietf.org/html/rfc2231#section-4\n                name = name[:-1]\n                if p.count(b\"'\") == 2:\n                    has_encoding = True\n            value = p[i + 1:].strip()\n            if len(value) >= 2 and value[:1] == value[-1:] == b'\"':\n                value = value[1:-1]\n                value = value.replace(b'\\\\\\\\', b'\\\\').replace(b'\\\\\"', b'\"')\n            if has_encoding:\n                encoding, lang, value = value.split(b\"'\")\n                value = unquote(value.decode(), encoding=encoding.decode())\n            pdict[name] = value\n    return key, pdict\n\n\ndef _parse_header_params(s):\n    plist = []\n    while s[:1] == b';':\n        s = s[1:]\n        end = s.find(b';')\n        while end > 0 and s.count(b'\"', 0, end) % 2:\n            end = s.find(b';', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        plist.append(f.strip())\n        s = s[end:]\n    return plist\n"
  },
  {
    "patch": "diff --git a/django/utils/archive.py b/django/utils/archive.py\nindex 235809f2ad..d5a0cf0446 100644\n--- a/django/utils/archive.py\n+++ b/django/utils/archive.py\n@@ -27,6 +27,8 @@ import stat\n import tarfile\n import zipfile\n \n+from django.core.exceptions import SuspiciousOperation\n+\n \n class ArchiveException(Exception):\n     \"\"\"\n@@ -133,6 +135,13 @@ class BaseArchive:\n                 return False\n         return True\n \n+    def target_filename(self, to_path, name):\n+        target_path = os.path.abspath(to_path)\n+        filename = os.path.abspath(os.path.join(target_path, name))\n+        if not filename.startswith(target_path):\n+            raise SuspiciousOperation(\"Archive contains invalid path: '%s'\" % name)\n+        return filename\n+\n     def extract(self):\n         raise NotImplementedError('subclasses of BaseArchive must provide an extract() method')\n \n@@ -155,7 +164,7 @@ class TarArchive(BaseArchive):\n             name = member.name\n             if leading:\n                 name = self.split_leading_dir(name)[1]\n-            filename = os.path.join(to_path, name)\n+            filename = self.target_filename(to_path, name)\n             if member.isdir():\n                 if filename:\n                     os.makedirs(filename, exist_ok=True)\n@@ -198,8 +207,10 @@ class ZipArchive(BaseArchive):\n             info = self._archive.getinfo(name)\n             if leading:\n                 name = self.split_leading_dir(name)[1]\n-            filename = os.path.join(to_path, name)\n-            if filename.endswith(('/', '\\\\')):\n+            if not name:\n+                continue\n+            filename = self.target_filename(to_path, name)\n+            if name.endswith(('/', '\\\\')):\n                 # A directory\n                 os.makedirs(filename, exist_ok=True)\n             else:\n",
    "commit_message": "Fixed CVE-2021-3281 -- Fixed potential directory-traversal via archive.extract().\n\nThanks Florian Apolloner, Shai Berger, and Simon Charette for reviews.\n\nThanks Wang Baohua for the report.\n\n",
    "code_before": "\"\"\"\nBased on \"python-archive\" -- https://pypi.org/project/python-archive/\n\nCopyright (c) 2010 Gary Wilson Jr. <gary.wilson@gmail.com> and contributors.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\nimport os\nimport shutil\nimport stat\nimport tarfile\nimport zipfile\n\n\nclass ArchiveException(Exception):\n    \"\"\"\n    Base exception class for all archive errors.\n    \"\"\"\n\n\nclass UnrecognizedArchiveFormat(ArchiveException):\n    \"\"\"\n    Error raised when passed file is not a recognized archive format.\n    \"\"\"\n\n\ndef extract(path, to_path):\n    \"\"\"\n    Unpack the tar or zip file at the specified path to the directory\n    specified by to_path.\n    \"\"\"\n    with Archive(path) as archive:\n        archive.extract(to_path)\n\n\nclass Archive:\n    \"\"\"\n    The external API class that encapsulates an archive implementation.\n    \"\"\"\n    def __init__(self, file):\n        self._archive = self._archive_cls(file)(file)\n\n    @staticmethod\n    def _archive_cls(file):\n        cls = None\n        if isinstance(file, str):\n            filename = file\n        else:\n            try:\n                filename = file.name\n            except AttributeError:\n                raise UnrecognizedArchiveFormat(\n                    \"File object not a recognized archive format.\")\n        base, tail_ext = os.path.splitext(filename.lower())\n        cls = extension_map.get(tail_ext)\n        if not cls:\n            base, ext = os.path.splitext(base)\n            cls = extension_map.get(ext)\n        if not cls:\n            raise UnrecognizedArchiveFormat(\n                \"Path not a recognized archive format: %s\" % filename)\n        return cls\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n    def extract(self, to_path):\n        self._archive.extract(to_path)\n\n    def list(self):\n        self._archive.list()\n\n    def close(self):\n        self._archive.close()\n\n\nclass BaseArchive:\n    \"\"\"\n    Base Archive class.  Implementations should inherit this class.\n    \"\"\"\n    @staticmethod\n    def _copy_permissions(mode, filename):\n        \"\"\"\n        If the file in the archive has some permissions (this assumes a file\n        won't be writable/executable without being readable), apply those\n        permissions to the unarchived file.\n        \"\"\"\n        if mode & stat.S_IROTH:\n            os.chmod(filename, mode)\n\n    def split_leading_dir(self, path):\n        path = str(path)\n        path = path.lstrip('/').lstrip('\\\\')\n        if '/' in path and (('\\\\' in path and path.find('/') < path.find('\\\\')) or '\\\\' not in path):\n            return path.split('/', 1)\n        elif '\\\\' in path:\n            return path.split('\\\\', 1)\n        else:\n            return path, ''\n\n    def has_leading_dir(self, paths):\n        \"\"\"\n        Return True if all the paths have the same leading path name\n        (i.e., everything is in one subdirectory in an archive).\n        \"\"\"\n        common_prefix = None\n        for path in paths:\n            prefix, rest = self.split_leading_dir(path)\n            if not prefix:\n                return False\n            elif common_prefix is None:\n                common_prefix = prefix\n            elif prefix != common_prefix:\n                return False\n        return True\n\n    def extract(self):\n        raise NotImplementedError('subclasses of BaseArchive must provide an extract() method')\n\n    def list(self):\n        raise NotImplementedError('subclasses of BaseArchive must provide a list() method')\n\n\nclass TarArchive(BaseArchive):\n\n    def __init__(self, file):\n        self._archive = tarfile.open(file)\n\n    def list(self, *args, **kwargs):\n        self._archive.list(*args, **kwargs)\n\n    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n\n    def close(self):\n        self._archive.close()\n\n\nclass ZipArchive(BaseArchive):\n\n    def __init__(self, file):\n        self._archive = zipfile.ZipFile(file)\n\n    def list(self, *args, **kwargs):\n        self._archive.printdir(*args, **kwargs)\n\n    def extract(self, to_path):\n        namelist = self._archive.namelist()\n        leading = self.has_leading_dir(namelist)\n        for name in namelist:\n            data = self._archive.read(name)\n            info = self._archive.getinfo(name)\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if filename.endswith(('/', '\\\\')):\n                # A directory\n                os.makedirs(filename, exist_ok=True)\n            else:\n                dirname = os.path.dirname(filename)\n                if dirname:\n                    os.makedirs(dirname, exist_ok=True)\n                with open(filename, 'wb') as outfile:\n                    outfile.write(data)\n                # Convert ZipInfo.external_attr to mode\n                mode = info.external_attr >> 16\n                self._copy_permissions(mode, filename)\n\n    def close(self):\n        self._archive.close()\n\n\nextension_map = dict.fromkeys((\n    '.tar',\n    '.tar.bz2', '.tbz2', '.tbz', '.tz2',\n    '.tar.gz', '.tgz', '.taz',\n    '.tar.lzma', '.tlz',\n    '.tar.xz', '.txz',\n), TarArchive)\nextension_map['.zip'] = ZipArchive\n",
    "code_after": "\"\"\"\nBased on \"python-archive\" -- https://pypi.org/project/python-archive/\n\nCopyright (c) 2010 Gary Wilson Jr. <gary.wilson@gmail.com> and contributors.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\nimport os\nimport shutil\nimport stat\nimport tarfile\nimport zipfile\n\nfrom django.core.exceptions import SuspiciousOperation\n\n\nclass ArchiveException(Exception):\n    \"\"\"\n    Base exception class for all archive errors.\n    \"\"\"\n\n\nclass UnrecognizedArchiveFormat(ArchiveException):\n    \"\"\"\n    Error raised when passed file is not a recognized archive format.\n    \"\"\"\n\n\ndef extract(path, to_path):\n    \"\"\"\n    Unpack the tar or zip file at the specified path to the directory\n    specified by to_path.\n    \"\"\"\n    with Archive(path) as archive:\n        archive.extract(to_path)\n\n\nclass Archive:\n    \"\"\"\n    The external API class that encapsulates an archive implementation.\n    \"\"\"\n    def __init__(self, file):\n        self._archive = self._archive_cls(file)(file)\n\n    @staticmethod\n    def _archive_cls(file):\n        cls = None\n        if isinstance(file, str):\n            filename = file\n        else:\n            try:\n                filename = file.name\n            except AttributeError:\n                raise UnrecognizedArchiveFormat(\n                    \"File object not a recognized archive format.\")\n        base, tail_ext = os.path.splitext(filename.lower())\n        cls = extension_map.get(tail_ext)\n        if not cls:\n            base, ext = os.path.splitext(base)\n            cls = extension_map.get(ext)\n        if not cls:\n            raise UnrecognizedArchiveFormat(\n                \"Path not a recognized archive format: %s\" % filename)\n        return cls\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n    def extract(self, to_path):\n        self._archive.extract(to_path)\n\n    def list(self):\n        self._archive.list()\n\n    def close(self):\n        self._archive.close()\n\n\nclass BaseArchive:\n    \"\"\"\n    Base Archive class.  Implementations should inherit this class.\n    \"\"\"\n    @staticmethod\n    def _copy_permissions(mode, filename):\n        \"\"\"\n        If the file in the archive has some permissions (this assumes a file\n        won't be writable/executable without being readable), apply those\n        permissions to the unarchived file.\n        \"\"\"\n        if mode & stat.S_IROTH:\n            os.chmod(filename, mode)\n\n    def split_leading_dir(self, path):\n        path = str(path)\n        path = path.lstrip('/').lstrip('\\\\')\n        if '/' in path and (('\\\\' in path and path.find('/') < path.find('\\\\')) or '\\\\' not in path):\n            return path.split('/', 1)\n        elif '\\\\' in path:\n            return path.split('\\\\', 1)\n        else:\n            return path, ''\n\n    def has_leading_dir(self, paths):\n        \"\"\"\n        Return True if all the paths have the same leading path name\n        (i.e., everything is in one subdirectory in an archive).\n        \"\"\"\n        common_prefix = None\n        for path in paths:\n            prefix, rest = self.split_leading_dir(path)\n            if not prefix:\n                return False\n            elif common_prefix is None:\n                common_prefix = prefix\n            elif prefix != common_prefix:\n                return False\n        return True\n\n    def target_filename(self, to_path, name):\n        target_path = os.path.abspath(to_path)\n        filename = os.path.abspath(os.path.join(target_path, name))\n        if not filename.startswith(target_path):\n            raise SuspiciousOperation(\"Archive contains invalid path: '%s'\" % name)\n        return filename\n\n    def extract(self):\n        raise NotImplementedError('subclasses of BaseArchive must provide an extract() method')\n\n    def list(self):\n        raise NotImplementedError('subclasses of BaseArchive must provide a list() method')\n\n\nclass TarArchive(BaseArchive):\n\n    def __init__(self, file):\n        self._archive = tarfile.open(file)\n\n    def list(self, *args, **kwargs):\n        self._archive.list(*args, **kwargs)\n\n    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n\n    def close(self):\n        self._archive.close()\n\n\nclass ZipArchive(BaseArchive):\n\n    def __init__(self, file):\n        self._archive = zipfile.ZipFile(file)\n\n    def list(self, *args, **kwargs):\n        self._archive.printdir(*args, **kwargs)\n\n    def extract(self, to_path):\n        namelist = self._archive.namelist()\n        leading = self.has_leading_dir(namelist)\n        for name in namelist:\n            data = self._archive.read(name)\n            info = self._archive.getinfo(name)\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            if not name:\n                continue\n            filename = self.target_filename(to_path, name)\n            if name.endswith(('/', '\\\\')):\n                # A directory\n                os.makedirs(filename, exist_ok=True)\n            else:\n                dirname = os.path.dirname(filename)\n                if dirname:\n                    os.makedirs(dirname, exist_ok=True)\n                with open(filename, 'wb') as outfile:\n                    outfile.write(data)\n                # Convert ZipInfo.external_attr to mode\n                mode = info.external_attr >> 16\n                self._copy_permissions(mode, filename)\n\n    def close(self):\n        self._archive.close()\n\n\nextension_map = dict.fromkeys((\n    '.tar',\n    '.tar.bz2', '.tbz2', '.tbz', '.tz2',\n    '.tar.gz', '.tgz', '.taz',\n    '.tar.lzma', '.tlz',\n    '.tar.xz', '.txz',\n), TarArchive)\nextension_map['.zip'] = ZipArchive\n"
  },
  {
    "patch": "diff --git a/django/core/cache/backends/filebased.py b/django/core/cache/backends/filebased.py\nindex 3d76f0371b..10779c5545 100644\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -114,7 +114,13 @@ class FileBasedCache(BaseCache):\n             self._delete(fname)\n \n     def _createdir(self):\n-        os.makedirs(self._dir, 0o700, exist_ok=True)\n+        # Set the umask because os.makedirs() doesn't apply the \"mode\" argument\n+        # to intermediate-level directories.\n+        old_umask = os.umask(0o077)\n+        try:\n+            os.makedirs(self._dir, 0o700, exist_ok=True)\n+        finally:\n+            os.umask(old_umask)\n \n     def _key_to_file(self, key, version=None):\n         \"\"\"\n",
    "commit_message": "Fixed CVE-2020-24584 -- Fixed permission escalation in intermediate-level directories of the file system cache on Python 3.7+.\n\n",
    "code_before": "\"File-based cache backend\"\nimport glob\nimport hashlib\nimport os\nimport pickle\nimport random\nimport tempfile\nimport time\nimport zlib\n\nfrom django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache\nfrom django.core.files import locks\nfrom django.core.files.move import file_move_safe\n\n\nclass FileBasedCache(BaseCache):\n    cache_suffix = '.djcache'\n    pickle_protocol = pickle.HIGHEST_PROTOCOL\n\n    def __init__(self, dir, params):\n        super().__init__(params)\n        self._dir = os.path.abspath(dir)\n        self._createdir()\n\n    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        if self.has_key(key, version):\n            return False\n        self.set(key, value, timeout, version)\n        return True\n\n    def get(self, key, default=None, version=None):\n        fname = self._key_to_file(key, version)\n        try:\n            with open(fname, 'rb') as f:\n                if not self._is_expired(f):\n                    return pickle.loads(zlib.decompress(f.read()))\n        except FileNotFoundError:\n            pass\n        return default\n\n    def _write_content(self, file, timeout, value):\n        expiry = self.get_backend_timeout(timeout)\n        file.write(pickle.dumps(expiry, self.pickle_protocol))\n        file.write(zlib.compress(pickle.dumps(value, self.pickle_protocol)))\n\n    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        self._createdir()  # Cache dir can be deleted at any time.\n        fname = self._key_to_file(key, version)\n        self._cull()  # make some room if necessary\n        fd, tmp_path = tempfile.mkstemp(dir=self._dir)\n        renamed = False\n        try:\n            with open(fd, 'wb') as f:\n                self._write_content(f, timeout, value)\n            file_move_safe(tmp_path, fname, allow_overwrite=True)\n            renamed = True\n        finally:\n            if not renamed:\n                os.remove(tmp_path)\n\n    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n        try:\n            with open(self._key_to_file(key, version), 'r+b') as f:\n                try:\n                    locks.lock(f, locks.LOCK_EX)\n                    if self._is_expired(f):\n                        return False\n                    else:\n                        previous_value = pickle.loads(zlib.decompress(f.read()))\n                        f.seek(0)\n                        self._write_content(f, timeout, previous_value)\n                        return True\n                finally:\n                    locks.unlock(f)\n        except FileNotFoundError:\n            return False\n\n    def delete(self, key, version=None):\n        return self._delete(self._key_to_file(key, version))\n\n    def _delete(self, fname):\n        if not fname.startswith(self._dir) or not os.path.exists(fname):\n            return False\n        try:\n            os.remove(fname)\n        except FileNotFoundError:\n            # The file may have been removed by another process.\n            return False\n        return True\n\n    def has_key(self, key, version=None):\n        fname = self._key_to_file(key, version)\n        if os.path.exists(fname):\n            with open(fname, 'rb') as f:\n                return not self._is_expired(f)\n        return False\n\n    def _cull(self):\n        \"\"\"\n        Remove random cache entries if max_entries is reached at a ratio\n        of num_entries / cull_frequency. A value of 0 for CULL_FREQUENCY means\n        that the entire cache will be purged.\n        \"\"\"\n        filelist = self._list_cache_files()\n        num_entries = len(filelist)\n        if num_entries < self._max_entries:\n            return  # return early if no culling is required\n        if self._cull_frequency == 0:\n            return self.clear()  # Clear the cache when CULL_FREQUENCY = 0\n        # Delete a random selection of entries\n        filelist = random.sample(filelist,\n                                 int(num_entries / self._cull_frequency))\n        for fname in filelist:\n            self._delete(fname)\n\n    def _createdir(self):\n        os.makedirs(self._dir, 0o700, exist_ok=True)\n\n    def _key_to_file(self, key, version=None):\n        \"\"\"\n        Convert a key into a cache file path. Basically this is the\n        root cache path joined with the md5sum of the key and a suffix.\n        \"\"\"\n        key = self.make_key(key, version=version)\n        self.validate_key(key)\n        return os.path.join(self._dir, ''.join(\n            [hashlib.md5(key.encode()).hexdigest(), self.cache_suffix]))\n\n    def clear(self):\n        \"\"\"\n        Remove all the cache files.\n        \"\"\"\n        for fname in self._list_cache_files():\n            self._delete(fname)\n\n    def _is_expired(self, f):\n        \"\"\"\n        Take an open cache file `f` and delete it if it's expired.\n        \"\"\"\n        try:\n            exp = pickle.load(f)\n        except EOFError:\n            exp = 0  # An empty file is considered expired.\n        if exp is not None and exp < time.time():\n            f.close()  # On Windows a file has to be closed before deleting\n            self._delete(f.name)\n            return True\n        return False\n\n    def _list_cache_files(self):\n        \"\"\"\n        Get a list of paths to all the cache files. These are all the files\n        in the root cache dir that end on the cache_suffix.\n        \"\"\"\n        return [\n            os.path.join(self._dir, fname)\n            for fname in glob.glob1(self._dir, '*%s' % self.cache_suffix)\n        ]\n",
    "code_after": "\"File-based cache backend\"\nimport glob\nimport hashlib\nimport os\nimport pickle\nimport random\nimport tempfile\nimport time\nimport zlib\n\nfrom django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache\nfrom django.core.files import locks\nfrom django.core.files.move import file_move_safe\n\n\nclass FileBasedCache(BaseCache):\n    cache_suffix = '.djcache'\n    pickle_protocol = pickle.HIGHEST_PROTOCOL\n\n    def __init__(self, dir, params):\n        super().__init__(params)\n        self._dir = os.path.abspath(dir)\n        self._createdir()\n\n    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        if self.has_key(key, version):\n            return False\n        self.set(key, value, timeout, version)\n        return True\n\n    def get(self, key, default=None, version=None):\n        fname = self._key_to_file(key, version)\n        try:\n            with open(fname, 'rb') as f:\n                if not self._is_expired(f):\n                    return pickle.loads(zlib.decompress(f.read()))\n        except FileNotFoundError:\n            pass\n        return default\n\n    def _write_content(self, file, timeout, value):\n        expiry = self.get_backend_timeout(timeout)\n        file.write(pickle.dumps(expiry, self.pickle_protocol))\n        file.write(zlib.compress(pickle.dumps(value, self.pickle_protocol)))\n\n    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        self._createdir()  # Cache dir can be deleted at any time.\n        fname = self._key_to_file(key, version)\n        self._cull()  # make some room if necessary\n        fd, tmp_path = tempfile.mkstemp(dir=self._dir)\n        renamed = False\n        try:\n            with open(fd, 'wb') as f:\n                self._write_content(f, timeout, value)\n            file_move_safe(tmp_path, fname, allow_overwrite=True)\n            renamed = True\n        finally:\n            if not renamed:\n                os.remove(tmp_path)\n\n    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n        try:\n            with open(self._key_to_file(key, version), 'r+b') as f:\n                try:\n                    locks.lock(f, locks.LOCK_EX)\n                    if self._is_expired(f):\n                        return False\n                    else:\n                        previous_value = pickle.loads(zlib.decompress(f.read()))\n                        f.seek(0)\n                        self._write_content(f, timeout, previous_value)\n                        return True\n                finally:\n                    locks.unlock(f)\n        except FileNotFoundError:\n            return False\n\n    def delete(self, key, version=None):\n        return self._delete(self._key_to_file(key, version))\n\n    def _delete(self, fname):\n        if not fname.startswith(self._dir) or not os.path.exists(fname):\n            return False\n        try:\n            os.remove(fname)\n        except FileNotFoundError:\n            # The file may have been removed by another process.\n            return False\n        return True\n\n    def has_key(self, key, version=None):\n        fname = self._key_to_file(key, version)\n        if os.path.exists(fname):\n            with open(fname, 'rb') as f:\n                return not self._is_expired(f)\n        return False\n\n    def _cull(self):\n        \"\"\"\n        Remove random cache entries if max_entries is reached at a ratio\n        of num_entries / cull_frequency. A value of 0 for CULL_FREQUENCY means\n        that the entire cache will be purged.\n        \"\"\"\n        filelist = self._list_cache_files()\n        num_entries = len(filelist)\n        if num_entries < self._max_entries:\n            return  # return early if no culling is required\n        if self._cull_frequency == 0:\n            return self.clear()  # Clear the cache when CULL_FREQUENCY = 0\n        # Delete a random selection of entries\n        filelist = random.sample(filelist,\n                                 int(num_entries / self._cull_frequency))\n        for fname in filelist:\n            self._delete(fname)\n\n    def _createdir(self):\n        # Set the umask because os.makedirs() doesn't apply the \"mode\" argument\n        # to intermediate-level directories.\n        old_umask = os.umask(0o077)\n        try:\n            os.makedirs(self._dir, 0o700, exist_ok=True)\n        finally:\n            os.umask(old_umask)\n\n    def _key_to_file(self, key, version=None):\n        \"\"\"\n        Convert a key into a cache file path. Basically this is the\n        root cache path joined with the md5sum of the key and a suffix.\n        \"\"\"\n        key = self.make_key(key, version=version)\n        self.validate_key(key)\n        return os.path.join(self._dir, ''.join(\n            [hashlib.md5(key.encode()).hexdigest(), self.cache_suffix]))\n\n    def clear(self):\n        \"\"\"\n        Remove all the cache files.\n        \"\"\"\n        for fname in self._list_cache_files():\n            self._delete(fname)\n\n    def _is_expired(self, f):\n        \"\"\"\n        Take an open cache file `f` and delete it if it's expired.\n        \"\"\"\n        try:\n            exp = pickle.load(f)\n        except EOFError:\n            exp = 0  # An empty file is considered expired.\n        if exp is not None and exp < time.time():\n            f.close()  # On Windows a file has to be closed before deleting\n            self._delete(f.name)\n            return True\n        return False\n\n    def _list_cache_files(self):\n        \"\"\"\n        Get a list of paths to all the cache files. These are all the files\n        in the root cache dir that end on the cache_suffix.\n        \"\"\"\n        return [\n            os.path.join(self._dir, fname)\n            for fname in glob.glob1(self._dir, '*%s' % self.cache_suffix)\n        ]\n"
  },
  {
    "patch": "diff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex e9166d94ff..16f9d4e27b 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -237,9 +237,9 @@ class FileSystemStorage(Storage):\n         directory = os.path.dirname(full_path)\n         try:\n             if self.directory_permissions_mode is not None:\n-                # os.makedirs applies the global umask, so we reset it,\n-                # for consistency with file_permissions_mode behavior.\n-                old_umask = os.umask(0)\n+                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n+                # argument to intermediate-level directories.\n+                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                 try:\n                     os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                 finally:\n",
    "commit_message": "Fixed CVE-2020-24583, #31921 -- Fixed permissions on intermediate-level static and storage directories on Python 3.7+.\n\nThanks WhiteSage for the report.\n\n",
    "code_before": "import os\nfrom datetime import datetime\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.core.exceptions import SuspiciousFileOperation\nfrom django.core.files import File, locks\nfrom django.core.files.move import file_move_safe\nfrom django.core.signals import setting_changed\nfrom django.utils import timezone\nfrom django.utils._os import safe_join\nfrom django.utils.crypto import get_random_string\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.encoding import filepath_to_uri\nfrom django.utils.functional import LazyObject, cached_property\nfrom django.utils.module_loading import import_string\nfrom django.utils.text import get_valid_filename\n\n__all__ = (\n    'Storage', 'FileSystemStorage', 'DefaultStorage', 'default_storage',\n    'get_storage_class',\n)\n\n\nclass Storage:\n    \"\"\"\n    A base storage class, providing some default behaviors that all other\n    storage systems can inherit or override, as necessary.\n    \"\"\"\n\n    # The following methods represent a public interface to private methods.\n    # These shouldn't be overridden by subclasses unless absolutely necessary.\n\n    def open(self, name, mode='rb'):\n        \"\"\"Retrieve the specified file from storage.\"\"\"\n        return self._open(name, mode)\n\n    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        return self._save(name, content)\n\n    # These methods are part of the public API, with default implementations.\n\n    def get_valid_name(self, name):\n        \"\"\"\n        Return a filename, based on the provided filename, that's suitable for\n        use in the target storage system.\n        \"\"\"\n        return get_valid_filename(name)\n\n    def get_alternative_name(self, file_root, file_ext):\n        \"\"\"\n        Return an alternative filename, by adding an underscore and a random 7\n        character alphanumeric string (before the file extension, if one\n        exists) to the filename.\n        \"\"\"\n        return '%s_%s%s' % (file_root, get_random_string(7), file_ext)\n\n    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n\n    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n\n    def path(self, name):\n        \"\"\"\n        Return a local filesystem path where the file can be retrieved using\n        Python's built-in open() function. Storage systems that can't be\n        accessed using open() should *not* implement this method.\n        \"\"\"\n        raise NotImplementedError(\"This backend doesn't support absolute paths.\")\n\n    # The following methods form the public API for storage systems, but with\n    # no default implementations. Subclasses must implement *all* of these.\n\n    def delete(self, name):\n        \"\"\"\n        Delete the specified file from the storage system.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a delete() method')\n\n    def exists(self, name):\n        \"\"\"\n        Return True if a file referenced by the given name already exists in the\n        storage system, or False if the name is available for a new file.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide an exists() method')\n\n    def listdir(self, path):\n        \"\"\"\n        List the contents of the specified path. Return a 2-tuple of lists:\n        the first item being directories, the second item being files.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a listdir() method')\n\n    def size(self, name):\n        \"\"\"\n        Return the total size, in bytes, of the file specified by name.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a size() method')\n\n    def url(self, name):\n        \"\"\"\n        Return an absolute URL where the file's contents can be accessed\n        directly by a Web browser.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a url() method')\n\n    def get_accessed_time(self, name):\n        \"\"\"\n        Return the last accessed time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_accessed_time() method')\n\n    def get_created_time(self, name):\n        \"\"\"\n        Return the creation time (as a datetime) of the file specified by name.\n        The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_created_time() method')\n\n    def get_modified_time(self, name):\n        \"\"\"\n        Return the last modified time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_modified_time() method')\n\n\n@deconstructible\nclass FileSystemStorage(Storage):\n    \"\"\"\n    Standard filesystem storage\n    \"\"\"\n    # The combination of O_CREAT and O_EXCL makes os.open() raise OSError if\n    # the file already exists before it's opened.\n    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)\n\n    def __init__(self, location=None, base_url=None, file_permissions_mode=None,\n                 directory_permissions_mode=None):\n        self._location = location\n        self._base_url = base_url\n        self._file_permissions_mode = file_permissions_mode\n        self._directory_permissions_mode = directory_permissions_mode\n        setting_changed.connect(self._clear_cached_properties)\n\n    def _clear_cached_properties(self, setting, **kwargs):\n        \"\"\"Reset setting based property values.\"\"\"\n        if setting == 'MEDIA_ROOT':\n            self.__dict__.pop('base_location', None)\n            self.__dict__.pop('location', None)\n        elif setting == 'MEDIA_URL':\n            self.__dict__.pop('base_url', None)\n        elif setting == 'FILE_UPLOAD_PERMISSIONS':\n            self.__dict__.pop('file_permissions_mode', None)\n        elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS':\n            self.__dict__.pop('directory_permissions_mode', None)\n\n    def _value_or_setting(self, value, setting):\n        return setting if value is None else value\n\n    @cached_property\n    def base_location(self):\n        return self._value_or_setting(self._location, settings.MEDIA_ROOT)\n\n    @cached_property\n    def location(self):\n        return os.path.abspath(self.base_location)\n\n    @cached_property\n    def base_url(self):\n        if self._base_url is not None and not self._base_url.endswith('/'):\n            self._base_url += '/'\n        return self._value_or_setting(self._base_url, settings.MEDIA_URL)\n\n    @cached_property\n    def file_permissions_mode(self):\n        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n\n    @cached_property\n    def directory_permissions_mode(self):\n        return self._value_or_setting(self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS)\n\n    def _open(self, name, mode='rb'):\n        return File(open(self.path(name), mode))\n\n    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # os.makedirs applies the global umask, so we reset it,\n                # for consistency with file_permissions_mode behavior.\n                old_umask = os.umask(0)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n\n    def delete(self, name):\n        assert name, \"The name argument is not allowed to be empty.\"\n        name = self.path(name)\n        # If the file or directory exists, delete it from the filesystem.\n        try:\n            if os.path.isdir(name):\n                os.rmdir(name)\n            else:\n                os.remove(name)\n        except FileNotFoundError:\n            # FileNotFoundError is raised if the file or directory was removed\n            # concurrently.\n            pass\n\n    def exists(self, name):\n        return os.path.exists(self.path(name))\n\n    def listdir(self, path):\n        path = self.path(path)\n        directories, files = [], []\n        for entry in os.scandir(path):\n            if entry.is_dir():\n                directories.append(entry.name)\n            else:\n                files.append(entry.name)\n        return directories, files\n\n    def path(self, name):\n        return safe_join(self.location, name)\n\n    def size(self, name):\n        return os.path.getsize(self.path(name))\n\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        return urljoin(self.base_url, url)\n\n    def _datetime_from_timestamp(self, ts):\n        \"\"\"\n        If timezone support is enabled, make an aware datetime object in UTC;\n        otherwise make a naive one in the local timezone.\n        \"\"\"\n        if settings.USE_TZ:\n            # Safe to use .replace() because UTC doesn't have DST\n            return datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc)\n        else:\n            return datetime.fromtimestamp(ts)\n\n    def get_accessed_time(self, name):\n        return self._datetime_from_timestamp(os.path.getatime(self.path(name)))\n\n    def get_created_time(self, name):\n        return self._datetime_from_timestamp(os.path.getctime(self.path(name)))\n\n    def get_modified_time(self, name):\n        return self._datetime_from_timestamp(os.path.getmtime(self.path(name)))\n\n\ndef get_storage_class(import_path=None):\n    return import_string(import_path or settings.DEFAULT_FILE_STORAGE)\n\n\nclass DefaultStorage(LazyObject):\n    def _setup(self):\n        self._wrapped = get_storage_class()()\n\n\ndefault_storage = DefaultStorage()\n",
    "code_after": "import os\nfrom datetime import datetime\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.core.exceptions import SuspiciousFileOperation\nfrom django.core.files import File, locks\nfrom django.core.files.move import file_move_safe\nfrom django.core.signals import setting_changed\nfrom django.utils import timezone\nfrom django.utils._os import safe_join\nfrom django.utils.crypto import get_random_string\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.encoding import filepath_to_uri\nfrom django.utils.functional import LazyObject, cached_property\nfrom django.utils.module_loading import import_string\nfrom django.utils.text import get_valid_filename\n\n__all__ = (\n    'Storage', 'FileSystemStorage', 'DefaultStorage', 'default_storage',\n    'get_storage_class',\n)\n\n\nclass Storage:\n    \"\"\"\n    A base storage class, providing some default behaviors that all other\n    storage systems can inherit or override, as necessary.\n    \"\"\"\n\n    # The following methods represent a public interface to private methods.\n    # These shouldn't be overridden by subclasses unless absolutely necessary.\n\n    def open(self, name, mode='rb'):\n        \"\"\"Retrieve the specified file from storage.\"\"\"\n        return self._open(name, mode)\n\n    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        return self._save(name, content)\n\n    # These methods are part of the public API, with default implementations.\n\n    def get_valid_name(self, name):\n        \"\"\"\n        Return a filename, based on the provided filename, that's suitable for\n        use in the target storage system.\n        \"\"\"\n        return get_valid_filename(name)\n\n    def get_alternative_name(self, file_root, file_ext):\n        \"\"\"\n        Return an alternative filename, by adding an underscore and a random 7\n        character alphanumeric string (before the file extension, if one\n        exists) to the filename.\n        \"\"\"\n        return '%s_%s%s' % (file_root, get_random_string(7), file_ext)\n\n    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n\n    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n\n    def path(self, name):\n        \"\"\"\n        Return a local filesystem path where the file can be retrieved using\n        Python's built-in open() function. Storage systems that can't be\n        accessed using open() should *not* implement this method.\n        \"\"\"\n        raise NotImplementedError(\"This backend doesn't support absolute paths.\")\n\n    # The following methods form the public API for storage systems, but with\n    # no default implementations. Subclasses must implement *all* of these.\n\n    def delete(self, name):\n        \"\"\"\n        Delete the specified file from the storage system.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a delete() method')\n\n    def exists(self, name):\n        \"\"\"\n        Return True if a file referenced by the given name already exists in the\n        storage system, or False if the name is available for a new file.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide an exists() method')\n\n    def listdir(self, path):\n        \"\"\"\n        List the contents of the specified path. Return a 2-tuple of lists:\n        the first item being directories, the second item being files.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a listdir() method')\n\n    def size(self, name):\n        \"\"\"\n        Return the total size, in bytes, of the file specified by name.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a size() method')\n\n    def url(self, name):\n        \"\"\"\n        Return an absolute URL where the file's contents can be accessed\n        directly by a Web browser.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a url() method')\n\n    def get_accessed_time(self, name):\n        \"\"\"\n        Return the last accessed time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_accessed_time() method')\n\n    def get_created_time(self, name):\n        \"\"\"\n        Return the creation time (as a datetime) of the file specified by name.\n        The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_created_time() method')\n\n    def get_modified_time(self, name):\n        \"\"\"\n        Return the last modified time (as a datetime) of the file specified by\n        name. The datetime will be timezone-aware if USE_TZ=True.\n        \"\"\"\n        raise NotImplementedError('subclasses of Storage must provide a get_modified_time() method')\n\n\n@deconstructible\nclass FileSystemStorage(Storage):\n    \"\"\"\n    Standard filesystem storage\n    \"\"\"\n    # The combination of O_CREAT and O_EXCL makes os.open() raise OSError if\n    # the file already exists before it's opened.\n    OS_OPEN_FLAGS = os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)\n\n    def __init__(self, location=None, base_url=None, file_permissions_mode=None,\n                 directory_permissions_mode=None):\n        self._location = location\n        self._base_url = base_url\n        self._file_permissions_mode = file_permissions_mode\n        self._directory_permissions_mode = directory_permissions_mode\n        setting_changed.connect(self._clear_cached_properties)\n\n    def _clear_cached_properties(self, setting, **kwargs):\n        \"\"\"Reset setting based property values.\"\"\"\n        if setting == 'MEDIA_ROOT':\n            self.__dict__.pop('base_location', None)\n            self.__dict__.pop('location', None)\n        elif setting == 'MEDIA_URL':\n            self.__dict__.pop('base_url', None)\n        elif setting == 'FILE_UPLOAD_PERMISSIONS':\n            self.__dict__.pop('file_permissions_mode', None)\n        elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS':\n            self.__dict__.pop('directory_permissions_mode', None)\n\n    def _value_or_setting(self, value, setting):\n        return setting if value is None else value\n\n    @cached_property\n    def base_location(self):\n        return self._value_or_setting(self._location, settings.MEDIA_ROOT)\n\n    @cached_property\n    def location(self):\n        return os.path.abspath(self.base_location)\n\n    @cached_property\n    def base_url(self):\n        if self._base_url is not None and not self._base_url.endswith('/'):\n            self._base_url += '/'\n        return self._value_or_setting(self._base_url, settings.MEDIA_URL)\n\n    @cached_property\n    def file_permissions_mode(self):\n        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n\n    @cached_property\n    def directory_permissions_mode(self):\n        return self._value_or_setting(self._directory_permissions_mode, settings.FILE_UPLOAD_DIRECTORY_PERMISSIONS)\n\n    def _open(self, name, mode='rb'):\n        return File(open(self.path(name), mode))\n\n    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n\n    def delete(self, name):\n        assert name, \"The name argument is not allowed to be empty.\"\n        name = self.path(name)\n        # If the file or directory exists, delete it from the filesystem.\n        try:\n            if os.path.isdir(name):\n                os.rmdir(name)\n            else:\n                os.remove(name)\n        except FileNotFoundError:\n            # FileNotFoundError is raised if the file or directory was removed\n            # concurrently.\n            pass\n\n    def exists(self, name):\n        return os.path.exists(self.path(name))\n\n    def listdir(self, path):\n        path = self.path(path)\n        directories, files = [], []\n        for entry in os.scandir(path):\n            if entry.is_dir():\n                directories.append(entry.name)\n            else:\n                files.append(entry.name)\n        return directories, files\n\n    def path(self, name):\n        return safe_join(self.location, name)\n\n    def size(self, name):\n        return os.path.getsize(self.path(name))\n\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        return urljoin(self.base_url, url)\n\n    def _datetime_from_timestamp(self, ts):\n        \"\"\"\n        If timezone support is enabled, make an aware datetime object in UTC;\n        otherwise make a naive one in the local timezone.\n        \"\"\"\n        if settings.USE_TZ:\n            # Safe to use .replace() because UTC doesn't have DST\n            return datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc)\n        else:\n            return datetime.fromtimestamp(ts)\n\n    def get_accessed_time(self, name):\n        return self._datetime_from_timestamp(os.path.getatime(self.path(name)))\n\n    def get_created_time(self, name):\n        return self._datetime_from_timestamp(os.path.getctime(self.path(name)))\n\n    def get_modified_time(self, name):\n        return self._datetime_from_timestamp(os.path.getmtime(self.path(name)))\n\n\ndef get_storage_class(import_path=None):\n    return import_string(import_path or settings.DEFAULT_FILE_STORAGE)\n\n\nclass DefaultStorage(LazyObject):\n    def _setup(self):\n        self._wrapped = get_storage_class()()\n\n\ndefault_storage = DefaultStorage()\n"
  },
  {
    "patch": "diff --git a/django/contrib/admin/widgets.py b/django/contrib/admin/widgets.py\nindex 1ec7c70abd..59d1004d2d 100644\n--- a/django/contrib/admin/widgets.py\n+++ b/django/contrib/admin/widgets.py\n@@ -12,7 +12,7 @@ from django.db.models import CASCADE\n from django.urls import reverse\n from django.urls.exceptions import NoReverseMatch\n from django.utils.html import smart_urlquote\n-from django.utils.safestring import mark_safe\n+from django.utils.http import urlencode\n from django.utils.text import Truncator\n from django.utils.translation import get_language, gettext as _\n \n@@ -145,8 +145,8 @@ class ForeignKeyRawIdWidget(forms.TextInput):\n \n             params = self.url_parameters()\n             if params:\n-                related_url += '?' + '&amp;'.join('%s=%s' % (k, v) for k, v in params.items())\n-            context['related_url'] = mark_safe(related_url)\n+                related_url += '?' + urlencode(params)\n+            context['related_url'] = related_url\n             context['link_title'] = _('Lookup')\n             # The JavaScript code looks for this class.\n             context['widget']['attrs'].setdefault('class', 'vForeignKeyRawIdAdminField')\n",
    "commit_message": "Fixed CVE-2020-13596 -- Fixed potential XSS in admin ForeignKeyRawIdWidget.\n\n",
    "code_before": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\nimport copy\nimport json\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.core.validators import URLValidator\nfrom django.db.models import CASCADE\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\nfrom django.utils.html import smart_urlquote\nfrom django.utils.safestring import mark_safe\nfrom django.utils.text import Truncator\nfrom django.utils.translation import get_language, gettext as _\n\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    class Media:\n        js = [\n            'admin/js/core.js',\n            'admin/js/SelectBox.js',\n            'admin/js/SelectFilter2.js',\n        ]\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super().__init__(attrs, choices)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['widget']['attrs']['class'] = 'selectfilter'\n        if self.is_stacked:\n            context['widget']['attrs']['class'] += 'stacked'\n        context['widget']['attrs']['data-field-name'] = self.verbose_name\n        context['widget']['attrs']['data-is-stacked'] = int(self.is_stacked)\n        return context\n\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vDateField', 'size': '10', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vTimeField', 'size': '8', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    template_name = 'admin/widgets/split_datetime.html'\n\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['date_label'] = _('Date:')\n        context['time_label'] = _('Time:')\n        return context\n\n\nclass AdminRadioSelect(forms.RadioSelect):\n    template_name = 'admin/widgets/radio.html'\n\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_name = 'admin/widgets/clearable_file_input.html'\n\n\ndef url_params_from_lookup_dict(lookups):\n    \"\"\"\n    Convert the type of lookups specified in a ForeignKey limit_choices_to\n    attribute to a dictionary of query parameters\n    \"\"\"\n    params = {}\n    if lookups and hasattr(lookups, 'items'):\n        for k, v in lookups.items():\n            if callable(v):\n                v = v()\n            if isinstance(v, (tuple, list)):\n                v = ','.join(str(x) for x in v)\n            elif isinstance(v, bool):\n                v = ('0', '1')[v]\n            else:\n                v = str(v)\n            params[k] = v\n    return params\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    template_name = 'admin/widgets/foreign_key_raw_id.html'\n\n    def __init__(self, rel, admin_site, attrs=None, using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        rel_to = self.rel.model\n        if rel_to in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            related_url = reverse(\n                'admin:%s_%s_changelist' % (\n                    rel_to._meta.app_label,\n                    rel_to._meta.model_name,\n                ),\n                current_app=self.admin_site.name,\n            )\n\n            params = self.url_parameters()\n            if params:\n                related_url += '?' + '&amp;'.join('%s=%s' % (k, v) for k, v in params.items())\n            context['related_url'] = mark_safe(related_url)\n            context['link_title'] = _('Lookup')\n            # The JavaScript code looks for this class.\n            context['widget']['attrs'].setdefault('class', 'vForeignKeyRawIdAdminField')\n        else:\n            context['related_url'] = None\n        if context['widget']['value']:\n            context['link_label'], context['link_url'] = self.label_and_url_for_value(value)\n        else:\n            context['link_label'] = None\n        return context\n\n    def base_url_parameters(self):\n        limit_choices_to = self.rel.limit_choices_to\n        if callable(limit_choices_to):\n            limit_choices_to = limit_choices_to()\n        return url_params_from_lookup_dict(limit_choices_to)\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_and_url_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.model._default_manager.using(self.db).get(**{key: value})\n        except (ValueError, self.rel.model.DoesNotExist, ValidationError):\n            return '', ''\n\n        try:\n            url = reverse(\n                '%s:%s_%s_change' % (\n                    self.admin_site.name,\n                    obj._meta.app_label,\n                    obj._meta.object_name.lower(),\n                ),\n                args=(obj.pk,)\n            )\n        except NoReverseMatch:\n            url = ''  # Admin not registered for target model.\n\n        return Truncator(obj).words(14), url\n\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    template_name = 'admin/widgets/many_to_many_raw_id.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.rel.model in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            context['widget']['attrs']['class'] = 'vManyToManyRawIdAdminField'\n        return context\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_and_url_for_value(self, value):\n        return '', ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def format_value(self, value):\n        return ','.join(str(v) for v in value) if value else ''\n\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    template_name = 'admin/widgets/related_widget_wrapper.html'\n\n    def __init__(self, widget, rel, admin_site, can_add_related=None,\n                 can_change_related=False, can_delete_related=False,\n                 can_view_related=False):\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.model in admin_site._registry\n        self.can_add_related = can_add_related\n        # XXX: The UX does not support multiple selected values.\n        multiple = getattr(widget, 'allow_multiple_selected', False)\n        self.can_change_related = not multiple and can_change_related\n        # XXX: The deletion UX can be confusing when dealing with cascading deletion.\n        cascade = getattr(rel, 'on_delete', None) is CASCADE\n        self.can_delete_related = not multiple and not cascade and can_delete_related\n        self.can_view_related = not multiple and can_view_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.widget.is_hidden\n\n    @property\n    def media(self):\n        return self.widget.media\n\n    def get_related_url(self, info, action, *args):\n        return reverse(\"admin:%s_%s_%s\" % (info + (action,)),\n                       current_app=self.admin_site.name, args=args)\n\n    def get_context(self, name, value, attrs):\n        from django.contrib.admin.views.main import IS_POPUP_VAR, TO_FIELD_VAR\n        rel_opts = self.rel.model._meta\n        info = (rel_opts.app_label, rel_opts.model_name)\n        self.widget.choices = self.choices\n        url_params = '&'.join(\"%s=%s\" % param for param in [\n            (TO_FIELD_VAR, self.rel.get_related_field().name),\n            (IS_POPUP_VAR, 1),\n        ])\n        context = {\n            'rendered_widget': self.widget.render(name, value, attrs),\n            'is_hidden': self.is_hidden,\n            'name': name,\n            'url_params': url_params,\n            'model': rel_opts.verbose_name,\n            'can_add_related': self.can_add_related,\n            'can_change_related': self.can_change_related,\n            'can_delete_related': self.can_delete_related,\n            'can_view_related': self.can_view_related,\n        }\n        if self.can_add_related:\n            context['add_related_url'] = self.get_related_url(info, 'add')\n        if self.can_delete_related:\n            context['delete_related_template_url'] = self.get_related_url(info, 'delete', '__fk__')\n        if self.can_view_related or self.can_change_related:\n            context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__')\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return self.widget.value_omitted_from_data(data, files, name)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vLargeTextField', **(attrs or {})})\n\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminEmailInputWidget(forms.EmailInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminURLFieldWidget(forms.URLInput):\n    template_name = 'admin/widgets/url.html'\n\n    def __init__(self, attrs=None, validator_class=URLValidator):\n        super().__init__(attrs={'class': 'vURLField', **(attrs or {})})\n        self.validator = validator_class()\n\n    def get_context(self, name, value, attrs):\n        try:\n            self.validator(value if value else '')\n            url_valid = True\n        except ValidationError:\n            url_valid = False\n        context = super().get_context(name, value, attrs)\n        context['current_label'] = _('Currently:')\n        context['change_label'] = _('Change:')\n        context['widget']['href'] = smart_urlquote(context['widget']['value']) if value else ''\n        context['url_valid'] = url_valid\n        return context\n\n\nclass AdminIntegerFieldWidget(forms.NumberInput):\n    class_name = 'vIntegerField'\n\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': self.class_name, **(attrs or {})})\n\n\nclass AdminBigIntegerFieldWidget(AdminIntegerFieldWidget):\n    class_name = 'vBigIntegerField'\n\n\nclass AdminUUIDInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vUUIDField', **(attrs or {})})\n\n\n# Mapping of lowercase language codes [returned by Django's get_language()] to\n# language codes supported by select2.\n# See django/contrib/admin/static/admin/js/vendor/select2/i18n/*\nSELECT2_TRANSLATIONS = {x.lower(): x for x in [\n    'ar', 'az', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et',\n    'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'is',\n    'it', 'ja', 'km', 'ko', 'lt', 'lv', 'mk', 'ms', 'nb', 'nl', 'pl',\n    'pt-BR', 'pt', 'ro', 'ru', 'sk', 'sr-Cyrl', 'sr', 'sv', 'th',\n    'tr', 'uk', 'vi',\n]}\nSELECT2_TRANSLATIONS.update({'zh-hans': 'zh-CN', 'zh-hant': 'zh-TW'})\n\n\nclass AutocompleteMixin:\n    \"\"\"\n    Select widget mixin that loads options from AutocompleteJsonView via AJAX.\n\n    Renders the necessary data attributes for select2 and adds the static form\n    media.\n    \"\"\"\n    url_name = '%s:%s_%s_autocomplete'\n\n    def __init__(self, rel, admin_site, attrs=None, choices=(), using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        self.choices = choices\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def get_url(self):\n        model = self.rel.model\n        return reverse(self.url_name % (self.admin_site.name, model._meta.app_label, model._meta.model_name))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"\n        Set select2's AJAX attributes.\n\n        Attributes can be set using the html5 data attribute.\n        Nested attributes require a double dash as per\n        https://select2.org/configuration/data-attributes#nested-subkey-options\n        \"\"\"\n        attrs = super().build_attrs(base_attrs, extra_attrs=extra_attrs)\n        attrs.setdefault('class', '')\n        attrs.update({\n            'data-ajax--cache': 'true',\n            'data-ajax--delay': 250,\n            'data-ajax--type': 'GET',\n            'data-ajax--url': self.get_url(),\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': json.dumps(not self.is_required),\n            'data-placeholder': '',  # Allows clearing of the input.\n            'class': attrs['class'] + (' ' if attrs['class'] else '') + 'admin-autocomplete',\n        })\n        return attrs\n\n    def optgroups(self, name, value, attr=None):\n        \"\"\"Return selected options based on the ModelChoiceIterator.\"\"\"\n        default = (None, [], 0)\n        groups = [default]\n        has_selected = False\n        selected_choices = {\n            str(v) for v in value\n            if str(v) not in self.choices.field.empty_values\n        }\n        if not self.is_required and not self.allow_multiple_selected:\n            default[1].append(self.create_option(name, '', '', False, 0))\n        choices = (\n            (obj.pk, self.choices.field.label_from_instance(obj))\n            for obj in self.choices.queryset.using(self.db).filter(pk__in=selected_choices)\n        )\n        for option_value, option_label in choices:\n            selected = (\n                str(option_value) in value and\n                (has_selected is False or self.allow_multiple_selected)\n            )\n            has_selected |= selected\n            index = len(default[1])\n            subgroup = default[1]\n            subgroup.append(self.create_option(name, option_value, option_label, selected_choices, index))\n        return groups\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        i18n_name = SELECT2_TRANSLATIONS.get(get_language())\n        i18n_file = ('admin/js/vendor/select2/i18n/%s.js' % i18n_name,) if i18n_name else ()\n        return forms.Media(\n            js=(\n                'admin/js/vendor/jquery/jquery%s.js' % extra,\n                'admin/js/vendor/select2/select2.full%s.js' % extra,\n            ) + i18n_file + (\n                'admin/js/jquery.init.js',\n                'admin/js/autocomplete.js',\n            ),\n            css={\n                'screen': (\n                    'admin/css/vendor/select2/select2%s.css' % extra,\n                    'admin/css/autocomplete.css',\n                ),\n            },\n        )\n\n\nclass AutocompleteSelect(AutocompleteMixin, forms.Select):\n    pass\n\n\nclass AutocompleteSelectMultiple(AutocompleteMixin, forms.SelectMultiple):\n    pass\n",
    "code_after": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\nimport copy\nimport json\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.core.validators import URLValidator\nfrom django.db.models import CASCADE\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\nfrom django.utils.html import smart_urlquote\nfrom django.utils.http import urlencode\nfrom django.utils.text import Truncator\nfrom django.utils.translation import get_language, gettext as _\n\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    class Media:\n        js = [\n            'admin/js/core.js',\n            'admin/js/SelectBox.js',\n            'admin/js/SelectFilter2.js',\n        ]\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super().__init__(attrs, choices)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['widget']['attrs']['class'] = 'selectfilter'\n        if self.is_stacked:\n            context['widget']['attrs']['class'] += 'stacked'\n        context['widget']['attrs']['data-field-name'] = self.verbose_name\n        context['widget']['attrs']['data-is-stacked'] = int(self.is_stacked)\n        return context\n\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vDateField', 'size': '10', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vTimeField', 'size': '8', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    template_name = 'admin/widgets/split_datetime.html'\n\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['date_label'] = _('Date:')\n        context['time_label'] = _('Time:')\n        return context\n\n\nclass AdminRadioSelect(forms.RadioSelect):\n    template_name = 'admin/widgets/radio.html'\n\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_name = 'admin/widgets/clearable_file_input.html'\n\n\ndef url_params_from_lookup_dict(lookups):\n    \"\"\"\n    Convert the type of lookups specified in a ForeignKey limit_choices_to\n    attribute to a dictionary of query parameters\n    \"\"\"\n    params = {}\n    if lookups and hasattr(lookups, 'items'):\n        for k, v in lookups.items():\n            if callable(v):\n                v = v()\n            if isinstance(v, (tuple, list)):\n                v = ','.join(str(x) for x in v)\n            elif isinstance(v, bool):\n                v = ('0', '1')[v]\n            else:\n                v = str(v)\n            params[k] = v\n    return params\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    template_name = 'admin/widgets/foreign_key_raw_id.html'\n\n    def __init__(self, rel, admin_site, attrs=None, using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        rel_to = self.rel.model\n        if rel_to in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            related_url = reverse(\n                'admin:%s_%s_changelist' % (\n                    rel_to._meta.app_label,\n                    rel_to._meta.model_name,\n                ),\n                current_app=self.admin_site.name,\n            )\n\n            params = self.url_parameters()\n            if params:\n                related_url += '?' + urlencode(params)\n            context['related_url'] = related_url\n            context['link_title'] = _('Lookup')\n            # The JavaScript code looks for this class.\n            context['widget']['attrs'].setdefault('class', 'vForeignKeyRawIdAdminField')\n        else:\n            context['related_url'] = None\n        if context['widget']['value']:\n            context['link_label'], context['link_url'] = self.label_and_url_for_value(value)\n        else:\n            context['link_label'] = None\n        return context\n\n    def base_url_parameters(self):\n        limit_choices_to = self.rel.limit_choices_to\n        if callable(limit_choices_to):\n            limit_choices_to = limit_choices_to()\n        return url_params_from_lookup_dict(limit_choices_to)\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_and_url_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.model._default_manager.using(self.db).get(**{key: value})\n        except (ValueError, self.rel.model.DoesNotExist, ValidationError):\n            return '', ''\n\n        try:\n            url = reverse(\n                '%s:%s_%s_change' % (\n                    self.admin_site.name,\n                    obj._meta.app_label,\n                    obj._meta.object_name.lower(),\n                ),\n                args=(obj.pk,)\n            )\n        except NoReverseMatch:\n            url = ''  # Admin not registered for target model.\n\n        return Truncator(obj).words(14), url\n\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    template_name = 'admin/widgets/many_to_many_raw_id.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.rel.model in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            context['widget']['attrs']['class'] = 'vManyToManyRawIdAdminField'\n        return context\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_and_url_for_value(self, value):\n        return '', ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def format_value(self, value):\n        return ','.join(str(v) for v in value) if value else ''\n\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    template_name = 'admin/widgets/related_widget_wrapper.html'\n\n    def __init__(self, widget, rel, admin_site, can_add_related=None,\n                 can_change_related=False, can_delete_related=False,\n                 can_view_related=False):\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.model in admin_site._registry\n        self.can_add_related = can_add_related\n        # XXX: The UX does not support multiple selected values.\n        multiple = getattr(widget, 'allow_multiple_selected', False)\n        self.can_change_related = not multiple and can_change_related\n        # XXX: The deletion UX can be confusing when dealing with cascading deletion.\n        cascade = getattr(rel, 'on_delete', None) is CASCADE\n        self.can_delete_related = not multiple and not cascade and can_delete_related\n        self.can_view_related = not multiple and can_view_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.widget.is_hidden\n\n    @property\n    def media(self):\n        return self.widget.media\n\n    def get_related_url(self, info, action, *args):\n        return reverse(\"admin:%s_%s_%s\" % (info + (action,)),\n                       current_app=self.admin_site.name, args=args)\n\n    def get_context(self, name, value, attrs):\n        from django.contrib.admin.views.main import IS_POPUP_VAR, TO_FIELD_VAR\n        rel_opts = self.rel.model._meta\n        info = (rel_opts.app_label, rel_opts.model_name)\n        self.widget.choices = self.choices\n        url_params = '&'.join(\"%s=%s\" % param for param in [\n            (TO_FIELD_VAR, self.rel.get_related_field().name),\n            (IS_POPUP_VAR, 1),\n        ])\n        context = {\n            'rendered_widget': self.widget.render(name, value, attrs),\n            'is_hidden': self.is_hidden,\n            'name': name,\n            'url_params': url_params,\n            'model': rel_opts.verbose_name,\n            'can_add_related': self.can_add_related,\n            'can_change_related': self.can_change_related,\n            'can_delete_related': self.can_delete_related,\n            'can_view_related': self.can_view_related,\n        }\n        if self.can_add_related:\n            context['add_related_url'] = self.get_related_url(info, 'add')\n        if self.can_delete_related:\n            context['delete_related_template_url'] = self.get_related_url(info, 'delete', '__fk__')\n        if self.can_view_related or self.can_change_related:\n            context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__')\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return self.widget.value_omitted_from_data(data, files, name)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vLargeTextField', **(attrs or {})})\n\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminEmailInputWidget(forms.EmailInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminURLFieldWidget(forms.URLInput):\n    template_name = 'admin/widgets/url.html'\n\n    def __init__(self, attrs=None, validator_class=URLValidator):\n        super().__init__(attrs={'class': 'vURLField', **(attrs or {})})\n        self.validator = validator_class()\n\n    def get_context(self, name, value, attrs):\n        try:\n            self.validator(value if value else '')\n            url_valid = True\n        except ValidationError:\n            url_valid = False\n        context = super().get_context(name, value, attrs)\n        context['current_label'] = _('Currently:')\n        context['change_label'] = _('Change:')\n        context['widget']['href'] = smart_urlquote(context['widget']['value']) if value else ''\n        context['url_valid'] = url_valid\n        return context\n\n\nclass AdminIntegerFieldWidget(forms.NumberInput):\n    class_name = 'vIntegerField'\n\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': self.class_name, **(attrs or {})})\n\n\nclass AdminBigIntegerFieldWidget(AdminIntegerFieldWidget):\n    class_name = 'vBigIntegerField'\n\n\nclass AdminUUIDInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vUUIDField', **(attrs or {})})\n\n\n# Mapping of lowercase language codes [returned by Django's get_language()] to\n# language codes supported by select2.\n# See django/contrib/admin/static/admin/js/vendor/select2/i18n/*\nSELECT2_TRANSLATIONS = {x.lower(): x for x in [\n    'ar', 'az', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et',\n    'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'is',\n    'it', 'ja', 'km', 'ko', 'lt', 'lv', 'mk', 'ms', 'nb', 'nl', 'pl',\n    'pt-BR', 'pt', 'ro', 'ru', 'sk', 'sr-Cyrl', 'sr', 'sv', 'th',\n    'tr', 'uk', 'vi',\n]}\nSELECT2_TRANSLATIONS.update({'zh-hans': 'zh-CN', 'zh-hant': 'zh-TW'})\n\n\nclass AutocompleteMixin:\n    \"\"\"\n    Select widget mixin that loads options from AutocompleteJsonView via AJAX.\n\n    Renders the necessary data attributes for select2 and adds the static form\n    media.\n    \"\"\"\n    url_name = '%s:%s_%s_autocomplete'\n\n    def __init__(self, rel, admin_site, attrs=None, choices=(), using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        self.choices = choices\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def get_url(self):\n        model = self.rel.model\n        return reverse(self.url_name % (self.admin_site.name, model._meta.app_label, model._meta.model_name))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"\n        Set select2's AJAX attributes.\n\n        Attributes can be set using the html5 data attribute.\n        Nested attributes require a double dash as per\n        https://select2.org/configuration/data-attributes#nested-subkey-options\n        \"\"\"\n        attrs = super().build_attrs(base_attrs, extra_attrs=extra_attrs)\n        attrs.setdefault('class', '')\n        attrs.update({\n            'data-ajax--cache': 'true',\n            'data-ajax--delay': 250,\n            'data-ajax--type': 'GET',\n            'data-ajax--url': self.get_url(),\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': json.dumps(not self.is_required),\n            'data-placeholder': '',  # Allows clearing of the input.\n            'class': attrs['class'] + (' ' if attrs['class'] else '') + 'admin-autocomplete',\n        })\n        return attrs\n\n    def optgroups(self, name, value, attr=None):\n        \"\"\"Return selected options based on the ModelChoiceIterator.\"\"\"\n        default = (None, [], 0)\n        groups = [default]\n        has_selected = False\n        selected_choices = {\n            str(v) for v in value\n            if str(v) not in self.choices.field.empty_values\n        }\n        if not self.is_required and not self.allow_multiple_selected:\n            default[1].append(self.create_option(name, '', '', False, 0))\n        choices = (\n            (obj.pk, self.choices.field.label_from_instance(obj))\n            for obj in self.choices.queryset.using(self.db).filter(pk__in=selected_choices)\n        )\n        for option_value, option_label in choices:\n            selected = (\n                str(option_value) in value and\n                (has_selected is False or self.allow_multiple_selected)\n            )\n            has_selected |= selected\n            index = len(default[1])\n            subgroup = default[1]\n            subgroup.append(self.create_option(name, option_value, option_label, selected_choices, index))\n        return groups\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        i18n_name = SELECT2_TRANSLATIONS.get(get_language())\n        i18n_file = ('admin/js/vendor/select2/i18n/%s.js' % i18n_name,) if i18n_name else ()\n        return forms.Media(\n            js=(\n                'admin/js/vendor/jquery/jquery%s.js' % extra,\n                'admin/js/vendor/select2/select2.full%s.js' % extra,\n            ) + i18n_file + (\n                'admin/js/jquery.init.js',\n                'admin/js/autocomplete.js',\n            ),\n            css={\n                'screen': (\n                    'admin/css/vendor/select2/select2%s.css' % extra,\n                    'admin/css/autocomplete.css',\n                ),\n            },\n        )\n\n\nclass AutocompleteSelect(AutocompleteMixin, forms.Select):\n    pass\n\n\nclass AutocompleteSelectMultiple(AutocompleteMixin, forms.SelectMultiple):\n    pass\n"
  },
  {
    "patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex 54e85d5a33..e5e6a86c1e 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -20,6 +20,15 @@ from django.utils.translation import gettext, gettext_lazy as _\n UserModel = get_user_model()\n \n \n+def _unicode_ci_compare(s1, s2):\n+    \"\"\"\n+    Perform case-insensitive comparison of two identifiers, using the\n+    recommended algorithm from Unicode Technical Report 36, section\n+    2.11.2(B)(2).\n+    \"\"\"\n+    return unicodedata.normalize('NFKC', s1).casefold() == unicodedata.normalize('NFKC', s2).casefold()\n+\n+\n class ReadOnlyPasswordHashWidget(forms.Widget):\n     template_name = 'auth/widgets/read_only_password_hash.html'\n     read_only = True\n@@ -269,11 +278,16 @@ class PasswordResetForm(forms.Form):\n         that prevent inactive users and users with unusable passwords from\n         resetting their password.\n         \"\"\"\n+        email_field_name = UserModel.get_email_field_name()\n         active_users = UserModel._default_manager.filter(**{\n-            '%s__iexact' % UserModel.get_email_field_name(): email,\n+            '%s__iexact' % email_field_name: email,\n             'is_active': True,\n         })\n-        return (u for u in active_users if u.has_usable_password())\n+        return (\n+            u for u in active_users\n+            if u.has_usable_password() and\n+            _unicode_ci_compare(email, getattr(u, email_field_name))\n+        )\n \n     def save(self, domain_override=None,\n              subject_template_name='registration/password_reset_subject.txt',\n@@ -292,9 +306,11 @@ class PasswordResetForm(forms.Form):\n             domain = current_site.domain\n         else:\n             site_name = domain = domain_override\n+        email_field_name = UserModel.get_email_field_name()\n         for user in self.get_users(email):\n+            user_email = getattr(user, email_field_name)\n             context = {\n-                'email': email,\n+                'email': user_email,\n                 'domain': domain,\n                 'site_name': site_name,\n                 'uid': urlsafe_base64_encode(force_bytes(user.pk)),\n@@ -305,7 +321,7 @@ class PasswordResetForm(forms.Form):\n             }\n             self.send_mail(\n                 subject_template_name, email_template_name, context, from_email,\n-                email, html_email_template_name=html_email_template_name,\n+                user_email, html_email_template_name=html_email_template_name,\n             )\n \n \n",
    "commit_message": "Fixed CVE-2019-19844 -- Used verified user email for password reset requests.\n\nCo-Authored-By: Florian Apolloner <florian@apolloner.eu>\n\n",
    "code_before": "import unicodedata\n\nfrom django import forms\nfrom django.contrib.auth import (\n    authenticate, get_user_model, password_validation,\n)\nfrom django.contrib.auth.hashers import (\n    UNUSABLE_PASSWORD_PREFIX, identify_hasher,\n)\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.tokens import default_token_generator\nfrom django.contrib.sites.shortcuts import get_current_site\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.template import loader\nfrom django.utils.encoding import force_bytes\nfrom django.utils.http import urlsafe_base64_encode\nfrom django.utils.text import capfirst\nfrom django.utils.translation import gettext, gettext_lazy as _\n\nUserModel = get_user_model()\n\n\nclass ReadOnlyPasswordHashWidget(forms.Widget):\n    template_name = 'auth/widgets/read_only_password_hash.html'\n    read_only = True\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        summary = []\n        if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n            summary.append({'label': gettext(\"No password set.\")})\n        else:\n            try:\n                hasher = identify_hasher(value)\n            except ValueError:\n                summary.append({'label': gettext(\"Invalid password format or unknown hashing algorithm.\")})\n            else:\n                for key, value_ in hasher.safe_summary(value).items():\n                    summary.append({'label': gettext(key), 'value': value_})\n        context['summary'] = summary\n        return context\n\n\nclass ReadOnlyPasswordHashField(forms.Field):\n    widget = ReadOnlyPasswordHashWidget\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault(\"required\", False)\n        super().__init__(*args, **kwargs)\n\n    def bound_data(self, data, initial):\n        # Always return initial because the widget doesn't\n        # render an input field.\n        return initial\n\n    def has_changed(self, initial, data):\n        return False\n\n\nclass UsernameField(forms.CharField):\n    def to_python(self, value):\n        return unicodedata.normalize('NFKC', super().to_python(value))\n\n    def widget_attrs(self, widget):\n        return {\n            **super().widget_attrs(widget),\n            'autocapitalize': 'none',\n            'autocomplete': 'username',\n        }\n\n\nclass UserCreationForm(forms.ModelForm):\n    \"\"\"\n    A form that creates a user, with no privileges, from the given username and\n    password.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password confirmation\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    class Meta:\n        model = User\n        fields = (\"username\",)\n        field_classes = {'username': UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if self._meta.model.USERNAME_FIELD in self.fields:\n            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs['autofocus'] = True\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get(\"password1\")\n        password2 = self.cleaned_data.get(\"password2\")\n        if password1 and password2 and password1 != password2:\n            raise forms.ValidationError(\n                self.error_messages['password_mismatch'],\n                code='password_mismatch',\n            )\n        return password2\n\n    def _post_clean(self):\n        super()._post_clean()\n        # Validate the password after self.instance is updated with form data\n        # by super().\n        password = self.cleaned_data.get('password2')\n        if password:\n            try:\n                password_validation.validate_password(password, self.instance)\n            except forms.ValidationError as error:\n                self.add_error('password2', error)\n\n    def save(self, commit=True):\n        user = super().save(commit=False)\n        user.set_password(self.cleaned_data[\"password1\"])\n        if commit:\n            user.save()\n        return user\n\n\nclass UserChangeForm(forms.ModelForm):\n    password = ReadOnlyPasswordHashField(\n        label=_(\"Password\"),\n        help_text=_(\n            'Raw passwords are not stored, so there is no way to see this '\n            'user\u2019s password, but you can change the password using '\n            '<a href=\"{}\">this form</a>.'\n        ),\n    )\n\n    class Meta:\n        model = User\n        fields = '__all__'\n        field_classes = {'username': UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        password = self.fields.get('password')\n        if password:\n            password.help_text = password.help_text.format('../password/')\n        user_permissions = self.fields.get('user_permissions')\n        if user_permissions:\n            user_permissions.queryset = user_permissions.queryset.select_related('content_type')\n\n    def clean_password(self):\n        # Regardless of what the user provides, return the initial value.\n        # This is done here, rather than on the field, because the\n        # field does not have access to the initial value\n        return self.initial.get('password')\n\n\nclass AuthenticationForm(forms.Form):\n    \"\"\"\n    Base class for authenticating users. Extend this to get a form that accepts\n    username/password logins.\n    \"\"\"\n    username = UsernameField(widget=forms.TextInput(attrs={'autofocus': True}))\n    password = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password'}),\n    )\n\n    error_messages = {\n        'invalid_login': _(\n            \"Please enter a correct %(username)s and password. Note that both \"\n            \"fields may be case-sensitive.\"\n        ),\n        'inactive': _(\"This account is inactive.\"),\n    }\n\n    def __init__(self, request=None, *args, **kwargs):\n        \"\"\"\n        The 'request' parameter is set for custom auth use by subclasses.\n        The form data comes in via the standard 'data' kwarg.\n        \"\"\"\n        self.request = request\n        self.user_cache = None\n        super().__init__(*args, **kwargs)\n\n        # Set the max length and label for the \"username\" field.\n        self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n        username_max_length = self.username_field.max_length or 254\n        self.fields['username'].max_length = username_max_length\n        self.fields['username'].widget.attrs['maxlength'] = username_max_length\n        if self.fields['username'].label is None:\n            self.fields['username'].label = capfirst(self.username_field.verbose_name)\n\n    def clean(self):\n        username = self.cleaned_data.get('username')\n        password = self.cleaned_data.get('password')\n\n        if username is not None and password:\n            self.user_cache = authenticate(self.request, username=username, password=password)\n            if self.user_cache is None:\n                raise self.get_invalid_login_error()\n            else:\n                self.confirm_login_allowed(self.user_cache)\n\n        return self.cleaned_data\n\n    def confirm_login_allowed(self, user):\n        \"\"\"\n        Controls whether the given User may log in. This is a policy setting,\n        independent of end-user authentication. This default behavior is to\n        allow login by active users, and reject login by inactive users.\n\n        If the given user cannot log in, this method should raise a\n        ``forms.ValidationError``.\n\n        If the given user may log in, this method should return None.\n        \"\"\"\n        if not user.is_active:\n            raise forms.ValidationError(\n                self.error_messages['inactive'],\n                code='inactive',\n            )\n\n    def get_user(self):\n        return self.user_cache\n\n    def get_invalid_login_error(self):\n        return forms.ValidationError(\n            self.error_messages['invalid_login'],\n            code='invalid_login',\n            params={'username': self.username_field.verbose_name},\n        )\n\n\nclass PasswordResetForm(forms.Form):\n    email = forms.EmailField(\n        label=_(\"Email\"),\n        max_length=254,\n        widget=forms.EmailInput(attrs={'autocomplete': 'email'})\n    )\n\n    def send_mail(self, subject_template_name, email_template_name,\n                  context, from_email, to_email, html_email_template_name=None):\n        \"\"\"\n        Send a django.core.mail.EmailMultiAlternatives to `to_email`.\n        \"\"\"\n        subject = loader.render_to_string(subject_template_name, context)\n        # Email subject *must not* contain newlines\n        subject = ''.join(subject.splitlines())\n        body = loader.render_to_string(email_template_name, context)\n\n        email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])\n        if html_email_template_name is not None:\n            html_email = loader.render_to_string(html_email_template_name, context)\n            email_message.attach_alternative(html_email, 'text/html')\n\n        email_message.send()\n\n    def get_users(self, email):\n        \"\"\"Given an email, return matching user(s) who should receive a reset.\n\n        This allows subclasses to more easily customize the default policies\n        that prevent inactive users and users with unusable passwords from\n        resetting their password.\n        \"\"\"\n        active_users = UserModel._default_manager.filter(**{\n            '%s__iexact' % UserModel.get_email_field_name(): email,\n            'is_active': True,\n        })\n        return (u for u in active_users if u.has_usable_password())\n\n    def save(self, domain_override=None,\n             subject_template_name='registration/password_reset_subject.txt',\n             email_template_name='registration/password_reset_email.html',\n             use_https=False, token_generator=default_token_generator,\n             from_email=None, request=None, html_email_template_name=None,\n             extra_email_context=None):\n        \"\"\"\n        Generate a one-use only link for resetting password and send it to the\n        user.\n        \"\"\"\n        email = self.cleaned_data[\"email\"]\n        if not domain_override:\n            current_site = get_current_site(request)\n            site_name = current_site.name\n            domain = current_site.domain\n        else:\n            site_name = domain = domain_override\n        for user in self.get_users(email):\n            context = {\n                'email': email,\n                'domain': domain,\n                'site_name': site_name,\n                'uid': urlsafe_base64_encode(force_bytes(user.pk)),\n                'user': user,\n                'token': token_generator.make_token(user),\n                'protocol': 'https' if use_https else 'http',\n                **(extra_email_context or {}),\n            }\n            self.send_mail(\n                subject_template_name, email_template_name, context, from_email,\n                email, html_email_template_name=html_email_template_name,\n            )\n\n\nclass SetPasswordForm(forms.Form):\n    \"\"\"\n    A form that lets a user change set their password without entering the old\n    password\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    new_password1 = forms.CharField(\n        label=_(\"New password\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    new_password2 = forms.CharField(\n        label=_(\"New password confirmation\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_new_password2(self):\n        password1 = self.cleaned_data.get('new_password1')\n        password2 = self.cleaned_data.get('new_password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        password = self.cleaned_data[\"new_password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n\nclass PasswordChangeForm(SetPasswordForm):\n    \"\"\"\n    A form that lets a user change their password by entering their old\n    password.\n    \"\"\"\n    error_messages = {\n        **SetPasswordForm.error_messages,\n        'password_incorrect': _(\"Your old password was entered incorrectly. Please enter it again.\"),\n    }\n    old_password = forms.CharField(\n        label=_(\"Old password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password', 'autofocus': True}),\n    )\n\n    field_order = ['old_password', 'new_password1', 'new_password2']\n\n    def clean_old_password(self):\n        \"\"\"\n        Validate that the old_password field is correct.\n        \"\"\"\n        old_password = self.cleaned_data[\"old_password\"]\n        if not self.user.check_password(old_password):\n            raise forms.ValidationError(\n                self.error_messages['password_incorrect'],\n                code='password_incorrect',\n            )\n        return old_password\n\n\nclass AdminPasswordChangeForm(forms.Form):\n    \"\"\"\n    A form used to change the password of a user in the admin interface.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    required_css_class = 'required'\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password', 'autofocus': True}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password (again)\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get('password1')\n        password2 = self.cleaned_data.get('password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        \"\"\"Save the new password.\"\"\"\n        password = self.cleaned_data[\"password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        for name in self.fields:\n            if name not in data:\n                return []\n        return ['password']\n",
    "code_after": "import unicodedata\n\nfrom django import forms\nfrom django.contrib.auth import (\n    authenticate, get_user_model, password_validation,\n)\nfrom django.contrib.auth.hashers import (\n    UNUSABLE_PASSWORD_PREFIX, identify_hasher,\n)\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.tokens import default_token_generator\nfrom django.contrib.sites.shortcuts import get_current_site\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.template import loader\nfrom django.utils.encoding import force_bytes\nfrom django.utils.http import urlsafe_base64_encode\nfrom django.utils.text import capfirst\nfrom django.utils.translation import gettext, gettext_lazy as _\n\nUserModel = get_user_model()\n\n\ndef _unicode_ci_compare(s1, s2):\n    \"\"\"\n    Perform case-insensitive comparison of two identifiers, using the\n    recommended algorithm from Unicode Technical Report 36, section\n    2.11.2(B)(2).\n    \"\"\"\n    return unicodedata.normalize('NFKC', s1).casefold() == unicodedata.normalize('NFKC', s2).casefold()\n\n\nclass ReadOnlyPasswordHashWidget(forms.Widget):\n    template_name = 'auth/widgets/read_only_password_hash.html'\n    read_only = True\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        summary = []\n        if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n            summary.append({'label': gettext(\"No password set.\")})\n        else:\n            try:\n                hasher = identify_hasher(value)\n            except ValueError:\n                summary.append({'label': gettext(\"Invalid password format or unknown hashing algorithm.\")})\n            else:\n                for key, value_ in hasher.safe_summary(value).items():\n                    summary.append({'label': gettext(key), 'value': value_})\n        context['summary'] = summary\n        return context\n\n\nclass ReadOnlyPasswordHashField(forms.Field):\n    widget = ReadOnlyPasswordHashWidget\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault(\"required\", False)\n        super().__init__(*args, **kwargs)\n\n    def bound_data(self, data, initial):\n        # Always return initial because the widget doesn't\n        # render an input field.\n        return initial\n\n    def has_changed(self, initial, data):\n        return False\n\n\nclass UsernameField(forms.CharField):\n    def to_python(self, value):\n        return unicodedata.normalize('NFKC', super().to_python(value))\n\n    def widget_attrs(self, widget):\n        return {\n            **super().widget_attrs(widget),\n            'autocapitalize': 'none',\n            'autocomplete': 'username',\n        }\n\n\nclass UserCreationForm(forms.ModelForm):\n    \"\"\"\n    A form that creates a user, with no privileges, from the given username and\n    password.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password confirmation\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    class Meta:\n        model = User\n        fields = (\"username\",)\n        field_classes = {'username': UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if self._meta.model.USERNAME_FIELD in self.fields:\n            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs['autofocus'] = True\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get(\"password1\")\n        password2 = self.cleaned_data.get(\"password2\")\n        if password1 and password2 and password1 != password2:\n            raise forms.ValidationError(\n                self.error_messages['password_mismatch'],\n                code='password_mismatch',\n            )\n        return password2\n\n    def _post_clean(self):\n        super()._post_clean()\n        # Validate the password after self.instance is updated with form data\n        # by super().\n        password = self.cleaned_data.get('password2')\n        if password:\n            try:\n                password_validation.validate_password(password, self.instance)\n            except forms.ValidationError as error:\n                self.add_error('password2', error)\n\n    def save(self, commit=True):\n        user = super().save(commit=False)\n        user.set_password(self.cleaned_data[\"password1\"])\n        if commit:\n            user.save()\n        return user\n\n\nclass UserChangeForm(forms.ModelForm):\n    password = ReadOnlyPasswordHashField(\n        label=_(\"Password\"),\n        help_text=_(\n            'Raw passwords are not stored, so there is no way to see this '\n            'user\u2019s password, but you can change the password using '\n            '<a href=\"{}\">this form</a>.'\n        ),\n    )\n\n    class Meta:\n        model = User\n        fields = '__all__'\n        field_classes = {'username': UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        password = self.fields.get('password')\n        if password:\n            password.help_text = password.help_text.format('../password/')\n        user_permissions = self.fields.get('user_permissions')\n        if user_permissions:\n            user_permissions.queryset = user_permissions.queryset.select_related('content_type')\n\n    def clean_password(self):\n        # Regardless of what the user provides, return the initial value.\n        # This is done here, rather than on the field, because the\n        # field does not have access to the initial value\n        return self.initial.get('password')\n\n\nclass AuthenticationForm(forms.Form):\n    \"\"\"\n    Base class for authenticating users. Extend this to get a form that accepts\n    username/password logins.\n    \"\"\"\n    username = UsernameField(widget=forms.TextInput(attrs={'autofocus': True}))\n    password = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password'}),\n    )\n\n    error_messages = {\n        'invalid_login': _(\n            \"Please enter a correct %(username)s and password. Note that both \"\n            \"fields may be case-sensitive.\"\n        ),\n        'inactive': _(\"This account is inactive.\"),\n    }\n\n    def __init__(self, request=None, *args, **kwargs):\n        \"\"\"\n        The 'request' parameter is set for custom auth use by subclasses.\n        The form data comes in via the standard 'data' kwarg.\n        \"\"\"\n        self.request = request\n        self.user_cache = None\n        super().__init__(*args, **kwargs)\n\n        # Set the max length and label for the \"username\" field.\n        self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n        username_max_length = self.username_field.max_length or 254\n        self.fields['username'].max_length = username_max_length\n        self.fields['username'].widget.attrs['maxlength'] = username_max_length\n        if self.fields['username'].label is None:\n            self.fields['username'].label = capfirst(self.username_field.verbose_name)\n\n    def clean(self):\n        username = self.cleaned_data.get('username')\n        password = self.cleaned_data.get('password')\n\n        if username is not None and password:\n            self.user_cache = authenticate(self.request, username=username, password=password)\n            if self.user_cache is None:\n                raise self.get_invalid_login_error()\n            else:\n                self.confirm_login_allowed(self.user_cache)\n\n        return self.cleaned_data\n\n    def confirm_login_allowed(self, user):\n        \"\"\"\n        Controls whether the given User may log in. This is a policy setting,\n        independent of end-user authentication. This default behavior is to\n        allow login by active users, and reject login by inactive users.\n\n        If the given user cannot log in, this method should raise a\n        ``forms.ValidationError``.\n\n        If the given user may log in, this method should return None.\n        \"\"\"\n        if not user.is_active:\n            raise forms.ValidationError(\n                self.error_messages['inactive'],\n                code='inactive',\n            )\n\n    def get_user(self):\n        return self.user_cache\n\n    def get_invalid_login_error(self):\n        return forms.ValidationError(\n            self.error_messages['invalid_login'],\n            code='invalid_login',\n            params={'username': self.username_field.verbose_name},\n        )\n\n\nclass PasswordResetForm(forms.Form):\n    email = forms.EmailField(\n        label=_(\"Email\"),\n        max_length=254,\n        widget=forms.EmailInput(attrs={'autocomplete': 'email'})\n    )\n\n    def send_mail(self, subject_template_name, email_template_name,\n                  context, from_email, to_email, html_email_template_name=None):\n        \"\"\"\n        Send a django.core.mail.EmailMultiAlternatives to `to_email`.\n        \"\"\"\n        subject = loader.render_to_string(subject_template_name, context)\n        # Email subject *must not* contain newlines\n        subject = ''.join(subject.splitlines())\n        body = loader.render_to_string(email_template_name, context)\n\n        email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])\n        if html_email_template_name is not None:\n            html_email = loader.render_to_string(html_email_template_name, context)\n            email_message.attach_alternative(html_email, 'text/html')\n\n        email_message.send()\n\n    def get_users(self, email):\n        \"\"\"Given an email, return matching user(s) who should receive a reset.\n\n        This allows subclasses to more easily customize the default policies\n        that prevent inactive users and users with unusable passwords from\n        resetting their password.\n        \"\"\"\n        email_field_name = UserModel.get_email_field_name()\n        active_users = UserModel._default_manager.filter(**{\n            '%s__iexact' % email_field_name: email,\n            'is_active': True,\n        })\n        return (\n            u for u in active_users\n            if u.has_usable_password() and\n            _unicode_ci_compare(email, getattr(u, email_field_name))\n        )\n\n    def save(self, domain_override=None,\n             subject_template_name='registration/password_reset_subject.txt',\n             email_template_name='registration/password_reset_email.html',\n             use_https=False, token_generator=default_token_generator,\n             from_email=None, request=None, html_email_template_name=None,\n             extra_email_context=None):\n        \"\"\"\n        Generate a one-use only link for resetting password and send it to the\n        user.\n        \"\"\"\n        email = self.cleaned_data[\"email\"]\n        if not domain_override:\n            current_site = get_current_site(request)\n            site_name = current_site.name\n            domain = current_site.domain\n        else:\n            site_name = domain = domain_override\n        email_field_name = UserModel.get_email_field_name()\n        for user in self.get_users(email):\n            user_email = getattr(user, email_field_name)\n            context = {\n                'email': user_email,\n                'domain': domain,\n                'site_name': site_name,\n                'uid': urlsafe_base64_encode(force_bytes(user.pk)),\n                'user': user,\n                'token': token_generator.make_token(user),\n                'protocol': 'https' if use_https else 'http',\n                **(extra_email_context or {}),\n            }\n            self.send_mail(\n                subject_template_name, email_template_name, context, from_email,\n                user_email, html_email_template_name=html_email_template_name,\n            )\n\n\nclass SetPasswordForm(forms.Form):\n    \"\"\"\n    A form that lets a user change set their password without entering the old\n    password\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    new_password1 = forms.CharField(\n        label=_(\"New password\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    new_password2 = forms.CharField(\n        label=_(\"New password confirmation\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_new_password2(self):\n        password1 = self.cleaned_data.get('new_password1')\n        password2 = self.cleaned_data.get('new_password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        password = self.cleaned_data[\"new_password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n\nclass PasswordChangeForm(SetPasswordForm):\n    \"\"\"\n    A form that lets a user change their password by entering their old\n    password.\n    \"\"\"\n    error_messages = {\n        **SetPasswordForm.error_messages,\n        'password_incorrect': _(\"Your old password was entered incorrectly. Please enter it again.\"),\n    }\n    old_password = forms.CharField(\n        label=_(\"Old password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autocomplete': 'current-password', 'autofocus': True}),\n    )\n\n    field_order = ['old_password', 'new_password1', 'new_password2']\n\n    def clean_old_password(self):\n        \"\"\"\n        Validate that the old_password field is correct.\n        \"\"\"\n        old_password = self.cleaned_data[\"old_password\"]\n        if not self.user.check_password(old_password):\n            raise forms.ValidationError(\n                self.error_messages['password_incorrect'],\n                code='password_incorrect',\n            )\n        return old_password\n\n\nclass AdminPasswordChangeForm(forms.Form):\n    \"\"\"\n    A form used to change the password of a user in the admin interface.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _('The two password fields didn\u2019t match.'),\n    }\n    required_css_class = 'required'\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password', 'autofocus': True}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password (again)\"),\n        widget=forms.PasswordInput(attrs={'autocomplete': 'new-password'}),\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get('password1')\n        password2 = self.cleaned_data.get('password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        \"\"\"Save the new password.\"\"\"\n        password = self.cleaned_data[\"password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        for name in self.fields:\n            if name not in data:\n                return []\n        return ['password']\n"
  },
  {
    "patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 85896bed7e..795d20f96a 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1464,13 +1464,20 @@ class ModelAdmin(BaseModelAdmin):\n         )\n \n     def get_inline_formsets(self, request, formsets, inline_instances, obj=None):\n+        # Edit permissions on parent model are required for editable inlines.\n+        can_edit_parent = self.has_change_permission(request, obj) if obj else self.has_add_permission(request)\n         inline_admin_formsets = []\n         for inline, formset in zip(inline_instances, formsets):\n             fieldsets = list(inline.get_fieldsets(request, obj))\n             readonly = list(inline.get_readonly_fields(request, obj))\n-            has_add_permission = inline.has_add_permission(request, obj)\n-            has_change_permission = inline.has_change_permission(request, obj)\n-            has_delete_permission = inline.has_delete_permission(request, obj)\n+            if can_edit_parent:\n+                has_add_permission = inline.has_add_permission(request, obj)\n+                has_change_permission = inline.has_change_permission(request, obj)\n+                has_delete_permission = inline.has_delete_permission(request, obj)\n+            else:\n+                # Disable all edit-permissions, and overide formset settings.\n+                has_add_permission = has_change_permission = has_delete_permission = False\n+                formset.extra = formset.max_num = 0\n             has_view_permission = inline.has_view_permission(request, obj)\n             prepopulated = dict(inline.get_prepopulated_fields(request, obj))\n             inline_admin_formset = helpers.InlineAdminFormSet(\n@@ -1535,8 +1542,12 @@ class ModelAdmin(BaseModelAdmin):\n         else:\n             obj = self.get_object(request, unquote(object_id), to_field)\n \n-            if not self.has_view_or_change_permission(request, obj):\n-                raise PermissionDenied\n+            if request.method == 'POST':\n+                if not self.has_change_permission(request, obj):\n+                    raise PermissionDenied\n+            else:\n+                if not self.has_view_or_change_permission(request, obj):\n+                    raise PermissionDenied\n \n             if obj is None:\n                 return self._get_obj_does_not_exist_redirect(request, opts, object_id)\n",
    "commit_message": "Fixed CVE-2019-19118 -- Required edit permissions on parent model for editable inlines in admin.\n\nThank you to Shen Ying for reporting this issue.\n\n",
    "code_before": "import copy\nimport json\nimport operator\nimport re\nfrom functools import partial, reduce, update_wrapper\nfrom urllib.parse import quote as urlquote\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.contrib.admin import helpers, widgets\nfrom django.contrib.admin.checks import (\n    BaseModelAdminChecks, InlineModelAdminChecks, ModelAdminChecks,\n)\nfrom django.contrib.admin.exceptions import DisallowedModelAdminToField\nfrom django.contrib.admin.templatetags.admin_urls import add_preserved_filters\nfrom django.contrib.admin.utils import (\n    NestedObjects, construct_change_message, flatten_fieldsets,\n    get_deleted_objects, lookup_needs_distinct, model_format_dict,\n    model_ngettext, quote, unquote,\n)\nfrom django.contrib.admin.views.autocomplete import AutocompleteJsonView\nfrom django.contrib.admin.widgets import (\n    AutocompleteSelect, AutocompleteSelectMultiple,\n)\nfrom django.contrib.auth import get_permission_codename\nfrom django.core.exceptions import (\n    FieldDoesNotExist, FieldError, PermissionDenied, ValidationError,\n)\nfrom django.core.paginator import Paginator\nfrom django.db import models, router, transaction\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.fields import BLANK_CHOICE_DASH\nfrom django.forms.formsets import DELETION_FIELD_NAME, all_valid\nfrom django.forms.models import (\n    BaseInlineFormSet, inlineformset_factory, modelform_defines_fields,\n    modelform_factory, modelformset_factory,\n)\nfrom django.forms.widgets import CheckboxSelectMultiple, SelectMultiple\nfrom django.http import HttpResponseRedirect\nfrom django.http.response import HttpResponseBase\nfrom django.template.response import SimpleTemplateResponse, TemplateResponse\nfrom django.urls import reverse\nfrom django.utils.decorators import method_decorator\nfrom django.utils.html import format_html\nfrom django.utils.http import urlencode\nfrom django.utils.safestring import mark_safe\nfrom django.utils.text import capfirst, format_lazy, get_text_list\nfrom django.utils.translation import gettext as _, ngettext\nfrom django.views.decorators.csrf import csrf_protect\nfrom django.views.generic import RedirectView\n\nIS_POPUP_VAR = '_popup'\nTO_FIELD_VAR = '_to_field'\n\n\nHORIZONTAL, VERTICAL = 1, 2\n\n\ndef get_content_type_for_model(obj):\n    # Since this module gets imported in the application's root package,\n    # it cannot import models from other applications at the module level.\n    from django.contrib.contenttypes.models import ContentType\n    return ContentType.objects.get_for_model(obj, for_concrete_model=False)\n\n\ndef get_ul_class(radio_style):\n    return 'radiolist' if radio_style == VERTICAL else 'radiolist inline'\n\n\nclass IncorrectLookupParameters(Exception):\n    pass\n\n\n# Defaults for formfield_overrides. ModelAdmin subclasses can change this\n# by adding to ModelAdmin.formfield_overrides.\n\nFORMFIELD_FOR_DBFIELD_DEFAULTS = {\n    models.DateTimeField: {\n        'form_class': forms.SplitDateTimeField,\n        'widget': widgets.AdminSplitDateTime\n    },\n    models.DateField: {'widget': widgets.AdminDateWidget},\n    models.TimeField: {'widget': widgets.AdminTimeWidget},\n    models.TextField: {'widget': widgets.AdminTextareaWidget},\n    models.URLField: {'widget': widgets.AdminURLFieldWidget},\n    models.IntegerField: {'widget': widgets.AdminIntegerFieldWidget},\n    models.BigIntegerField: {'widget': widgets.AdminBigIntegerFieldWidget},\n    models.CharField: {'widget': widgets.AdminTextInputWidget},\n    models.ImageField: {'widget': widgets.AdminFileWidget},\n    models.FileField: {'widget': widgets.AdminFileWidget},\n    models.EmailField: {'widget': widgets.AdminEmailInputWidget},\n    models.UUIDField: {'widget': widgets.AdminUUIDInputWidget},\n}\n\ncsrf_protect_m = method_decorator(csrf_protect)\n\n\nclass BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n    \"\"\"Functionality common to both ModelAdmin and InlineAdmin.\"\"\"\n\n    autocomplete_fields = ()\n    raw_id_fields = ()\n    fields = None\n    exclude = None\n    fieldsets = None\n    form = forms.ModelForm\n    filter_vertical = ()\n    filter_horizontal = ()\n    radio_fields = {}\n    prepopulated_fields = {}\n    formfield_overrides = {}\n    readonly_fields = ()\n    ordering = None\n    sortable_by = None\n    view_on_site = True\n    show_full_result_count = True\n    checks_class = BaseModelAdminChecks\n\n    def check(self, **kwargs):\n        return self.checks_class().check(self, **kwargs)\n\n    def __init__(self):\n        # Merge FORMFIELD_FOR_DBFIELD_DEFAULTS with the formfield_overrides\n        # rather than simply overwriting.\n        overrides = copy.deepcopy(FORMFIELD_FOR_DBFIELD_DEFAULTS)\n        for k, v in self.formfield_overrides.items():\n            overrides.setdefault(k, {}).update(v)\n        self.formfield_overrides = overrides\n\n    def formfield_for_dbfield(self, db_field, request, **kwargs):\n        \"\"\"\n        Hook for specifying the form Field instance for a given database Field\n        instance.\n\n        If kwargs are given, they're passed to the form Field's constructor.\n        \"\"\"\n        # If the field specifies choices, we don't need to look for special\n        # admin widgets - we just need to use a select widget of some kind.\n        if db_field.choices:\n            return self.formfield_for_choice_field(db_field, request, **kwargs)\n\n        # ForeignKey or ManyToManyFields\n        if isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n            # Combine the field kwargs with any options for formfield_overrides.\n            # Make sure the passed in **kwargs override anything in\n            # formfield_overrides because **kwargs is more specific, and should\n            # always win.\n            if db_field.__class__ in self.formfield_overrides:\n                kwargs = {**self.formfield_overrides[db_field.__class__], **kwargs}\n\n            # Get the correct formfield.\n            if isinstance(db_field, models.ForeignKey):\n                formfield = self.formfield_for_foreignkey(db_field, request, **kwargs)\n            elif isinstance(db_field, models.ManyToManyField):\n                formfield = self.formfield_for_manytomany(db_field, request, **kwargs)\n\n            # For non-raw_id fields, wrap the widget with a wrapper that adds\n            # extra HTML -- the \"add other\" interface -- to the end of the\n            # rendered output. formfield can be None if it came from a\n            # OneToOneField with parent_link=True or a M2M intermediary.\n            if formfield and db_field.name not in self.raw_id_fields:\n                related_modeladmin = self.admin_site._registry.get(db_field.remote_field.model)\n                wrapper_kwargs = {}\n                if related_modeladmin:\n                    wrapper_kwargs.update(\n                        can_add_related=related_modeladmin.has_add_permission(request),\n                        can_change_related=related_modeladmin.has_change_permission(request),\n                        can_delete_related=related_modeladmin.has_delete_permission(request),\n                        can_view_related=related_modeladmin.has_view_permission(request),\n                    )\n                formfield.widget = widgets.RelatedFieldWidgetWrapper(\n                    formfield.widget, db_field.remote_field, self.admin_site, **wrapper_kwargs\n                )\n\n            return formfield\n\n        # If we've got overrides for the formfield defined, use 'em. **kwargs\n        # passed to formfield_for_dbfield override the defaults.\n        for klass in db_field.__class__.mro():\n            if klass in self.formfield_overrides:\n                kwargs = {**copy.deepcopy(self.formfield_overrides[klass]), **kwargs}\n                return db_field.formfield(**kwargs)\n\n        # For any other type of field, just call its formfield() method.\n        return db_field.formfield(**kwargs)\n\n    def formfield_for_choice_field(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a database Field that has declared choices.\n        \"\"\"\n        # If the field is named as a radio_field, use a RadioSelect\n        if db_field.name in self.radio_fields:\n            # Avoid stomping on custom widget/choices arguments.\n            if 'widget' not in kwargs:\n                kwargs['widget'] = widgets.AdminRadioSelect(attrs={\n                    'class': get_ul_class(self.radio_fields[db_field.name]),\n                })\n            if 'choices' not in kwargs:\n                kwargs['choices'] = db_field.get_choices(\n                    include_blank=db_field.blank,\n                    blank_choice=[('', _('None'))]\n                )\n        return db_field.formfield(**kwargs)\n\n    def get_field_queryset(self, db, db_field, request):\n        \"\"\"\n        If the ModelAdmin specifies ordering, the queryset should respect that\n        ordering.  Otherwise don't specify the queryset, let the field decide\n        (return None in that case).\n        \"\"\"\n        related_admin = self.admin_site._registry.get(db_field.remote_field.model)\n        if related_admin is not None:\n            ordering = related_admin.get_ordering(request)\n            if ordering is not None and ordering != ():\n                return db_field.remote_field.model._default_manager.using(db).order_by(*ordering)\n        return None\n\n    def formfield_for_foreignkey(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a ForeignKey.\n        \"\"\"\n        db = kwargs.get('using')\n\n        if 'widget' not in kwargs:\n            if db_field.name in self.get_autocomplete_fields(request):\n                kwargs['widget'] = AutocompleteSelect(db_field.remote_field, self.admin_site, using=db)\n            elif db_field.name in self.raw_id_fields:\n                kwargs['widget'] = widgets.ForeignKeyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n            elif db_field.name in self.radio_fields:\n                kwargs['widget'] = widgets.AdminRadioSelect(attrs={\n                    'class': get_ul_class(self.radio_fields[db_field.name]),\n                })\n                kwargs['empty_label'] = _('None') if db_field.blank else None\n\n        if 'queryset' not in kwargs:\n            queryset = self.get_field_queryset(db, db_field, request)\n            if queryset is not None:\n                kwargs['queryset'] = queryset\n\n        return db_field.formfield(**kwargs)\n\n    def formfield_for_manytomany(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a ManyToManyField.\n        \"\"\"\n        # If it uses an intermediary model that isn't auto created, don't show\n        # a field in admin.\n        if not db_field.remote_field.through._meta.auto_created:\n            return None\n        db = kwargs.get('using')\n\n        autocomplete_fields = self.get_autocomplete_fields(request)\n        if db_field.name in autocomplete_fields:\n            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n        elif db_field.name in self.raw_id_fields:\n            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n            kwargs['widget'] = widgets.FilteredSelectMultiple(\n                db_field.verbose_name,\n                db_field.name in self.filter_vertical\n            )\n\n        if 'queryset' not in kwargs:\n            queryset = self.get_field_queryset(db, db_field, request)\n            if queryset is not None:\n                kwargs['queryset'] = queryset\n\n        form_field = db_field.formfield(**kwargs)\n        if (isinstance(form_field.widget, SelectMultiple) and\n                not isinstance(form_field.widget, (CheckboxSelectMultiple, AutocompleteSelectMultiple))):\n            msg = _('Hold down \u201cControl\u201d, or \u201cCommand\u201d on a Mac, to select more than one.')\n            help_text = form_field.help_text\n            form_field.help_text = format_lazy('{} {}', help_text, msg) if help_text else msg\n        return form_field\n\n    def get_autocomplete_fields(self, request):\n        \"\"\"\n        Return a list of ForeignKey and/or ManyToMany fields which should use\n        an autocomplete widget.\n        \"\"\"\n        return self.autocomplete_fields\n\n    def get_view_on_site_url(self, obj=None):\n        if obj is None or not self.view_on_site:\n            return None\n\n        if callable(self.view_on_site):\n            return self.view_on_site(obj)\n        elif self.view_on_site and hasattr(obj, 'get_absolute_url'):\n            # use the ContentType lookup if view_on_site is True\n            return reverse('admin:view_on_site', kwargs={\n                'content_type_id': get_content_type_for_model(obj).pk,\n                'object_id': obj.pk\n            })\n\n    def get_empty_value_display(self):\n        \"\"\"\n        Return the empty_value_display set on ModelAdmin or AdminSite.\n        \"\"\"\n        try:\n            return mark_safe(self.empty_value_display)\n        except AttributeError:\n            return mark_safe(self.admin_site.empty_value_display)\n\n    def get_exclude(self, request, obj=None):\n        \"\"\"\n        Hook for specifying exclude.\n        \"\"\"\n        return self.exclude\n\n    def get_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying fields.\n        \"\"\"\n        if self.fields:\n            return self.fields\n        # _get_form_for_get_fields() is implemented in subclasses.\n        form = self._get_form_for_get_fields(request, obj)\n        return [*form.base_fields, *self.get_readonly_fields(request, obj)]\n\n    def get_fieldsets(self, request, obj=None):\n        \"\"\"\n        Hook for specifying fieldsets.\n        \"\"\"\n        if self.fieldsets:\n            return self.fieldsets\n        return [(None, {'fields': self.get_fields(request, obj)})]\n\n    def get_inlines(self, request, obj):\n        \"\"\"Hook for specifying custom inlines.\"\"\"\n        return self.inlines\n\n    def get_ordering(self, request):\n        \"\"\"\n        Hook for specifying field ordering.\n        \"\"\"\n        return self.ordering or ()  # otherwise we might try to *None, which is bad ;)\n\n    def get_readonly_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying custom readonly fields.\n        \"\"\"\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying custom prepopulated fields.\n        \"\"\"\n        return self.prepopulated_fields\n\n    def get_queryset(self, request):\n        \"\"\"\n        Return a QuerySet of all model instances that can be edited by the\n        admin site. This is used by changelist_view.\n        \"\"\"\n        qs = self.model._default_manager.get_queryset()\n        # TODO: this should be handled by some parameter to the ChangeList.\n        ordering = self.get_ordering(request)\n        if ordering:\n            qs = qs.order_by(*ordering)\n        return qs\n\n    def get_sortable_by(self, request):\n        \"\"\"Hook for specifying which fields can be sorted in the changelist.\"\"\"\n        return self.sortable_by if self.sortable_by is not None else self.get_list_display(request)\n\n    def lookup_allowed(self, lookup, value):\n        from django.contrib.admin.filters import SimpleListFilter\n\n        model = self.model\n        # Check FKey lookups that are allowed, so that popups produced by\n        # ForeignKeyRawIdWidget, on the basis of ForeignKey.limit_choices_to,\n        # are allowed to work.\n        for fk_lookup in model._meta.related_fkey_lookups:\n            # As ``limit_choices_to`` can be a callable, invoke it here.\n            if callable(fk_lookup):\n                fk_lookup = fk_lookup()\n            if (lookup, value) in widgets.url_params_from_lookup_dict(fk_lookup).items():\n                return True\n\n        relation_parts = []\n        prev_field = None\n        for part in lookup.split(LOOKUP_SEP):\n            try:\n                field = model._meta.get_field(part)\n            except FieldDoesNotExist:\n                # Lookups on nonexistent fields are ok, since they're ignored\n                # later.\n                break\n            # It is allowed to filter on values that would be found from local\n            # model anyways. For example, if you filter on employee__department__id,\n            # then the id value would be found already from employee__department_id.\n            if not prev_field or (prev_field.is_relation and\n                                  field not in prev_field.get_path_info()[-1].target_fields):\n                relation_parts.append(part)\n            if not getattr(field, 'get_path_info', None):\n                # This is not a relational field, so further parts\n                # must be transforms.\n                break\n            prev_field = field\n            model = field.get_path_info()[-1].to_opts.model\n\n        if len(relation_parts) <= 1:\n            # Either a local field filter, or no fields at all.\n            return True\n        valid_lookups = {self.date_hierarchy}\n        for filter_item in self.list_filter:\n            if isinstance(filter_item, type) and issubclass(filter_item, SimpleListFilter):\n                valid_lookups.add(filter_item.parameter_name)\n            elif isinstance(filter_item, (list, tuple)):\n                valid_lookups.add(filter_item[0])\n            else:\n                valid_lookups.add(filter_item)\n\n        # Is it a valid relational lookup?\n        return not {\n            LOOKUP_SEP.join(relation_parts),\n            LOOKUP_SEP.join(relation_parts + [part])\n        }.isdisjoint(valid_lookups)\n\n    def to_field_allowed(self, request, to_field):\n        \"\"\"\n        Return True if the model associated with this admin should be\n        allowed to be referenced by the specified field.\n        \"\"\"\n        opts = self.model._meta\n\n        try:\n            field = opts.get_field(to_field)\n        except FieldDoesNotExist:\n            return False\n\n        # Always allow referencing the primary key since it's already possible\n        # to get this information from the change view URL.\n        if field.primary_key:\n            return True\n\n        # Allow reverse relationships to models defining m2m fields if they\n        # target the specified field.\n        for many_to_many in opts.many_to_many:\n            if many_to_many.m2m_target_field_name() == to_field:\n                return True\n\n        # Make sure at least one of the models registered for this site\n        # references this field through a FK or a M2M relationship.\n        registered_models = set()\n        for model, admin in self.admin_site._registry.items():\n            registered_models.add(model)\n            for inline in admin.inlines:\n                registered_models.add(inline.model)\n\n        related_objects = (\n            f for f in opts.get_fields(include_hidden=True)\n            if (f.auto_created and not f.concrete)\n        )\n        for related_object in related_objects:\n            related_model = related_object.related_model\n            remote_field = related_object.field.remote_field\n            if (any(issubclass(model, related_model) for model in registered_models) and\n                    hasattr(remote_field, 'get_related_field') and\n                    remote_field.get_related_field() == field):\n                return True\n\n        return False\n\n    def has_add_permission(self, request):\n        \"\"\"\n        Return True if the given request has permission to add an object.\n        Can be overridden by the user in subclasses.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('add', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_change_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to change the given\n        Django model instance, the default implementation doesn't examine the\n        `obj` parameter.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to change the `obj`\n        model instance. If `obj` is None, this should return True if the given\n        request has permission to change *any* object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('change', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_delete_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to change the given\n        Django model instance, the default implementation doesn't examine the\n        `obj` parameter.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to delete the `obj`\n        model instance. If `obj` is None, this should return True if the given\n        request has permission to delete *any* object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('delete', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_view_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to view the given\n        Django model instance. The default implementation doesn't examine the\n        `obj` parameter.\n\n        If overridden by the user in subclasses, it should return True if the\n        given request has permission to view the `obj` model instance. If `obj`\n        is None, it should return True if the request has permission to view\n        any object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename_view = get_permission_codename('view', opts)\n        codename_change = get_permission_codename('change', opts)\n        return (\n            request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or\n            request.user.has_perm('%s.%s' % (opts.app_label, codename_change))\n        )\n\n    def has_view_or_change_permission(self, request, obj=None):\n        return self.has_view_permission(request, obj) or self.has_change_permission(request, obj)\n\n    def has_module_permission(self, request):\n        \"\"\"\n        Return True if the given request has any permission in the given\n        app label.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to view the module on\n        the admin index page and access the module's index page. Overriding it\n        does not restrict access to the add, change or delete views. Use\n        `ModelAdmin.has_(add|change|delete)_permission` for that.\n        \"\"\"\n        return request.user.has_module_perms(self.opts.app_label)\n\n\nclass ModelAdmin(BaseModelAdmin):\n    \"\"\"Encapsulate all admin options and functionality for a given model.\"\"\"\n\n    list_display = ('__str__',)\n    list_display_links = ()\n    list_filter = ()\n    list_select_related = False\n    list_per_page = 100\n    list_max_show_all = 200\n    list_editable = ()\n    search_fields = ()\n    date_hierarchy = None\n    save_as = False\n    save_as_continue = True\n    save_on_top = False\n    paginator = Paginator\n    preserve_filters = True\n    inlines = []\n\n    # Custom templates (designed to be over-ridden in subclasses)\n    add_form_template = None\n    change_form_template = None\n    change_list_template = None\n    delete_confirmation_template = None\n    delete_selected_confirmation_template = None\n    object_history_template = None\n    popup_response_template = None\n\n    # Actions\n    actions = []\n    action_form = helpers.ActionForm\n    actions_on_top = True\n    actions_on_bottom = False\n    actions_selection_counter = True\n    checks_class = ModelAdminChecks\n\n    def __init__(self, model, admin_site):\n        self.model = model\n        self.opts = model._meta\n        self.admin_site = admin_site\n        super().__init__()\n\n    def __str__(self):\n        return \"%s.%s\" % (self.model._meta.app_label, self.__class__.__name__)\n\n    def get_inline_instances(self, request, obj=None):\n        inline_instances = []\n        for inline_class in self.get_inlines(request, obj):\n            inline = inline_class(self.model, self.admin_site)\n            if request:\n                if not (inline.has_view_or_change_permission(request, obj) or\n                        inline.has_add_permission(request, obj) or\n                        inline.has_delete_permission(request, obj)):\n                    continue\n                if not inline.has_add_permission(request, obj):\n                    inline.max_num = 0\n            inline_instances.append(inline)\n\n        return inline_instances\n\n    def get_urls(self):\n        from django.urls import path\n\n        def wrap(view):\n            def wrapper(*args, **kwargs):\n                return self.admin_site.admin_view(view)(*args, **kwargs)\n            wrapper.model_admin = self\n            return update_wrapper(wrapper, view)\n\n        info = self.model._meta.app_label, self.model._meta.model_name\n\n        return [\n            path('', wrap(self.changelist_view), name='%s_%s_changelist' % info),\n            path('add/', wrap(self.add_view), name='%s_%s_add' % info),\n            path('autocomplete/', wrap(self.autocomplete_view), name='%s_%s_autocomplete' % info),\n            path('<path:object_id>/history/', wrap(self.history_view), name='%s_%s_history' % info),\n            path('<path:object_id>/delete/', wrap(self.delete_view), name='%s_%s_delete' % info),\n            path('<path:object_id>/change/', wrap(self.change_view), name='%s_%s_change' % info),\n            # For backwards compatibility (was the change url before 1.9)\n            path('<path:object_id>/', wrap(RedirectView.as_view(\n                pattern_name='%s:%s_%s_change' % ((self.admin_site.name,) + info)\n            ))),\n        ]\n\n    @property\n    def urls(self):\n        return self.get_urls()\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = [\n            'vendor/jquery/jquery%s.js' % extra,\n            'jquery.init.js',\n            'core.js',\n            'admin/RelatedObjectLookups.js',\n            'actions%s.js' % extra,\n            'urlify.js',\n            'prepopulate%s.js' % extra,\n            'vendor/xregexp/xregexp%s.js' % extra,\n        ]\n        return forms.Media(js=['admin/js/%s' % url for url in js])\n\n    def get_model_perms(self, request):\n        \"\"\"\n        Return a dict of all perms for this model. This dict has the keys\n        ``add``, ``change``, ``delete``, and ``view`` mapping to the True/False\n        for each of those actions.\n        \"\"\"\n        return {\n            'add': self.has_add_permission(request),\n            'change': self.has_change_permission(request),\n            'delete': self.has_delete_permission(request),\n            'view': self.has_view_permission(request),\n        }\n\n    def _get_form_for_get_fields(self, request, obj):\n        return self.get_form(request, obj, fields=None)\n\n    def get_form(self, request, obj=None, change=False, **kwargs):\n        \"\"\"\n        Return a Form class for use in the admin add view. This is used by\n        add_view and change_view.\n        \"\"\"\n        if 'fields' in kwargs:\n            fields = kwargs.pop('fields')\n        else:\n            fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        excluded = self.get_exclude(request, obj)\n        exclude = [] if excluded is None else list(excluded)\n        readonly_fields = self.get_readonly_fields(request, obj)\n        exclude.extend(readonly_fields)\n        # Exclude all fields if it's a change form and the user doesn't have\n        # the change permission.\n        if change and hasattr(request, 'user') and not self.has_change_permission(request, obj):\n            exclude.extend(fields)\n        if excluded is None and hasattr(self.form, '_meta') and self.form._meta.exclude:\n            # Take the custom ModelForm's Meta.exclude into account only if the\n            # ModelAdmin doesn't define its own.\n            exclude.extend(self.form._meta.exclude)\n        # if exclude is an empty list we pass None to be consistent with the\n        # default on modelform_factory\n        exclude = exclude or None\n\n        # Remove declared form fields which are in readonly_fields.\n        new_attrs = dict.fromkeys(f for f in readonly_fields if f in self.form.declared_fields)\n        form = type(self.form.__name__, (self.form,), new_attrs)\n\n        defaults = {\n            'form': form,\n            'fields': fields,\n            'exclude': exclude,\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n\n        if defaults['fields'] is None and not modelform_defines_fields(defaults['form']):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        try:\n            return modelform_factory(self.model, **defaults)\n        except FieldError as e:\n            raise FieldError(\n                '%s. Check fields/fieldsets/exclude attributes of class %s.'\n                % (e, self.__class__.__name__)\n            )\n\n    def get_changelist(self, request, **kwargs):\n        \"\"\"\n        Return the ChangeList class for use on the changelist page.\n        \"\"\"\n        from django.contrib.admin.views.main import ChangeList\n        return ChangeList\n\n    def get_changelist_instance(self, request):\n        \"\"\"\n        Return a `ChangeList` instance based on `request`. May raise\n        `IncorrectLookupParameters`.\n        \"\"\"\n        list_display = self.get_list_display(request)\n        list_display_links = self.get_list_display_links(request, list_display)\n        # Add the action checkboxes if any actions are available.\n        if self.get_actions(request):\n            list_display = ['action_checkbox', *list_display]\n        sortable_by = self.get_sortable_by(request)\n        ChangeList = self.get_changelist(request)\n        return ChangeList(\n            request,\n            self.model,\n            list_display,\n            list_display_links,\n            self.get_list_filter(request),\n            self.date_hierarchy,\n            self.get_search_fields(request),\n            self.get_list_select_related(request),\n            self.list_per_page,\n            self.list_max_show_all,\n            self.list_editable,\n            self,\n            sortable_by,\n        )\n\n    def get_object(self, request, object_id, from_field=None):\n        \"\"\"\n        Return an instance matching the field and value provided, the primary\n        key is used if no field is provided. Return ``None`` if no match is\n        found or the object_id fails validation.\n        \"\"\"\n        queryset = self.get_queryset(request)\n        model = queryset.model\n        field = model._meta.pk if from_field is None else model._meta.get_field(from_field)\n        try:\n            object_id = field.to_python(object_id)\n            return queryset.get(**{field.name: object_id})\n        except (model.DoesNotExist, ValidationError, ValueError):\n            return None\n\n    def get_changelist_form(self, request, **kwargs):\n        \"\"\"\n        Return a Form class for use in the Formset on the changelist page.\n        \"\"\"\n        defaults = {\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n        if defaults.get('fields') is None and not modelform_defines_fields(defaults.get('form')):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        return modelform_factory(self.model, **defaults)\n\n    def get_changelist_formset(self, request, **kwargs):\n        \"\"\"\n        Return a FormSet class for use on the changelist page if list_editable\n        is used.\n        \"\"\"\n        defaults = {\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n        return modelformset_factory(\n            self.model, self.get_changelist_form(request), extra=0,\n            fields=self.list_editable, **defaults\n        )\n\n    def get_formsets_with_inlines(self, request, obj=None):\n        \"\"\"\n        Yield formsets and the corresponding inlines.\n        \"\"\"\n        for inline in self.get_inline_instances(request, obj):\n            yield inline.get_formset(request, obj), inline\n\n    def get_paginator(self, request, queryset, per_page, orphans=0, allow_empty_first_page=True):\n        return self.paginator(queryset, per_page, orphans, allow_empty_first_page)\n\n    def log_addition(self, request, object, message):\n        \"\"\"\n        Log that an object has been successfully added.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, ADDITION\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=str(object),\n            action_flag=ADDITION,\n            change_message=message,\n        )\n\n    def log_change(self, request, object, message):\n        \"\"\"\n        Log that an object has been successfully changed.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, CHANGE\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=str(object),\n            action_flag=CHANGE,\n            change_message=message,\n        )\n\n    def log_deletion(self, request, object, object_repr):\n        \"\"\"\n        Log that an object will be deleted. Note that this method must be\n        called before the deletion.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, DELETION\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=object_repr,\n            action_flag=DELETION,\n        )\n\n    def action_checkbox(self, obj):\n        \"\"\"\n        A list_display column containing a checkbox widget.\n        \"\"\"\n        return helpers.checkbox.render(helpers.ACTION_CHECKBOX_NAME, str(obj.pk))\n    action_checkbox.short_description = mark_safe('<input type=\"checkbox\" id=\"action-toggle\">')\n\n    def _get_base_actions(self):\n        \"\"\"Return the list of actions, prior to any request-based filtering.\"\"\"\n        actions = []\n\n        # Gather actions from the admin site first\n        for (name, func) in self.admin_site.actions:\n            description = getattr(func, 'short_description', name.replace('_', ' '))\n            actions.append((func, name, description))\n        # Add actions from this ModelAdmin.\n        actions.extend(self.get_action(action) for action in self.actions or [])\n        # get_action might have returned None, so filter any of those out.\n        return filter(None, actions)\n\n    def _filter_actions_by_permissions(self, request, actions):\n        \"\"\"Filter out any actions that the user doesn't have access to.\"\"\"\n        filtered_actions = []\n        for action in actions:\n            callable = action[0]\n            if not hasattr(callable, 'allowed_permissions'):\n                filtered_actions.append(action)\n                continue\n            permission_checks = (\n                getattr(self, 'has_%s_permission' % permission)\n                for permission in callable.allowed_permissions\n            )\n            if any(has_permission(request) for has_permission in permission_checks):\n                filtered_actions.append(action)\n        return filtered_actions\n\n    def get_actions(self, request):\n        \"\"\"\n        Return a dictionary mapping the names of all actions for this\n        ModelAdmin to a tuple of (callable, name, description) for each action.\n        \"\"\"\n        # If self.actions is set to None that means actions are disabled on\n        # this page.\n        if self.actions is None or IS_POPUP_VAR in request.GET:\n            return {}\n        actions = self._filter_actions_by_permissions(request, self._get_base_actions())\n        return {name: (func, name, desc) for func, name, desc in actions}\n\n    def get_action_choices(self, request, default_choices=BLANK_CHOICE_DASH):\n        \"\"\"\n        Return a list of choices for use in a form object.  Each choice is a\n        tuple (name, description).\n        \"\"\"\n        choices = [] + default_choices\n        for func, name, description in self.get_actions(request).values():\n            choice = (name, description % model_format_dict(self.opts))\n            choices.append(choice)\n        return choices\n\n    def get_action(self, action):\n        \"\"\"\n        Return a given action from a parameter, which can either be a callable,\n        or the name of a method on the ModelAdmin.  Return is a tuple of\n        (callable, name, description).\n        \"\"\"\n        # If the action is a callable, just use it.\n        if callable(action):\n            func = action\n            action = action.__name__\n\n        # Next, look for a method. Grab it off self.__class__ to get an unbound\n        # method instead of a bound one; this ensures that the calling\n        # conventions are the same for functions and methods.\n        elif hasattr(self.__class__, action):\n            func = getattr(self.__class__, action)\n\n        # Finally, look for a named method on the admin site\n        else:\n            try:\n                func = self.admin_site.get_action(action)\n            except KeyError:\n                return None\n\n        if hasattr(func, 'short_description'):\n            description = func.short_description\n        else:\n            description = capfirst(action.replace('_', ' '))\n        return func, action, description\n\n    def get_list_display(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be displayed on the\n        changelist.\n        \"\"\"\n        return self.list_display\n\n    def get_list_display_links(self, request, list_display):\n        \"\"\"\n        Return a sequence containing the fields to be displayed as links\n        on the changelist. The list_display parameter is the list of fields\n        returned by get_list_display().\n        \"\"\"\n        if self.list_display_links or self.list_display_links is None or not list_display:\n            return self.list_display_links\n        else:\n            # Use only the first item in list_display as link\n            return list(list_display)[:1]\n\n    def get_list_filter(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be displayed as filters in\n        the right sidebar of the changelist page.\n        \"\"\"\n        return self.list_filter\n\n    def get_list_select_related(self, request):\n        \"\"\"\n        Return a list of fields to add to the select_related() part of the\n        changelist items query.\n        \"\"\"\n        return self.list_select_related\n\n    def get_search_fields(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be searched whenever\n        somebody submits a search query.\n        \"\"\"\n        return self.search_fields\n\n    def get_search_results(self, request, queryset, search_term):\n        \"\"\"\n        Return a tuple containing a queryset to implement the search\n        and a boolean indicating if the results may contain duplicates.\n        \"\"\"\n        # Apply keyword searches.\n        def construct_search(field_name):\n            if field_name.startswith('^'):\n                return \"%s__istartswith\" % field_name[1:]\n            elif field_name.startswith('='):\n                return \"%s__iexact\" % field_name[1:]\n            elif field_name.startswith('@'):\n                return \"%s__search\" % field_name[1:]\n            # Use field_name if it includes a lookup.\n            opts = queryset.model._meta\n            lookup_fields = field_name.split(LOOKUP_SEP)\n            # Go through the fields, following all relations.\n            prev_field = None\n            for path_part in lookup_fields:\n                if path_part == 'pk':\n                    path_part = opts.pk.name\n                try:\n                    field = opts.get_field(path_part)\n                except FieldDoesNotExist:\n                    # Use valid query lookups.\n                    if prev_field and prev_field.get_lookup(path_part):\n                        return field_name\n                else:\n                    prev_field = field\n                    if hasattr(field, 'get_path_info'):\n                        # Update opts to follow the relation.\n                        opts = field.get_path_info()[-1].to_opts\n            # Otherwise, use the field with icontains.\n            return \"%s__icontains\" % field_name\n\n        use_distinct = False\n        search_fields = self.get_search_fields(request)\n        if search_fields and search_term:\n            orm_lookups = [construct_search(str(search_field))\n                           for search_field in search_fields]\n            for bit in search_term.split():\n                or_queries = [models.Q(**{orm_lookup: bit})\n                              for orm_lookup in orm_lookups]\n                queryset = queryset.filter(reduce(operator.or_, or_queries))\n            use_distinct |= any(lookup_needs_distinct(self.opts, search_spec) for search_spec in orm_lookups)\n\n        return queryset, use_distinct\n\n    def get_preserved_filters(self, request):\n        \"\"\"\n        Return the preserved filters querystring.\n        \"\"\"\n        match = request.resolver_match\n        if self.preserve_filters and match:\n            opts = self.model._meta\n            current_url = '%s:%s' % (match.app_name, match.url_name)\n            changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name)\n            if current_url == changelist_url:\n                preserved_filters = request.GET.urlencode()\n            else:\n                preserved_filters = request.GET.get('_changelist_filters')\n\n            if preserved_filters:\n                return urlencode({'_changelist_filters': preserved_filters})\n        return ''\n\n    def construct_change_message(self, request, form, formsets, add=False):\n        \"\"\"\n        Construct a JSON structure describing changes from a changed object.\n        \"\"\"\n        return construct_change_message(form, formsets, add)\n\n    def message_user(self, request, message, level=messages.INFO, extra_tags='',\n                     fail_silently=False):\n        \"\"\"\n        Send a message to the user. The default implementation\n        posts a message using the django.contrib.messages backend.\n\n        Exposes almost the same API as messages.add_message(), but accepts the\n        positional arguments in a different order to maintain backwards\n        compatibility. For convenience, it accepts the `level` argument as\n        a string rather than the usual level number.\n        \"\"\"\n        if not isinstance(level, int):\n            # attempt to get the level if passed a string\n            try:\n                level = getattr(messages.constants, level.upper())\n            except AttributeError:\n                levels = messages.constants.DEFAULT_TAGS.values()\n                levels_repr = ', '.join('`%s`' % l for l in levels)\n                raise ValueError(\n                    'Bad message level string: `%s`. Possible values are: %s'\n                    % (level, levels_repr)\n                )\n\n        messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n\n    def save_form(self, request, form, change):\n        \"\"\"\n        Given a ModelForm return an unsaved instance. ``change`` is True if\n        the object is being changed, and False if it's being added.\n        \"\"\"\n        return form.save(commit=False)\n\n    def save_model(self, request, obj, form, change):\n        \"\"\"\n        Given a model instance save it to the database.\n        \"\"\"\n        obj.save()\n\n    def delete_model(self, request, obj):\n        \"\"\"\n        Given a model instance delete it from the database.\n        \"\"\"\n        obj.delete()\n\n    def delete_queryset(self, request, queryset):\n        \"\"\"Given a queryset, delete it from the database.\"\"\"\n        queryset.delete()\n\n    def save_formset(self, request, form, formset, change):\n        \"\"\"\n        Given an inline formset save it to the database.\n        \"\"\"\n        formset.save()\n\n    def save_related(self, request, form, formsets, change):\n        \"\"\"\n        Given the ``HttpRequest``, the parent ``ModelForm`` instance, the\n        list of inline formsets and a boolean value based on whether the\n        parent is being added or changed, save the related objects to the\n        database. Note that at this point save_form() and save_model() have\n        already been called.\n        \"\"\"\n        form.save_m2m()\n        for formset in formsets:\n            self.save_formset(request, form, formset, change=change)\n\n    def render_change_form(self, request, context, add=False, change=False, form_url='', obj=None):\n        opts = self.model._meta\n        app_label = opts.app_label\n        preserved_filters = self.get_preserved_filters(request)\n        form_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, form_url)\n        view_on_site_url = self.get_view_on_site_url(obj)\n        has_editable_inline_admin_formsets = False\n        for inline in context['inline_admin_formsets']:\n            if inline.has_add_permission or inline.has_change_permission or inline.has_delete_permission:\n                has_editable_inline_admin_formsets = True\n                break\n        context.update({\n            'add': add,\n            'change': change,\n            'has_view_permission': self.has_view_permission(request, obj),\n            'has_add_permission': self.has_add_permission(request),\n            'has_change_permission': self.has_change_permission(request, obj),\n            'has_delete_permission': self.has_delete_permission(request, obj),\n            'has_editable_inline_admin_formsets': has_editable_inline_admin_formsets,\n            'has_file_field': context['adminform'].form.is_multipart() or any(\n                admin_formset.formset.is_multipart()\n                for admin_formset in context['inline_admin_formsets']\n            ),\n            'has_absolute_url': view_on_site_url is not None,\n            'absolute_url': view_on_site_url,\n            'form_url': form_url,\n            'opts': opts,\n            'content_type_id': get_content_type_for_model(self.model).pk,\n            'save_as': self.save_as,\n            'save_on_top': self.save_on_top,\n            'to_field_var': TO_FIELD_VAR,\n            'is_popup_var': IS_POPUP_VAR,\n            'app_label': app_label,\n        })\n        if add and self.add_form_template is not None:\n            form_template = self.add_form_template\n        else:\n            form_template = self.change_form_template\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, form_template or [\n            \"admin/%s/%s/change_form.html\" % (app_label, opts.model_name),\n            \"admin/%s/change_form.html\" % app_label,\n            \"admin/change_form.html\"\n        ], context)\n\n    def response_add(self, request, obj, post_url_continue=None):\n        \"\"\"\n        Determine the HttpResponse for the add_view stage.\n        \"\"\"\n        opts = obj._meta\n        preserved_filters = self.get_preserved_filters(request)\n        obj_url = reverse(\n            'admin:%s_%s_change' % (opts.app_label, opts.model_name),\n            args=(quote(obj.pk),),\n            current_app=self.admin_site.name,\n        )\n        # Add a link to the object's change form if the user can edit the obj.\n        if self.has_change_permission(request, obj):\n            obj_repr = format_html('<a href=\"{}\">{}</a>', urlquote(obj_url), obj)\n        else:\n            obj_repr = str(obj)\n        msg_dict = {\n            'name': opts.verbose_name,\n            'obj': obj_repr,\n        }\n        # Here, we distinguish between different save types by checking for\n        # the presence of keys in request.POST.\n\n        if IS_POPUP_VAR in request.POST:\n            to_field = request.POST.get(TO_FIELD_VAR)\n            if to_field:\n                attr = str(to_field)\n            else:\n                attr = obj._meta.pk.attname\n            value = obj.serializable_value(attr)\n            popup_response_data = json.dumps({\n                'value': str(value),\n                'obj': str(obj),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        elif \"_continue\" in request.POST or (\n                # Redirecting after \"Save as new\".\n                \"_saveasnew\" in request.POST and self.save_as_continue and\n                self.has_change_permission(request, obj)\n        ):\n            msg = _('The {name} \u201c{obj}\u201d was added successfully.')\n            if self.has_change_permission(request, obj):\n                msg += ' ' + _('You may edit it again below.')\n            self.message_user(request, format_html(msg, **msg_dict), messages.SUCCESS)\n            if post_url_continue is None:\n                post_url_continue = obj_url\n            post_url_continue = add_preserved_filters(\n                {'preserved_filters': preserved_filters, 'opts': opts},\n                post_url_continue\n            )\n            return HttpResponseRedirect(post_url_continue)\n\n        elif \"_addanother\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully. You may add another {name} below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = request.path\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        else:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            return self.response_post_save_add(request, obj)\n\n    def response_change(self, request, obj):\n        \"\"\"\n        Determine the HttpResponse for the change_view stage.\n        \"\"\"\n\n        if IS_POPUP_VAR in request.POST:\n            opts = obj._meta\n            to_field = request.POST.get(TO_FIELD_VAR)\n            attr = str(to_field) if to_field else opts.pk.attname\n            value = request.resolver_match.kwargs['object_id']\n            new_value = obj.serializable_value(attr)\n            popup_response_data = json.dumps({\n                'action': 'change',\n                'value': str(value),\n                'obj': str(obj),\n                'new_value': str(new_value),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        opts = self.model._meta\n        preserved_filters = self.get_preserved_filters(request)\n\n        msg_dict = {\n            'name': opts.verbose_name,\n            'obj': format_html('<a href=\"{}\">{}</a>', urlquote(request.path), obj),\n        }\n        if \"_continue\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully. You may edit it again below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = request.path\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        elif \"_saveasnew\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully. You may edit it again below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = reverse('admin:%s_%s_change' %\n                                   (opts.app_label, opts.model_name),\n                                   args=(obj.pk,),\n                                   current_app=self.admin_site.name)\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        elif \"_addanother\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully. You may add another {name} below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = reverse('admin:%s_%s_add' %\n                                   (opts.app_label, opts.model_name),\n                                   current_app=self.admin_site.name)\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        else:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            return self.response_post_save_change(request, obj)\n\n    def _response_post_save(self, request, obj):\n        opts = self.model._meta\n        if self.has_view_or_change_permission(request):\n            post_url = reverse('admin:%s_%s_changelist' %\n                               (opts.app_label, opts.model_name),\n                               current_app=self.admin_site.name)\n            preserved_filters = self.get_preserved_filters(request)\n            post_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, post_url)\n        else:\n            post_url = reverse('admin:index',\n                               current_app=self.admin_site.name)\n        return HttpResponseRedirect(post_url)\n\n    def response_post_save_add(self, request, obj):\n        \"\"\"\n        Figure out where to redirect after the 'Save' button has been pressed\n        when adding a new object.\n        \"\"\"\n        return self._response_post_save(request, obj)\n\n    def response_post_save_change(self, request, obj):\n        \"\"\"\n        Figure out where to redirect after the 'Save' button has been pressed\n        when editing an existing object.\n        \"\"\"\n        return self._response_post_save(request, obj)\n\n    def response_action(self, request, queryset):\n        \"\"\"\n        Handle an admin action. This is called if a request is POSTed to the\n        changelist; it returns an HttpResponse if the action was handled, and\n        None otherwise.\n        \"\"\"\n\n        # There can be multiple action forms on the page (at the top\n        # and bottom of the change list, for example). Get the action\n        # whose button was pushed.\n        try:\n            action_index = int(request.POST.get('index', 0))\n        except ValueError:\n            action_index = 0\n\n        # Construct the action form.\n        data = request.POST.copy()\n        data.pop(helpers.ACTION_CHECKBOX_NAME, None)\n        data.pop(\"index\", None)\n\n        # Use the action whose button was pushed\n        try:\n            data.update({'action': data.getlist('action')[action_index]})\n        except IndexError:\n            # If we didn't get an action from the chosen form that's invalid\n            # POST data, so by deleting action it'll fail the validation check\n            # below. So no need to do anything here\n            pass\n\n        action_form = self.action_form(data, auto_id=None)\n        action_form.fields['action'].choices = self.get_action_choices(request)\n\n        # If the form's valid we can handle the action.\n        if action_form.is_valid():\n            action = action_form.cleaned_data['action']\n            select_across = action_form.cleaned_data['select_across']\n            func = self.get_actions(request)[action][0]\n\n            # Get the list of selected PKs. If nothing's selected, we can't\n            # perform an action on it, so bail. Except we want to perform\n            # the action explicitly on all objects.\n            selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)\n            if not selected and not select_across:\n                # Reminder that something needs to be selected or nothing will happen\n                msg = _(\"Items must be selected in order to perform \"\n                        \"actions on them. No items have been changed.\")\n                self.message_user(request, msg, messages.WARNING)\n                return None\n\n            if not select_across:\n                # Perform the action only on the selected objects\n                queryset = queryset.filter(pk__in=selected)\n\n            response = func(self, request, queryset)\n\n            # Actions may return an HttpResponse-like object, which will be\n            # used as the response from the POST. If not, we'll be a good\n            # little HTTP citizen and redirect back to the changelist page.\n            if isinstance(response, HttpResponseBase):\n                return response\n            else:\n                return HttpResponseRedirect(request.get_full_path())\n        else:\n            msg = _(\"No action selected.\")\n            self.message_user(request, msg, messages.WARNING)\n            return None\n\n    def response_delete(self, request, obj_display, obj_id):\n        \"\"\"\n        Determine the HttpResponse for the delete_view stage.\n        \"\"\"\n        opts = self.model._meta\n\n        if IS_POPUP_VAR in request.POST:\n            popup_response_data = json.dumps({\n                'action': 'delete',\n                'value': str(obj_id),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        self.message_user(\n            request,\n            _('The %(name)s \u201c%(obj)s\u201d was deleted successfully.') % {\n                'name': opts.verbose_name,\n                'obj': obj_display,\n            },\n            messages.SUCCESS,\n        )\n\n        if self.has_change_permission(request, None):\n            post_url = reverse(\n                'admin:%s_%s_changelist' % (opts.app_label, opts.model_name),\n                current_app=self.admin_site.name,\n            )\n            preserved_filters = self.get_preserved_filters(request)\n            post_url = add_preserved_filters(\n                {'preserved_filters': preserved_filters, 'opts': opts}, post_url\n            )\n        else:\n            post_url = reverse('admin:index', current_app=self.admin_site.name)\n        return HttpResponseRedirect(post_url)\n\n    def render_delete_form(self, request, context):\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        request.current_app = self.admin_site.name\n        context.update(\n            to_field_var=TO_FIELD_VAR,\n            is_popup_var=IS_POPUP_VAR,\n            media=self.media,\n        )\n\n        return TemplateResponse(\n            request,\n            self.delete_confirmation_template or [\n                \"admin/{}/{}/delete_confirmation.html\".format(app_label, opts.model_name),\n                \"admin/{}/delete_confirmation.html\".format(app_label),\n                \"admin/delete_confirmation.html\",\n            ],\n            context,\n        )\n\n    def get_inline_formsets(self, request, formsets, inline_instances, obj=None):\n        inline_admin_formsets = []\n        for inline, formset in zip(inline_instances, formsets):\n            fieldsets = list(inline.get_fieldsets(request, obj))\n            readonly = list(inline.get_readonly_fields(request, obj))\n            has_add_permission = inline.has_add_permission(request, obj)\n            has_change_permission = inline.has_change_permission(request, obj)\n            has_delete_permission = inline.has_delete_permission(request, obj)\n            has_view_permission = inline.has_view_permission(request, obj)\n            prepopulated = dict(inline.get_prepopulated_fields(request, obj))\n            inline_admin_formset = helpers.InlineAdminFormSet(\n                inline, formset, fieldsets, prepopulated, readonly, model_admin=self,\n                has_add_permission=has_add_permission, has_change_permission=has_change_permission,\n                has_delete_permission=has_delete_permission, has_view_permission=has_view_permission,\n            )\n            inline_admin_formsets.append(inline_admin_formset)\n        return inline_admin_formsets\n\n    def get_changeform_initial_data(self, request):\n        \"\"\"\n        Get the initial form data from the request's GET params.\n        \"\"\"\n        initial = dict(request.GET.items())\n        for k in initial:\n            try:\n                f = self.model._meta.get_field(k)\n            except FieldDoesNotExist:\n                continue\n            # We have to special-case M2Ms as a list of comma-separated PKs.\n            if isinstance(f, models.ManyToManyField):\n                initial[k] = initial[k].split(\",\")\n        return initial\n\n    def _get_obj_does_not_exist_redirect(self, request, opts, object_id):\n        \"\"\"\n        Create a message informing the user that the object doesn't exist\n        and return a redirect to the admin index page.\n        \"\"\"\n        msg = _('%(name)s with ID \u201c%(key)s\u201d doesn\u2019t exist. Perhaps it was deleted?') % {\n            'name': opts.verbose_name,\n            'key': unquote(object_id),\n        }\n        self.message_user(request, msg, messages.WARNING)\n        url = reverse('admin:index', current_app=self.admin_site.name)\n        return HttpResponseRedirect(url)\n\n    @csrf_protect_m\n    def changeform_view(self, request, object_id=None, form_url='', extra_context=None):\n        with transaction.atomic(using=router.db_for_write(self.model)):\n            return self._changeform_view(request, object_id, form_url, extra_context)\n\n    def _changeform_view(self, request, object_id, form_url, extra_context):\n        to_field = request.POST.get(TO_FIELD_VAR, request.GET.get(TO_FIELD_VAR))\n        if to_field and not self.to_field_allowed(request, to_field):\n            raise DisallowedModelAdminToField(\"The field %s cannot be referenced.\" % to_field)\n\n        model = self.model\n        opts = model._meta\n\n        if request.method == 'POST' and '_saveasnew' in request.POST:\n            object_id = None\n\n        add = object_id is None\n\n        if add:\n            if not self.has_add_permission(request):\n                raise PermissionDenied\n            obj = None\n\n        else:\n            obj = self.get_object(request, unquote(object_id), to_field)\n\n            if not self.has_view_or_change_permission(request, obj):\n                raise PermissionDenied\n\n            if obj is None:\n                return self._get_obj_does_not_exist_redirect(request, opts, object_id)\n\n        ModelForm = self.get_form(request, obj, change=not add)\n        if request.method == 'POST':\n            form = ModelForm(request.POST, request.FILES, instance=obj)\n            form_validated = form.is_valid()\n            if form_validated:\n                new_object = self.save_form(request, form, change=not add)\n            else:\n                new_object = form.instance\n            formsets, inline_instances = self._create_formsets(request, new_object, change=not add)\n            if all_valid(formsets) and form_validated:\n                self.save_model(request, new_object, form, not add)\n                self.save_related(request, form, formsets, not add)\n                change_message = self.construct_change_message(request, form, formsets, add)\n                if add:\n                    self.log_addition(request, new_object, change_message)\n                    return self.response_add(request, new_object)\n                else:\n                    self.log_change(request, new_object, change_message)\n                    return self.response_change(request, new_object)\n            else:\n                form_validated = False\n        else:\n            if add:\n                initial = self.get_changeform_initial_data(request)\n                form = ModelForm(initial=initial)\n                formsets, inline_instances = self._create_formsets(request, form.instance, change=False)\n            else:\n                form = ModelForm(instance=obj)\n                formsets, inline_instances = self._create_formsets(request, obj, change=True)\n\n        if not add and not self.has_change_permission(request, obj):\n            readonly_fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        else:\n            readonly_fields = self.get_readonly_fields(request, obj)\n        adminForm = helpers.AdminForm(\n            form,\n            list(self.get_fieldsets(request, obj)),\n            # Clear prepopulated fields on a view-only form to avoid a crash.\n            self.get_prepopulated_fields(request, obj) if add or self.has_change_permission(request, obj) else {},\n            readonly_fields,\n            model_admin=self)\n        media = self.media + adminForm.media\n\n        inline_formsets = self.get_inline_formsets(request, formsets, inline_instances, obj)\n        for inline_formset in inline_formsets:\n            media = media + inline_formset.media\n\n        if add:\n            title = _('Add %s')\n        elif self.has_change_permission(request, obj):\n            title = _('Change %s')\n        else:\n            title = _('View %s')\n        context = {\n            **self.admin_site.each_context(request),\n            'title': title % opts.verbose_name,\n            'adminform': adminForm,\n            'object_id': object_id,\n            'original': obj,\n            'is_popup': IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,\n            'to_field': to_field,\n            'media': media,\n            'inline_admin_formsets': inline_formsets,\n            'errors': helpers.AdminErrorList(form, formsets),\n            'preserved_filters': self.get_preserved_filters(request),\n        }\n\n        # Hide the \"Save\" and \"Save and continue\" buttons if \"Save as New\" was\n        # previously chosen to prevent the interface from getting confusing.\n        if request.method == 'POST' and not form_validated and \"_saveasnew\" in request.POST:\n            context['show_save'] = False\n            context['show_save_and_continue'] = False\n            # Use the change template instead of the add template.\n            add = False\n\n        context.update(extra_context or {})\n\n        return self.render_change_form(request, context, add=add, change=not add, obj=obj, form_url=form_url)\n\n    def autocomplete_view(self, request):\n        return AutocompleteJsonView.as_view(model_admin=self)(request)\n\n    def add_view(self, request, form_url='', extra_context=None):\n        return self.changeform_view(request, None, form_url, extra_context)\n\n    def change_view(self, request, object_id, form_url='', extra_context=None):\n        return self.changeform_view(request, object_id, form_url, extra_context)\n\n    def _get_edited_object_pks(self, request, prefix):\n        \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n        pk_pattern = re.compile(\n            r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name)\n        )\n        return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n\n    def _get_list_editable_queryset(self, request, prefix):\n        \"\"\"\n        Based on POST data, return a queryset of the objects that were edited\n        via list_editable.\n        \"\"\"\n        object_pks = self._get_edited_object_pks(request, prefix)\n        queryset = self.get_queryset(request)\n        validate = queryset.model._meta.pk.to_python\n        try:\n            for pk in object_pks:\n                validate(pk)\n        except ValidationError:\n            # Disable the optimization if the POST data was tampered with.\n            return queryset\n        return queryset.filter(pk__in=object_pks)\n\n    @csrf_protect_m\n    def changelist_view(self, request, extra_context=None):\n        \"\"\"\n        The 'change list' admin view for this model.\n        \"\"\"\n        from django.contrib.admin.views.main import ERROR_FLAG\n        opts = self.model._meta\n        app_label = opts.app_label\n        if not self.has_view_or_change_permission(request):\n            raise PermissionDenied\n\n        try:\n            cl = self.get_changelist_instance(request)\n        except IncorrectLookupParameters:\n            # Wacky lookup parameters were given, so redirect to the main\n            # changelist page, without parameters, and pass an 'invalid=1'\n            # parameter via the query string. If wacky parameters were given\n            # and the 'invalid=1' parameter was already in the query string,\n            # something is screwed up with the database, so display an error\n            # page.\n            if ERROR_FLAG in request.GET:\n                return SimpleTemplateResponse('admin/invalid_setup.html', {\n                    'title': _('Database error'),\n                })\n            return HttpResponseRedirect(request.path + '?' + ERROR_FLAG + '=1')\n\n        # If the request was POSTed, this might be a bulk action or a bulk\n        # edit. Try to look up an action or confirmation first, but if this\n        # isn't an action the POST will fall through to the bulk edit check,\n        # below.\n        action_failed = False\n        selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)\n\n        actions = self.get_actions(request)\n        # Actions with no confirmation\n        if (actions and request.method == 'POST' and\n                'index' in request.POST and '_save' not in request.POST):\n            if selected:\n                response = self.response_action(request, queryset=cl.get_queryset(request))\n                if response:\n                    return response\n                else:\n                    action_failed = True\n            else:\n                msg = _(\"Items must be selected in order to perform \"\n                        \"actions on them. No items have been changed.\")\n                self.message_user(request, msg, messages.WARNING)\n                action_failed = True\n\n        # Actions with confirmation\n        if (actions and request.method == 'POST' and\n                helpers.ACTION_CHECKBOX_NAME in request.POST and\n                'index' not in request.POST and '_save' not in request.POST):\n            if selected:\n                response = self.response_action(request, queryset=cl.get_queryset(request))\n                if response:\n                    return response\n                else:\n                    action_failed = True\n\n        if action_failed:\n            # Redirect back to the changelist page to avoid resubmitting the\n            # form if the user refreshes the browser or uses the \"No, take\n            # me back\" button on the action confirmation page.\n            return HttpResponseRedirect(request.get_full_path())\n\n        # If we're allowing changelist editing, we need to construct a formset\n        # for the changelist given all the fields to be edited. Then we'll\n        # use the formset to validate/process POSTed data.\n        formset = cl.formset = None\n\n        # Handle POSTed bulk-edit data.\n        if request.method == 'POST' and cl.list_editable and '_save' in request.POST:\n            if not self.has_change_permission(request):\n                raise PermissionDenied\n            FormSet = self.get_changelist_formset(request)\n            modified_objects = self._get_list_editable_queryset(request, FormSet.get_default_prefix())\n            formset = cl.formset = FormSet(request.POST, request.FILES, queryset=modified_objects)\n            if formset.is_valid():\n                changecount = 0\n                for form in formset.forms:\n                    if form.has_changed():\n                        obj = self.save_form(request, form, change=True)\n                        self.save_model(request, obj, form, change=True)\n                        self.save_related(request, form, formsets=[], change=True)\n                        change_msg = self.construct_change_message(request, form, None)\n                        self.log_change(request, obj, change_msg)\n                        changecount += 1\n\n                if changecount:\n                    msg = ngettext(\n                        \"%(count)s %(name)s was changed successfully.\",\n                        \"%(count)s %(name)s were changed successfully.\",\n                        changecount\n                    ) % {\n                        'count': changecount,\n                        'name': model_ngettext(opts, changecount),\n                    }\n                    self.message_user(request, msg, messages.SUCCESS)\n\n                return HttpResponseRedirect(request.get_full_path())\n\n        # Handle GET -- construct a formset for display.\n        elif cl.list_editable and self.has_change_permission(request):\n            FormSet = self.get_changelist_formset(request)\n            formset = cl.formset = FormSet(queryset=cl.result_list)\n\n        # Build the list of media to be used by the formset.\n        if formset:\n            media = self.media + formset.media\n        else:\n            media = self.media\n\n        # Build the action form and populate it with available actions.\n        if actions:\n            action_form = self.action_form(auto_id=None)\n            action_form.fields['action'].choices = self.get_action_choices(request)\n            media += action_form.media\n        else:\n            action_form = None\n\n        selection_note_all = ngettext(\n            '%(total_count)s selected',\n            'All %(total_count)s selected',\n            cl.result_count\n        )\n\n        context = {\n            **self.admin_site.each_context(request),\n            'module_name': str(opts.verbose_name_plural),\n            'selection_note': _('0 of %(cnt)s selected') % {'cnt': len(cl.result_list)},\n            'selection_note_all': selection_note_all % {'total_count': cl.result_count},\n            'title': cl.title,\n            'is_popup': cl.is_popup,\n            'to_field': cl.to_field,\n            'cl': cl,\n            'media': media,\n            'has_add_permission': self.has_add_permission(request),\n            'opts': cl.opts,\n            'action_form': action_form,\n            'actions_on_top': self.actions_on_top,\n            'actions_on_bottom': self.actions_on_bottom,\n            'actions_selection_counter': self.actions_selection_counter,\n            'preserved_filters': self.get_preserved_filters(request),\n            **(extra_context or {}),\n        }\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, self.change_list_template or [\n            'admin/%s/%s/change_list.html' % (app_label, opts.model_name),\n            'admin/%s/change_list.html' % app_label,\n            'admin/change_list.html'\n        ], context)\n\n    def get_deleted_objects(self, objs, request):\n        \"\"\"\n        Hook for customizing the delete process for the delete view and the\n        \"delete selected\" action.\n        \"\"\"\n        return get_deleted_objects(objs, request, self.admin_site)\n\n    @csrf_protect_m\n    def delete_view(self, request, object_id, extra_context=None):\n        with transaction.atomic(using=router.db_for_write(self.model)):\n            return self._delete_view(request, object_id, extra_context)\n\n    def _delete_view(self, request, object_id, extra_context):\n        \"The 'delete' admin view for this model.\"\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        to_field = request.POST.get(TO_FIELD_VAR, request.GET.get(TO_FIELD_VAR))\n        if to_field and not self.to_field_allowed(request, to_field):\n            raise DisallowedModelAdminToField(\"The field %s cannot be referenced.\" % to_field)\n\n        obj = self.get_object(request, unquote(object_id), to_field)\n\n        if not self.has_delete_permission(request, obj):\n            raise PermissionDenied\n\n        if obj is None:\n            return self._get_obj_does_not_exist_redirect(request, opts, object_id)\n\n        # Populate deleted_objects, a data structure of all related objects that\n        # will also be deleted.\n        deleted_objects, model_count, perms_needed, protected = self.get_deleted_objects([obj], request)\n\n        if request.POST and not protected:  # The user has confirmed the deletion.\n            if perms_needed:\n                raise PermissionDenied\n            obj_display = str(obj)\n            attr = str(to_field) if to_field else opts.pk.attname\n            obj_id = obj.serializable_value(attr)\n            self.log_deletion(request, obj, obj_display)\n            self.delete_model(request, obj)\n\n            return self.response_delete(request, obj_display, obj_id)\n\n        object_name = str(opts.verbose_name)\n\n        if perms_needed or protected:\n            title = _(\"Cannot delete %(name)s\") % {\"name\": object_name}\n        else:\n            title = _(\"Are you sure?\")\n\n        context = {\n            **self.admin_site.each_context(request),\n            'title': title,\n            'object_name': object_name,\n            'object': obj,\n            'deleted_objects': deleted_objects,\n            'model_count': dict(model_count).items(),\n            'perms_lacking': perms_needed,\n            'protected': protected,\n            'opts': opts,\n            'app_label': app_label,\n            'preserved_filters': self.get_preserved_filters(request),\n            'is_popup': IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,\n            'to_field': to_field,\n            **(extra_context or {}),\n        }\n\n        return self.render_delete_form(request, context)\n\n    def history_view(self, request, object_id, extra_context=None):\n        \"The 'history' admin view for this model.\"\n        from django.contrib.admin.models import LogEntry\n        # First check if the user can see this history.\n        model = self.model\n        obj = self.get_object(request, unquote(object_id))\n        if obj is None:\n            return self._get_obj_does_not_exist_redirect(request, model._meta, object_id)\n\n        if not self.has_view_or_change_permission(request, obj):\n            raise PermissionDenied\n\n        # Then get the history for this object.\n        opts = model._meta\n        app_label = opts.app_label\n        action_list = LogEntry.objects.filter(\n            object_id=unquote(object_id),\n            content_type=get_content_type_for_model(model)\n        ).select_related().order_by('action_time')\n\n        context = {\n            **self.admin_site.each_context(request),\n            'title': _('Change history: %s') % obj,\n            'action_list': action_list,\n            'module_name': str(capfirst(opts.verbose_name_plural)),\n            'object': obj,\n            'opts': opts,\n            'preserved_filters': self.get_preserved_filters(request),\n            **(extra_context or {}),\n        }\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, self.object_history_template or [\n            \"admin/%s/%s/object_history.html\" % (app_label, opts.model_name),\n            \"admin/%s/object_history.html\" % app_label,\n            \"admin/object_history.html\"\n        ], context)\n\n    def _create_formsets(self, request, obj, change):\n        \"Helper function to generate formsets for add/change_view.\"\n        formsets = []\n        inline_instances = []\n        prefixes = {}\n        get_formsets_args = [request]\n        if change:\n            get_formsets_args.append(obj)\n        for FormSet, inline in self.get_formsets_with_inlines(*get_formsets_args):\n            prefix = FormSet.get_default_prefix()\n            prefixes[prefix] = prefixes.get(prefix, 0) + 1\n            if prefixes[prefix] != 1 or not prefix:\n                prefix = \"%s-%s\" % (prefix, prefixes[prefix])\n            formset_params = {\n                'instance': obj,\n                'prefix': prefix,\n                'queryset': inline.get_queryset(request),\n            }\n            if request.method == 'POST':\n                formset_params.update({\n                    'data': request.POST.copy(),\n                    'files': request.FILES,\n                    'save_as_new': '_saveasnew' in request.POST\n                })\n            formset = FormSet(**formset_params)\n\n            def user_deleted_form(request, obj, formset, index):\n                \"\"\"Return whether or not the user deleted the form.\"\"\"\n                return (\n                    inline.has_delete_permission(request, obj) and\n                    '{}-{}-DELETE'.format(formset.prefix, index) in request.POST\n                )\n\n            # Bypass validation of each view-only inline form (since the form's\n            # data won't be in request.POST), unless the form was deleted.\n            if not inline.has_change_permission(request, obj if change else None):\n                for index, form in enumerate(formset.initial_forms):\n                    if user_deleted_form(request, obj, formset, index):\n                        continue\n                    form._errors = {}\n                    form.cleaned_data = form.initial\n            formsets.append(formset)\n            inline_instances.append(inline)\n        return formsets, inline_instances\n\n\nclass InlineModelAdmin(BaseModelAdmin):\n    \"\"\"\n    Options for inline editing of ``model`` instances.\n\n    Provide ``fk_name`` to specify the attribute name of the ``ForeignKey``\n    from ``model`` to its parent. This is required if ``model`` has more than\n    one ``ForeignKey`` to its parent.\n    \"\"\"\n    model = None\n    fk_name = None\n    formset = BaseInlineFormSet\n    extra = 3\n    min_num = None\n    max_num = None\n    template = None\n    verbose_name = None\n    verbose_name_plural = None\n    can_delete = True\n    show_change_link = False\n    checks_class = InlineModelAdminChecks\n    classes = None\n\n    def __init__(self, parent_model, admin_site):\n        self.admin_site = admin_site\n        self.parent_model = parent_model\n        self.opts = self.model._meta\n        self.has_registered_model = admin_site.is_registered(self.model)\n        super().__init__()\n        if self.verbose_name is None:\n            self.verbose_name = self.model._meta.verbose_name\n        if self.verbose_name_plural is None:\n            self.verbose_name_plural = self.model._meta.verbose_name_plural\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = ['vendor/jquery/jquery%s.js' % extra, 'jquery.init.js',\n              'inlines%s.js' % extra]\n        if self.filter_vertical or self.filter_horizontal:\n            js.extend(['SelectBox.js', 'SelectFilter2.js'])\n        if self.classes and 'collapse' in self.classes:\n            js.append('collapse%s.js' % extra)\n        return forms.Media(js=['admin/js/%s' % url for url in js])\n\n    def get_extra(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the number of extra inline forms.\"\"\"\n        return self.extra\n\n    def get_min_num(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the min number of inline forms.\"\"\"\n        return self.min_num\n\n    def get_max_num(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the max number of extra inline forms.\"\"\"\n        return self.max_num\n\n    def get_formset(self, request, obj=None, **kwargs):\n        \"\"\"Return a BaseInlineFormSet class for use in admin add/change views.\"\"\"\n        if 'fields' in kwargs:\n            fields = kwargs.pop('fields')\n        else:\n            fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        excluded = self.get_exclude(request, obj)\n        exclude = [] if excluded is None else list(excluded)\n        exclude.extend(self.get_readonly_fields(request, obj))\n        if excluded is None and hasattr(self.form, '_meta') and self.form._meta.exclude:\n            # Take the custom ModelForm's Meta.exclude into account only if the\n            # InlineModelAdmin doesn't define its own.\n            exclude.extend(self.form._meta.exclude)\n        # If exclude is an empty list we use None, since that's the actual\n        # default.\n        exclude = exclude or None\n        can_delete = self.can_delete and self.has_delete_permission(request, obj)\n        defaults = {\n            'form': self.form,\n            'formset': self.formset,\n            'fk_name': self.fk_name,\n            'fields': fields,\n            'exclude': exclude,\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            'extra': self.get_extra(request, obj, **kwargs),\n            'min_num': self.get_min_num(request, obj, **kwargs),\n            'max_num': self.get_max_num(request, obj, **kwargs),\n            'can_delete': can_delete,\n            **kwargs,\n        }\n\n        base_model_form = defaults['form']\n        can_change = self.has_change_permission(request, obj) if request else True\n        can_add = self.has_add_permission(request, obj) if request else True\n\n        class DeleteProtectedModelForm(base_model_form):\n\n            def hand_clean_DELETE(self):\n                \"\"\"\n                We don't validate the 'DELETE' field itself because on\n                templates it's not rendered using the field information, but\n                just using a generic \"deletion_field\" of the InlineModelAdmin.\n                \"\"\"\n                if self.cleaned_data.get(DELETION_FIELD_NAME, False):\n                    using = router.db_for_write(self._meta.model)\n                    collector = NestedObjects(using=using)\n                    if self.instance._state.adding:\n                        return\n                    collector.collect([self.instance])\n                    if collector.protected:\n                        objs = []\n                        for p in collector.protected:\n                            objs.append(\n                                # Translators: Model verbose name and instance representation,\n                                # suitable to be an item in a list.\n                                _('%(class_name)s %(instance)s') % {\n                                    'class_name': p._meta.verbose_name,\n                                    'instance': p}\n                            )\n                        params = {\n                            'class_name': self._meta.model._meta.verbose_name,\n                            'instance': self.instance,\n                            'related_objects': get_text_list(objs, _('and')),\n                        }\n                        msg = _(\"Deleting %(class_name)s %(instance)s would require \"\n                                \"deleting the following protected related objects: \"\n                                \"%(related_objects)s\")\n                        raise ValidationError(msg, code='deleting_protected', params=params)\n\n            def is_valid(self):\n                result = super().is_valid()\n                self.hand_clean_DELETE()\n                return result\n\n            def has_changed(self):\n                # Protect against unauthorized edits.\n                if not can_change and not self.instance._state.adding:\n                    return False\n                if not can_add and self.instance._state.adding:\n                    return False\n                return super().has_changed()\n\n        defaults['form'] = DeleteProtectedModelForm\n\n        if defaults['fields'] is None and not modelform_defines_fields(defaults['form']):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        return inlineformset_factory(self.parent_model, self.model, **defaults)\n\n    def _get_form_for_get_fields(self, request, obj=None):\n        return self.get_formset(request, obj, fields=None).form\n\n    def get_queryset(self, request):\n        queryset = super().get_queryset(request)\n        if not self.has_view_or_change_permission(request):\n            queryset = queryset.none()\n        return queryset\n\n    def _has_any_perms_for_target_model(self, request, perms):\n        \"\"\"\n        This method is called only when the ModelAdmin's model is for an\n        ManyToManyField's implicit through model (if self.opts.auto_created).\n        Return True if the user has any of the given permissions ('add',\n        'change', etc.) for the model that points to the through model.\n        \"\"\"\n        opts = self.opts\n        # Find the target model of an auto-created many-to-many relationship.\n        for field in opts.fields:\n            if field.remote_field and field.remote_field.model != self.parent_model:\n                opts = field.remote_field.model._meta\n                break\n        return any(\n            request.user.has_perm('%s.%s' % (opts.app_label, get_permission_codename(perm, opts)))\n            for perm in perms\n        )\n\n    def has_add_permission(self, request, obj):\n        if self.opts.auto_created:\n            # Auto-created intermediate models don't have their own\n            # permissions. The user needs to have the change permission for the\n            # related model in order to be able to do anything with the\n            # intermediate model.\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_add_permission(request)\n\n    def has_change_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission().\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_change_permission(request)\n\n    def has_delete_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission().\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_delete_permission(request, obj)\n\n    def has_view_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission(). The 'change' permission\n            # also implies the 'view' permission.\n            return self._has_any_perms_for_target_model(request, ['view', 'change'])\n        return super().has_view_permission(request)\n\n\nclass StackedInline(InlineModelAdmin):\n    template = 'admin/edit_inline/stacked.html'\n\n\nclass TabularInline(InlineModelAdmin):\n    template = 'admin/edit_inline/tabular.html'\n",
    "code_after": "import copy\nimport json\nimport operator\nimport re\nfrom functools import partial, reduce, update_wrapper\nfrom urllib.parse import quote as urlquote\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.contrib.admin import helpers, widgets\nfrom django.contrib.admin.checks import (\n    BaseModelAdminChecks, InlineModelAdminChecks, ModelAdminChecks,\n)\nfrom django.contrib.admin.exceptions import DisallowedModelAdminToField\nfrom django.contrib.admin.templatetags.admin_urls import add_preserved_filters\nfrom django.contrib.admin.utils import (\n    NestedObjects, construct_change_message, flatten_fieldsets,\n    get_deleted_objects, lookup_needs_distinct, model_format_dict,\n    model_ngettext, quote, unquote,\n)\nfrom django.contrib.admin.views.autocomplete import AutocompleteJsonView\nfrom django.contrib.admin.widgets import (\n    AutocompleteSelect, AutocompleteSelectMultiple,\n)\nfrom django.contrib.auth import get_permission_codename\nfrom django.core.exceptions import (\n    FieldDoesNotExist, FieldError, PermissionDenied, ValidationError,\n)\nfrom django.core.paginator import Paginator\nfrom django.db import models, router, transaction\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.fields import BLANK_CHOICE_DASH\nfrom django.forms.formsets import DELETION_FIELD_NAME, all_valid\nfrom django.forms.models import (\n    BaseInlineFormSet, inlineformset_factory, modelform_defines_fields,\n    modelform_factory, modelformset_factory,\n)\nfrom django.forms.widgets import CheckboxSelectMultiple, SelectMultiple\nfrom django.http import HttpResponseRedirect\nfrom django.http.response import HttpResponseBase\nfrom django.template.response import SimpleTemplateResponse, TemplateResponse\nfrom django.urls import reverse\nfrom django.utils.decorators import method_decorator\nfrom django.utils.html import format_html\nfrom django.utils.http import urlencode\nfrom django.utils.safestring import mark_safe\nfrom django.utils.text import capfirst, format_lazy, get_text_list\nfrom django.utils.translation import gettext as _, ngettext\nfrom django.views.decorators.csrf import csrf_protect\nfrom django.views.generic import RedirectView\n\nIS_POPUP_VAR = '_popup'\nTO_FIELD_VAR = '_to_field'\n\n\nHORIZONTAL, VERTICAL = 1, 2\n\n\ndef get_content_type_for_model(obj):\n    # Since this module gets imported in the application's root package,\n    # it cannot import models from other applications at the module level.\n    from django.contrib.contenttypes.models import ContentType\n    return ContentType.objects.get_for_model(obj, for_concrete_model=False)\n\n\ndef get_ul_class(radio_style):\n    return 'radiolist' if radio_style == VERTICAL else 'radiolist inline'\n\n\nclass IncorrectLookupParameters(Exception):\n    pass\n\n\n# Defaults for formfield_overrides. ModelAdmin subclasses can change this\n# by adding to ModelAdmin.formfield_overrides.\n\nFORMFIELD_FOR_DBFIELD_DEFAULTS = {\n    models.DateTimeField: {\n        'form_class': forms.SplitDateTimeField,\n        'widget': widgets.AdminSplitDateTime\n    },\n    models.DateField: {'widget': widgets.AdminDateWidget},\n    models.TimeField: {'widget': widgets.AdminTimeWidget},\n    models.TextField: {'widget': widgets.AdminTextareaWidget},\n    models.URLField: {'widget': widgets.AdminURLFieldWidget},\n    models.IntegerField: {'widget': widgets.AdminIntegerFieldWidget},\n    models.BigIntegerField: {'widget': widgets.AdminBigIntegerFieldWidget},\n    models.CharField: {'widget': widgets.AdminTextInputWidget},\n    models.ImageField: {'widget': widgets.AdminFileWidget},\n    models.FileField: {'widget': widgets.AdminFileWidget},\n    models.EmailField: {'widget': widgets.AdminEmailInputWidget},\n    models.UUIDField: {'widget': widgets.AdminUUIDInputWidget},\n}\n\ncsrf_protect_m = method_decorator(csrf_protect)\n\n\nclass BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n    \"\"\"Functionality common to both ModelAdmin and InlineAdmin.\"\"\"\n\n    autocomplete_fields = ()\n    raw_id_fields = ()\n    fields = None\n    exclude = None\n    fieldsets = None\n    form = forms.ModelForm\n    filter_vertical = ()\n    filter_horizontal = ()\n    radio_fields = {}\n    prepopulated_fields = {}\n    formfield_overrides = {}\n    readonly_fields = ()\n    ordering = None\n    sortable_by = None\n    view_on_site = True\n    show_full_result_count = True\n    checks_class = BaseModelAdminChecks\n\n    def check(self, **kwargs):\n        return self.checks_class().check(self, **kwargs)\n\n    def __init__(self):\n        # Merge FORMFIELD_FOR_DBFIELD_DEFAULTS with the formfield_overrides\n        # rather than simply overwriting.\n        overrides = copy.deepcopy(FORMFIELD_FOR_DBFIELD_DEFAULTS)\n        for k, v in self.formfield_overrides.items():\n            overrides.setdefault(k, {}).update(v)\n        self.formfield_overrides = overrides\n\n    def formfield_for_dbfield(self, db_field, request, **kwargs):\n        \"\"\"\n        Hook for specifying the form Field instance for a given database Field\n        instance.\n\n        If kwargs are given, they're passed to the form Field's constructor.\n        \"\"\"\n        # If the field specifies choices, we don't need to look for special\n        # admin widgets - we just need to use a select widget of some kind.\n        if db_field.choices:\n            return self.formfield_for_choice_field(db_field, request, **kwargs)\n\n        # ForeignKey or ManyToManyFields\n        if isinstance(db_field, (models.ForeignKey, models.ManyToManyField)):\n            # Combine the field kwargs with any options for formfield_overrides.\n            # Make sure the passed in **kwargs override anything in\n            # formfield_overrides because **kwargs is more specific, and should\n            # always win.\n            if db_field.__class__ in self.formfield_overrides:\n                kwargs = {**self.formfield_overrides[db_field.__class__], **kwargs}\n\n            # Get the correct formfield.\n            if isinstance(db_field, models.ForeignKey):\n                formfield = self.formfield_for_foreignkey(db_field, request, **kwargs)\n            elif isinstance(db_field, models.ManyToManyField):\n                formfield = self.formfield_for_manytomany(db_field, request, **kwargs)\n\n            # For non-raw_id fields, wrap the widget with a wrapper that adds\n            # extra HTML -- the \"add other\" interface -- to the end of the\n            # rendered output. formfield can be None if it came from a\n            # OneToOneField with parent_link=True or a M2M intermediary.\n            if formfield and db_field.name not in self.raw_id_fields:\n                related_modeladmin = self.admin_site._registry.get(db_field.remote_field.model)\n                wrapper_kwargs = {}\n                if related_modeladmin:\n                    wrapper_kwargs.update(\n                        can_add_related=related_modeladmin.has_add_permission(request),\n                        can_change_related=related_modeladmin.has_change_permission(request),\n                        can_delete_related=related_modeladmin.has_delete_permission(request),\n                        can_view_related=related_modeladmin.has_view_permission(request),\n                    )\n                formfield.widget = widgets.RelatedFieldWidgetWrapper(\n                    formfield.widget, db_field.remote_field, self.admin_site, **wrapper_kwargs\n                )\n\n            return formfield\n\n        # If we've got overrides for the formfield defined, use 'em. **kwargs\n        # passed to formfield_for_dbfield override the defaults.\n        for klass in db_field.__class__.mro():\n            if klass in self.formfield_overrides:\n                kwargs = {**copy.deepcopy(self.formfield_overrides[klass]), **kwargs}\n                return db_field.formfield(**kwargs)\n\n        # For any other type of field, just call its formfield() method.\n        return db_field.formfield(**kwargs)\n\n    def formfield_for_choice_field(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a database Field that has declared choices.\n        \"\"\"\n        # If the field is named as a radio_field, use a RadioSelect\n        if db_field.name in self.radio_fields:\n            # Avoid stomping on custom widget/choices arguments.\n            if 'widget' not in kwargs:\n                kwargs['widget'] = widgets.AdminRadioSelect(attrs={\n                    'class': get_ul_class(self.radio_fields[db_field.name]),\n                })\n            if 'choices' not in kwargs:\n                kwargs['choices'] = db_field.get_choices(\n                    include_blank=db_field.blank,\n                    blank_choice=[('', _('None'))]\n                )\n        return db_field.formfield(**kwargs)\n\n    def get_field_queryset(self, db, db_field, request):\n        \"\"\"\n        If the ModelAdmin specifies ordering, the queryset should respect that\n        ordering.  Otherwise don't specify the queryset, let the field decide\n        (return None in that case).\n        \"\"\"\n        related_admin = self.admin_site._registry.get(db_field.remote_field.model)\n        if related_admin is not None:\n            ordering = related_admin.get_ordering(request)\n            if ordering is not None and ordering != ():\n                return db_field.remote_field.model._default_manager.using(db).order_by(*ordering)\n        return None\n\n    def formfield_for_foreignkey(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a ForeignKey.\n        \"\"\"\n        db = kwargs.get('using')\n\n        if 'widget' not in kwargs:\n            if db_field.name in self.get_autocomplete_fields(request):\n                kwargs['widget'] = AutocompleteSelect(db_field.remote_field, self.admin_site, using=db)\n            elif db_field.name in self.raw_id_fields:\n                kwargs['widget'] = widgets.ForeignKeyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n            elif db_field.name in self.radio_fields:\n                kwargs['widget'] = widgets.AdminRadioSelect(attrs={\n                    'class': get_ul_class(self.radio_fields[db_field.name]),\n                })\n                kwargs['empty_label'] = _('None') if db_field.blank else None\n\n        if 'queryset' not in kwargs:\n            queryset = self.get_field_queryset(db, db_field, request)\n            if queryset is not None:\n                kwargs['queryset'] = queryset\n\n        return db_field.formfield(**kwargs)\n\n    def formfield_for_manytomany(self, db_field, request, **kwargs):\n        \"\"\"\n        Get a form Field for a ManyToManyField.\n        \"\"\"\n        # If it uses an intermediary model that isn't auto created, don't show\n        # a field in admin.\n        if not db_field.remote_field.through._meta.auto_created:\n            return None\n        db = kwargs.get('using')\n\n        autocomplete_fields = self.get_autocomplete_fields(request)\n        if db_field.name in autocomplete_fields:\n            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n        elif db_field.name in self.raw_id_fields:\n            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n            kwargs['widget'] = widgets.FilteredSelectMultiple(\n                db_field.verbose_name,\n                db_field.name in self.filter_vertical\n            )\n\n        if 'queryset' not in kwargs:\n            queryset = self.get_field_queryset(db, db_field, request)\n            if queryset is not None:\n                kwargs['queryset'] = queryset\n\n        form_field = db_field.formfield(**kwargs)\n        if (isinstance(form_field.widget, SelectMultiple) and\n                not isinstance(form_field.widget, (CheckboxSelectMultiple, AutocompleteSelectMultiple))):\n            msg = _('Hold down \u201cControl\u201d, or \u201cCommand\u201d on a Mac, to select more than one.')\n            help_text = form_field.help_text\n            form_field.help_text = format_lazy('{} {}', help_text, msg) if help_text else msg\n        return form_field\n\n    def get_autocomplete_fields(self, request):\n        \"\"\"\n        Return a list of ForeignKey and/or ManyToMany fields which should use\n        an autocomplete widget.\n        \"\"\"\n        return self.autocomplete_fields\n\n    def get_view_on_site_url(self, obj=None):\n        if obj is None or not self.view_on_site:\n            return None\n\n        if callable(self.view_on_site):\n            return self.view_on_site(obj)\n        elif self.view_on_site and hasattr(obj, 'get_absolute_url'):\n            # use the ContentType lookup if view_on_site is True\n            return reverse('admin:view_on_site', kwargs={\n                'content_type_id': get_content_type_for_model(obj).pk,\n                'object_id': obj.pk\n            })\n\n    def get_empty_value_display(self):\n        \"\"\"\n        Return the empty_value_display set on ModelAdmin or AdminSite.\n        \"\"\"\n        try:\n            return mark_safe(self.empty_value_display)\n        except AttributeError:\n            return mark_safe(self.admin_site.empty_value_display)\n\n    def get_exclude(self, request, obj=None):\n        \"\"\"\n        Hook for specifying exclude.\n        \"\"\"\n        return self.exclude\n\n    def get_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying fields.\n        \"\"\"\n        if self.fields:\n            return self.fields\n        # _get_form_for_get_fields() is implemented in subclasses.\n        form = self._get_form_for_get_fields(request, obj)\n        return [*form.base_fields, *self.get_readonly_fields(request, obj)]\n\n    def get_fieldsets(self, request, obj=None):\n        \"\"\"\n        Hook for specifying fieldsets.\n        \"\"\"\n        if self.fieldsets:\n            return self.fieldsets\n        return [(None, {'fields': self.get_fields(request, obj)})]\n\n    def get_inlines(self, request, obj):\n        \"\"\"Hook for specifying custom inlines.\"\"\"\n        return self.inlines\n\n    def get_ordering(self, request):\n        \"\"\"\n        Hook for specifying field ordering.\n        \"\"\"\n        return self.ordering or ()  # otherwise we might try to *None, which is bad ;)\n\n    def get_readonly_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying custom readonly fields.\n        \"\"\"\n        return self.readonly_fields\n\n    def get_prepopulated_fields(self, request, obj=None):\n        \"\"\"\n        Hook for specifying custom prepopulated fields.\n        \"\"\"\n        return self.prepopulated_fields\n\n    def get_queryset(self, request):\n        \"\"\"\n        Return a QuerySet of all model instances that can be edited by the\n        admin site. This is used by changelist_view.\n        \"\"\"\n        qs = self.model._default_manager.get_queryset()\n        # TODO: this should be handled by some parameter to the ChangeList.\n        ordering = self.get_ordering(request)\n        if ordering:\n            qs = qs.order_by(*ordering)\n        return qs\n\n    def get_sortable_by(self, request):\n        \"\"\"Hook for specifying which fields can be sorted in the changelist.\"\"\"\n        return self.sortable_by if self.sortable_by is not None else self.get_list_display(request)\n\n    def lookup_allowed(self, lookup, value):\n        from django.contrib.admin.filters import SimpleListFilter\n\n        model = self.model\n        # Check FKey lookups that are allowed, so that popups produced by\n        # ForeignKeyRawIdWidget, on the basis of ForeignKey.limit_choices_to,\n        # are allowed to work.\n        for fk_lookup in model._meta.related_fkey_lookups:\n            # As ``limit_choices_to`` can be a callable, invoke it here.\n            if callable(fk_lookup):\n                fk_lookup = fk_lookup()\n            if (lookup, value) in widgets.url_params_from_lookup_dict(fk_lookup).items():\n                return True\n\n        relation_parts = []\n        prev_field = None\n        for part in lookup.split(LOOKUP_SEP):\n            try:\n                field = model._meta.get_field(part)\n            except FieldDoesNotExist:\n                # Lookups on nonexistent fields are ok, since they're ignored\n                # later.\n                break\n            # It is allowed to filter on values that would be found from local\n            # model anyways. For example, if you filter on employee__department__id,\n            # then the id value would be found already from employee__department_id.\n            if not prev_field or (prev_field.is_relation and\n                                  field not in prev_field.get_path_info()[-1].target_fields):\n                relation_parts.append(part)\n            if not getattr(field, 'get_path_info', None):\n                # This is not a relational field, so further parts\n                # must be transforms.\n                break\n            prev_field = field\n            model = field.get_path_info()[-1].to_opts.model\n\n        if len(relation_parts) <= 1:\n            # Either a local field filter, or no fields at all.\n            return True\n        valid_lookups = {self.date_hierarchy}\n        for filter_item in self.list_filter:\n            if isinstance(filter_item, type) and issubclass(filter_item, SimpleListFilter):\n                valid_lookups.add(filter_item.parameter_name)\n            elif isinstance(filter_item, (list, tuple)):\n                valid_lookups.add(filter_item[0])\n            else:\n                valid_lookups.add(filter_item)\n\n        # Is it a valid relational lookup?\n        return not {\n            LOOKUP_SEP.join(relation_parts),\n            LOOKUP_SEP.join(relation_parts + [part])\n        }.isdisjoint(valid_lookups)\n\n    def to_field_allowed(self, request, to_field):\n        \"\"\"\n        Return True if the model associated with this admin should be\n        allowed to be referenced by the specified field.\n        \"\"\"\n        opts = self.model._meta\n\n        try:\n            field = opts.get_field(to_field)\n        except FieldDoesNotExist:\n            return False\n\n        # Always allow referencing the primary key since it's already possible\n        # to get this information from the change view URL.\n        if field.primary_key:\n            return True\n\n        # Allow reverse relationships to models defining m2m fields if they\n        # target the specified field.\n        for many_to_many in opts.many_to_many:\n            if many_to_many.m2m_target_field_name() == to_field:\n                return True\n\n        # Make sure at least one of the models registered for this site\n        # references this field through a FK or a M2M relationship.\n        registered_models = set()\n        for model, admin in self.admin_site._registry.items():\n            registered_models.add(model)\n            for inline in admin.inlines:\n                registered_models.add(inline.model)\n\n        related_objects = (\n            f for f in opts.get_fields(include_hidden=True)\n            if (f.auto_created and not f.concrete)\n        )\n        for related_object in related_objects:\n            related_model = related_object.related_model\n            remote_field = related_object.field.remote_field\n            if (any(issubclass(model, related_model) for model in registered_models) and\n                    hasattr(remote_field, 'get_related_field') and\n                    remote_field.get_related_field() == field):\n                return True\n\n        return False\n\n    def has_add_permission(self, request):\n        \"\"\"\n        Return True if the given request has permission to add an object.\n        Can be overridden by the user in subclasses.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('add', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_change_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to change the given\n        Django model instance, the default implementation doesn't examine the\n        `obj` parameter.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to change the `obj`\n        model instance. If `obj` is None, this should return True if the given\n        request has permission to change *any* object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('change', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_delete_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to change the given\n        Django model instance, the default implementation doesn't examine the\n        `obj` parameter.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to delete the `obj`\n        model instance. If `obj` is None, this should return True if the given\n        request has permission to delete *any* object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename = get_permission_codename('delete', opts)\n        return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n\n    def has_view_permission(self, request, obj=None):\n        \"\"\"\n        Return True if the given request has permission to view the given\n        Django model instance. The default implementation doesn't examine the\n        `obj` parameter.\n\n        If overridden by the user in subclasses, it should return True if the\n        given request has permission to view the `obj` model instance. If `obj`\n        is None, it should return True if the request has permission to view\n        any object of the given type.\n        \"\"\"\n        opts = self.opts\n        codename_view = get_permission_codename('view', opts)\n        codename_change = get_permission_codename('change', opts)\n        return (\n            request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or\n            request.user.has_perm('%s.%s' % (opts.app_label, codename_change))\n        )\n\n    def has_view_or_change_permission(self, request, obj=None):\n        return self.has_view_permission(request, obj) or self.has_change_permission(request, obj)\n\n    def has_module_permission(self, request):\n        \"\"\"\n        Return True if the given request has any permission in the given\n        app label.\n\n        Can be overridden by the user in subclasses. In such case it should\n        return True if the given request has permission to view the module on\n        the admin index page and access the module's index page. Overriding it\n        does not restrict access to the add, change or delete views. Use\n        `ModelAdmin.has_(add|change|delete)_permission` for that.\n        \"\"\"\n        return request.user.has_module_perms(self.opts.app_label)\n\n\nclass ModelAdmin(BaseModelAdmin):\n    \"\"\"Encapsulate all admin options and functionality for a given model.\"\"\"\n\n    list_display = ('__str__',)\n    list_display_links = ()\n    list_filter = ()\n    list_select_related = False\n    list_per_page = 100\n    list_max_show_all = 200\n    list_editable = ()\n    search_fields = ()\n    date_hierarchy = None\n    save_as = False\n    save_as_continue = True\n    save_on_top = False\n    paginator = Paginator\n    preserve_filters = True\n    inlines = []\n\n    # Custom templates (designed to be over-ridden in subclasses)\n    add_form_template = None\n    change_form_template = None\n    change_list_template = None\n    delete_confirmation_template = None\n    delete_selected_confirmation_template = None\n    object_history_template = None\n    popup_response_template = None\n\n    # Actions\n    actions = []\n    action_form = helpers.ActionForm\n    actions_on_top = True\n    actions_on_bottom = False\n    actions_selection_counter = True\n    checks_class = ModelAdminChecks\n\n    def __init__(self, model, admin_site):\n        self.model = model\n        self.opts = model._meta\n        self.admin_site = admin_site\n        super().__init__()\n\n    def __str__(self):\n        return \"%s.%s\" % (self.model._meta.app_label, self.__class__.__name__)\n\n    def get_inline_instances(self, request, obj=None):\n        inline_instances = []\n        for inline_class in self.get_inlines(request, obj):\n            inline = inline_class(self.model, self.admin_site)\n            if request:\n                if not (inline.has_view_or_change_permission(request, obj) or\n                        inline.has_add_permission(request, obj) or\n                        inline.has_delete_permission(request, obj)):\n                    continue\n                if not inline.has_add_permission(request, obj):\n                    inline.max_num = 0\n            inline_instances.append(inline)\n\n        return inline_instances\n\n    def get_urls(self):\n        from django.urls import path\n\n        def wrap(view):\n            def wrapper(*args, **kwargs):\n                return self.admin_site.admin_view(view)(*args, **kwargs)\n            wrapper.model_admin = self\n            return update_wrapper(wrapper, view)\n\n        info = self.model._meta.app_label, self.model._meta.model_name\n\n        return [\n            path('', wrap(self.changelist_view), name='%s_%s_changelist' % info),\n            path('add/', wrap(self.add_view), name='%s_%s_add' % info),\n            path('autocomplete/', wrap(self.autocomplete_view), name='%s_%s_autocomplete' % info),\n            path('<path:object_id>/history/', wrap(self.history_view), name='%s_%s_history' % info),\n            path('<path:object_id>/delete/', wrap(self.delete_view), name='%s_%s_delete' % info),\n            path('<path:object_id>/change/', wrap(self.change_view), name='%s_%s_change' % info),\n            # For backwards compatibility (was the change url before 1.9)\n            path('<path:object_id>/', wrap(RedirectView.as_view(\n                pattern_name='%s:%s_%s_change' % ((self.admin_site.name,) + info)\n            ))),\n        ]\n\n    @property\n    def urls(self):\n        return self.get_urls()\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = [\n            'vendor/jquery/jquery%s.js' % extra,\n            'jquery.init.js',\n            'core.js',\n            'admin/RelatedObjectLookups.js',\n            'actions%s.js' % extra,\n            'urlify.js',\n            'prepopulate%s.js' % extra,\n            'vendor/xregexp/xregexp%s.js' % extra,\n        ]\n        return forms.Media(js=['admin/js/%s' % url for url in js])\n\n    def get_model_perms(self, request):\n        \"\"\"\n        Return a dict of all perms for this model. This dict has the keys\n        ``add``, ``change``, ``delete``, and ``view`` mapping to the True/False\n        for each of those actions.\n        \"\"\"\n        return {\n            'add': self.has_add_permission(request),\n            'change': self.has_change_permission(request),\n            'delete': self.has_delete_permission(request),\n            'view': self.has_view_permission(request),\n        }\n\n    def _get_form_for_get_fields(self, request, obj):\n        return self.get_form(request, obj, fields=None)\n\n    def get_form(self, request, obj=None, change=False, **kwargs):\n        \"\"\"\n        Return a Form class for use in the admin add view. This is used by\n        add_view and change_view.\n        \"\"\"\n        if 'fields' in kwargs:\n            fields = kwargs.pop('fields')\n        else:\n            fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        excluded = self.get_exclude(request, obj)\n        exclude = [] if excluded is None else list(excluded)\n        readonly_fields = self.get_readonly_fields(request, obj)\n        exclude.extend(readonly_fields)\n        # Exclude all fields if it's a change form and the user doesn't have\n        # the change permission.\n        if change and hasattr(request, 'user') and not self.has_change_permission(request, obj):\n            exclude.extend(fields)\n        if excluded is None and hasattr(self.form, '_meta') and self.form._meta.exclude:\n            # Take the custom ModelForm's Meta.exclude into account only if the\n            # ModelAdmin doesn't define its own.\n            exclude.extend(self.form._meta.exclude)\n        # if exclude is an empty list we pass None to be consistent with the\n        # default on modelform_factory\n        exclude = exclude or None\n\n        # Remove declared form fields which are in readonly_fields.\n        new_attrs = dict.fromkeys(f for f in readonly_fields if f in self.form.declared_fields)\n        form = type(self.form.__name__, (self.form,), new_attrs)\n\n        defaults = {\n            'form': form,\n            'fields': fields,\n            'exclude': exclude,\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n\n        if defaults['fields'] is None and not modelform_defines_fields(defaults['form']):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        try:\n            return modelform_factory(self.model, **defaults)\n        except FieldError as e:\n            raise FieldError(\n                '%s. Check fields/fieldsets/exclude attributes of class %s.'\n                % (e, self.__class__.__name__)\n            )\n\n    def get_changelist(self, request, **kwargs):\n        \"\"\"\n        Return the ChangeList class for use on the changelist page.\n        \"\"\"\n        from django.contrib.admin.views.main import ChangeList\n        return ChangeList\n\n    def get_changelist_instance(self, request):\n        \"\"\"\n        Return a `ChangeList` instance based on `request`. May raise\n        `IncorrectLookupParameters`.\n        \"\"\"\n        list_display = self.get_list_display(request)\n        list_display_links = self.get_list_display_links(request, list_display)\n        # Add the action checkboxes if any actions are available.\n        if self.get_actions(request):\n            list_display = ['action_checkbox', *list_display]\n        sortable_by = self.get_sortable_by(request)\n        ChangeList = self.get_changelist(request)\n        return ChangeList(\n            request,\n            self.model,\n            list_display,\n            list_display_links,\n            self.get_list_filter(request),\n            self.date_hierarchy,\n            self.get_search_fields(request),\n            self.get_list_select_related(request),\n            self.list_per_page,\n            self.list_max_show_all,\n            self.list_editable,\n            self,\n            sortable_by,\n        )\n\n    def get_object(self, request, object_id, from_field=None):\n        \"\"\"\n        Return an instance matching the field and value provided, the primary\n        key is used if no field is provided. Return ``None`` if no match is\n        found or the object_id fails validation.\n        \"\"\"\n        queryset = self.get_queryset(request)\n        model = queryset.model\n        field = model._meta.pk if from_field is None else model._meta.get_field(from_field)\n        try:\n            object_id = field.to_python(object_id)\n            return queryset.get(**{field.name: object_id})\n        except (model.DoesNotExist, ValidationError, ValueError):\n            return None\n\n    def get_changelist_form(self, request, **kwargs):\n        \"\"\"\n        Return a Form class for use in the Formset on the changelist page.\n        \"\"\"\n        defaults = {\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n        if defaults.get('fields') is None and not modelform_defines_fields(defaults.get('form')):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        return modelform_factory(self.model, **defaults)\n\n    def get_changelist_formset(self, request, **kwargs):\n        \"\"\"\n        Return a FormSet class for use on the changelist page if list_editable\n        is used.\n        \"\"\"\n        defaults = {\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            **kwargs,\n        }\n        return modelformset_factory(\n            self.model, self.get_changelist_form(request), extra=0,\n            fields=self.list_editable, **defaults\n        )\n\n    def get_formsets_with_inlines(self, request, obj=None):\n        \"\"\"\n        Yield formsets and the corresponding inlines.\n        \"\"\"\n        for inline in self.get_inline_instances(request, obj):\n            yield inline.get_formset(request, obj), inline\n\n    def get_paginator(self, request, queryset, per_page, orphans=0, allow_empty_first_page=True):\n        return self.paginator(queryset, per_page, orphans, allow_empty_first_page)\n\n    def log_addition(self, request, object, message):\n        \"\"\"\n        Log that an object has been successfully added.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, ADDITION\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=str(object),\n            action_flag=ADDITION,\n            change_message=message,\n        )\n\n    def log_change(self, request, object, message):\n        \"\"\"\n        Log that an object has been successfully changed.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, CHANGE\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=str(object),\n            action_flag=CHANGE,\n            change_message=message,\n        )\n\n    def log_deletion(self, request, object, object_repr):\n        \"\"\"\n        Log that an object will be deleted. Note that this method must be\n        called before the deletion.\n\n        The default implementation creates an admin LogEntry object.\n        \"\"\"\n        from django.contrib.admin.models import LogEntry, DELETION\n        return LogEntry.objects.log_action(\n            user_id=request.user.pk,\n            content_type_id=get_content_type_for_model(object).pk,\n            object_id=object.pk,\n            object_repr=object_repr,\n            action_flag=DELETION,\n        )\n\n    def action_checkbox(self, obj):\n        \"\"\"\n        A list_display column containing a checkbox widget.\n        \"\"\"\n        return helpers.checkbox.render(helpers.ACTION_CHECKBOX_NAME, str(obj.pk))\n    action_checkbox.short_description = mark_safe('<input type=\"checkbox\" id=\"action-toggle\">')\n\n    def _get_base_actions(self):\n        \"\"\"Return the list of actions, prior to any request-based filtering.\"\"\"\n        actions = []\n\n        # Gather actions from the admin site first\n        for (name, func) in self.admin_site.actions:\n            description = getattr(func, 'short_description', name.replace('_', ' '))\n            actions.append((func, name, description))\n        # Add actions from this ModelAdmin.\n        actions.extend(self.get_action(action) for action in self.actions or [])\n        # get_action might have returned None, so filter any of those out.\n        return filter(None, actions)\n\n    def _filter_actions_by_permissions(self, request, actions):\n        \"\"\"Filter out any actions that the user doesn't have access to.\"\"\"\n        filtered_actions = []\n        for action in actions:\n            callable = action[0]\n            if not hasattr(callable, 'allowed_permissions'):\n                filtered_actions.append(action)\n                continue\n            permission_checks = (\n                getattr(self, 'has_%s_permission' % permission)\n                for permission in callable.allowed_permissions\n            )\n            if any(has_permission(request) for has_permission in permission_checks):\n                filtered_actions.append(action)\n        return filtered_actions\n\n    def get_actions(self, request):\n        \"\"\"\n        Return a dictionary mapping the names of all actions for this\n        ModelAdmin to a tuple of (callable, name, description) for each action.\n        \"\"\"\n        # If self.actions is set to None that means actions are disabled on\n        # this page.\n        if self.actions is None or IS_POPUP_VAR in request.GET:\n            return {}\n        actions = self._filter_actions_by_permissions(request, self._get_base_actions())\n        return {name: (func, name, desc) for func, name, desc in actions}\n\n    def get_action_choices(self, request, default_choices=BLANK_CHOICE_DASH):\n        \"\"\"\n        Return a list of choices for use in a form object.  Each choice is a\n        tuple (name, description).\n        \"\"\"\n        choices = [] + default_choices\n        for func, name, description in self.get_actions(request).values():\n            choice = (name, description % model_format_dict(self.opts))\n            choices.append(choice)\n        return choices\n\n    def get_action(self, action):\n        \"\"\"\n        Return a given action from a parameter, which can either be a callable,\n        or the name of a method on the ModelAdmin.  Return is a tuple of\n        (callable, name, description).\n        \"\"\"\n        # If the action is a callable, just use it.\n        if callable(action):\n            func = action\n            action = action.__name__\n\n        # Next, look for a method. Grab it off self.__class__ to get an unbound\n        # method instead of a bound one; this ensures that the calling\n        # conventions are the same for functions and methods.\n        elif hasattr(self.__class__, action):\n            func = getattr(self.__class__, action)\n\n        # Finally, look for a named method on the admin site\n        else:\n            try:\n                func = self.admin_site.get_action(action)\n            except KeyError:\n                return None\n\n        if hasattr(func, 'short_description'):\n            description = func.short_description\n        else:\n            description = capfirst(action.replace('_', ' '))\n        return func, action, description\n\n    def get_list_display(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be displayed on the\n        changelist.\n        \"\"\"\n        return self.list_display\n\n    def get_list_display_links(self, request, list_display):\n        \"\"\"\n        Return a sequence containing the fields to be displayed as links\n        on the changelist. The list_display parameter is the list of fields\n        returned by get_list_display().\n        \"\"\"\n        if self.list_display_links or self.list_display_links is None or not list_display:\n            return self.list_display_links\n        else:\n            # Use only the first item in list_display as link\n            return list(list_display)[:1]\n\n    def get_list_filter(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be displayed as filters in\n        the right sidebar of the changelist page.\n        \"\"\"\n        return self.list_filter\n\n    def get_list_select_related(self, request):\n        \"\"\"\n        Return a list of fields to add to the select_related() part of the\n        changelist items query.\n        \"\"\"\n        return self.list_select_related\n\n    def get_search_fields(self, request):\n        \"\"\"\n        Return a sequence containing the fields to be searched whenever\n        somebody submits a search query.\n        \"\"\"\n        return self.search_fields\n\n    def get_search_results(self, request, queryset, search_term):\n        \"\"\"\n        Return a tuple containing a queryset to implement the search\n        and a boolean indicating if the results may contain duplicates.\n        \"\"\"\n        # Apply keyword searches.\n        def construct_search(field_name):\n            if field_name.startswith('^'):\n                return \"%s__istartswith\" % field_name[1:]\n            elif field_name.startswith('='):\n                return \"%s__iexact\" % field_name[1:]\n            elif field_name.startswith('@'):\n                return \"%s__search\" % field_name[1:]\n            # Use field_name if it includes a lookup.\n            opts = queryset.model._meta\n            lookup_fields = field_name.split(LOOKUP_SEP)\n            # Go through the fields, following all relations.\n            prev_field = None\n            for path_part in lookup_fields:\n                if path_part == 'pk':\n                    path_part = opts.pk.name\n                try:\n                    field = opts.get_field(path_part)\n                except FieldDoesNotExist:\n                    # Use valid query lookups.\n                    if prev_field and prev_field.get_lookup(path_part):\n                        return field_name\n                else:\n                    prev_field = field\n                    if hasattr(field, 'get_path_info'):\n                        # Update opts to follow the relation.\n                        opts = field.get_path_info()[-1].to_opts\n            # Otherwise, use the field with icontains.\n            return \"%s__icontains\" % field_name\n\n        use_distinct = False\n        search_fields = self.get_search_fields(request)\n        if search_fields and search_term:\n            orm_lookups = [construct_search(str(search_field))\n                           for search_field in search_fields]\n            for bit in search_term.split():\n                or_queries = [models.Q(**{orm_lookup: bit})\n                              for orm_lookup in orm_lookups]\n                queryset = queryset.filter(reduce(operator.or_, or_queries))\n            use_distinct |= any(lookup_needs_distinct(self.opts, search_spec) for search_spec in orm_lookups)\n\n        return queryset, use_distinct\n\n    def get_preserved_filters(self, request):\n        \"\"\"\n        Return the preserved filters querystring.\n        \"\"\"\n        match = request.resolver_match\n        if self.preserve_filters and match:\n            opts = self.model._meta\n            current_url = '%s:%s' % (match.app_name, match.url_name)\n            changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name)\n            if current_url == changelist_url:\n                preserved_filters = request.GET.urlencode()\n            else:\n                preserved_filters = request.GET.get('_changelist_filters')\n\n            if preserved_filters:\n                return urlencode({'_changelist_filters': preserved_filters})\n        return ''\n\n    def construct_change_message(self, request, form, formsets, add=False):\n        \"\"\"\n        Construct a JSON structure describing changes from a changed object.\n        \"\"\"\n        return construct_change_message(form, formsets, add)\n\n    def message_user(self, request, message, level=messages.INFO, extra_tags='',\n                     fail_silently=False):\n        \"\"\"\n        Send a message to the user. The default implementation\n        posts a message using the django.contrib.messages backend.\n\n        Exposes almost the same API as messages.add_message(), but accepts the\n        positional arguments in a different order to maintain backwards\n        compatibility. For convenience, it accepts the `level` argument as\n        a string rather than the usual level number.\n        \"\"\"\n        if not isinstance(level, int):\n            # attempt to get the level if passed a string\n            try:\n                level = getattr(messages.constants, level.upper())\n            except AttributeError:\n                levels = messages.constants.DEFAULT_TAGS.values()\n                levels_repr = ', '.join('`%s`' % l for l in levels)\n                raise ValueError(\n                    'Bad message level string: `%s`. Possible values are: %s'\n                    % (level, levels_repr)\n                )\n\n        messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n\n    def save_form(self, request, form, change):\n        \"\"\"\n        Given a ModelForm return an unsaved instance. ``change`` is True if\n        the object is being changed, and False if it's being added.\n        \"\"\"\n        return form.save(commit=False)\n\n    def save_model(self, request, obj, form, change):\n        \"\"\"\n        Given a model instance save it to the database.\n        \"\"\"\n        obj.save()\n\n    def delete_model(self, request, obj):\n        \"\"\"\n        Given a model instance delete it from the database.\n        \"\"\"\n        obj.delete()\n\n    def delete_queryset(self, request, queryset):\n        \"\"\"Given a queryset, delete it from the database.\"\"\"\n        queryset.delete()\n\n    def save_formset(self, request, form, formset, change):\n        \"\"\"\n        Given an inline formset save it to the database.\n        \"\"\"\n        formset.save()\n\n    def save_related(self, request, form, formsets, change):\n        \"\"\"\n        Given the ``HttpRequest``, the parent ``ModelForm`` instance, the\n        list of inline formsets and a boolean value based on whether the\n        parent is being added or changed, save the related objects to the\n        database. Note that at this point save_form() and save_model() have\n        already been called.\n        \"\"\"\n        form.save_m2m()\n        for formset in formsets:\n            self.save_formset(request, form, formset, change=change)\n\n    def render_change_form(self, request, context, add=False, change=False, form_url='', obj=None):\n        opts = self.model._meta\n        app_label = opts.app_label\n        preserved_filters = self.get_preserved_filters(request)\n        form_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, form_url)\n        view_on_site_url = self.get_view_on_site_url(obj)\n        has_editable_inline_admin_formsets = False\n        for inline in context['inline_admin_formsets']:\n            if inline.has_add_permission or inline.has_change_permission or inline.has_delete_permission:\n                has_editable_inline_admin_formsets = True\n                break\n        context.update({\n            'add': add,\n            'change': change,\n            'has_view_permission': self.has_view_permission(request, obj),\n            'has_add_permission': self.has_add_permission(request),\n            'has_change_permission': self.has_change_permission(request, obj),\n            'has_delete_permission': self.has_delete_permission(request, obj),\n            'has_editable_inline_admin_formsets': has_editable_inline_admin_formsets,\n            'has_file_field': context['adminform'].form.is_multipart() or any(\n                admin_formset.formset.is_multipart()\n                for admin_formset in context['inline_admin_formsets']\n            ),\n            'has_absolute_url': view_on_site_url is not None,\n            'absolute_url': view_on_site_url,\n            'form_url': form_url,\n            'opts': opts,\n            'content_type_id': get_content_type_for_model(self.model).pk,\n            'save_as': self.save_as,\n            'save_on_top': self.save_on_top,\n            'to_field_var': TO_FIELD_VAR,\n            'is_popup_var': IS_POPUP_VAR,\n            'app_label': app_label,\n        })\n        if add and self.add_form_template is not None:\n            form_template = self.add_form_template\n        else:\n            form_template = self.change_form_template\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, form_template or [\n            \"admin/%s/%s/change_form.html\" % (app_label, opts.model_name),\n            \"admin/%s/change_form.html\" % app_label,\n            \"admin/change_form.html\"\n        ], context)\n\n    def response_add(self, request, obj, post_url_continue=None):\n        \"\"\"\n        Determine the HttpResponse for the add_view stage.\n        \"\"\"\n        opts = obj._meta\n        preserved_filters = self.get_preserved_filters(request)\n        obj_url = reverse(\n            'admin:%s_%s_change' % (opts.app_label, opts.model_name),\n            args=(quote(obj.pk),),\n            current_app=self.admin_site.name,\n        )\n        # Add a link to the object's change form if the user can edit the obj.\n        if self.has_change_permission(request, obj):\n            obj_repr = format_html('<a href=\"{}\">{}</a>', urlquote(obj_url), obj)\n        else:\n            obj_repr = str(obj)\n        msg_dict = {\n            'name': opts.verbose_name,\n            'obj': obj_repr,\n        }\n        # Here, we distinguish between different save types by checking for\n        # the presence of keys in request.POST.\n\n        if IS_POPUP_VAR in request.POST:\n            to_field = request.POST.get(TO_FIELD_VAR)\n            if to_field:\n                attr = str(to_field)\n            else:\n                attr = obj._meta.pk.attname\n            value = obj.serializable_value(attr)\n            popup_response_data = json.dumps({\n                'value': str(value),\n                'obj': str(obj),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        elif \"_continue\" in request.POST or (\n                # Redirecting after \"Save as new\".\n                \"_saveasnew\" in request.POST and self.save_as_continue and\n                self.has_change_permission(request, obj)\n        ):\n            msg = _('The {name} \u201c{obj}\u201d was added successfully.')\n            if self.has_change_permission(request, obj):\n                msg += ' ' + _('You may edit it again below.')\n            self.message_user(request, format_html(msg, **msg_dict), messages.SUCCESS)\n            if post_url_continue is None:\n                post_url_continue = obj_url\n            post_url_continue = add_preserved_filters(\n                {'preserved_filters': preserved_filters, 'opts': opts},\n                post_url_continue\n            )\n            return HttpResponseRedirect(post_url_continue)\n\n        elif \"_addanother\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully. You may add another {name} below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = request.path\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        else:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            return self.response_post_save_add(request, obj)\n\n    def response_change(self, request, obj):\n        \"\"\"\n        Determine the HttpResponse for the change_view stage.\n        \"\"\"\n\n        if IS_POPUP_VAR in request.POST:\n            opts = obj._meta\n            to_field = request.POST.get(TO_FIELD_VAR)\n            attr = str(to_field) if to_field else opts.pk.attname\n            value = request.resolver_match.kwargs['object_id']\n            new_value = obj.serializable_value(attr)\n            popup_response_data = json.dumps({\n                'action': 'change',\n                'value': str(value),\n                'obj': str(obj),\n                'new_value': str(new_value),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        opts = self.model._meta\n        preserved_filters = self.get_preserved_filters(request)\n\n        msg_dict = {\n            'name': opts.verbose_name,\n            'obj': format_html('<a href=\"{}\">{}</a>', urlquote(request.path), obj),\n        }\n        if \"_continue\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully. You may edit it again below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = request.path\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        elif \"_saveasnew\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was added successfully. You may edit it again below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = reverse('admin:%s_%s_change' %\n                                   (opts.app_label, opts.model_name),\n                                   args=(obj.pk,),\n                                   current_app=self.admin_site.name)\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        elif \"_addanother\" in request.POST:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully. You may add another {name} below.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            redirect_url = reverse('admin:%s_%s_add' %\n                                   (opts.app_label, opts.model_name),\n                                   current_app=self.admin_site.name)\n            redirect_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, redirect_url)\n            return HttpResponseRedirect(redirect_url)\n\n        else:\n            msg = format_html(\n                _('The {name} \u201c{obj}\u201d was changed successfully.'),\n                **msg_dict\n            )\n            self.message_user(request, msg, messages.SUCCESS)\n            return self.response_post_save_change(request, obj)\n\n    def _response_post_save(self, request, obj):\n        opts = self.model._meta\n        if self.has_view_or_change_permission(request):\n            post_url = reverse('admin:%s_%s_changelist' %\n                               (opts.app_label, opts.model_name),\n                               current_app=self.admin_site.name)\n            preserved_filters = self.get_preserved_filters(request)\n            post_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, post_url)\n        else:\n            post_url = reverse('admin:index',\n                               current_app=self.admin_site.name)\n        return HttpResponseRedirect(post_url)\n\n    def response_post_save_add(self, request, obj):\n        \"\"\"\n        Figure out where to redirect after the 'Save' button has been pressed\n        when adding a new object.\n        \"\"\"\n        return self._response_post_save(request, obj)\n\n    def response_post_save_change(self, request, obj):\n        \"\"\"\n        Figure out where to redirect after the 'Save' button has been pressed\n        when editing an existing object.\n        \"\"\"\n        return self._response_post_save(request, obj)\n\n    def response_action(self, request, queryset):\n        \"\"\"\n        Handle an admin action. This is called if a request is POSTed to the\n        changelist; it returns an HttpResponse if the action was handled, and\n        None otherwise.\n        \"\"\"\n\n        # There can be multiple action forms on the page (at the top\n        # and bottom of the change list, for example). Get the action\n        # whose button was pushed.\n        try:\n            action_index = int(request.POST.get('index', 0))\n        except ValueError:\n            action_index = 0\n\n        # Construct the action form.\n        data = request.POST.copy()\n        data.pop(helpers.ACTION_CHECKBOX_NAME, None)\n        data.pop(\"index\", None)\n\n        # Use the action whose button was pushed\n        try:\n            data.update({'action': data.getlist('action')[action_index]})\n        except IndexError:\n            # If we didn't get an action from the chosen form that's invalid\n            # POST data, so by deleting action it'll fail the validation check\n            # below. So no need to do anything here\n            pass\n\n        action_form = self.action_form(data, auto_id=None)\n        action_form.fields['action'].choices = self.get_action_choices(request)\n\n        # If the form's valid we can handle the action.\n        if action_form.is_valid():\n            action = action_form.cleaned_data['action']\n            select_across = action_form.cleaned_data['select_across']\n            func = self.get_actions(request)[action][0]\n\n            # Get the list of selected PKs. If nothing's selected, we can't\n            # perform an action on it, so bail. Except we want to perform\n            # the action explicitly on all objects.\n            selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)\n            if not selected and not select_across:\n                # Reminder that something needs to be selected or nothing will happen\n                msg = _(\"Items must be selected in order to perform \"\n                        \"actions on them. No items have been changed.\")\n                self.message_user(request, msg, messages.WARNING)\n                return None\n\n            if not select_across:\n                # Perform the action only on the selected objects\n                queryset = queryset.filter(pk__in=selected)\n\n            response = func(self, request, queryset)\n\n            # Actions may return an HttpResponse-like object, which will be\n            # used as the response from the POST. If not, we'll be a good\n            # little HTTP citizen and redirect back to the changelist page.\n            if isinstance(response, HttpResponseBase):\n                return response\n            else:\n                return HttpResponseRedirect(request.get_full_path())\n        else:\n            msg = _(\"No action selected.\")\n            self.message_user(request, msg, messages.WARNING)\n            return None\n\n    def response_delete(self, request, obj_display, obj_id):\n        \"\"\"\n        Determine the HttpResponse for the delete_view stage.\n        \"\"\"\n        opts = self.model._meta\n\n        if IS_POPUP_VAR in request.POST:\n            popup_response_data = json.dumps({\n                'action': 'delete',\n                'value': str(obj_id),\n            })\n            return TemplateResponse(request, self.popup_response_template or [\n                'admin/%s/%s/popup_response.html' % (opts.app_label, opts.model_name),\n                'admin/%s/popup_response.html' % opts.app_label,\n                'admin/popup_response.html',\n            ], {\n                'popup_response_data': popup_response_data,\n            })\n\n        self.message_user(\n            request,\n            _('The %(name)s \u201c%(obj)s\u201d was deleted successfully.') % {\n                'name': opts.verbose_name,\n                'obj': obj_display,\n            },\n            messages.SUCCESS,\n        )\n\n        if self.has_change_permission(request, None):\n            post_url = reverse(\n                'admin:%s_%s_changelist' % (opts.app_label, opts.model_name),\n                current_app=self.admin_site.name,\n            )\n            preserved_filters = self.get_preserved_filters(request)\n            post_url = add_preserved_filters(\n                {'preserved_filters': preserved_filters, 'opts': opts}, post_url\n            )\n        else:\n            post_url = reverse('admin:index', current_app=self.admin_site.name)\n        return HttpResponseRedirect(post_url)\n\n    def render_delete_form(self, request, context):\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        request.current_app = self.admin_site.name\n        context.update(\n            to_field_var=TO_FIELD_VAR,\n            is_popup_var=IS_POPUP_VAR,\n            media=self.media,\n        )\n\n        return TemplateResponse(\n            request,\n            self.delete_confirmation_template or [\n                \"admin/{}/{}/delete_confirmation.html\".format(app_label, opts.model_name),\n                \"admin/{}/delete_confirmation.html\".format(app_label),\n                \"admin/delete_confirmation.html\",\n            ],\n            context,\n        )\n\n    def get_inline_formsets(self, request, formsets, inline_instances, obj=None):\n        # Edit permissions on parent model are required for editable inlines.\n        can_edit_parent = self.has_change_permission(request, obj) if obj else self.has_add_permission(request)\n        inline_admin_formsets = []\n        for inline, formset in zip(inline_instances, formsets):\n            fieldsets = list(inline.get_fieldsets(request, obj))\n            readonly = list(inline.get_readonly_fields(request, obj))\n            if can_edit_parent:\n                has_add_permission = inline.has_add_permission(request, obj)\n                has_change_permission = inline.has_change_permission(request, obj)\n                has_delete_permission = inline.has_delete_permission(request, obj)\n            else:\n                # Disable all edit-permissions, and overide formset settings.\n                has_add_permission = has_change_permission = has_delete_permission = False\n                formset.extra = formset.max_num = 0\n            has_view_permission = inline.has_view_permission(request, obj)\n            prepopulated = dict(inline.get_prepopulated_fields(request, obj))\n            inline_admin_formset = helpers.InlineAdminFormSet(\n                inline, formset, fieldsets, prepopulated, readonly, model_admin=self,\n                has_add_permission=has_add_permission, has_change_permission=has_change_permission,\n                has_delete_permission=has_delete_permission, has_view_permission=has_view_permission,\n            )\n            inline_admin_formsets.append(inline_admin_formset)\n        return inline_admin_formsets\n\n    def get_changeform_initial_data(self, request):\n        \"\"\"\n        Get the initial form data from the request's GET params.\n        \"\"\"\n        initial = dict(request.GET.items())\n        for k in initial:\n            try:\n                f = self.model._meta.get_field(k)\n            except FieldDoesNotExist:\n                continue\n            # We have to special-case M2Ms as a list of comma-separated PKs.\n            if isinstance(f, models.ManyToManyField):\n                initial[k] = initial[k].split(\",\")\n        return initial\n\n    def _get_obj_does_not_exist_redirect(self, request, opts, object_id):\n        \"\"\"\n        Create a message informing the user that the object doesn't exist\n        and return a redirect to the admin index page.\n        \"\"\"\n        msg = _('%(name)s with ID \u201c%(key)s\u201d doesn\u2019t exist. Perhaps it was deleted?') % {\n            'name': opts.verbose_name,\n            'key': unquote(object_id),\n        }\n        self.message_user(request, msg, messages.WARNING)\n        url = reverse('admin:index', current_app=self.admin_site.name)\n        return HttpResponseRedirect(url)\n\n    @csrf_protect_m\n    def changeform_view(self, request, object_id=None, form_url='', extra_context=None):\n        with transaction.atomic(using=router.db_for_write(self.model)):\n            return self._changeform_view(request, object_id, form_url, extra_context)\n\n    def _changeform_view(self, request, object_id, form_url, extra_context):\n        to_field = request.POST.get(TO_FIELD_VAR, request.GET.get(TO_FIELD_VAR))\n        if to_field and not self.to_field_allowed(request, to_field):\n            raise DisallowedModelAdminToField(\"The field %s cannot be referenced.\" % to_field)\n\n        model = self.model\n        opts = model._meta\n\n        if request.method == 'POST' and '_saveasnew' in request.POST:\n            object_id = None\n\n        add = object_id is None\n\n        if add:\n            if not self.has_add_permission(request):\n                raise PermissionDenied\n            obj = None\n\n        else:\n            obj = self.get_object(request, unquote(object_id), to_field)\n\n            if request.method == 'POST':\n                if not self.has_change_permission(request, obj):\n                    raise PermissionDenied\n            else:\n                if not self.has_view_or_change_permission(request, obj):\n                    raise PermissionDenied\n\n            if obj is None:\n                return self._get_obj_does_not_exist_redirect(request, opts, object_id)\n\n        ModelForm = self.get_form(request, obj, change=not add)\n        if request.method == 'POST':\n            form = ModelForm(request.POST, request.FILES, instance=obj)\n            form_validated = form.is_valid()\n            if form_validated:\n                new_object = self.save_form(request, form, change=not add)\n            else:\n                new_object = form.instance\n            formsets, inline_instances = self._create_formsets(request, new_object, change=not add)\n            if all_valid(formsets) and form_validated:\n                self.save_model(request, new_object, form, not add)\n                self.save_related(request, form, formsets, not add)\n                change_message = self.construct_change_message(request, form, formsets, add)\n                if add:\n                    self.log_addition(request, new_object, change_message)\n                    return self.response_add(request, new_object)\n                else:\n                    self.log_change(request, new_object, change_message)\n                    return self.response_change(request, new_object)\n            else:\n                form_validated = False\n        else:\n            if add:\n                initial = self.get_changeform_initial_data(request)\n                form = ModelForm(initial=initial)\n                formsets, inline_instances = self._create_formsets(request, form.instance, change=False)\n            else:\n                form = ModelForm(instance=obj)\n                formsets, inline_instances = self._create_formsets(request, obj, change=True)\n\n        if not add and not self.has_change_permission(request, obj):\n            readonly_fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        else:\n            readonly_fields = self.get_readonly_fields(request, obj)\n        adminForm = helpers.AdminForm(\n            form,\n            list(self.get_fieldsets(request, obj)),\n            # Clear prepopulated fields on a view-only form to avoid a crash.\n            self.get_prepopulated_fields(request, obj) if add or self.has_change_permission(request, obj) else {},\n            readonly_fields,\n            model_admin=self)\n        media = self.media + adminForm.media\n\n        inline_formsets = self.get_inline_formsets(request, formsets, inline_instances, obj)\n        for inline_formset in inline_formsets:\n            media = media + inline_formset.media\n\n        if add:\n            title = _('Add %s')\n        elif self.has_change_permission(request, obj):\n            title = _('Change %s')\n        else:\n            title = _('View %s')\n        context = {\n            **self.admin_site.each_context(request),\n            'title': title % opts.verbose_name,\n            'adminform': adminForm,\n            'object_id': object_id,\n            'original': obj,\n            'is_popup': IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,\n            'to_field': to_field,\n            'media': media,\n            'inline_admin_formsets': inline_formsets,\n            'errors': helpers.AdminErrorList(form, formsets),\n            'preserved_filters': self.get_preserved_filters(request),\n        }\n\n        # Hide the \"Save\" and \"Save and continue\" buttons if \"Save as New\" was\n        # previously chosen to prevent the interface from getting confusing.\n        if request.method == 'POST' and not form_validated and \"_saveasnew\" in request.POST:\n            context['show_save'] = False\n            context['show_save_and_continue'] = False\n            # Use the change template instead of the add template.\n            add = False\n\n        context.update(extra_context or {})\n\n        return self.render_change_form(request, context, add=add, change=not add, obj=obj, form_url=form_url)\n\n    def autocomplete_view(self, request):\n        return AutocompleteJsonView.as_view(model_admin=self)(request)\n\n    def add_view(self, request, form_url='', extra_context=None):\n        return self.changeform_view(request, None, form_url, extra_context)\n\n    def change_view(self, request, object_id, form_url='', extra_context=None):\n        return self.changeform_view(request, object_id, form_url, extra_context)\n\n    def _get_edited_object_pks(self, request, prefix):\n        \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n        pk_pattern = re.compile(\n            r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name)\n        )\n        return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n\n    def _get_list_editable_queryset(self, request, prefix):\n        \"\"\"\n        Based on POST data, return a queryset of the objects that were edited\n        via list_editable.\n        \"\"\"\n        object_pks = self._get_edited_object_pks(request, prefix)\n        queryset = self.get_queryset(request)\n        validate = queryset.model._meta.pk.to_python\n        try:\n            for pk in object_pks:\n                validate(pk)\n        except ValidationError:\n            # Disable the optimization if the POST data was tampered with.\n            return queryset\n        return queryset.filter(pk__in=object_pks)\n\n    @csrf_protect_m\n    def changelist_view(self, request, extra_context=None):\n        \"\"\"\n        The 'change list' admin view for this model.\n        \"\"\"\n        from django.contrib.admin.views.main import ERROR_FLAG\n        opts = self.model._meta\n        app_label = opts.app_label\n        if not self.has_view_or_change_permission(request):\n            raise PermissionDenied\n\n        try:\n            cl = self.get_changelist_instance(request)\n        except IncorrectLookupParameters:\n            # Wacky lookup parameters were given, so redirect to the main\n            # changelist page, without parameters, and pass an 'invalid=1'\n            # parameter via the query string. If wacky parameters were given\n            # and the 'invalid=1' parameter was already in the query string,\n            # something is screwed up with the database, so display an error\n            # page.\n            if ERROR_FLAG in request.GET:\n                return SimpleTemplateResponse('admin/invalid_setup.html', {\n                    'title': _('Database error'),\n                })\n            return HttpResponseRedirect(request.path + '?' + ERROR_FLAG + '=1')\n\n        # If the request was POSTed, this might be a bulk action or a bulk\n        # edit. Try to look up an action or confirmation first, but if this\n        # isn't an action the POST will fall through to the bulk edit check,\n        # below.\n        action_failed = False\n        selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)\n\n        actions = self.get_actions(request)\n        # Actions with no confirmation\n        if (actions and request.method == 'POST' and\n                'index' in request.POST and '_save' not in request.POST):\n            if selected:\n                response = self.response_action(request, queryset=cl.get_queryset(request))\n                if response:\n                    return response\n                else:\n                    action_failed = True\n            else:\n                msg = _(\"Items must be selected in order to perform \"\n                        \"actions on them. No items have been changed.\")\n                self.message_user(request, msg, messages.WARNING)\n                action_failed = True\n\n        # Actions with confirmation\n        if (actions and request.method == 'POST' and\n                helpers.ACTION_CHECKBOX_NAME in request.POST and\n                'index' not in request.POST and '_save' not in request.POST):\n            if selected:\n                response = self.response_action(request, queryset=cl.get_queryset(request))\n                if response:\n                    return response\n                else:\n                    action_failed = True\n\n        if action_failed:\n            # Redirect back to the changelist page to avoid resubmitting the\n            # form if the user refreshes the browser or uses the \"No, take\n            # me back\" button on the action confirmation page.\n            return HttpResponseRedirect(request.get_full_path())\n\n        # If we're allowing changelist editing, we need to construct a formset\n        # for the changelist given all the fields to be edited. Then we'll\n        # use the formset to validate/process POSTed data.\n        formset = cl.formset = None\n\n        # Handle POSTed bulk-edit data.\n        if request.method == 'POST' and cl.list_editable and '_save' in request.POST:\n            if not self.has_change_permission(request):\n                raise PermissionDenied\n            FormSet = self.get_changelist_formset(request)\n            modified_objects = self._get_list_editable_queryset(request, FormSet.get_default_prefix())\n            formset = cl.formset = FormSet(request.POST, request.FILES, queryset=modified_objects)\n            if formset.is_valid():\n                changecount = 0\n                for form in formset.forms:\n                    if form.has_changed():\n                        obj = self.save_form(request, form, change=True)\n                        self.save_model(request, obj, form, change=True)\n                        self.save_related(request, form, formsets=[], change=True)\n                        change_msg = self.construct_change_message(request, form, None)\n                        self.log_change(request, obj, change_msg)\n                        changecount += 1\n\n                if changecount:\n                    msg = ngettext(\n                        \"%(count)s %(name)s was changed successfully.\",\n                        \"%(count)s %(name)s were changed successfully.\",\n                        changecount\n                    ) % {\n                        'count': changecount,\n                        'name': model_ngettext(opts, changecount),\n                    }\n                    self.message_user(request, msg, messages.SUCCESS)\n\n                return HttpResponseRedirect(request.get_full_path())\n\n        # Handle GET -- construct a formset for display.\n        elif cl.list_editable and self.has_change_permission(request):\n            FormSet = self.get_changelist_formset(request)\n            formset = cl.formset = FormSet(queryset=cl.result_list)\n\n        # Build the list of media to be used by the formset.\n        if formset:\n            media = self.media + formset.media\n        else:\n            media = self.media\n\n        # Build the action form and populate it with available actions.\n        if actions:\n            action_form = self.action_form(auto_id=None)\n            action_form.fields['action'].choices = self.get_action_choices(request)\n            media += action_form.media\n        else:\n            action_form = None\n\n        selection_note_all = ngettext(\n            '%(total_count)s selected',\n            'All %(total_count)s selected',\n            cl.result_count\n        )\n\n        context = {\n            **self.admin_site.each_context(request),\n            'module_name': str(opts.verbose_name_plural),\n            'selection_note': _('0 of %(cnt)s selected') % {'cnt': len(cl.result_list)},\n            'selection_note_all': selection_note_all % {'total_count': cl.result_count},\n            'title': cl.title,\n            'is_popup': cl.is_popup,\n            'to_field': cl.to_field,\n            'cl': cl,\n            'media': media,\n            'has_add_permission': self.has_add_permission(request),\n            'opts': cl.opts,\n            'action_form': action_form,\n            'actions_on_top': self.actions_on_top,\n            'actions_on_bottom': self.actions_on_bottom,\n            'actions_selection_counter': self.actions_selection_counter,\n            'preserved_filters': self.get_preserved_filters(request),\n            **(extra_context or {}),\n        }\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, self.change_list_template or [\n            'admin/%s/%s/change_list.html' % (app_label, opts.model_name),\n            'admin/%s/change_list.html' % app_label,\n            'admin/change_list.html'\n        ], context)\n\n    def get_deleted_objects(self, objs, request):\n        \"\"\"\n        Hook for customizing the delete process for the delete view and the\n        \"delete selected\" action.\n        \"\"\"\n        return get_deleted_objects(objs, request, self.admin_site)\n\n    @csrf_protect_m\n    def delete_view(self, request, object_id, extra_context=None):\n        with transaction.atomic(using=router.db_for_write(self.model)):\n            return self._delete_view(request, object_id, extra_context)\n\n    def _delete_view(self, request, object_id, extra_context):\n        \"The 'delete' admin view for this model.\"\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        to_field = request.POST.get(TO_FIELD_VAR, request.GET.get(TO_FIELD_VAR))\n        if to_field and not self.to_field_allowed(request, to_field):\n            raise DisallowedModelAdminToField(\"The field %s cannot be referenced.\" % to_field)\n\n        obj = self.get_object(request, unquote(object_id), to_field)\n\n        if not self.has_delete_permission(request, obj):\n            raise PermissionDenied\n\n        if obj is None:\n            return self._get_obj_does_not_exist_redirect(request, opts, object_id)\n\n        # Populate deleted_objects, a data structure of all related objects that\n        # will also be deleted.\n        deleted_objects, model_count, perms_needed, protected = self.get_deleted_objects([obj], request)\n\n        if request.POST and not protected:  # The user has confirmed the deletion.\n            if perms_needed:\n                raise PermissionDenied\n            obj_display = str(obj)\n            attr = str(to_field) if to_field else opts.pk.attname\n            obj_id = obj.serializable_value(attr)\n            self.log_deletion(request, obj, obj_display)\n            self.delete_model(request, obj)\n\n            return self.response_delete(request, obj_display, obj_id)\n\n        object_name = str(opts.verbose_name)\n\n        if perms_needed or protected:\n            title = _(\"Cannot delete %(name)s\") % {\"name\": object_name}\n        else:\n            title = _(\"Are you sure?\")\n\n        context = {\n            **self.admin_site.each_context(request),\n            'title': title,\n            'object_name': object_name,\n            'object': obj,\n            'deleted_objects': deleted_objects,\n            'model_count': dict(model_count).items(),\n            'perms_lacking': perms_needed,\n            'protected': protected,\n            'opts': opts,\n            'app_label': app_label,\n            'preserved_filters': self.get_preserved_filters(request),\n            'is_popup': IS_POPUP_VAR in request.POST or IS_POPUP_VAR in request.GET,\n            'to_field': to_field,\n            **(extra_context or {}),\n        }\n\n        return self.render_delete_form(request, context)\n\n    def history_view(self, request, object_id, extra_context=None):\n        \"The 'history' admin view for this model.\"\n        from django.contrib.admin.models import LogEntry\n        # First check if the user can see this history.\n        model = self.model\n        obj = self.get_object(request, unquote(object_id))\n        if obj is None:\n            return self._get_obj_does_not_exist_redirect(request, model._meta, object_id)\n\n        if not self.has_view_or_change_permission(request, obj):\n            raise PermissionDenied\n\n        # Then get the history for this object.\n        opts = model._meta\n        app_label = opts.app_label\n        action_list = LogEntry.objects.filter(\n            object_id=unquote(object_id),\n            content_type=get_content_type_for_model(model)\n        ).select_related().order_by('action_time')\n\n        context = {\n            **self.admin_site.each_context(request),\n            'title': _('Change history: %s') % obj,\n            'action_list': action_list,\n            'module_name': str(capfirst(opts.verbose_name_plural)),\n            'object': obj,\n            'opts': opts,\n            'preserved_filters': self.get_preserved_filters(request),\n            **(extra_context or {}),\n        }\n\n        request.current_app = self.admin_site.name\n\n        return TemplateResponse(request, self.object_history_template or [\n            \"admin/%s/%s/object_history.html\" % (app_label, opts.model_name),\n            \"admin/%s/object_history.html\" % app_label,\n            \"admin/object_history.html\"\n        ], context)\n\n    def _create_formsets(self, request, obj, change):\n        \"Helper function to generate formsets for add/change_view.\"\n        formsets = []\n        inline_instances = []\n        prefixes = {}\n        get_formsets_args = [request]\n        if change:\n            get_formsets_args.append(obj)\n        for FormSet, inline in self.get_formsets_with_inlines(*get_formsets_args):\n            prefix = FormSet.get_default_prefix()\n            prefixes[prefix] = prefixes.get(prefix, 0) + 1\n            if prefixes[prefix] != 1 or not prefix:\n                prefix = \"%s-%s\" % (prefix, prefixes[prefix])\n            formset_params = {\n                'instance': obj,\n                'prefix': prefix,\n                'queryset': inline.get_queryset(request),\n            }\n            if request.method == 'POST':\n                formset_params.update({\n                    'data': request.POST.copy(),\n                    'files': request.FILES,\n                    'save_as_new': '_saveasnew' in request.POST\n                })\n            formset = FormSet(**formset_params)\n\n            def user_deleted_form(request, obj, formset, index):\n                \"\"\"Return whether or not the user deleted the form.\"\"\"\n                return (\n                    inline.has_delete_permission(request, obj) and\n                    '{}-{}-DELETE'.format(formset.prefix, index) in request.POST\n                )\n\n            # Bypass validation of each view-only inline form (since the form's\n            # data won't be in request.POST), unless the form was deleted.\n            if not inline.has_change_permission(request, obj if change else None):\n                for index, form in enumerate(formset.initial_forms):\n                    if user_deleted_form(request, obj, formset, index):\n                        continue\n                    form._errors = {}\n                    form.cleaned_data = form.initial\n            formsets.append(formset)\n            inline_instances.append(inline)\n        return formsets, inline_instances\n\n\nclass InlineModelAdmin(BaseModelAdmin):\n    \"\"\"\n    Options for inline editing of ``model`` instances.\n\n    Provide ``fk_name`` to specify the attribute name of the ``ForeignKey``\n    from ``model`` to its parent. This is required if ``model`` has more than\n    one ``ForeignKey`` to its parent.\n    \"\"\"\n    model = None\n    fk_name = None\n    formset = BaseInlineFormSet\n    extra = 3\n    min_num = None\n    max_num = None\n    template = None\n    verbose_name = None\n    verbose_name_plural = None\n    can_delete = True\n    show_change_link = False\n    checks_class = InlineModelAdminChecks\n    classes = None\n\n    def __init__(self, parent_model, admin_site):\n        self.admin_site = admin_site\n        self.parent_model = parent_model\n        self.opts = self.model._meta\n        self.has_registered_model = admin_site.is_registered(self.model)\n        super().__init__()\n        if self.verbose_name is None:\n            self.verbose_name = self.model._meta.verbose_name\n        if self.verbose_name_plural is None:\n            self.verbose_name_plural = self.model._meta.verbose_name_plural\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = ['vendor/jquery/jquery%s.js' % extra, 'jquery.init.js',\n              'inlines%s.js' % extra]\n        if self.filter_vertical or self.filter_horizontal:\n            js.extend(['SelectBox.js', 'SelectFilter2.js'])\n        if self.classes and 'collapse' in self.classes:\n            js.append('collapse%s.js' % extra)\n        return forms.Media(js=['admin/js/%s' % url for url in js])\n\n    def get_extra(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the number of extra inline forms.\"\"\"\n        return self.extra\n\n    def get_min_num(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the min number of inline forms.\"\"\"\n        return self.min_num\n\n    def get_max_num(self, request, obj=None, **kwargs):\n        \"\"\"Hook for customizing the max number of extra inline forms.\"\"\"\n        return self.max_num\n\n    def get_formset(self, request, obj=None, **kwargs):\n        \"\"\"Return a BaseInlineFormSet class for use in admin add/change views.\"\"\"\n        if 'fields' in kwargs:\n            fields = kwargs.pop('fields')\n        else:\n            fields = flatten_fieldsets(self.get_fieldsets(request, obj))\n        excluded = self.get_exclude(request, obj)\n        exclude = [] if excluded is None else list(excluded)\n        exclude.extend(self.get_readonly_fields(request, obj))\n        if excluded is None and hasattr(self.form, '_meta') and self.form._meta.exclude:\n            # Take the custom ModelForm's Meta.exclude into account only if the\n            # InlineModelAdmin doesn't define its own.\n            exclude.extend(self.form._meta.exclude)\n        # If exclude is an empty list we use None, since that's the actual\n        # default.\n        exclude = exclude or None\n        can_delete = self.can_delete and self.has_delete_permission(request, obj)\n        defaults = {\n            'form': self.form,\n            'formset': self.formset,\n            'fk_name': self.fk_name,\n            'fields': fields,\n            'exclude': exclude,\n            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n            'extra': self.get_extra(request, obj, **kwargs),\n            'min_num': self.get_min_num(request, obj, **kwargs),\n            'max_num': self.get_max_num(request, obj, **kwargs),\n            'can_delete': can_delete,\n            **kwargs,\n        }\n\n        base_model_form = defaults['form']\n        can_change = self.has_change_permission(request, obj) if request else True\n        can_add = self.has_add_permission(request, obj) if request else True\n\n        class DeleteProtectedModelForm(base_model_form):\n\n            def hand_clean_DELETE(self):\n                \"\"\"\n                We don't validate the 'DELETE' field itself because on\n                templates it's not rendered using the field information, but\n                just using a generic \"deletion_field\" of the InlineModelAdmin.\n                \"\"\"\n                if self.cleaned_data.get(DELETION_FIELD_NAME, False):\n                    using = router.db_for_write(self._meta.model)\n                    collector = NestedObjects(using=using)\n                    if self.instance._state.adding:\n                        return\n                    collector.collect([self.instance])\n                    if collector.protected:\n                        objs = []\n                        for p in collector.protected:\n                            objs.append(\n                                # Translators: Model verbose name and instance representation,\n                                # suitable to be an item in a list.\n                                _('%(class_name)s %(instance)s') % {\n                                    'class_name': p._meta.verbose_name,\n                                    'instance': p}\n                            )\n                        params = {\n                            'class_name': self._meta.model._meta.verbose_name,\n                            'instance': self.instance,\n                            'related_objects': get_text_list(objs, _('and')),\n                        }\n                        msg = _(\"Deleting %(class_name)s %(instance)s would require \"\n                                \"deleting the following protected related objects: \"\n                                \"%(related_objects)s\")\n                        raise ValidationError(msg, code='deleting_protected', params=params)\n\n            def is_valid(self):\n                result = super().is_valid()\n                self.hand_clean_DELETE()\n                return result\n\n            def has_changed(self):\n                # Protect against unauthorized edits.\n                if not can_change and not self.instance._state.adding:\n                    return False\n                if not can_add and self.instance._state.adding:\n                    return False\n                return super().has_changed()\n\n        defaults['form'] = DeleteProtectedModelForm\n\n        if defaults['fields'] is None and not modelform_defines_fields(defaults['form']):\n            defaults['fields'] = forms.ALL_FIELDS\n\n        return inlineformset_factory(self.parent_model, self.model, **defaults)\n\n    def _get_form_for_get_fields(self, request, obj=None):\n        return self.get_formset(request, obj, fields=None).form\n\n    def get_queryset(self, request):\n        queryset = super().get_queryset(request)\n        if not self.has_view_or_change_permission(request):\n            queryset = queryset.none()\n        return queryset\n\n    def _has_any_perms_for_target_model(self, request, perms):\n        \"\"\"\n        This method is called only when the ModelAdmin's model is for an\n        ManyToManyField's implicit through model (if self.opts.auto_created).\n        Return True if the user has any of the given permissions ('add',\n        'change', etc.) for the model that points to the through model.\n        \"\"\"\n        opts = self.opts\n        # Find the target model of an auto-created many-to-many relationship.\n        for field in opts.fields:\n            if field.remote_field and field.remote_field.model != self.parent_model:\n                opts = field.remote_field.model._meta\n                break\n        return any(\n            request.user.has_perm('%s.%s' % (opts.app_label, get_permission_codename(perm, opts)))\n            for perm in perms\n        )\n\n    def has_add_permission(self, request, obj):\n        if self.opts.auto_created:\n            # Auto-created intermediate models don't have their own\n            # permissions. The user needs to have the change permission for the\n            # related model in order to be able to do anything with the\n            # intermediate model.\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_add_permission(request)\n\n    def has_change_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission().\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_change_permission(request)\n\n    def has_delete_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission().\n            return self._has_any_perms_for_target_model(request, ['change'])\n        return super().has_delete_permission(request, obj)\n\n    def has_view_permission(self, request, obj=None):\n        if self.opts.auto_created:\n            # Same comment as has_add_permission(). The 'change' permission\n            # also implies the 'view' permission.\n            return self._has_any_perms_for_target_model(request, ['view', 'change'])\n        return super().has_view_permission(request)\n\n\nclass StackedInline(InlineModelAdmin):\n    template = 'admin/edit_inline/stacked.html'\n\n\nclass TabularInline(InlineModelAdmin):\n    template = 'admin/edit_inline/tabular.html'\n"
  },
  {
    "patch": "diff --git a/django/utils/encoding.py b/django/utils/encoding.py\nindex 2e2ad44e31..0721d516c4 100644\n--- a/django/utils/encoding.py\n+++ b/django/utils/encoding.py\n@@ -229,13 +229,16 @@ def repercent_broken_unicode(path):\n     repercent-encode any octet produced that is not part of a strictly legal\n     UTF-8 octet sequence.\n     \"\"\"\n-    try:\n-        path.decode()\n-    except UnicodeDecodeError as e:\n-        repercent = quote(path[e.start:e.end], safe=b\"/#%[]=:;$&()+,!?*@'~\")\n-        path = repercent_broken_unicode(\n-            path[:e.start] + force_bytes(repercent) + path[e.end:])\n-    return path\n+    while True:\n+        try:\n+            path.decode()\n+        except UnicodeDecodeError as e:\n+            # CVE-2019-14235: A recursion shouldn't be used since the exception\n+            # handling uses massive amounts of memory\n+            repercent = quote(path[e.start:e.end], safe=b\"/#%[]=:;$&()+,!?*@'~\")\n+            path = path[:e.start] + force_bytes(repercent) + path[e.end:]\n+        else:\n+            return path\n \n \n def filepath_to_uri(path):\n",
    "commit_message": "Fixed CVE-2019-14235 -- Fixed potential memory exhaustion in django.utils.encoding.uri_to_iri().\n\nThanks to Guido Vranken for initial report.\n\n",
    "code_before": "import codecs\nimport datetime\nimport locale\nimport warnings\nfrom decimal import Decimal\nfrom urllib.parse import quote\n\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.functional import Promise\n\n\nclass DjangoUnicodeDecodeError(UnicodeDecodeError):\n    def __init__(self, obj, *args):\n        self.obj = obj\n        super().__init__(*args)\n\n    def __str__(self):\n        return '%s. You passed in %r (%s)' % (super().__str__(), self.obj, type(self.obj))\n\n\ndef smart_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Return a string representing 's'. Treat bytestrings using the 'encoding'\n    codec.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if isinstance(s, Promise):\n        # The input is the result of a gettext_lazy() call.\n        return s\n    return force_str(s, encoding, strings_only, errors)\n\n\n_PROTECTED_TYPES = (\n    type(None), int, float, Decimal, datetime.datetime, datetime.date, datetime.time,\n)\n\n\ndef is_protected_type(obj):\n    \"\"\"Determine if the object instance is of a protected type.\n\n    Objects of protected types are preserved as-is when passed to\n    force_str(strings_only=True).\n    \"\"\"\n    return isinstance(obj, _PROTECTED_TYPES)\n\n\ndef force_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Similar to smart_str(), except that lazy instances are resolved to\n    strings, rather than kept as lazy objects.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    # Handle the common case first for performance reasons.\n    if issubclass(type(s), str):\n        return s\n    if strings_only and is_protected_type(s):\n        return s\n    try:\n        if isinstance(s, bytes):\n            s = str(s, encoding, errors)\n        else:\n            s = str(s)\n    except UnicodeDecodeError as e:\n        raise DjangoUnicodeDecodeError(s, *e.args)\n    return s\n\n\ndef smart_bytes(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Return a bytestring version of 's', encoded as specified in 'encoding'.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if isinstance(s, Promise):\n        # The input is the result of a gettext_lazy() call.\n        return s\n    return force_bytes(s, encoding, strings_only, errors)\n\n\ndef force_bytes(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Similar to smart_bytes, except that lazy instances are resolved to\n    strings, rather than kept as lazy objects.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    # Handle the common case first for performance reasons.\n    if isinstance(s, bytes):\n        if encoding == 'utf-8':\n            return s\n        else:\n            return s.decode('utf-8', errors).encode(encoding, errors)\n    if strings_only and is_protected_type(s):\n        return s\n    if isinstance(s, memoryview):\n        return bytes(s)\n    return str(s).encode(encoding, errors)\n\n\ndef smart_text(s, encoding='utf-8', strings_only=False, errors='strict'):\n    warnings.warn(\n        'smart_text() is deprecated in favor of smart_str().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return smart_str(s, encoding, strings_only, errors)\n\n\ndef force_text(s, encoding='utf-8', strings_only=False, errors='strict'):\n    warnings.warn(\n        'force_text() is deprecated in favor of force_str().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return force_str(s, encoding, strings_only, errors)\n\n\ndef iri_to_uri(iri):\n    \"\"\"\n    Convert an Internationalized Resource Identifier (IRI) portion to a URI\n    portion that is suitable for inclusion in a URL.\n\n    This is the algorithm from section 3.1 of RFC 3987, slightly simplified\n    since the input is assumed to be a string rather than an arbitrary byte\n    stream.\n\n    Take an IRI (string or UTF-8 bytes, e.g. '/I \u2665 Django/' or\n    b'/I \\xe2\\x99\\xa5 Django/') and return a string containing the encoded\n    result with ASCII chars only (e.g. '/I%20%E2%99%A5%20Django/').\n    \"\"\"\n    # The list of safe characters here is constructed from the \"reserved\" and\n    # \"unreserved\" characters specified in sections 2.2 and 2.3 of RFC 3986:\n    #     reserved    = gen-delims / sub-delims\n    #     gen-delims  = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    #     sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n    #                   / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n    #     unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    # Of the unreserved characters, urllib.parse.quote() already considers all\n    # but the ~ safe.\n    # The % character is also added to the list of safe characters here, as the\n    # end of section 3.1 of RFC 3987 specifically mentions that % must not be\n    # converted.\n    if iri is None:\n        return iri\n    elif isinstance(iri, Promise):\n        iri = str(iri)\n    return quote(iri, safe=\"/#%[]=:;$&()+,!?*@'~\")\n\n\n# List of byte values that uri_to_iri() decodes from percent encoding.\n# First, the unreserved characters from RFC 3986:\n_ascii_ranges = [[45, 46, 95, 126], range(65, 91), range(97, 123)]\n_hextobyte = {\n    (fmt % char).encode(): bytes((char,))\n    for ascii_range in _ascii_ranges\n    for char in ascii_range\n    for fmt in ['%02x', '%02X']\n}\n# And then everything above 128, because bytes \u2265 128 are part of multibyte\n# unicode characters.\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte.update({\n    (a + b).encode(): bytes.fromhex(a + b)\n    for a in _hexdig[8:] for b in _hexdig\n})\n\n\ndef uri_to_iri(uri):\n    \"\"\"\n    Convert a Uniform Resource Identifier(URI) into an Internationalized\n    Resource Identifier(IRI).\n\n    This is the algorithm from section 3.2 of RFC 3987, excluding step 4.\n\n    Take an URI in ASCII bytes (e.g. '/I%20%E2%99%A5%20Django/') and return\n    a string containing the encoded result (e.g. '/I%20\u2665%20Django/').\n    \"\"\"\n    if uri is None:\n        return uri\n    uri = force_bytes(uri)\n    # Fast selective unqote: First, split on '%' and then starting with the\n    # second block, decode the first 2 bytes if they represent a hex code to\n    # decode. The rest of the block is the part after '%AB', not containing\n    # any '%'. Add that to the output without further processing.\n    bits = uri.split(b'%')\n    if len(bits) == 1:\n        iri = uri\n    else:\n        parts = [bits[0]]\n        append = parts.append\n        hextobyte = _hextobyte\n        for item in bits[1:]:\n            hex = item[:2]\n            if hex in hextobyte:\n                append(hextobyte[item[:2]])\n                append(item[2:])\n            else:\n                append(b'%')\n                append(item)\n        iri = b''.join(parts)\n    return repercent_broken_unicode(iri).decode()\n\n\ndef escape_uri_path(path):\n    \"\"\"\n    Escape the unsafe characters from the path portion of a Uniform Resource\n    Identifier (URI).\n    \"\"\"\n    # These are the \"reserved\" and \"unreserved\" characters specified in\n    # sections 2.2 and 2.3 of RFC 2396:\n    #   reserved    = \";\" | \"/\" | \"?\" | \":\" | \"@\" | \"&\" | \"=\" | \"+\" | \"$\" | \",\"\n    #   unreserved  = alphanum | mark\n    #   mark        = \"-\" | \"_\" | \".\" | \"!\" | \"~\" | \"*\" | \"'\" | \"(\" | \")\"\n    # The list of safe characters here is constructed subtracting \";\", \"=\",\n    # and \"?\" according to section 3.3 of RFC 2396.\n    # The reason for not subtracting and escaping \"/\" is that we are escaping\n    # the entire path, not a path segment.\n    return quote(path, safe=\"/:@&+$,-_.!~*'()\")\n\n\ndef punycode(domain):\n    \"\"\"Return the Punycode of the given domain if it's non-ASCII.\"\"\"\n    return domain.encode('idna').decode('ascii')\n\n\ndef repercent_broken_unicode(path):\n    \"\"\"\n    As per section 3.2 of RFC 3987, step three of converting a URI into an IRI,\n    repercent-encode any octet produced that is not part of a strictly legal\n    UTF-8 octet sequence.\n    \"\"\"\n    try:\n        path.decode()\n    except UnicodeDecodeError as e:\n        repercent = quote(path[e.start:e.end], safe=b\"/#%[]=:;$&()+,!?*@'~\")\n        path = repercent_broken_unicode(\n            path[:e.start] + force_bytes(repercent) + path[e.end:])\n    return path\n\n\ndef filepath_to_uri(path):\n    \"\"\"Convert a file system path to a URI portion that is suitable for\n    inclusion in a URL.\n\n    Encode certain chars that would normally be recognized as special chars\n    for URIs. Do not encode the ' character, as it is a valid character\n    within URIs. See the encodeURIComponent() JavaScript function for details.\n    \"\"\"\n    if path is None:\n        return path\n    # I know about `os.sep` and `os.altsep` but I want to leave\n    # some flexibility for hardcoding separators.\n    return quote(path.replace(\"\\\\\", \"/\"), safe=\"/~!*()'\")\n\n\ndef get_system_encoding():\n    \"\"\"\n    The encoding of the default system locale. Fallback to 'ascii' if the\n    #encoding is unsupported by Python or could not be determined. See tickets\n    #10335 and #5846.\n    \"\"\"\n    try:\n        encoding = locale.getdefaultlocale()[1] or 'ascii'\n        codecs.lookup(encoding)\n    except Exception:\n        encoding = 'ascii'\n    return encoding\n\n\nDEFAULT_LOCALE_ENCODING = get_system_encoding()\n",
    "code_after": "import codecs\nimport datetime\nimport locale\nimport warnings\nfrom decimal import Decimal\nfrom urllib.parse import quote\n\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.functional import Promise\n\n\nclass DjangoUnicodeDecodeError(UnicodeDecodeError):\n    def __init__(self, obj, *args):\n        self.obj = obj\n        super().__init__(*args)\n\n    def __str__(self):\n        return '%s. You passed in %r (%s)' % (super().__str__(), self.obj, type(self.obj))\n\n\ndef smart_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Return a string representing 's'. Treat bytestrings using the 'encoding'\n    codec.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if isinstance(s, Promise):\n        # The input is the result of a gettext_lazy() call.\n        return s\n    return force_str(s, encoding, strings_only, errors)\n\n\n_PROTECTED_TYPES = (\n    type(None), int, float, Decimal, datetime.datetime, datetime.date, datetime.time,\n)\n\n\ndef is_protected_type(obj):\n    \"\"\"Determine if the object instance is of a protected type.\n\n    Objects of protected types are preserved as-is when passed to\n    force_str(strings_only=True).\n    \"\"\"\n    return isinstance(obj, _PROTECTED_TYPES)\n\n\ndef force_str(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Similar to smart_str(), except that lazy instances are resolved to\n    strings, rather than kept as lazy objects.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    # Handle the common case first for performance reasons.\n    if issubclass(type(s), str):\n        return s\n    if strings_only and is_protected_type(s):\n        return s\n    try:\n        if isinstance(s, bytes):\n            s = str(s, encoding, errors)\n        else:\n            s = str(s)\n    except UnicodeDecodeError as e:\n        raise DjangoUnicodeDecodeError(s, *e.args)\n    return s\n\n\ndef smart_bytes(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Return a bytestring version of 's', encoded as specified in 'encoding'.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    if isinstance(s, Promise):\n        # The input is the result of a gettext_lazy() call.\n        return s\n    return force_bytes(s, encoding, strings_only, errors)\n\n\ndef force_bytes(s, encoding='utf-8', strings_only=False, errors='strict'):\n    \"\"\"\n    Similar to smart_bytes, except that lazy instances are resolved to\n    strings, rather than kept as lazy objects.\n\n    If strings_only is True, don't convert (some) non-string-like objects.\n    \"\"\"\n    # Handle the common case first for performance reasons.\n    if isinstance(s, bytes):\n        if encoding == 'utf-8':\n            return s\n        else:\n            return s.decode('utf-8', errors).encode(encoding, errors)\n    if strings_only and is_protected_type(s):\n        return s\n    if isinstance(s, memoryview):\n        return bytes(s)\n    return str(s).encode(encoding, errors)\n\n\ndef smart_text(s, encoding='utf-8', strings_only=False, errors='strict'):\n    warnings.warn(\n        'smart_text() is deprecated in favor of smart_str().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return smart_str(s, encoding, strings_only, errors)\n\n\ndef force_text(s, encoding='utf-8', strings_only=False, errors='strict'):\n    warnings.warn(\n        'force_text() is deprecated in favor of force_str().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return force_str(s, encoding, strings_only, errors)\n\n\ndef iri_to_uri(iri):\n    \"\"\"\n    Convert an Internationalized Resource Identifier (IRI) portion to a URI\n    portion that is suitable for inclusion in a URL.\n\n    This is the algorithm from section 3.1 of RFC 3987, slightly simplified\n    since the input is assumed to be a string rather than an arbitrary byte\n    stream.\n\n    Take an IRI (string or UTF-8 bytes, e.g. '/I \u2665 Django/' or\n    b'/I \\xe2\\x99\\xa5 Django/') and return a string containing the encoded\n    result with ASCII chars only (e.g. '/I%20%E2%99%A5%20Django/').\n    \"\"\"\n    # The list of safe characters here is constructed from the \"reserved\" and\n    # \"unreserved\" characters specified in sections 2.2 and 2.3 of RFC 3986:\n    #     reserved    = gen-delims / sub-delims\n    #     gen-delims  = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    #     sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n    #                   / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n    #     unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    # Of the unreserved characters, urllib.parse.quote() already considers all\n    # but the ~ safe.\n    # The % character is also added to the list of safe characters here, as the\n    # end of section 3.1 of RFC 3987 specifically mentions that % must not be\n    # converted.\n    if iri is None:\n        return iri\n    elif isinstance(iri, Promise):\n        iri = str(iri)\n    return quote(iri, safe=\"/#%[]=:;$&()+,!?*@'~\")\n\n\n# List of byte values that uri_to_iri() decodes from percent encoding.\n# First, the unreserved characters from RFC 3986:\n_ascii_ranges = [[45, 46, 95, 126], range(65, 91), range(97, 123)]\n_hextobyte = {\n    (fmt % char).encode(): bytes((char,))\n    for ascii_range in _ascii_ranges\n    for char in ascii_range\n    for fmt in ['%02x', '%02X']\n}\n# And then everything above 128, because bytes \u2265 128 are part of multibyte\n# unicode characters.\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte.update({\n    (a + b).encode(): bytes.fromhex(a + b)\n    for a in _hexdig[8:] for b in _hexdig\n})\n\n\ndef uri_to_iri(uri):\n    \"\"\"\n    Convert a Uniform Resource Identifier(URI) into an Internationalized\n    Resource Identifier(IRI).\n\n    This is the algorithm from section 3.2 of RFC 3987, excluding step 4.\n\n    Take an URI in ASCII bytes (e.g. '/I%20%E2%99%A5%20Django/') and return\n    a string containing the encoded result (e.g. '/I%20\u2665%20Django/').\n    \"\"\"\n    if uri is None:\n        return uri\n    uri = force_bytes(uri)\n    # Fast selective unqote: First, split on '%' and then starting with the\n    # second block, decode the first 2 bytes if they represent a hex code to\n    # decode. The rest of the block is the part after '%AB', not containing\n    # any '%'. Add that to the output without further processing.\n    bits = uri.split(b'%')\n    if len(bits) == 1:\n        iri = uri\n    else:\n        parts = [bits[0]]\n        append = parts.append\n        hextobyte = _hextobyte\n        for item in bits[1:]:\n            hex = item[:2]\n            if hex in hextobyte:\n                append(hextobyte[item[:2]])\n                append(item[2:])\n            else:\n                append(b'%')\n                append(item)\n        iri = b''.join(parts)\n    return repercent_broken_unicode(iri).decode()\n\n\ndef escape_uri_path(path):\n    \"\"\"\n    Escape the unsafe characters from the path portion of a Uniform Resource\n    Identifier (URI).\n    \"\"\"\n    # These are the \"reserved\" and \"unreserved\" characters specified in\n    # sections 2.2 and 2.3 of RFC 2396:\n    #   reserved    = \";\" | \"/\" | \"?\" | \":\" | \"@\" | \"&\" | \"=\" | \"+\" | \"$\" | \",\"\n    #   unreserved  = alphanum | mark\n    #   mark        = \"-\" | \"_\" | \".\" | \"!\" | \"~\" | \"*\" | \"'\" | \"(\" | \")\"\n    # The list of safe characters here is constructed subtracting \";\", \"=\",\n    # and \"?\" according to section 3.3 of RFC 2396.\n    # The reason for not subtracting and escaping \"/\" is that we are escaping\n    # the entire path, not a path segment.\n    return quote(path, safe=\"/:@&+$,-_.!~*'()\")\n\n\ndef punycode(domain):\n    \"\"\"Return the Punycode of the given domain if it's non-ASCII.\"\"\"\n    return domain.encode('idna').decode('ascii')\n\n\ndef repercent_broken_unicode(path):\n    \"\"\"\n    As per section 3.2 of RFC 3987, step three of converting a URI into an IRI,\n    repercent-encode any octet produced that is not part of a strictly legal\n    UTF-8 octet sequence.\n    \"\"\"\n    while True:\n        try:\n            path.decode()\n        except UnicodeDecodeError as e:\n            # CVE-2019-14235: A recursion shouldn't be used since the exception\n            # handling uses massive amounts of memory\n            repercent = quote(path[e.start:e.end], safe=b\"/#%[]=:;$&()+,!?*@'~\")\n            path = path[:e.start] + force_bytes(repercent) + path[e.end:]\n        else:\n            return path\n\n\ndef filepath_to_uri(path):\n    \"\"\"Convert a file system path to a URI portion that is suitable for\n    inclusion in a URL.\n\n    Encode certain chars that would normally be recognized as special chars\n    for URIs. Do not encode the ' character, as it is a valid character\n    within URIs. See the encodeURIComponent() JavaScript function for details.\n    \"\"\"\n    if path is None:\n        return path\n    # I know about `os.sep` and `os.altsep` but I want to leave\n    # some flexibility for hardcoding separators.\n    return quote(path.replace(\"\\\\\", \"/\"), safe=\"/~!*()'\")\n\n\ndef get_system_encoding():\n    \"\"\"\n    The encoding of the default system locale. Fallback to 'ascii' if the\n    #encoding is unsupported by Python or could not be determined. See tickets\n    #10335 and #5846.\n    \"\"\"\n    try:\n        encoding = locale.getdefaultlocale()[1] or 'ascii'\n        codecs.lookup(encoding)\n    except Exception:\n        encoding = 'ascii'\n    return encoding\n\n\nDEFAULT_LOCALE_ENCODING = get_system_encoding()\n"
  },
  {
    "patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d8fa00dab8..94aa0ff35e 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -181,8 +181,8 @@ def strip_tags(value):\n     value = str(value)\n     while '<' in value and '>' in value:\n         new_value = _strip_once(value)\n-        if len(new_value) >= len(value):\n-            # _strip_once was not able to detect more tags\n+        if value.count('<') == new_value.count('<'):\n+            # _strip_once wasn't able to detect more tags.\n             break\n         value = new_value\n     return value\n",
    "commit_message": "Fixed CVE-2019-14233 -- Prevented excessive HTMLParser recursion in strip_tags() when handling incomplete HTML entities.\n\nThanks to Guido Vranken for initial report.\n\n",
    "code_before": "\"\"\"HTML utilities suitable for global use.\"\"\"\n\nimport html\nimport json\nimport re\nfrom html.parser import HTMLParser\nfrom urllib.parse import (\n    parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n)\n\nfrom django.utils.encoding import punycode\nfrom django.utils.functional import Promise, keep_lazy, keep_lazy_text\nfrom django.utils.http import RFC3986_GENDELIMS, RFC3986_SUBDELIMS\nfrom django.utils.safestring import SafeData, SafeString, mark_safe\nfrom django.utils.text import normalize_newlines\n\n# Configuration for urlize() function.\nTRAILING_PUNCTUATION_CHARS = '.,:;!'\nWRAPPING_PUNCTUATION = [('(', ')'), ('[', ']')]\n\n# List of possible strings used for bullets in bulleted lists.\nDOTS = ['&middot;', '*', '\\u2022', '&#149;', '&bull;', '&#8226;']\n\nunencoded_ampersands_re = re.compile(r'&(?!(\\w+|#\\d+);)')\nword_split_re = re.compile(r'''([\\s<>\"']+)''')\nsimple_url_re = re.compile(r'^https?://\\[?\\w', re.IGNORECASE)\nsimple_url_2_re = re.compile(r'^www\\.|^(?!http)\\w[^@]+\\.(com|edu|gov|int|mil|net|org)($|/.*)$', re.IGNORECASE)\n\n\n@keep_lazy(str, SafeString)\ndef escape(text):\n    \"\"\"\n    Return the given text with ampersands, quotes and angle brackets encoded\n    for use in HTML.\n\n    Always escape input, even if it's already escaped and marked as such.\n    This may result in double-escaping. If this is a concern, use\n    conditional_escape() instead.\n    \"\"\"\n    return mark_safe(html.escape(str(text)))\n\n\n_js_escapes = {\n    ord('\\\\'): '\\\\u005C',\n    ord('\\''): '\\\\u0027',\n    ord('\"'): '\\\\u0022',\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n    ord('='): '\\\\u003D',\n    ord('-'): '\\\\u002D',\n    ord(';'): '\\\\u003B',\n    ord('`'): '\\\\u0060',\n    ord('\\u2028'): '\\\\u2028',\n    ord('\\u2029'): '\\\\u2029'\n}\n\n# Escape every ASCII character with a value less than 32.\n_js_escapes.update((ord('%c' % z), '\\\\u%04X' % z) for z in range(32))\n\n\n@keep_lazy(str, SafeString)\ndef escapejs(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return mark_safe(str(value).translate(_js_escapes))\n\n\n_json_script_escapes = {\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n}\n\n\ndef json_script(value, element_id):\n    \"\"\"\n    Escape all the HTML/XML special characters with their unicode escapes, so\n    value is safe to be output anywhere except for inside a tag attribute. Wrap\n    the escaped JSON in a script tag.\n    \"\"\"\n    from django.core.serializers.json import DjangoJSONEncoder\n    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    return format_html(\n        '<script id=\"{}\" type=\"application/json\">{}</script>',\n        element_id, mark_safe(json_str)\n    )\n\n\ndef conditional_escape(text):\n    \"\"\"\n    Similar to escape(), except that it doesn't operate on pre-escaped strings.\n\n    This function relies on the __html__ convention used both by Django's\n    SafeData class and by third-party libraries like markupsafe.\n    \"\"\"\n    if isinstance(text, Promise):\n        text = str(text)\n    if hasattr(text, '__html__'):\n        return text.__html__()\n    else:\n        return escape(text)\n\n\ndef format_html(format_string, *args, **kwargs):\n    \"\"\"\n    Similar to str.format, but pass all arguments through conditional_escape(),\n    and call mark_safe() on the result. This function should be used instead\n    of str.format or % interpolation to build up small HTML fragments.\n    \"\"\"\n    args_safe = map(conditional_escape, args)\n    kwargs_safe = {k: conditional_escape(v) for (k, v) in kwargs.items()}\n    return mark_safe(format_string.format(*args_safe, **kwargs_safe))\n\n\ndef format_html_join(sep, format_string, args_generator):\n    \"\"\"\n    A wrapper of format_html, for the common case of a group of arguments that\n    need to be formatted using the same format string, and then joined using\n    'sep'. 'sep' is also passed through conditional_escape.\n\n    'args_generator' should be an iterator that returns the sequence of 'args'\n    that will be passed to format_html.\n\n    Example:\n\n      format_html_join('\\n', \"<li>{} {}</li>\", ((u.first_name, u.last_name)\n                                                  for u in users))\n    \"\"\"\n    return mark_safe(conditional_escape(sep).join(\n        format_html(format_string, *args)\n        for args in args_generator\n    ))\n\n\n@keep_lazy_text\ndef linebreaks(value, autoescape=False):\n    \"\"\"Convert newlines into <p> and <br>s.\"\"\"\n    value = normalize_newlines(value)\n    paras = re.split('\\n{2,}', str(value))\n    if autoescape:\n        paras = ['<p>%s</p>' % escape(p).replace('\\n', '<br>') for p in paras]\n    else:\n        paras = ['<p>%s</p>' % p.replace('\\n', '<br>') for p in paras]\n    return '\\n\\n'.join(paras)\n\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        super().__init__(convert_charrefs=False)\n        self.reset()\n        self.fed = []\n\n    def handle_data(self, d):\n        self.fed.append(d)\n\n    def handle_entityref(self, name):\n        self.fed.append('&%s;' % name)\n\n    def handle_charref(self, name):\n        self.fed.append('&#%s;' % name)\n\n    def get_data(self):\n        return ''.join(self.fed)\n\n\ndef _strip_once(value):\n    \"\"\"\n    Internal tag stripping utility used by strip_tags.\n    \"\"\"\n    s = MLStripper()\n    s.feed(value)\n    s.close()\n    return s.get_data()\n\n\n@keep_lazy_text\ndef strip_tags(value):\n    \"\"\"Return the given HTML with all tags stripped.\"\"\"\n    # Note: in typical case this loop executes _strip_once once. Loop condition\n    # is redundant, but helps to reduce number of executions of _strip_once.\n    value = str(value)\n    while '<' in value and '>' in value:\n        new_value = _strip_once(value)\n        if len(new_value) >= len(value):\n            # _strip_once was not able to detect more tags\n            break\n        value = new_value\n    return value\n\n\n@keep_lazy_text\ndef strip_spaces_between_tags(value):\n    \"\"\"Return the given HTML with spaces between tags removed.\"\"\"\n    return re.sub(r'>\\s+<', '><', str(value))\n\n\ndef smart_urlquote(url):\n    \"\"\"Quote a URL if it isn't already quoted.\"\"\"\n    def unquote_quote(segment):\n        segment = unquote(segment)\n        # Tilde is part of RFC3986 Unreserved Characters\n        # https://tools.ietf.org/html/rfc3986#section-2.3\n        # See also https://bugs.python.org/issue16285\n        return quote(segment, safe=RFC3986_SUBDELIMS + RFC3986_GENDELIMS + '~')\n\n    # Handle IDN before quoting.\n    try:\n        scheme, netloc, path, query, fragment = urlsplit(url)\n    except ValueError:\n        # invalid IPv6 URL (normally square brackets in hostname part).\n        return unquote_quote(url)\n\n    try:\n        netloc = punycode(netloc)  # IDN -> ACE\n    except UnicodeError:  # invalid domain part\n        return unquote_quote(url)\n\n    if query:\n        # Separately unquoting key/value, so as to not mix querystring separators\n        # included in query values. See #22267.\n        query_parts = [(unquote(q[0]), unquote(q[1]))\n                       for q in parse_qsl(query, keep_blank_values=True)]\n        # urlencode will take care of quoting\n        query = urlencode(query_parts)\n\n    path = unquote_quote(path)\n    fragment = unquote_quote(fragment)\n\n    return urlunsplit((scheme, netloc, path, query, fragment))\n\n\n@keep_lazy_text\ndef urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n    \"\"\"\n    Convert any URLs in text into clickable links.\n\n    Works on http://, https://, www. links, and also on links ending in one of\n    the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).\n    Links can have trailing punctuation (periods, commas, close-parens) and\n    leading punctuation (opening parens) and it'll still do the right thing.\n\n    If trim_url_limit is not None, truncate the URLs in the link text longer\n    than this limit to trim_url_limit - 1 characters and append an ellipsis.\n\n    If nofollow is True, give the links a rel=\"nofollow\" attribute.\n\n    If autoescape is True, autoescape the link text and URLs.\n    \"\"\"\n    safe_input = isinstance(text, SafeData)\n\n    def trim_url(x, limit=trim_url_limit):\n        if limit is None or len(x) <= limit:\n            return x\n        return '%s\u2026' % x[:max(0, limit - 1)]\n\n    def trim_punctuation(lead, middle, trail):\n        \"\"\"\n        Trim trailing and wrapping punctuation from `middle`. Return the items\n        of the new state.\n        \"\"\"\n        # Continue trimming until middle remains unchanged.\n        trimmed_something = True\n        while trimmed_something:\n            trimmed_something = False\n            # Trim wrapping punctuation.\n            for opening, closing in WRAPPING_PUNCTUATION:\n                if middle.startswith(opening):\n                    middle = middle[len(opening):]\n                    lead += opening\n                    trimmed_something = True\n                # Keep parentheses at the end only if they're balanced.\n                if (middle.endswith(closing) and\n                        middle.count(closing) == middle.count(opening) + 1):\n                    middle = middle[:-len(closing)]\n                    trail = closing + trail\n                    trimmed_something = True\n            # Trim trailing punctuation (after trimming wrapping punctuation,\n            # as encoded entities contain ';'). Unescape entities to avoid\n            # breaking them by removing ';'.\n            middle_unescaped = html.unescape(middle)\n            stripped = middle_unescaped.rstrip(TRAILING_PUNCTUATION_CHARS)\n            if middle_unescaped != stripped:\n                trail = middle[len(stripped):] + trail\n                middle = middle[:len(stripped) - len(middle_unescaped)]\n                trimmed_something = True\n        return lead, middle, trail\n\n    def is_email_simple(value):\n        \"\"\"Return True if value looks like an email address.\"\"\"\n        # An @ must be in the middle of the value.\n        if '@' not in value or value.startswith('@') or value.endswith('@'):\n            return False\n        try:\n            p1, p2 = value.split('@')\n        except ValueError:\n            # value contains more than one @.\n            return False\n        # Dot must be in p2 (e.g. example.com)\n        if '.' not in p2 or p2.startswith('.'):\n            return False\n        return True\n\n    words = word_split_re.split(str(text))\n    for i, word in enumerate(words):\n        if '.' in word or '@' in word or ':' in word:\n            # lead: Current punctuation trimmed from the beginning of the word.\n            # middle: Current state of the word.\n            # trail: Current punctuation trimmed from the end of the word.\n            lead, middle, trail = '', word, ''\n            # Deal with punctuation.\n            lead, middle, trail = trim_punctuation(lead, middle, trail)\n\n            # Make URL we want to point to.\n            url = None\n            nofollow_attr = ' rel=\"nofollow\"' if nofollow else ''\n            if simple_url_re.match(middle):\n                url = smart_urlquote(html.unescape(middle))\n            elif simple_url_2_re.match(middle):\n                url = smart_urlquote('http://%s' % html.unescape(middle))\n            elif ':' not in middle and is_email_simple(middle):\n                local, domain = middle.rsplit('@', 1)\n                try:\n                    domain = punycode(domain)\n                except UnicodeError:\n                    continue\n                url = 'mailto:%s@%s' % (local, domain)\n                nofollow_attr = ''\n\n            # Make link.\n            if url:\n                trimmed = trim_url(middle)\n                if autoescape and not safe_input:\n                    lead, trail = escape(lead), escape(trail)\n                    trimmed = escape(trimmed)\n                middle = '<a href=\"%s\"%s>%s</a>' % (escape(url), nofollow_attr, trimmed)\n                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))\n            else:\n                if safe_input:\n                    words[i] = mark_safe(word)\n                elif autoescape:\n                    words[i] = escape(word)\n        elif safe_input:\n            words[i] = mark_safe(word)\n        elif autoescape:\n            words[i] = escape(word)\n    return ''.join(words)\n\n\ndef avoid_wrapping(value):\n    \"\"\"\n    Avoid text wrapping in the middle of a phrase by adding non-breaking\n    spaces where there previously were normal spaces.\n    \"\"\"\n    return value.replace(\" \", \"\\xa0\")\n\n\ndef html_safe(klass):\n    \"\"\"\n    A decorator that defines the __html__ method. This helps non-Django\n    templates to detect classes whose __str__ methods return SafeString.\n    \"\"\"\n    if '__html__' in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it defines \"\n            \"__html__().\" % klass.__name__\n        )\n    if '__str__' not in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it doesn't \"\n            \"define __str__().\" % klass.__name__\n        )\n    klass_str = klass.__str__\n    klass.__str__ = lambda self: mark_safe(klass_str(self))\n    klass.__html__ = lambda self: str(self)\n    return klass\n",
    "code_after": "\"\"\"HTML utilities suitable for global use.\"\"\"\n\nimport html\nimport json\nimport re\nfrom html.parser import HTMLParser\nfrom urllib.parse import (\n    parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n)\n\nfrom django.utils.encoding import punycode\nfrom django.utils.functional import Promise, keep_lazy, keep_lazy_text\nfrom django.utils.http import RFC3986_GENDELIMS, RFC3986_SUBDELIMS\nfrom django.utils.safestring import SafeData, SafeString, mark_safe\nfrom django.utils.text import normalize_newlines\n\n# Configuration for urlize() function.\nTRAILING_PUNCTUATION_CHARS = '.,:;!'\nWRAPPING_PUNCTUATION = [('(', ')'), ('[', ']')]\n\n# List of possible strings used for bullets in bulleted lists.\nDOTS = ['&middot;', '*', '\\u2022', '&#149;', '&bull;', '&#8226;']\n\nunencoded_ampersands_re = re.compile(r'&(?!(\\w+|#\\d+);)')\nword_split_re = re.compile(r'''([\\s<>\"']+)''')\nsimple_url_re = re.compile(r'^https?://\\[?\\w', re.IGNORECASE)\nsimple_url_2_re = re.compile(r'^www\\.|^(?!http)\\w[^@]+\\.(com|edu|gov|int|mil|net|org)($|/.*)$', re.IGNORECASE)\n\n\n@keep_lazy(str, SafeString)\ndef escape(text):\n    \"\"\"\n    Return the given text with ampersands, quotes and angle brackets encoded\n    for use in HTML.\n\n    Always escape input, even if it's already escaped and marked as such.\n    This may result in double-escaping. If this is a concern, use\n    conditional_escape() instead.\n    \"\"\"\n    return mark_safe(html.escape(str(text)))\n\n\n_js_escapes = {\n    ord('\\\\'): '\\\\u005C',\n    ord('\\''): '\\\\u0027',\n    ord('\"'): '\\\\u0022',\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n    ord('='): '\\\\u003D',\n    ord('-'): '\\\\u002D',\n    ord(';'): '\\\\u003B',\n    ord('`'): '\\\\u0060',\n    ord('\\u2028'): '\\\\u2028',\n    ord('\\u2029'): '\\\\u2029'\n}\n\n# Escape every ASCII character with a value less than 32.\n_js_escapes.update((ord('%c' % z), '\\\\u%04X' % z) for z in range(32))\n\n\n@keep_lazy(str, SafeString)\ndef escapejs(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return mark_safe(str(value).translate(_js_escapes))\n\n\n_json_script_escapes = {\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n}\n\n\ndef json_script(value, element_id):\n    \"\"\"\n    Escape all the HTML/XML special characters with their unicode escapes, so\n    value is safe to be output anywhere except for inside a tag attribute. Wrap\n    the escaped JSON in a script tag.\n    \"\"\"\n    from django.core.serializers.json import DjangoJSONEncoder\n    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    return format_html(\n        '<script id=\"{}\" type=\"application/json\">{}</script>',\n        element_id, mark_safe(json_str)\n    )\n\n\ndef conditional_escape(text):\n    \"\"\"\n    Similar to escape(), except that it doesn't operate on pre-escaped strings.\n\n    This function relies on the __html__ convention used both by Django's\n    SafeData class and by third-party libraries like markupsafe.\n    \"\"\"\n    if isinstance(text, Promise):\n        text = str(text)\n    if hasattr(text, '__html__'):\n        return text.__html__()\n    else:\n        return escape(text)\n\n\ndef format_html(format_string, *args, **kwargs):\n    \"\"\"\n    Similar to str.format, but pass all arguments through conditional_escape(),\n    and call mark_safe() on the result. This function should be used instead\n    of str.format or % interpolation to build up small HTML fragments.\n    \"\"\"\n    args_safe = map(conditional_escape, args)\n    kwargs_safe = {k: conditional_escape(v) for (k, v) in kwargs.items()}\n    return mark_safe(format_string.format(*args_safe, **kwargs_safe))\n\n\ndef format_html_join(sep, format_string, args_generator):\n    \"\"\"\n    A wrapper of format_html, for the common case of a group of arguments that\n    need to be formatted using the same format string, and then joined using\n    'sep'. 'sep' is also passed through conditional_escape.\n\n    'args_generator' should be an iterator that returns the sequence of 'args'\n    that will be passed to format_html.\n\n    Example:\n\n      format_html_join('\\n', \"<li>{} {}</li>\", ((u.first_name, u.last_name)\n                                                  for u in users))\n    \"\"\"\n    return mark_safe(conditional_escape(sep).join(\n        format_html(format_string, *args)\n        for args in args_generator\n    ))\n\n\n@keep_lazy_text\ndef linebreaks(value, autoescape=False):\n    \"\"\"Convert newlines into <p> and <br>s.\"\"\"\n    value = normalize_newlines(value)\n    paras = re.split('\\n{2,}', str(value))\n    if autoescape:\n        paras = ['<p>%s</p>' % escape(p).replace('\\n', '<br>') for p in paras]\n    else:\n        paras = ['<p>%s</p>' % p.replace('\\n', '<br>') for p in paras]\n    return '\\n\\n'.join(paras)\n\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        super().__init__(convert_charrefs=False)\n        self.reset()\n        self.fed = []\n\n    def handle_data(self, d):\n        self.fed.append(d)\n\n    def handle_entityref(self, name):\n        self.fed.append('&%s;' % name)\n\n    def handle_charref(self, name):\n        self.fed.append('&#%s;' % name)\n\n    def get_data(self):\n        return ''.join(self.fed)\n\n\ndef _strip_once(value):\n    \"\"\"\n    Internal tag stripping utility used by strip_tags.\n    \"\"\"\n    s = MLStripper()\n    s.feed(value)\n    s.close()\n    return s.get_data()\n\n\n@keep_lazy_text\ndef strip_tags(value):\n    \"\"\"Return the given HTML with all tags stripped.\"\"\"\n    # Note: in typical case this loop executes _strip_once once. Loop condition\n    # is redundant, but helps to reduce number of executions of _strip_once.\n    value = str(value)\n    while '<' in value and '>' in value:\n        new_value = _strip_once(value)\n        if value.count('<') == new_value.count('<'):\n            # _strip_once wasn't able to detect more tags.\n            break\n        value = new_value\n    return value\n\n\n@keep_lazy_text\ndef strip_spaces_between_tags(value):\n    \"\"\"Return the given HTML with spaces between tags removed.\"\"\"\n    return re.sub(r'>\\s+<', '><', str(value))\n\n\ndef smart_urlquote(url):\n    \"\"\"Quote a URL if it isn't already quoted.\"\"\"\n    def unquote_quote(segment):\n        segment = unquote(segment)\n        # Tilde is part of RFC3986 Unreserved Characters\n        # https://tools.ietf.org/html/rfc3986#section-2.3\n        # See also https://bugs.python.org/issue16285\n        return quote(segment, safe=RFC3986_SUBDELIMS + RFC3986_GENDELIMS + '~')\n\n    # Handle IDN before quoting.\n    try:\n        scheme, netloc, path, query, fragment = urlsplit(url)\n    except ValueError:\n        # invalid IPv6 URL (normally square brackets in hostname part).\n        return unquote_quote(url)\n\n    try:\n        netloc = punycode(netloc)  # IDN -> ACE\n    except UnicodeError:  # invalid domain part\n        return unquote_quote(url)\n\n    if query:\n        # Separately unquoting key/value, so as to not mix querystring separators\n        # included in query values. See #22267.\n        query_parts = [(unquote(q[0]), unquote(q[1]))\n                       for q in parse_qsl(query, keep_blank_values=True)]\n        # urlencode will take care of quoting\n        query = urlencode(query_parts)\n\n    path = unquote_quote(path)\n    fragment = unquote_quote(fragment)\n\n    return urlunsplit((scheme, netloc, path, query, fragment))\n\n\n@keep_lazy_text\ndef urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n    \"\"\"\n    Convert any URLs in text into clickable links.\n\n    Works on http://, https://, www. links, and also on links ending in one of\n    the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).\n    Links can have trailing punctuation (periods, commas, close-parens) and\n    leading punctuation (opening parens) and it'll still do the right thing.\n\n    If trim_url_limit is not None, truncate the URLs in the link text longer\n    than this limit to trim_url_limit - 1 characters and append an ellipsis.\n\n    If nofollow is True, give the links a rel=\"nofollow\" attribute.\n\n    If autoescape is True, autoescape the link text and URLs.\n    \"\"\"\n    safe_input = isinstance(text, SafeData)\n\n    def trim_url(x, limit=trim_url_limit):\n        if limit is None or len(x) <= limit:\n            return x\n        return '%s\u2026' % x[:max(0, limit - 1)]\n\n    def trim_punctuation(lead, middle, trail):\n        \"\"\"\n        Trim trailing and wrapping punctuation from `middle`. Return the items\n        of the new state.\n        \"\"\"\n        # Continue trimming until middle remains unchanged.\n        trimmed_something = True\n        while trimmed_something:\n            trimmed_something = False\n            # Trim wrapping punctuation.\n            for opening, closing in WRAPPING_PUNCTUATION:\n                if middle.startswith(opening):\n                    middle = middle[len(opening):]\n                    lead += opening\n                    trimmed_something = True\n                # Keep parentheses at the end only if they're balanced.\n                if (middle.endswith(closing) and\n                        middle.count(closing) == middle.count(opening) + 1):\n                    middle = middle[:-len(closing)]\n                    trail = closing + trail\n                    trimmed_something = True\n            # Trim trailing punctuation (after trimming wrapping punctuation,\n            # as encoded entities contain ';'). Unescape entities to avoid\n            # breaking them by removing ';'.\n            middle_unescaped = html.unescape(middle)\n            stripped = middle_unescaped.rstrip(TRAILING_PUNCTUATION_CHARS)\n            if middle_unescaped != stripped:\n                trail = middle[len(stripped):] + trail\n                middle = middle[:len(stripped) - len(middle_unescaped)]\n                trimmed_something = True\n        return lead, middle, trail\n\n    def is_email_simple(value):\n        \"\"\"Return True if value looks like an email address.\"\"\"\n        # An @ must be in the middle of the value.\n        if '@' not in value or value.startswith('@') or value.endswith('@'):\n            return False\n        try:\n            p1, p2 = value.split('@')\n        except ValueError:\n            # value contains more than one @.\n            return False\n        # Dot must be in p2 (e.g. example.com)\n        if '.' not in p2 or p2.startswith('.'):\n            return False\n        return True\n\n    words = word_split_re.split(str(text))\n    for i, word in enumerate(words):\n        if '.' in word or '@' in word or ':' in word:\n            # lead: Current punctuation trimmed from the beginning of the word.\n            # middle: Current state of the word.\n            # trail: Current punctuation trimmed from the end of the word.\n            lead, middle, trail = '', word, ''\n            # Deal with punctuation.\n            lead, middle, trail = trim_punctuation(lead, middle, trail)\n\n            # Make URL we want to point to.\n            url = None\n            nofollow_attr = ' rel=\"nofollow\"' if nofollow else ''\n            if simple_url_re.match(middle):\n                url = smart_urlquote(html.unescape(middle))\n            elif simple_url_2_re.match(middle):\n                url = smart_urlquote('http://%s' % html.unescape(middle))\n            elif ':' not in middle and is_email_simple(middle):\n                local, domain = middle.rsplit('@', 1)\n                try:\n                    domain = punycode(domain)\n                except UnicodeError:\n                    continue\n                url = 'mailto:%s@%s' % (local, domain)\n                nofollow_attr = ''\n\n            # Make link.\n            if url:\n                trimmed = trim_url(middle)\n                if autoescape and not safe_input:\n                    lead, trail = escape(lead), escape(trail)\n                    trimmed = escape(trimmed)\n                middle = '<a href=\"%s\"%s>%s</a>' % (escape(url), nofollow_attr, trimmed)\n                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))\n            else:\n                if safe_input:\n                    words[i] = mark_safe(word)\n                elif autoescape:\n                    words[i] = escape(word)\n        elif safe_input:\n            words[i] = mark_safe(word)\n        elif autoescape:\n            words[i] = escape(word)\n    return ''.join(words)\n\n\ndef avoid_wrapping(value):\n    \"\"\"\n    Avoid text wrapping in the middle of a phrase by adding non-breaking\n    spaces where there previously were normal spaces.\n    \"\"\"\n    return value.replace(\" \", \"\\xa0\")\n\n\ndef html_safe(klass):\n    \"\"\"\n    A decorator that defines the __html__ method. This helps non-Django\n    templates to detect classes whose __str__ methods return SafeString.\n    \"\"\"\n    if '__html__' in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it defines \"\n            \"__html__().\" % klass.__name__\n        )\n    if '__str__' not in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it doesn't \"\n            \"define __str__().\" % klass.__name__\n        )\n    klass_str = klass.__str__\n    klass.__str__ = lambda self: mark_safe(klass_str(self))\n    klass.__html__ = lambda self: str(self)\n    return klass\n"
  },
  {
    "patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex e9b7dcc72b..c2576b012a 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -17,8 +17,8 @@ def capfirst(x):\n \n \n # Set up regular expressions\n-re_words = re.compile(r'<.*?>|((?:\\w[-\\w]*|&.*?;)+)', re.S)\n-re_chars = re.compile(r'<.*?>|(.)', re.S)\n+re_words = re.compile(r'<[^>]+?>|([^<>\\s]+)', re.S)\n+re_chars = re.compile(r'<[^>]+?>|(.)', re.S)\n re_tag = re.compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\n re_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\n re_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n",
    "commit_message": "Fixed CVE-2019-14232 -- Adjusted regex to avoid backtracking issues when truncating HTML.\n\nThanks to Guido Vranken for initial report.\n\n",
    "code_before": "import html.entities\nimport re\nimport unicodedata\nimport warnings\nfrom gzip import GzipFile\nfrom io import BytesIO\n\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.functional import SimpleLazyObject, keep_lazy_text, lazy\nfrom django.utils.translation import gettext as _, gettext_lazy, pgettext\n\n\n@keep_lazy_text\ndef capfirst(x):\n    \"\"\"Capitalize the first letter of a string.\"\"\"\n    return x and str(x)[0].upper() + str(x)[1:]\n\n\n# Set up regular expressions\nre_words = re.compile(r'<.*?>|((?:\\w[-\\w]*|&.*?;)+)', re.S)\nre_chars = re.compile(r'<.*?>|(.)', re.S)\nre_tag = re.compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\nre_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\nre_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n\n\n@keep_lazy_text\ndef wrap(text, width):\n    \"\"\"\n    A word-wrap function that preserves existing line breaks. Expects that\n    existing line breaks are posix newlines.\n\n    Preserve all white space except added line breaks consume the space on\n    which they break the line.\n\n    Don't wrap long words, thus the output text may have lines longer than\n    ``width``.\n    \"\"\"\n    def _generator():\n        for line in text.splitlines(True):  # True keeps trailing linebreaks\n            max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            while len(line) > max_width:\n                space = line[:max_width + 1].rfind(' ') + 1\n                if space == 0:\n                    space = line.find(' ') + 1\n                    if space == 0:\n                        yield line\n                        line = ''\n                        break\n                yield '%s\\n' % line[:space - 1]\n                line = line[space:]\n                max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            if line:\n                yield line\n    return ''.join(_generator())\n\n\nclass Truncator(SimpleLazyObject):\n    \"\"\"\n    An object used to truncate text, either by characters or words.\n    \"\"\"\n    def __init__(self, text):\n        super().__init__(lambda: str(text))\n\n    def add_truncation_text(self, text, truncate=None):\n        if truncate is None:\n            truncate = pgettext(\n                'String to return when truncating text',\n                '%(truncated_text)s\u2026')\n        if '%(truncated_text)s' in truncate:\n            return truncate % {'truncated_text': text}\n        # The truncation text didn't contain the %(truncated_text)s string\n        # replacement argument so just append it to the text.\n        if text.endswith(truncate):\n            # But don't append the truncation text if the current text already\n            # ends in this.\n            return text\n        return '%s%s' % (text, truncate)\n\n    def chars(self, num, truncate=None, html=False):\n        \"\"\"\n        Return the text truncated to be no longer than the specified number\n        of characters.\n\n        `truncate` specifies what should be used to notify that the string has\n        been truncated, defaulting to a translatable string of an ellipsis.\n        \"\"\"\n        self._setup()\n        length = int(num)\n        text = unicodedata.normalize('NFC', self._wrapped)\n\n        # Calculate the length to truncate to (max length - end_text length)\n        truncate_len = length\n        for char in self.add_truncation_text('', truncate):\n            if not unicodedata.combining(char):\n                truncate_len -= 1\n                if truncate_len == 0:\n                    break\n        if html:\n            return self._truncate_html(length, truncate, text, truncate_len, False)\n        return self._text_chars(length, truncate, text, truncate_len)\n\n    def _text_chars(self, length, truncate, text, truncate_len):\n        \"\"\"Truncate a string after a certain number of chars.\"\"\"\n        s_len = 0\n        end_index = None\n        for i, char in enumerate(text):\n            if unicodedata.combining(char):\n                # Don't consider combining characters\n                # as adding to the string length\n                continue\n            s_len += 1\n            if end_index is None and s_len > truncate_len:\n                end_index = i\n            if s_len > length:\n                # Return the truncated string\n                return self.add_truncation_text(text[:end_index or 0],\n                                                truncate)\n\n        # Return the original string since no truncation was necessary\n        return text\n\n    def words(self, num, truncate=None, html=False):\n        \"\"\"\n        Truncate a string after a certain number of words. `truncate` specifies\n        what should be used to notify that the string has been truncated,\n        defaulting to ellipsis.\n        \"\"\"\n        self._setup()\n        length = int(num)\n        if html:\n            return self._truncate_html(length, truncate, self._wrapped, length, True)\n        return self._text_words(length, truncate)\n\n    def _text_words(self, length, truncate):\n        \"\"\"\n        Truncate a string after a certain number of words.\n\n        Strip newlines in the string.\n        \"\"\"\n        words = self._wrapped.split()\n        if len(words) > length:\n            words = words[:length]\n            return self.add_truncation_text(' '.join(words), truncate)\n        return ' '.join(words)\n\n    def _truncate_html(self, length, truncate, text, truncate_len, words):\n        \"\"\"\n        Truncate HTML to a certain number of chars (not counting tags and\n        comments), or, if words is True, then to a certain number of words.\n        Close opened tags if they were correctly closed in the given HTML.\n\n        Preserve newlines in the HTML.\n        \"\"\"\n        if words and length <= 0:\n            return ''\n\n        html4_singlets = (\n            'br', 'col', 'link', 'base', 'img',\n            'param', 'area', 'hr', 'input'\n        )\n\n        # Count non-HTML chars/words and keep note of open tags\n        pos = 0\n        end_text_pos = 0\n        current_len = 0\n        open_tags = []\n\n        regex = re_words if words else re_chars\n\n        while current_len <= length:\n            m = regex.search(text, pos)\n            if not m:\n                # Checked through whole string\n                break\n            pos = m.end(0)\n            if m.group(1):\n                # It's an actual non-HTML word or char\n                current_len += 1\n                if current_len == truncate_len:\n                    end_text_pos = pos\n                continue\n            # Check for tag\n            tag = re_tag.match(m.group(0))\n            if not tag or current_len >= truncate_len:\n                # Don't worry about non tags or tags after our truncate point\n                continue\n            closing_tag, tagname, self_closing = tag.groups()\n            # Element names are always case-insensitive\n            tagname = tagname.lower()\n            if self_closing or tagname in html4_singlets:\n                pass\n            elif closing_tag:\n                # Check for match in open tags list\n                try:\n                    i = open_tags.index(tagname)\n                except ValueError:\n                    pass\n                else:\n                    # SGML: An end tag closes, back to the matching start tag,\n                    # all unclosed intervening start tags with omitted end tags\n                    open_tags = open_tags[i + 1:]\n            else:\n                # Add it to the start of the open tags list\n                open_tags.insert(0, tagname)\n\n        if current_len <= length:\n            return text\n        out = text[:end_text_pos]\n        truncate_text = self.add_truncation_text('', truncate)\n        if truncate_text:\n            out += truncate_text\n        # Close any tags still open\n        for tag in open_tags:\n            out += '</%s>' % tag\n        # Return string\n        return out\n\n\n@keep_lazy_text\ndef get_valid_filename(s):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)\n\n\n@keep_lazy_text\ndef get_text_list(list_, last_word=gettext_lazy('or')):\n    \"\"\"\n    >>> get_text_list(['a', 'b', 'c', 'd'])\n    'a, b, c or d'\n    >>> get_text_list(['a', 'b', 'c'], 'and')\n    'a, b and c'\n    >>> get_text_list(['a', 'b'], 'and')\n    'a and b'\n    >>> get_text_list(['a'])\n    'a'\n    >>> get_text_list([])\n    ''\n    \"\"\"\n    if not list_:\n        return ''\n    if len(list_) == 1:\n        return str(list_[0])\n    return '%s %s %s' % (\n        # Translators: This string is used as a separator between list elements\n        _(', ').join(str(i) for i in list_[:-1]), str(last_word), str(list_[-1])\n    )\n\n\n@keep_lazy_text\ndef normalize_newlines(text):\n    \"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"\n    return re_newlines.sub('\\n', str(text))\n\n\n@keep_lazy_text\ndef phone2numeric(phone):\n    \"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"\n    char2number = {\n        'a': '2', 'b': '2', 'c': '2', 'd': '3', 'e': '3', 'f': '3', 'g': '4',\n        'h': '4', 'i': '4', 'j': '5', 'k': '5', 'l': '5', 'm': '6', 'n': '6',\n        'o': '6', 'p': '7', 'q': '7', 'r': '7', 's': '7', 't': '8', 'u': '8',\n        'v': '8', 'w': '9', 'x': '9', 'y': '9', 'z': '9',\n    }\n    return ''.join(char2number.get(c, c) for c in phone.lower())\n\n\n# From http://www.xhaus.com/alan/python/httpcomp.html#gzip\n# Used with permission.\ndef compress_string(s):\n    zbuf = BytesIO()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n        zfile.write(s)\n    return zbuf.getvalue()\n\n\nclass StreamingBuffer(BytesIO):\n    def read(self):\n        ret = self.getvalue()\n        self.seek(0)\n        self.truncate()\n        return ret\n\n\n# Like compress_string, but for iterators of strings.\ndef compress_sequence(sequence):\n    buf = StreamingBuffer()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=buf, mtime=0) as zfile:\n        # Output headers...\n        yield buf.read()\n        for item in sequence:\n            zfile.write(item)\n            data = buf.read()\n            if data:\n                yield data\n    yield buf.read()\n\n\n# Expression to match some_token and some_token=\"with spaces\" (and similarly\n# for single-quoted strings).\nsmart_split_re = re.compile(r\"\"\"\n    ((?:\n        [^\\s'\"]*\n        (?:\n            (?:\"(?:[^\"\\\\]|\\\\.)*\" | '(?:[^'\\\\]|\\\\.)*')\n            [^\\s'\"]*\n        )+\n    ) | \\S+)\n\"\"\", re.VERBOSE)\n\n\ndef smart_split(text):\n    r\"\"\"\n    Generator that splits a string by spaces, leaving quoted phrases together.\n    Supports both single and double quotes, and supports escaping quotes with\n    backslashes. In the output, strings will keep their initial and trailing\n    quote marks and escaped quotes will remain escaped (the results can then\n    be further processed with unescape_string_literal()).\n\n    >>> list(smart_split(r'This is \"a person\\'s\" test.'))\n    ['This', 'is', '\"a person\\\\\\'s\"', 'test.']\n    >>> list(smart_split(r\"Another 'person\\'s' test.\"))\n    ['Another', \"'person\\\\'s'\", 'test.']\n    >>> list(smart_split(r'A \"\\\"funky\\\" style\" test.'))\n    ['A', '\"\\\\\"funky\\\\\" style\"', 'test.']\n    \"\"\"\n    for bit in smart_split_re.finditer(str(text)):\n        yield bit.group(0)\n\n\ndef _replace_entity(match):\n    text = match.group(1)\n    if text[0] == '#':\n        text = text[1:]\n        try:\n            if text[0] in 'xX':\n                c = int(text[1:], 16)\n            else:\n                c = int(text)\n            return chr(c)\n        except ValueError:\n            return match.group(0)\n    else:\n        try:\n            return chr(html.entities.name2codepoint[text])\n        except (ValueError, KeyError):\n            return match.group(0)\n\n\n_entity_re = re.compile(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\")\n\n\n@keep_lazy_text\ndef unescape_entities(text):\n    warnings.warn(\n        'django.utils.text.unescape_entities() is deprecated in favor of '\n        'html.unescape().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return _entity_re.sub(_replace_entity, str(text))\n\n\n@keep_lazy_text\ndef unescape_string_literal(s):\n    r\"\"\"\n    Convert quoted string literals to unquoted strings with escaped quotes and\n    backslashes unquoted::\n\n        >>> unescape_string_literal('\"abc\"')\n        'abc'\n        >>> unescape_string_literal(\"'abc'\")\n        'abc'\n        >>> unescape_string_literal('\"a \\\"bc\\\"\"')\n        'a \"bc\"'\n        >>> unescape_string_literal(\"'\\'ab\\' c'\")\n        \"'ab' c\"\n    \"\"\"\n    if s[0] not in \"\\\"'\" or s[-1] != s[0]:\n        raise ValueError(\"Not a string literal: %r\" % s)\n    quote = s[0]\n    return s[1:-1].replace(r'\\%s' % quote, quote).replace(r'\\\\', '\\\\')\n\n\n@keep_lazy_text\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces to hyphens.\n    Remove characters that aren't alphanumerics, underscores, or hyphens.\n    Convert to lowercase. Also strip leading and trailing whitespace.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return re.sub(r'[-\\s]+', '-', value)\n\n\ndef camel_case_to_spaces(value):\n    \"\"\"\n    Split CamelCase and convert to lowercase. Strip surrounding whitespace.\n    \"\"\"\n    return re_camel_case.sub(r' \\1', value).strip().lower()\n\n\ndef _format_lazy(format_string, *args, **kwargs):\n    \"\"\"\n    Apply str.format() on 'format_string' where format_string, args,\n    and/or kwargs might be lazy.\n    \"\"\"\n    return format_string.format(*args, **kwargs)\n\n\nformat_lazy = lazy(_format_lazy, str)\n",
    "code_after": "import html.entities\nimport re\nimport unicodedata\nimport warnings\nfrom gzip import GzipFile\nfrom io import BytesIO\n\nfrom django.utils.deprecation import RemovedInDjango40Warning\nfrom django.utils.functional import SimpleLazyObject, keep_lazy_text, lazy\nfrom django.utils.translation import gettext as _, gettext_lazy, pgettext\n\n\n@keep_lazy_text\ndef capfirst(x):\n    \"\"\"Capitalize the first letter of a string.\"\"\"\n    return x and str(x)[0].upper() + str(x)[1:]\n\n\n# Set up regular expressions\nre_words = re.compile(r'<[^>]+?>|([^<>\\s]+)', re.S)\nre_chars = re.compile(r'<[^>]+?>|(.)', re.S)\nre_tag = re.compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\nre_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\nre_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n\n\n@keep_lazy_text\ndef wrap(text, width):\n    \"\"\"\n    A word-wrap function that preserves existing line breaks. Expects that\n    existing line breaks are posix newlines.\n\n    Preserve all white space except added line breaks consume the space on\n    which they break the line.\n\n    Don't wrap long words, thus the output text may have lines longer than\n    ``width``.\n    \"\"\"\n    def _generator():\n        for line in text.splitlines(True):  # True keeps trailing linebreaks\n            max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            while len(line) > max_width:\n                space = line[:max_width + 1].rfind(' ') + 1\n                if space == 0:\n                    space = line.find(' ') + 1\n                    if space == 0:\n                        yield line\n                        line = ''\n                        break\n                yield '%s\\n' % line[:space - 1]\n                line = line[space:]\n                max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            if line:\n                yield line\n    return ''.join(_generator())\n\n\nclass Truncator(SimpleLazyObject):\n    \"\"\"\n    An object used to truncate text, either by characters or words.\n    \"\"\"\n    def __init__(self, text):\n        super().__init__(lambda: str(text))\n\n    def add_truncation_text(self, text, truncate=None):\n        if truncate is None:\n            truncate = pgettext(\n                'String to return when truncating text',\n                '%(truncated_text)s\u2026')\n        if '%(truncated_text)s' in truncate:\n            return truncate % {'truncated_text': text}\n        # The truncation text didn't contain the %(truncated_text)s string\n        # replacement argument so just append it to the text.\n        if text.endswith(truncate):\n            # But don't append the truncation text if the current text already\n            # ends in this.\n            return text\n        return '%s%s' % (text, truncate)\n\n    def chars(self, num, truncate=None, html=False):\n        \"\"\"\n        Return the text truncated to be no longer than the specified number\n        of characters.\n\n        `truncate` specifies what should be used to notify that the string has\n        been truncated, defaulting to a translatable string of an ellipsis.\n        \"\"\"\n        self._setup()\n        length = int(num)\n        text = unicodedata.normalize('NFC', self._wrapped)\n\n        # Calculate the length to truncate to (max length - end_text length)\n        truncate_len = length\n        for char in self.add_truncation_text('', truncate):\n            if not unicodedata.combining(char):\n                truncate_len -= 1\n                if truncate_len == 0:\n                    break\n        if html:\n            return self._truncate_html(length, truncate, text, truncate_len, False)\n        return self._text_chars(length, truncate, text, truncate_len)\n\n    def _text_chars(self, length, truncate, text, truncate_len):\n        \"\"\"Truncate a string after a certain number of chars.\"\"\"\n        s_len = 0\n        end_index = None\n        for i, char in enumerate(text):\n            if unicodedata.combining(char):\n                # Don't consider combining characters\n                # as adding to the string length\n                continue\n            s_len += 1\n            if end_index is None and s_len > truncate_len:\n                end_index = i\n            if s_len > length:\n                # Return the truncated string\n                return self.add_truncation_text(text[:end_index or 0],\n                                                truncate)\n\n        # Return the original string since no truncation was necessary\n        return text\n\n    def words(self, num, truncate=None, html=False):\n        \"\"\"\n        Truncate a string after a certain number of words. `truncate` specifies\n        what should be used to notify that the string has been truncated,\n        defaulting to ellipsis.\n        \"\"\"\n        self._setup()\n        length = int(num)\n        if html:\n            return self._truncate_html(length, truncate, self._wrapped, length, True)\n        return self._text_words(length, truncate)\n\n    def _text_words(self, length, truncate):\n        \"\"\"\n        Truncate a string after a certain number of words.\n\n        Strip newlines in the string.\n        \"\"\"\n        words = self._wrapped.split()\n        if len(words) > length:\n            words = words[:length]\n            return self.add_truncation_text(' '.join(words), truncate)\n        return ' '.join(words)\n\n    def _truncate_html(self, length, truncate, text, truncate_len, words):\n        \"\"\"\n        Truncate HTML to a certain number of chars (not counting tags and\n        comments), or, if words is True, then to a certain number of words.\n        Close opened tags if they were correctly closed in the given HTML.\n\n        Preserve newlines in the HTML.\n        \"\"\"\n        if words and length <= 0:\n            return ''\n\n        html4_singlets = (\n            'br', 'col', 'link', 'base', 'img',\n            'param', 'area', 'hr', 'input'\n        )\n\n        # Count non-HTML chars/words and keep note of open tags\n        pos = 0\n        end_text_pos = 0\n        current_len = 0\n        open_tags = []\n\n        regex = re_words if words else re_chars\n\n        while current_len <= length:\n            m = regex.search(text, pos)\n            if not m:\n                # Checked through whole string\n                break\n            pos = m.end(0)\n            if m.group(1):\n                # It's an actual non-HTML word or char\n                current_len += 1\n                if current_len == truncate_len:\n                    end_text_pos = pos\n                continue\n            # Check for tag\n            tag = re_tag.match(m.group(0))\n            if not tag or current_len >= truncate_len:\n                # Don't worry about non tags or tags after our truncate point\n                continue\n            closing_tag, tagname, self_closing = tag.groups()\n            # Element names are always case-insensitive\n            tagname = tagname.lower()\n            if self_closing or tagname in html4_singlets:\n                pass\n            elif closing_tag:\n                # Check for match in open tags list\n                try:\n                    i = open_tags.index(tagname)\n                except ValueError:\n                    pass\n                else:\n                    # SGML: An end tag closes, back to the matching start tag,\n                    # all unclosed intervening start tags with omitted end tags\n                    open_tags = open_tags[i + 1:]\n            else:\n                # Add it to the start of the open tags list\n                open_tags.insert(0, tagname)\n\n        if current_len <= length:\n            return text\n        out = text[:end_text_pos]\n        truncate_text = self.add_truncation_text('', truncate)\n        if truncate_text:\n            out += truncate_text\n        # Close any tags still open\n        for tag in open_tags:\n            out += '</%s>' % tag\n        # Return string\n        return out\n\n\n@keep_lazy_text\ndef get_valid_filename(s):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)\n\n\n@keep_lazy_text\ndef get_text_list(list_, last_word=gettext_lazy('or')):\n    \"\"\"\n    >>> get_text_list(['a', 'b', 'c', 'd'])\n    'a, b, c or d'\n    >>> get_text_list(['a', 'b', 'c'], 'and')\n    'a, b and c'\n    >>> get_text_list(['a', 'b'], 'and')\n    'a and b'\n    >>> get_text_list(['a'])\n    'a'\n    >>> get_text_list([])\n    ''\n    \"\"\"\n    if not list_:\n        return ''\n    if len(list_) == 1:\n        return str(list_[0])\n    return '%s %s %s' % (\n        # Translators: This string is used as a separator between list elements\n        _(', ').join(str(i) for i in list_[:-1]), str(last_word), str(list_[-1])\n    )\n\n\n@keep_lazy_text\ndef normalize_newlines(text):\n    \"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"\n    return re_newlines.sub('\\n', str(text))\n\n\n@keep_lazy_text\ndef phone2numeric(phone):\n    \"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"\n    char2number = {\n        'a': '2', 'b': '2', 'c': '2', 'd': '3', 'e': '3', 'f': '3', 'g': '4',\n        'h': '4', 'i': '4', 'j': '5', 'k': '5', 'l': '5', 'm': '6', 'n': '6',\n        'o': '6', 'p': '7', 'q': '7', 'r': '7', 's': '7', 't': '8', 'u': '8',\n        'v': '8', 'w': '9', 'x': '9', 'y': '9', 'z': '9',\n    }\n    return ''.join(char2number.get(c, c) for c in phone.lower())\n\n\n# From http://www.xhaus.com/alan/python/httpcomp.html#gzip\n# Used with permission.\ndef compress_string(s):\n    zbuf = BytesIO()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n        zfile.write(s)\n    return zbuf.getvalue()\n\n\nclass StreamingBuffer(BytesIO):\n    def read(self):\n        ret = self.getvalue()\n        self.seek(0)\n        self.truncate()\n        return ret\n\n\n# Like compress_string, but for iterators of strings.\ndef compress_sequence(sequence):\n    buf = StreamingBuffer()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=buf, mtime=0) as zfile:\n        # Output headers...\n        yield buf.read()\n        for item in sequence:\n            zfile.write(item)\n            data = buf.read()\n            if data:\n                yield data\n    yield buf.read()\n\n\n# Expression to match some_token and some_token=\"with spaces\" (and similarly\n# for single-quoted strings).\nsmart_split_re = re.compile(r\"\"\"\n    ((?:\n        [^\\s'\"]*\n        (?:\n            (?:\"(?:[^\"\\\\]|\\\\.)*\" | '(?:[^'\\\\]|\\\\.)*')\n            [^\\s'\"]*\n        )+\n    ) | \\S+)\n\"\"\", re.VERBOSE)\n\n\ndef smart_split(text):\n    r\"\"\"\n    Generator that splits a string by spaces, leaving quoted phrases together.\n    Supports both single and double quotes, and supports escaping quotes with\n    backslashes. In the output, strings will keep their initial and trailing\n    quote marks and escaped quotes will remain escaped (the results can then\n    be further processed with unescape_string_literal()).\n\n    >>> list(smart_split(r'This is \"a person\\'s\" test.'))\n    ['This', 'is', '\"a person\\\\\\'s\"', 'test.']\n    >>> list(smart_split(r\"Another 'person\\'s' test.\"))\n    ['Another', \"'person\\\\'s'\", 'test.']\n    >>> list(smart_split(r'A \"\\\"funky\\\" style\" test.'))\n    ['A', '\"\\\\\"funky\\\\\" style\"', 'test.']\n    \"\"\"\n    for bit in smart_split_re.finditer(str(text)):\n        yield bit.group(0)\n\n\ndef _replace_entity(match):\n    text = match.group(1)\n    if text[0] == '#':\n        text = text[1:]\n        try:\n            if text[0] in 'xX':\n                c = int(text[1:], 16)\n            else:\n                c = int(text)\n            return chr(c)\n        except ValueError:\n            return match.group(0)\n    else:\n        try:\n            return chr(html.entities.name2codepoint[text])\n        except (ValueError, KeyError):\n            return match.group(0)\n\n\n_entity_re = re.compile(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\")\n\n\n@keep_lazy_text\ndef unescape_entities(text):\n    warnings.warn(\n        'django.utils.text.unescape_entities() is deprecated in favor of '\n        'html.unescape().',\n        RemovedInDjango40Warning, stacklevel=2,\n    )\n    return _entity_re.sub(_replace_entity, str(text))\n\n\n@keep_lazy_text\ndef unescape_string_literal(s):\n    r\"\"\"\n    Convert quoted string literals to unquoted strings with escaped quotes and\n    backslashes unquoted::\n\n        >>> unescape_string_literal('\"abc\"')\n        'abc'\n        >>> unescape_string_literal(\"'abc'\")\n        'abc'\n        >>> unescape_string_literal('\"a \\\"bc\\\"\"')\n        'a \"bc\"'\n        >>> unescape_string_literal(\"'\\'ab\\' c'\")\n        \"'ab' c\"\n    \"\"\"\n    if s[0] not in \"\\\"'\" or s[-1] != s[0]:\n        raise ValueError(\"Not a string literal: %r\" % s)\n    quote = s[0]\n    return s[1:-1].replace(r'\\%s' % quote, quote).replace(r'\\\\', '\\\\')\n\n\n@keep_lazy_text\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces to hyphens.\n    Remove characters that aren't alphanumerics, underscores, or hyphens.\n    Convert to lowercase. Also strip leading and trailing whitespace.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return re.sub(r'[-\\s]+', '-', value)\n\n\ndef camel_case_to_spaces(value):\n    \"\"\"\n    Split CamelCase and convert to lowercase. Strip surrounding whitespace.\n    \"\"\"\n    return re_camel_case.sub(r' \\1', value).strip().lower()\n\n\ndef _format_lazy(format_string, *args, **kwargs):\n    \"\"\"\n    Apply str.format() on 'format_string' where format_string, args,\n    and/or kwargs might be lazy.\n    \"\"\"\n    return format_string.format(*args, **kwargs)\n\n\nformat_lazy = lazy(_format_lazy, str)\n"
  },
  {
    "patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 804db6bf66..98a51f57c8 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -226,13 +226,14 @@ class HttpRequest:\n     def scheme(self):\n         if settings.SECURE_PROXY_SSL_HEADER:\n             try:\n-                header, value = settings.SECURE_PROXY_SSL_HEADER\n+                header, secure_value = settings.SECURE_PROXY_SSL_HEADER\n             except ValueError:\n                 raise ImproperlyConfigured(\n                     'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n                 )\n-            if self.META.get(header) == value:\n-                return 'https'\n+            header_value = self.META.get(header)\n+            if header_value is not None:\n+                return 'https' if header_value == secure_value else 'http'\n         return self._get_scheme()\n \n     def is_secure(self):\n",
    "commit_message": "Fixed CVE-2019-12781 -- Made HttpRequest always trust SECURE_PROXY_SSL_HEADER if set.\n\nAn HTTP request would not be redirected to HTTPS when the\nSECURE_PROXY_SSL_HEADER and SECURE_SSL_REDIRECT settings were used if\nthe proxy connected to Django via HTTPS.\n\nHttpRequest.scheme will now always trust the SECURE_PROXY_SSL_HEADER if\nset, rather than falling back to the request scheme when the\nSECURE_PROXY_SSL_HEADER did not have the secure value.\n\nThanks to Gavin Wahl for the report and initial patch suggestion, and\nShai Berger for review.\n\n",
    "code_before": "import cgi\nimport codecs\nimport copy\nimport re\nfrom io import BytesIO\nfrom itertools import chain\nfrom urllib.parse import quote, urlencode, urljoin, urlsplit\n\nfrom django.conf import settings\nfrom django.core import signing\nfrom django.core.exceptions import (\n    DisallowedHost, ImproperlyConfigured, RequestDataTooBig,\n)\nfrom django.core.files import uploadhandler\nfrom django.http.multipartparser import MultiPartParser, MultiPartParserError\nfrom django.utils.datastructures import (\n    CaseInsensitiveMapping, ImmutableList, MultiValueDict,\n)\nfrom django.utils.encoding import escape_uri_path, iri_to_uri\nfrom django.utils.functional import cached_property\nfrom django.utils.http import is_same_domain, limited_parse_qsl\n\nRAISE_ERROR = object()\nhost_validation_re = re.compile(r\"^([a-z0-9.-]+|\\[[a-f0-9]*:[a-f0-9\\.:]+\\])(:\\d+)?$\")\n\n\nclass UnreadablePostError(OSError):\n    pass\n\n\nclass RawPostDataException(Exception):\n    \"\"\"\n    You cannot access raw_post_data from a request that has\n    multipart/* POST data if it has been accessed via POST,\n    FILES, etc..\n    \"\"\"\n    pass\n\n\nclass HttpRequest:\n    \"\"\"A basic HTTP request.\"\"\"\n\n    # The encoding used in GET/POST dicts. None means use default setting.\n    _encoding = None\n    _upload_handlers = []\n\n    def __init__(self):\n        # WARNING: The `WSGIRequest` subclass doesn't call `super`.\n        # Any variable assignment made here should also happen in\n        # `WSGIRequest.__init__()`.\n\n        self.GET = QueryDict(mutable=True)\n        self.POST = QueryDict(mutable=True)\n        self.COOKIES = {}\n        self.META = {}\n        self.FILES = MultiValueDict()\n\n        self.path = ''\n        self.path_info = ''\n        self.method = None\n        self.resolver_match = None\n        self.content_type = None\n        self.content_params = None\n\n    def __repr__(self):\n        if self.method is None or not self.get_full_path():\n            return '<%s>' % self.__class__.__name__\n        return '<%s: %s %r>' % (self.__class__.__name__, self.method, self.get_full_path())\n\n    @cached_property\n    def headers(self):\n        return HttpHeaders(self.META)\n\n    def _set_content_type_params(self, meta):\n        \"\"\"Set content_type, content_params, and encoding.\"\"\"\n        self.content_type, self.content_params = cgi.parse_header(meta.get('CONTENT_TYPE', ''))\n        if 'charset' in self.content_params:\n            try:\n                codecs.lookup(self.content_params['charset'])\n            except LookupError:\n                pass\n            else:\n                self.encoding = self.content_params['charset']\n\n    def _get_raw_host(self):\n        \"\"\"\n        Return the HTTP host using the environment or request headers. Skip\n        allowed hosts protection, so may return an insecure host.\n        \"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n                'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = self.get_port()\n            if server_port != ('443' if self.is_secure() else '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n\n    def get_host(self):\n        \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n        host = self._get_raw_host()\n\n        # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n        allowed_hosts = settings.ALLOWED_HOSTS\n        if settings.DEBUG and not allowed_hosts:\n            allowed_hosts = ['localhost', '127.0.0.1', '[::1]']\n\n        domain, port = split_domain_port(host)\n        if domain and validate_host(domain, allowed_hosts):\n            return host\n        else:\n            msg = \"Invalid HTTP_HOST header: %r.\" % host\n            if domain:\n                msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain\n            else:\n                msg += \" The domain name provided is not valid according to RFC 1034/1035.\"\n            raise DisallowedHost(msg)\n\n    def get_port(self):\n        \"\"\"Return the port number for the request as a string.\"\"\"\n        if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META:\n            port = self.META['HTTP_X_FORWARDED_PORT']\n        else:\n            port = self.META['SERVER_PORT']\n        return str(port)\n\n    def get_full_path(self, force_append_slash=False):\n        return self._get_full_path(self.path, force_append_slash)\n\n    def get_full_path_info(self, force_append_slash=False):\n        return self._get_full_path(self.path_info, force_append_slash)\n\n    def _get_full_path(self, path, force_append_slash):\n        # RFC 3986 requires query string arguments to be in the ASCII range.\n        # Rather than crash if this doesn't happen, we encode defensively.\n        return '%s%s%s' % (\n            escape_uri_path(path),\n            '/' if force_append_slash and not path.endswith('/') else '',\n            ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else ''\n        )\n\n    def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n        \"\"\"\n        Attempt to return a signed cookie. If the signature fails or the\n        cookie has expired, raise an exception, unless the `default` argument\n        is provided,  in which case return that value.\n        \"\"\"\n        try:\n            cookie_value = self.COOKIES[key]\n        except KeyError:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        try:\n            value = signing.get_cookie_signer(salt=key + salt).unsign(\n                cookie_value, max_age=max_age)\n        except signing.BadSignature:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        return value\n\n    def get_raw_uri(self):\n        \"\"\"\n        Return an absolute URI from variables available in this request. Skip\n        allowed hosts protection, so may return insecure URI.\n        \"\"\"\n        return '{scheme}://{host}{path}'.format(\n            scheme=self.scheme,\n            host=self._get_raw_host(),\n            path=self.get_full_path(),\n        )\n\n    def build_absolute_uri(self, location=None):\n        \"\"\"\n        Build an absolute URI from the location and the variables available in\n        this request. If no ``location`` is specified, build the absolute URI\n        using request.get_full_path(). If the location is absolute, convert it\n        to an RFC 3987 compliant URI and return it. If location is relative or\n        is scheme-relative (i.e., ``//example.com/``), urljoin() it to a base\n        URL constructed from the request variables.\n        \"\"\"\n        if location is None:\n            # Make it an absolute url (but schemeless and domainless) for the\n            # edge case that the path starts with '//'.\n            location = '//%s' % self.get_full_path()\n        bits = urlsplit(location)\n        if not (bits.scheme and bits.netloc):\n            # Handle the simple, most common case. If the location is absolute\n            # and a scheme or host (netloc) isn't provided, skip an expensive\n            # urljoin() as long as no path segments are '.' or '..'.\n            if (bits.path.startswith('/') and not bits.scheme and not bits.netloc and\n                    '/./' not in bits.path and '/../' not in bits.path):\n                # If location starts with '//' but has no netloc, reuse the\n                # schema and netloc from the current request. Strip the double\n                # slashes and continue as if it wasn't specified.\n                if location.startswith('//'):\n                    location = location[2:]\n                location = self._current_scheme_host + location\n            else:\n                # Join the constructed URL with the provided location, which\n                # allows the provided location to apply query strings to the\n                # base path.\n                location = urljoin(self._current_scheme_host + self.path, location)\n        return iri_to_uri(location)\n\n    @cached_property\n    def _current_scheme_host(self):\n        return '{}://{}'.format(self.scheme, self.get_host())\n\n    def _get_scheme(self):\n        \"\"\"\n        Hook for subclasses like WSGIRequest to implement. Return 'http' by\n        default.\n        \"\"\"\n        return 'http'\n\n    @property\n    def scheme(self):\n        if settings.SECURE_PROXY_SSL_HEADER:\n            try:\n                header, value = settings.SECURE_PROXY_SSL_HEADER\n            except ValueError:\n                raise ImproperlyConfigured(\n                    'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n                )\n            if self.META.get(header) == value:\n                return 'https'\n        return self._get_scheme()\n\n    def is_secure(self):\n        return self.scheme == 'https'\n\n    def is_ajax(self):\n        return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n\n    @property\n    def encoding(self):\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, val):\n        \"\"\"\n        Set the encoding used for GET/POST accesses. If the GET or POST\n        dictionary has already been created, remove and recreate it on the\n        next access (so that it is decoded correctly).\n        \"\"\"\n        self._encoding = val\n        if hasattr(self, 'GET'):\n            del self.GET\n        if hasattr(self, '_post'):\n            del self._post\n\n    def _initialize_handlers(self):\n        self._upload_handlers = [uploadhandler.load_handler(handler, self)\n                                 for handler in settings.FILE_UPLOAD_HANDLERS]\n\n    @property\n    def upload_handlers(self):\n        if not self._upload_handlers:\n            # If there are no upload handlers defined, initialize them from settings.\n            self._initialize_handlers()\n        return self._upload_handlers\n\n    @upload_handlers.setter\n    def upload_handlers(self, upload_handlers):\n        if hasattr(self, '_files'):\n            raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n        self._upload_handlers = upload_handlers\n\n    def parse_file_upload(self, META, post_data):\n        \"\"\"Return a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n        self.upload_handlers = ImmutableList(\n            self.upload_handlers,\n            warning=\"You cannot alter upload handlers after the upload has been processed.\"\n        )\n        parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n        return parser.parse()\n\n    @property\n    def body(self):\n        if not hasattr(self, '_body'):\n            if self._read_started:\n                raise RawPostDataException(\"You cannot access body after reading from request's data stream\")\n\n            # Limit the maximum request data size that will be handled in-memory.\n            if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                    int(self.META.get('CONTENT_LENGTH') or 0) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n            try:\n                self._body = self.read()\n            except OSError as e:\n                raise UnreadablePostError(*e.args) from e\n            self._stream = BytesIO(self._body)\n        return self._body\n\n    def _mark_post_parse_error(self):\n        self._post = QueryDict()\n        self._files = MultiValueDict()\n\n    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != 'POST':\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n            return\n        if self._read_started and not hasattr(self, '_body'):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == 'multipart/form-data':\n            if hasattr(self, '_body'):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == 'application/x-www-form-urlencoded':\n            self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n        else:\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n\n    def close(self):\n        if hasattr(self, '_files'):\n            for f in chain.from_iterable(l[1] for l in self._files.lists()):\n                f.close()\n\n    # File-like and iterator interface.\n    #\n    # Expects self._stream to be set to an appropriate source of bytes by\n    # a corresponding request subclass (e.g. WSGIRequest).\n    # Also when request data has already been read by request.POST or\n    # request.body, self._stream points to a BytesIO instance\n    # containing that data.\n\n    def read(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.read(*args, **kwargs)\n        except OSError as e:\n            raise UnreadablePostError(*e.args) from e\n\n    def readline(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.readline(*args, **kwargs)\n        except OSError as e:\n            raise UnreadablePostError(*e.args) from e\n\n    def __iter__(self):\n        return iter(self.readline, b'')\n\n    def readlines(self):\n        return list(self)\n\n\nclass HttpHeaders(CaseInsensitiveMapping):\n    HTTP_PREFIX = 'HTTP_'\n    # PEP 333 gives two headers which aren't prepended with HTTP_.\n    UNPREFIXED_HEADERS = {'CONTENT_TYPE', 'CONTENT_LENGTH'}\n\n    def __init__(self, environ):\n        headers = {}\n        for header, value in environ.items():\n            name = self.parse_header_name(header)\n            if name:\n                headers[name] = value\n        super().__init__(headers)\n\n    def __getitem__(self, key):\n        \"\"\"Allow header lookup using underscores in place of hyphens.\"\"\"\n        return super().__getitem__(key.replace('_', '-'))\n\n    @classmethod\n    def parse_header_name(cls, header):\n        if header.startswith(cls.HTTP_PREFIX):\n            header = header[len(cls.HTTP_PREFIX):]\n        elif header not in cls.UNPREFIXED_HEADERS:\n            return None\n        return header.replace('_', '-').title()\n\n\nclass QueryDict(MultiValueDict):\n    \"\"\"\n    A specialized MultiValueDict which represents a query string.\n\n    A QueryDict can be used to represent GET or POST data. It subclasses\n    MultiValueDict since keys in such data can be repeated, for instance\n    in the data from a form with a <select multiple> field.\n\n    By default QueryDicts are immutable, though the copy() method\n    will always return a mutable copy.\n\n    Both keys and values set on this class are converted from the given encoding\n    (DEFAULT_CHARSET by default) to str.\n    \"\"\"\n\n    # These are both reset in __init__, but is specified here at the class\n    # level so that unpickling will have valid values\n    _mutable = True\n    _encoding = None\n\n    def __init__(self, query_string=None, mutable=False, encoding=None):\n        super().__init__()\n        self.encoding = encoding or settings.DEFAULT_CHARSET\n        query_string = query_string or ''\n        parse_qsl_kwargs = {\n            'keep_blank_values': True,\n            'fields_limit': settings.DATA_UPLOAD_MAX_NUMBER_FIELDS,\n            'encoding': self.encoding,\n        }\n        if isinstance(query_string, bytes):\n            # query_string normally contains URL-encoded data, a subset of ASCII.\n            try:\n                query_string = query_string.decode(self.encoding)\n            except UnicodeDecodeError:\n                # ... but some user agents are misbehaving :-(\n                query_string = query_string.decode('iso-8859-1')\n        for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n            self.appendlist(key, value)\n        self._mutable = mutable\n\n    @classmethod\n    def fromkeys(cls, iterable, value='', mutable=False, encoding=None):\n        \"\"\"\n        Return a new QueryDict with keys (may be repeated) from an iterable and\n        values from value.\n        \"\"\"\n        q = cls('', mutable=True, encoding=encoding)\n        for key in iterable:\n            q.appendlist(key, value)\n        if not mutable:\n            q._mutable = False\n        return q\n\n    @property\n    def encoding(self):\n        if self._encoding is None:\n            self._encoding = settings.DEFAULT_CHARSET\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value):\n        self._encoding = value\n\n    def _assert_mutable(self):\n        if not self._mutable:\n            raise AttributeError(\"This QueryDict instance is immutable\")\n\n    def __setitem__(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super().__setitem__(key, value)\n\n    def __delitem__(self, key):\n        self._assert_mutable()\n        super().__delitem__(key)\n\n    def __copy__(self):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        for key, value in self.lists():\n            result.setlist(key, value)\n        return result\n\n    def __deepcopy__(self, memo):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        memo[id(self)] = result\n        for key, value in self.lists():\n            result.setlist(copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n        return result\n\n    def setlist(self, key, list_):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        list_ = [bytes_to_text(elt, self.encoding) for elt in list_]\n        super().setlist(key, list_)\n\n    def setlistdefault(self, key, default_list=None):\n        self._assert_mutable()\n        return super().setlistdefault(key, default_list)\n\n    def appendlist(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super().appendlist(key, value)\n\n    def pop(self, key, *args):\n        self._assert_mutable()\n        return super().pop(key, *args)\n\n    def popitem(self):\n        self._assert_mutable()\n        return super().popitem()\n\n    def clear(self):\n        self._assert_mutable()\n        super().clear()\n\n    def setdefault(self, key, default=None):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        default = bytes_to_text(default, self.encoding)\n        return super().setdefault(key, default)\n\n    def copy(self):\n        \"\"\"Return a mutable copy of this object.\"\"\"\n        return self.__deepcopy__({})\n\n    def urlencode(self, safe=None):\n        \"\"\"\n        Return an encoded string of all query string arguments.\n\n        `safe` specifies characters which don't require quoting, for example::\n\n            >>> q = QueryDict(mutable=True)\n            >>> q['next'] = '/a&b/'\n            >>> q.urlencode()\n            'next=%2Fa%26b%2F'\n            >>> q.urlencode(safe='/')\n            'next=/a%26b/'\n        \"\"\"\n        output = []\n        if safe:\n            safe = safe.encode(self.encoding)\n\n            def encode(k, v):\n                return '%s=%s' % ((quote(k, safe), quote(v, safe)))\n        else:\n            def encode(k, v):\n                return urlencode({k: v})\n        for k, list_ in self.lists():\n            output.extend(\n                encode(k.encode(self.encoding), str(v).encode(self.encoding))\n                for v in list_\n            )\n        return '&'.join(output)\n\n\n# It's neither necessary nor appropriate to use\n# django.utils.encoding.force_str() for parsing URLs and form inputs. Thus,\n# this slightly more restricted function, used by QueryDict.\ndef bytes_to_text(s, encoding):\n    \"\"\"\n    Convert bytes objects to strings, using the given encoding. Illegally\n    encoded input characters are replaced with Unicode \"unknown\" codepoint\n    (\\ufffd).\n\n    Return any non-bytes objects without change.\n    \"\"\"\n    if isinstance(s, bytes):\n        return str(s, encoding, 'replace')\n    else:\n        return s\n\n\ndef split_domain_port(host):\n    \"\"\"\n    Return a (domain, port) tuple from a given host.\n\n    Returned domain is lowercased. If the host is invalid, the domain will be\n    empty.\n    \"\"\"\n    host = host.lower()\n\n    if not host_validation_re.match(host):\n        return '', ''\n\n    if host[-1] == ']':\n        # It's an IPv6 address without a port.\n        return host, ''\n    bits = host.rsplit(':', 1)\n    domain, port = bits if len(bits) == 2 else (bits[0], '')\n    # Remove a trailing dot (if present) from the domain.\n    domain = domain[:-1] if domain.endswith('.') else domain\n    return domain, port\n\n\ndef validate_host(host, allowed_hosts):\n    \"\"\"\n    Validate the given host for this site.\n\n    Check that the host looks valid and matches a host or host pattern in the\n    given list of ``allowed_hosts``. Any pattern beginning with a period\n    matches a domain and all its subdomains (e.g. ``.example.com`` matches\n    ``example.com`` and any subdomain), ``*`` matches anything, and anything\n    else must match exactly.\n\n    Note: This function assumes that the given host is lowercased and has\n    already had the port, if any, stripped off.\n\n    Return ``True`` for a valid host, ``False`` otherwise.\n    \"\"\"\n    return any(pattern == '*' or is_same_domain(host, pattern) for pattern in allowed_hosts)\n",
    "code_after": "import cgi\nimport codecs\nimport copy\nimport re\nfrom io import BytesIO\nfrom itertools import chain\nfrom urllib.parse import quote, urlencode, urljoin, urlsplit\n\nfrom django.conf import settings\nfrom django.core import signing\nfrom django.core.exceptions import (\n    DisallowedHost, ImproperlyConfigured, RequestDataTooBig,\n)\nfrom django.core.files import uploadhandler\nfrom django.http.multipartparser import MultiPartParser, MultiPartParserError\nfrom django.utils.datastructures import (\n    CaseInsensitiveMapping, ImmutableList, MultiValueDict,\n)\nfrom django.utils.encoding import escape_uri_path, iri_to_uri\nfrom django.utils.functional import cached_property\nfrom django.utils.http import is_same_domain, limited_parse_qsl\n\nRAISE_ERROR = object()\nhost_validation_re = re.compile(r\"^([a-z0-9.-]+|\\[[a-f0-9]*:[a-f0-9\\.:]+\\])(:\\d+)?$\")\n\n\nclass UnreadablePostError(OSError):\n    pass\n\n\nclass RawPostDataException(Exception):\n    \"\"\"\n    You cannot access raw_post_data from a request that has\n    multipart/* POST data if it has been accessed via POST,\n    FILES, etc..\n    \"\"\"\n    pass\n\n\nclass HttpRequest:\n    \"\"\"A basic HTTP request.\"\"\"\n\n    # The encoding used in GET/POST dicts. None means use default setting.\n    _encoding = None\n    _upload_handlers = []\n\n    def __init__(self):\n        # WARNING: The `WSGIRequest` subclass doesn't call `super`.\n        # Any variable assignment made here should also happen in\n        # `WSGIRequest.__init__()`.\n\n        self.GET = QueryDict(mutable=True)\n        self.POST = QueryDict(mutable=True)\n        self.COOKIES = {}\n        self.META = {}\n        self.FILES = MultiValueDict()\n\n        self.path = ''\n        self.path_info = ''\n        self.method = None\n        self.resolver_match = None\n        self.content_type = None\n        self.content_params = None\n\n    def __repr__(self):\n        if self.method is None or not self.get_full_path():\n            return '<%s>' % self.__class__.__name__\n        return '<%s: %s %r>' % (self.__class__.__name__, self.method, self.get_full_path())\n\n    @cached_property\n    def headers(self):\n        return HttpHeaders(self.META)\n\n    def _set_content_type_params(self, meta):\n        \"\"\"Set content_type, content_params, and encoding.\"\"\"\n        self.content_type, self.content_params = cgi.parse_header(meta.get('CONTENT_TYPE', ''))\n        if 'charset' in self.content_params:\n            try:\n                codecs.lookup(self.content_params['charset'])\n            except LookupError:\n                pass\n            else:\n                self.encoding = self.content_params['charset']\n\n    def _get_raw_host(self):\n        \"\"\"\n        Return the HTTP host using the environment or request headers. Skip\n        allowed hosts protection, so may return an insecure host.\n        \"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n                'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = self.get_port()\n            if server_port != ('443' if self.is_secure() else '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n\n    def get_host(self):\n        \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n        host = self._get_raw_host()\n\n        # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n        allowed_hosts = settings.ALLOWED_HOSTS\n        if settings.DEBUG and not allowed_hosts:\n            allowed_hosts = ['localhost', '127.0.0.1', '[::1]']\n\n        domain, port = split_domain_port(host)\n        if domain and validate_host(domain, allowed_hosts):\n            return host\n        else:\n            msg = \"Invalid HTTP_HOST header: %r.\" % host\n            if domain:\n                msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain\n            else:\n                msg += \" The domain name provided is not valid according to RFC 1034/1035.\"\n            raise DisallowedHost(msg)\n\n    def get_port(self):\n        \"\"\"Return the port number for the request as a string.\"\"\"\n        if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META:\n            port = self.META['HTTP_X_FORWARDED_PORT']\n        else:\n            port = self.META['SERVER_PORT']\n        return str(port)\n\n    def get_full_path(self, force_append_slash=False):\n        return self._get_full_path(self.path, force_append_slash)\n\n    def get_full_path_info(self, force_append_slash=False):\n        return self._get_full_path(self.path_info, force_append_slash)\n\n    def _get_full_path(self, path, force_append_slash):\n        # RFC 3986 requires query string arguments to be in the ASCII range.\n        # Rather than crash if this doesn't happen, we encode defensively.\n        return '%s%s%s' % (\n            escape_uri_path(path),\n            '/' if force_append_slash and not path.endswith('/') else '',\n            ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else ''\n        )\n\n    def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n        \"\"\"\n        Attempt to return a signed cookie. If the signature fails or the\n        cookie has expired, raise an exception, unless the `default` argument\n        is provided,  in which case return that value.\n        \"\"\"\n        try:\n            cookie_value = self.COOKIES[key]\n        except KeyError:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        try:\n            value = signing.get_cookie_signer(salt=key + salt).unsign(\n                cookie_value, max_age=max_age)\n        except signing.BadSignature:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        return value\n\n    def get_raw_uri(self):\n        \"\"\"\n        Return an absolute URI from variables available in this request. Skip\n        allowed hosts protection, so may return insecure URI.\n        \"\"\"\n        return '{scheme}://{host}{path}'.format(\n            scheme=self.scheme,\n            host=self._get_raw_host(),\n            path=self.get_full_path(),\n        )\n\n    def build_absolute_uri(self, location=None):\n        \"\"\"\n        Build an absolute URI from the location and the variables available in\n        this request. If no ``location`` is specified, build the absolute URI\n        using request.get_full_path(). If the location is absolute, convert it\n        to an RFC 3987 compliant URI and return it. If location is relative or\n        is scheme-relative (i.e., ``//example.com/``), urljoin() it to a base\n        URL constructed from the request variables.\n        \"\"\"\n        if location is None:\n            # Make it an absolute url (but schemeless and domainless) for the\n            # edge case that the path starts with '//'.\n            location = '//%s' % self.get_full_path()\n        bits = urlsplit(location)\n        if not (bits.scheme and bits.netloc):\n            # Handle the simple, most common case. If the location is absolute\n            # and a scheme or host (netloc) isn't provided, skip an expensive\n            # urljoin() as long as no path segments are '.' or '..'.\n            if (bits.path.startswith('/') and not bits.scheme and not bits.netloc and\n                    '/./' not in bits.path and '/../' not in bits.path):\n                # If location starts with '//' but has no netloc, reuse the\n                # schema and netloc from the current request. Strip the double\n                # slashes and continue as if it wasn't specified.\n                if location.startswith('//'):\n                    location = location[2:]\n                location = self._current_scheme_host + location\n            else:\n                # Join the constructed URL with the provided location, which\n                # allows the provided location to apply query strings to the\n                # base path.\n                location = urljoin(self._current_scheme_host + self.path, location)\n        return iri_to_uri(location)\n\n    @cached_property\n    def _current_scheme_host(self):\n        return '{}://{}'.format(self.scheme, self.get_host())\n\n    def _get_scheme(self):\n        \"\"\"\n        Hook for subclasses like WSGIRequest to implement. Return 'http' by\n        default.\n        \"\"\"\n        return 'http'\n\n    @property\n    def scheme(self):\n        if settings.SECURE_PROXY_SSL_HEADER:\n            try:\n                header, secure_value = settings.SECURE_PROXY_SSL_HEADER\n            except ValueError:\n                raise ImproperlyConfigured(\n                    'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n                )\n            header_value = self.META.get(header)\n            if header_value is not None:\n                return 'https' if header_value == secure_value else 'http'\n        return self._get_scheme()\n\n    def is_secure(self):\n        return self.scheme == 'https'\n\n    def is_ajax(self):\n        return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n\n    @property\n    def encoding(self):\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, val):\n        \"\"\"\n        Set the encoding used for GET/POST accesses. If the GET or POST\n        dictionary has already been created, remove and recreate it on the\n        next access (so that it is decoded correctly).\n        \"\"\"\n        self._encoding = val\n        if hasattr(self, 'GET'):\n            del self.GET\n        if hasattr(self, '_post'):\n            del self._post\n\n    def _initialize_handlers(self):\n        self._upload_handlers = [uploadhandler.load_handler(handler, self)\n                                 for handler in settings.FILE_UPLOAD_HANDLERS]\n\n    @property\n    def upload_handlers(self):\n        if not self._upload_handlers:\n            # If there are no upload handlers defined, initialize them from settings.\n            self._initialize_handlers()\n        return self._upload_handlers\n\n    @upload_handlers.setter\n    def upload_handlers(self, upload_handlers):\n        if hasattr(self, '_files'):\n            raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n        self._upload_handlers = upload_handlers\n\n    def parse_file_upload(self, META, post_data):\n        \"\"\"Return a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n        self.upload_handlers = ImmutableList(\n            self.upload_handlers,\n            warning=\"You cannot alter upload handlers after the upload has been processed.\"\n        )\n        parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n        return parser.parse()\n\n    @property\n    def body(self):\n        if not hasattr(self, '_body'):\n            if self._read_started:\n                raise RawPostDataException(\"You cannot access body after reading from request's data stream\")\n\n            # Limit the maximum request data size that will be handled in-memory.\n            if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                    int(self.META.get('CONTENT_LENGTH') or 0) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n            try:\n                self._body = self.read()\n            except OSError as e:\n                raise UnreadablePostError(*e.args) from e\n            self._stream = BytesIO(self._body)\n        return self._body\n\n    def _mark_post_parse_error(self):\n        self._post = QueryDict()\n        self._files = MultiValueDict()\n\n    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != 'POST':\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n            return\n        if self._read_started and not hasattr(self, '_body'):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == 'multipart/form-data':\n            if hasattr(self, '_body'):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == 'application/x-www-form-urlencoded':\n            self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n        else:\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n\n    def close(self):\n        if hasattr(self, '_files'):\n            for f in chain.from_iterable(l[1] for l in self._files.lists()):\n                f.close()\n\n    # File-like and iterator interface.\n    #\n    # Expects self._stream to be set to an appropriate source of bytes by\n    # a corresponding request subclass (e.g. WSGIRequest).\n    # Also when request data has already been read by request.POST or\n    # request.body, self._stream points to a BytesIO instance\n    # containing that data.\n\n    def read(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.read(*args, **kwargs)\n        except OSError as e:\n            raise UnreadablePostError(*e.args) from e\n\n    def readline(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.readline(*args, **kwargs)\n        except OSError as e:\n            raise UnreadablePostError(*e.args) from e\n\n    def __iter__(self):\n        return iter(self.readline, b'')\n\n    def readlines(self):\n        return list(self)\n\n\nclass HttpHeaders(CaseInsensitiveMapping):\n    HTTP_PREFIX = 'HTTP_'\n    # PEP 333 gives two headers which aren't prepended with HTTP_.\n    UNPREFIXED_HEADERS = {'CONTENT_TYPE', 'CONTENT_LENGTH'}\n\n    def __init__(self, environ):\n        headers = {}\n        for header, value in environ.items():\n            name = self.parse_header_name(header)\n            if name:\n                headers[name] = value\n        super().__init__(headers)\n\n    def __getitem__(self, key):\n        \"\"\"Allow header lookup using underscores in place of hyphens.\"\"\"\n        return super().__getitem__(key.replace('_', '-'))\n\n    @classmethod\n    def parse_header_name(cls, header):\n        if header.startswith(cls.HTTP_PREFIX):\n            header = header[len(cls.HTTP_PREFIX):]\n        elif header not in cls.UNPREFIXED_HEADERS:\n            return None\n        return header.replace('_', '-').title()\n\n\nclass QueryDict(MultiValueDict):\n    \"\"\"\n    A specialized MultiValueDict which represents a query string.\n\n    A QueryDict can be used to represent GET or POST data. It subclasses\n    MultiValueDict since keys in such data can be repeated, for instance\n    in the data from a form with a <select multiple> field.\n\n    By default QueryDicts are immutable, though the copy() method\n    will always return a mutable copy.\n\n    Both keys and values set on this class are converted from the given encoding\n    (DEFAULT_CHARSET by default) to str.\n    \"\"\"\n\n    # These are both reset in __init__, but is specified here at the class\n    # level so that unpickling will have valid values\n    _mutable = True\n    _encoding = None\n\n    def __init__(self, query_string=None, mutable=False, encoding=None):\n        super().__init__()\n        self.encoding = encoding or settings.DEFAULT_CHARSET\n        query_string = query_string or ''\n        parse_qsl_kwargs = {\n            'keep_blank_values': True,\n            'fields_limit': settings.DATA_UPLOAD_MAX_NUMBER_FIELDS,\n            'encoding': self.encoding,\n        }\n        if isinstance(query_string, bytes):\n            # query_string normally contains URL-encoded data, a subset of ASCII.\n            try:\n                query_string = query_string.decode(self.encoding)\n            except UnicodeDecodeError:\n                # ... but some user agents are misbehaving :-(\n                query_string = query_string.decode('iso-8859-1')\n        for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n            self.appendlist(key, value)\n        self._mutable = mutable\n\n    @classmethod\n    def fromkeys(cls, iterable, value='', mutable=False, encoding=None):\n        \"\"\"\n        Return a new QueryDict with keys (may be repeated) from an iterable and\n        values from value.\n        \"\"\"\n        q = cls('', mutable=True, encoding=encoding)\n        for key in iterable:\n            q.appendlist(key, value)\n        if not mutable:\n            q._mutable = False\n        return q\n\n    @property\n    def encoding(self):\n        if self._encoding is None:\n            self._encoding = settings.DEFAULT_CHARSET\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value):\n        self._encoding = value\n\n    def _assert_mutable(self):\n        if not self._mutable:\n            raise AttributeError(\"This QueryDict instance is immutable\")\n\n    def __setitem__(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super().__setitem__(key, value)\n\n    def __delitem__(self, key):\n        self._assert_mutable()\n        super().__delitem__(key)\n\n    def __copy__(self):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        for key, value in self.lists():\n            result.setlist(key, value)\n        return result\n\n    def __deepcopy__(self, memo):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        memo[id(self)] = result\n        for key, value in self.lists():\n            result.setlist(copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n        return result\n\n    def setlist(self, key, list_):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        list_ = [bytes_to_text(elt, self.encoding) for elt in list_]\n        super().setlist(key, list_)\n\n    def setlistdefault(self, key, default_list=None):\n        self._assert_mutable()\n        return super().setlistdefault(key, default_list)\n\n    def appendlist(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super().appendlist(key, value)\n\n    def pop(self, key, *args):\n        self._assert_mutable()\n        return super().pop(key, *args)\n\n    def popitem(self):\n        self._assert_mutable()\n        return super().popitem()\n\n    def clear(self):\n        self._assert_mutable()\n        super().clear()\n\n    def setdefault(self, key, default=None):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        default = bytes_to_text(default, self.encoding)\n        return super().setdefault(key, default)\n\n    def copy(self):\n        \"\"\"Return a mutable copy of this object.\"\"\"\n        return self.__deepcopy__({})\n\n    def urlencode(self, safe=None):\n        \"\"\"\n        Return an encoded string of all query string arguments.\n\n        `safe` specifies characters which don't require quoting, for example::\n\n            >>> q = QueryDict(mutable=True)\n            >>> q['next'] = '/a&b/'\n            >>> q.urlencode()\n            'next=%2Fa%26b%2F'\n            >>> q.urlencode(safe='/')\n            'next=/a%26b/'\n        \"\"\"\n        output = []\n        if safe:\n            safe = safe.encode(self.encoding)\n\n            def encode(k, v):\n                return '%s=%s' % ((quote(k, safe), quote(v, safe)))\n        else:\n            def encode(k, v):\n                return urlencode({k: v})\n        for k, list_ in self.lists():\n            output.extend(\n                encode(k.encode(self.encoding), str(v).encode(self.encoding))\n                for v in list_\n            )\n        return '&'.join(output)\n\n\n# It's neither necessary nor appropriate to use\n# django.utils.encoding.force_str() for parsing URLs and form inputs. Thus,\n# this slightly more restricted function, used by QueryDict.\ndef bytes_to_text(s, encoding):\n    \"\"\"\n    Convert bytes objects to strings, using the given encoding. Illegally\n    encoded input characters are replaced with Unicode \"unknown\" codepoint\n    (\\ufffd).\n\n    Return any non-bytes objects without change.\n    \"\"\"\n    if isinstance(s, bytes):\n        return str(s, encoding, 'replace')\n    else:\n        return s\n\n\ndef split_domain_port(host):\n    \"\"\"\n    Return a (domain, port) tuple from a given host.\n\n    Returned domain is lowercased. If the host is invalid, the domain will be\n    empty.\n    \"\"\"\n    host = host.lower()\n\n    if not host_validation_re.match(host):\n        return '', ''\n\n    if host[-1] == ']':\n        # It's an IPv6 address without a port.\n        return host, ''\n    bits = host.rsplit(':', 1)\n    domain, port = bits if len(bits) == 2 else (bits[0], '')\n    # Remove a trailing dot (if present) from the domain.\n    domain = domain[:-1] if domain.endswith('.') else domain\n    return domain, port\n\n\ndef validate_host(host, allowed_hosts):\n    \"\"\"\n    Validate the given host for this site.\n\n    Check that the host looks valid and matches a host or host pattern in the\n    given list of ``allowed_hosts``. Any pattern beginning with a period\n    matches a domain and all its subdomains (e.g. ``.example.com`` matches\n    ``example.com`` and any subdomain), ``*`` matches anything, and anything\n    else must match exactly.\n\n    Note: This function assumes that the given host is lowercased and has\n    already had the port, if any, stripped off.\n\n    Return ``True`` for a valid host, ``False`` otherwise.\n    \"\"\"\n    return any(pattern == '*' or is_same_domain(host, pattern) for pattern in allowed_hosts)\n"
  },
  {
    "patch": "diff --git a/django/contrib/admin/widgets.py b/django/contrib/admin/widgets.py\nindex 81dbcaf236..aa4b613894 100644\n--- a/django/contrib/admin/widgets.py\n+++ b/django/contrib/admin/widgets.py\n@@ -7,6 +7,7 @@ import json\n from django import forms\n from django.conf import settings\n from django.core.exceptions import ValidationError\n+from django.core.validators import URLValidator\n from django.db.models.deletion import CASCADE\n from django.urls import reverse\n from django.urls.exceptions import NoReverseMatch\n@@ -330,14 +331,21 @@ class AdminEmailInputWidget(forms.EmailInput):\n class AdminURLFieldWidget(forms.URLInput):\n     template_name = 'admin/widgets/url.html'\n \n-    def __init__(self, attrs=None):\n+    def __init__(self, attrs=None, validator_class=URLValidator):\n         super().__init__(attrs={'class': 'vURLField', **(attrs or {})})\n+        self.validator = validator_class()\n \n     def get_context(self, name, value, attrs):\n+        try:\n+            self.validator(value if value else '')\n+            url_valid = True\n+        except ValidationError:\n+            url_valid = False\n         context = super().get_context(name, value, attrs)\n         context['current_label'] = _('Currently:')\n         context['change_label'] = _('Change:')\n         context['widget']['href'] = smart_urlquote(context['widget']['value']) if value else ''\n+        context['url_valid'] = url_valid\n         return context\n \n \n",
    "commit_message": "Fixed CVE-2019-12308 -- Made AdminURLFieldWidget validate URL before rendering clickable link.\n\n",
    "code_before": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\nimport copy\nimport json\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.db.models.deletion import CASCADE\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\nfrom django.utils.html import smart_urlquote\nfrom django.utils.safestring import mark_safe\nfrom django.utils.text import Truncator\nfrom django.utils.translation import get_language, gettext as _\n\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = [\n            'vendor/jquery/jquery%s.js' % extra,\n            'jquery.init.js',\n            'core.js',\n            'SelectBox.js',\n            'SelectFilter2.js',\n        ]\n        return forms.Media(js=[\"admin/js/%s\" % path for path in js])\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super().__init__(attrs, choices)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['widget']['attrs']['class'] = 'selectfilter'\n        if self.is_stacked:\n            context['widget']['attrs']['class'] += 'stacked'\n        context['widget']['attrs']['data-field-name'] = self.verbose_name\n        context['widget']['attrs']['data-is-stacked'] = int(self.is_stacked)\n        return context\n\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vDateField', 'size': '10', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vTimeField', 'size': '8', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    template_name = 'admin/widgets/split_datetime.html'\n\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['date_label'] = _('Date:')\n        context['time_label'] = _('Time:')\n        return context\n\n\nclass AdminRadioSelect(forms.RadioSelect):\n    template_name = 'admin/widgets/radio.html'\n\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_name = 'admin/widgets/clearable_file_input.html'\n\n\ndef url_params_from_lookup_dict(lookups):\n    \"\"\"\n    Convert the type of lookups specified in a ForeignKey limit_choices_to\n    attribute to a dictionary of query parameters\n    \"\"\"\n    params = {}\n    if lookups and hasattr(lookups, 'items'):\n        for k, v in lookups.items():\n            if callable(v):\n                v = v()\n            if isinstance(v, (tuple, list)):\n                v = ','.join(str(x) for x in v)\n            elif isinstance(v, bool):\n                v = ('0', '1')[v]\n            else:\n                v = str(v)\n            params[k] = v\n    return params\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    template_name = 'admin/widgets/foreign_key_raw_id.html'\n\n    def __init__(self, rel, admin_site, attrs=None, using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        rel_to = self.rel.model\n        if rel_to in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            related_url = reverse(\n                'admin:%s_%s_changelist' % (\n                    rel_to._meta.app_label,\n                    rel_to._meta.model_name,\n                ),\n                current_app=self.admin_site.name,\n            )\n\n            params = self.url_parameters()\n            if params:\n                related_url += '?' + '&amp;'.join('%s=%s' % (k, v) for k, v in params.items())\n            context['related_url'] = mark_safe(related_url)\n            context['link_title'] = _('Lookup')\n            # The JavaScript code looks for this class.\n            context['widget']['attrs'].setdefault('class', 'vForeignKeyRawIdAdminField')\n        else:\n            context['related_url'] = None\n        if context['widget']['value']:\n            context['link_label'], context['link_url'] = self.label_and_url_for_value(value)\n        else:\n            context['link_label'] = None\n        return context\n\n    def base_url_parameters(self):\n        limit_choices_to = self.rel.limit_choices_to\n        if callable(limit_choices_to):\n            limit_choices_to = limit_choices_to()\n        return url_params_from_lookup_dict(limit_choices_to)\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_and_url_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.model._default_manager.using(self.db).get(**{key: value})\n        except (ValueError, self.rel.model.DoesNotExist, ValidationError):\n            return '', ''\n\n        try:\n            url = reverse(\n                '%s:%s_%s_change' % (\n                    self.admin_site.name,\n                    obj._meta.app_label,\n                    obj._meta.object_name.lower(),\n                ),\n                args=(obj.pk,)\n            )\n        except NoReverseMatch:\n            url = ''  # Admin not registered for target model.\n\n        return Truncator(obj).words(14), url\n\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    template_name = 'admin/widgets/many_to_many_raw_id.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.rel.model in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            context['widget']['attrs']['class'] = 'vManyToManyRawIdAdminField'\n        return context\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_and_url_for_value(self, value):\n        return '', ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def format_value(self, value):\n        return ','.join(str(v) for v in value) if value else ''\n\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    template_name = 'admin/widgets/related_widget_wrapper.html'\n\n    def __init__(self, widget, rel, admin_site, can_add_related=None,\n                 can_change_related=False, can_delete_related=False,\n                 can_view_related=False):\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.model in admin_site._registry\n        self.can_add_related = can_add_related\n        # XXX: The UX does not support multiple selected values.\n        multiple = getattr(widget, 'allow_multiple_selected', False)\n        self.can_change_related = not multiple and can_change_related\n        # XXX: The deletion UX can be confusing when dealing with cascading deletion.\n        cascade = getattr(rel, 'on_delete', None) is CASCADE\n        self.can_delete_related = not multiple and not cascade and can_delete_related\n        self.can_view_related = not multiple and can_view_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.widget.is_hidden\n\n    @property\n    def media(self):\n        return self.widget.media\n\n    def get_related_url(self, info, action, *args):\n        return reverse(\"admin:%s_%s_%s\" % (info + (action,)),\n                       current_app=self.admin_site.name, args=args)\n\n    def get_context(self, name, value, attrs):\n        from django.contrib.admin.views.main import IS_POPUP_VAR, TO_FIELD_VAR\n        rel_opts = self.rel.model._meta\n        info = (rel_opts.app_label, rel_opts.model_name)\n        self.widget.choices = self.choices\n        url_params = '&'.join(\"%s=%s\" % param for param in [\n            (TO_FIELD_VAR, self.rel.get_related_field().name),\n            (IS_POPUP_VAR, 1),\n        ])\n        context = {\n            'rendered_widget': self.widget.render(name, value, attrs),\n            'is_hidden': self.is_hidden,\n            'name': name,\n            'url_params': url_params,\n            'model': rel_opts.verbose_name,\n            'can_add_related': self.can_add_related,\n            'can_change_related': self.can_change_related,\n            'can_delete_related': self.can_delete_related,\n            'can_view_related': self.can_view_related,\n        }\n        if self.can_add_related:\n            context['add_related_url'] = self.get_related_url(info, 'add')\n        if self.can_delete_related:\n            context['delete_related_template_url'] = self.get_related_url(info, 'delete', '__fk__')\n        if self.can_view_related or self.can_change_related:\n            context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__')\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return self.widget.value_omitted_from_data(data, files, name)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vLargeTextField', **(attrs or {})})\n\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminEmailInputWidget(forms.EmailInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminURLFieldWidget(forms.URLInput):\n    template_name = 'admin/widgets/url.html'\n\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vURLField', **(attrs or {})})\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['current_label'] = _('Currently:')\n        context['change_label'] = _('Change:')\n        context['widget']['href'] = smart_urlquote(context['widget']['value']) if value else ''\n        return context\n\n\nclass AdminIntegerFieldWidget(forms.NumberInput):\n    class_name = 'vIntegerField'\n\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': self.class_name, **(attrs or {})})\n\n\nclass AdminBigIntegerFieldWidget(AdminIntegerFieldWidget):\n    class_name = 'vBigIntegerField'\n\n\nclass AdminUUIDInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vUUIDField', **(attrs or {})})\n\n\n# Mapping of lowercase language codes [returned by Django's get_language()] to\n# language codes supported by select2.\n# See django/contrib/admin/static/admin/js/vendor/select2/i18n/*\nSELECT2_TRANSLATIONS = {x.lower(): x for x in [\n    'ar', 'az', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et',\n    'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'is',\n    'it', 'ja', 'km', 'ko', 'lt', 'lv', 'mk', 'ms', 'nb', 'nl', 'pl',\n    'pt-BR', 'pt', 'ro', 'ru', 'sk', 'sr-Cyrl', 'sr', 'sv', 'th',\n    'tr', 'uk', 'vi',\n]}\nSELECT2_TRANSLATIONS.update({'zh-hans': 'zh-CN', 'zh-hant': 'zh-TW'})\n\n\nclass AutocompleteMixin:\n    \"\"\"\n    Select widget mixin that loads options from AutocompleteJsonView via AJAX.\n\n    Renders the necessary data attributes for select2 and adds the static form\n    media.\n    \"\"\"\n    url_name = '%s:%s_%s_autocomplete'\n\n    def __init__(self, rel, admin_site, attrs=None, choices=(), using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        self.choices = choices\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def get_url(self):\n        model = self.rel.model\n        return reverse(self.url_name % (self.admin_site.name, model._meta.app_label, model._meta.model_name))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"\n        Set select2's AJAX attributes.\n\n        Attributes can be set using the html5 data attribute.\n        Nested attributes require a double dash as per\n        https://select2.org/configuration/data-attributes#nested-subkey-options\n        \"\"\"\n        attrs = super().build_attrs(base_attrs, extra_attrs=extra_attrs)\n        attrs.setdefault('class', '')\n        attrs.update({\n            'data-ajax--cache': 'true',\n            'data-ajax--type': 'GET',\n            'data-ajax--url': self.get_url(),\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': json.dumps(not self.is_required),\n            'data-placeholder': '',  # Allows clearing of the input.\n            'class': attrs['class'] + (' ' if attrs['class'] else '') + 'admin-autocomplete',\n        })\n        return attrs\n\n    def optgroups(self, name, value, attr=None):\n        \"\"\"Return selected options based on the ModelChoiceIterator.\"\"\"\n        default = (None, [], 0)\n        groups = [default]\n        has_selected = False\n        selected_choices = {\n            str(v) for v in value\n            if str(v) not in self.choices.field.empty_values\n        }\n        if not self.is_required and not self.allow_multiple_selected:\n            default[1].append(self.create_option(name, '', '', False, 0))\n        choices = (\n            (obj.pk, self.choices.field.label_from_instance(obj))\n            for obj in self.choices.queryset.using(self.db).filter(pk__in=selected_choices)\n        )\n        for option_value, option_label in choices:\n            selected = (\n                str(option_value) in value and\n                (has_selected is False or self.allow_multiple_selected)\n            )\n            has_selected |= selected\n            index = len(default[1])\n            subgroup = default[1]\n            subgroup.append(self.create_option(name, option_value, option_label, selected_choices, index))\n        return groups\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        i18n_name = SELECT2_TRANSLATIONS.get(get_language())\n        i18n_file = ('admin/js/vendor/select2/i18n/%s.js' % i18n_name,) if i18n_name else ()\n        return forms.Media(\n            js=(\n                'admin/js/vendor/jquery/jquery%s.js' % extra,\n                'admin/js/vendor/select2/select2.full%s.js' % extra,\n            ) + i18n_file + (\n                'admin/js/jquery.init.js',\n                'admin/js/autocomplete.js',\n            ),\n            css={\n                'screen': (\n                    'admin/css/vendor/select2/select2%s.css' % extra,\n                    'admin/css/autocomplete.css',\n                ),\n            },\n        )\n\n\nclass AutocompleteSelect(AutocompleteMixin, forms.Select):\n    pass\n\n\nclass AutocompleteSelectMultiple(AutocompleteMixin, forms.SelectMultiple):\n    pass\n",
    "code_after": "\"\"\"\nForm Widget classes specific to the Django admin site.\n\"\"\"\nimport copy\nimport json\n\nfrom django import forms\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.core.validators import URLValidator\nfrom django.db.models.deletion import CASCADE\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\nfrom django.utils.html import smart_urlquote\nfrom django.utils.safestring import mark_safe\nfrom django.utils.text import Truncator\nfrom django.utils.translation import get_language, gettext as _\n\n\nclass FilteredSelectMultiple(forms.SelectMultiple):\n    \"\"\"\n    A SelectMultiple with a JavaScript filter interface.\n\n    Note that the resulting JavaScript assumes that the jsi18n\n    catalog has been loaded in the page\n    \"\"\"\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        js = [\n            'vendor/jquery/jquery%s.js' % extra,\n            'jquery.init.js',\n            'core.js',\n            'SelectBox.js',\n            'SelectFilter2.js',\n        ]\n        return forms.Media(js=[\"admin/js/%s\" % path for path in js])\n\n    def __init__(self, verbose_name, is_stacked, attrs=None, choices=()):\n        self.verbose_name = verbose_name\n        self.is_stacked = is_stacked\n        super().__init__(attrs, choices)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['widget']['attrs']['class'] = 'selectfilter'\n        if self.is_stacked:\n            context['widget']['attrs']['class'] += 'stacked'\n        context['widget']['attrs']['data-field-name'] = self.verbose_name\n        context['widget']['attrs']['data-is-stacked'] = int(self.is_stacked)\n        return context\n\n\nclass AdminDateWidget(forms.DateInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vDateField', 'size': '10', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminTimeWidget(forms.TimeInput):\n    class Media:\n        js = [\n            'admin/js/calendar.js',\n            'admin/js/admin/DateTimeShortcuts.js',\n        ]\n\n    def __init__(self, attrs=None, format=None):\n        attrs = {'class': 'vTimeField', 'size': '8', **(attrs or {})}\n        super().__init__(attrs=attrs, format=format)\n\n\nclass AdminSplitDateTime(forms.SplitDateTimeWidget):\n    \"\"\"\n    A SplitDateTime Widget that has some admin-specific styling.\n    \"\"\"\n    template_name = 'admin/widgets/split_datetime.html'\n\n    def __init__(self, attrs=None):\n        widgets = [AdminDateWidget, AdminTimeWidget]\n        # Note that we're calling MultiWidget, not SplitDateTimeWidget, because\n        # we want to define widgets.\n        forms.MultiWidget.__init__(self, widgets, attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        context['date_label'] = _('Date:')\n        context['time_label'] = _('Time:')\n        return context\n\n\nclass AdminRadioSelect(forms.RadioSelect):\n    template_name = 'admin/widgets/radio.html'\n\n\nclass AdminFileWidget(forms.ClearableFileInput):\n    template_name = 'admin/widgets/clearable_file_input.html'\n\n\ndef url_params_from_lookup_dict(lookups):\n    \"\"\"\n    Convert the type of lookups specified in a ForeignKey limit_choices_to\n    attribute to a dictionary of query parameters\n    \"\"\"\n    params = {}\n    if lookups and hasattr(lookups, 'items'):\n        for k, v in lookups.items():\n            if callable(v):\n                v = v()\n            if isinstance(v, (tuple, list)):\n                v = ','.join(str(x) for x in v)\n            elif isinstance(v, bool):\n                v = ('0', '1')[v]\n            else:\n                v = str(v)\n            params[k] = v\n    return params\n\n\nclass ForeignKeyRawIdWidget(forms.TextInput):\n    \"\"\"\n    A Widget for displaying ForeignKeys in the \"raw_id\" interface rather than\n    in a <select> box.\n    \"\"\"\n    template_name = 'admin/widgets/foreign_key_raw_id.html'\n\n    def __init__(self, rel, admin_site, attrs=None, using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        super().__init__(attrs)\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        rel_to = self.rel.model\n        if rel_to in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            related_url = reverse(\n                'admin:%s_%s_changelist' % (\n                    rel_to._meta.app_label,\n                    rel_to._meta.model_name,\n                ),\n                current_app=self.admin_site.name,\n            )\n\n            params = self.url_parameters()\n            if params:\n                related_url += '?' + '&amp;'.join('%s=%s' % (k, v) for k, v in params.items())\n            context['related_url'] = mark_safe(related_url)\n            context['link_title'] = _('Lookup')\n            # The JavaScript code looks for this class.\n            context['widget']['attrs'].setdefault('class', 'vForeignKeyRawIdAdminField')\n        else:\n            context['related_url'] = None\n        if context['widget']['value']:\n            context['link_label'], context['link_url'] = self.label_and_url_for_value(value)\n        else:\n            context['link_label'] = None\n        return context\n\n    def base_url_parameters(self):\n        limit_choices_to = self.rel.limit_choices_to\n        if callable(limit_choices_to):\n            limit_choices_to = limit_choices_to()\n        return url_params_from_lookup_dict(limit_choices_to)\n\n    def url_parameters(self):\n        from django.contrib.admin.views.main import TO_FIELD_VAR\n        params = self.base_url_parameters()\n        params.update({TO_FIELD_VAR: self.rel.get_related_field().name})\n        return params\n\n    def label_and_url_for_value(self, value):\n        key = self.rel.get_related_field().name\n        try:\n            obj = self.rel.model._default_manager.using(self.db).get(**{key: value})\n        except (ValueError, self.rel.model.DoesNotExist, ValidationError):\n            return '', ''\n\n        try:\n            url = reverse(\n                '%s:%s_%s_change' % (\n                    self.admin_site.name,\n                    obj._meta.app_label,\n                    obj._meta.object_name.lower(),\n                ),\n                args=(obj.pk,)\n            )\n        except NoReverseMatch:\n            url = ''  # Admin not registered for target model.\n\n        return Truncator(obj).words(14), url\n\n\nclass ManyToManyRawIdWidget(ForeignKeyRawIdWidget):\n    \"\"\"\n    A Widget for displaying ManyToMany ids in the \"raw_id\" interface rather than\n    in a <select multiple> box.\n    \"\"\"\n    template_name = 'admin/widgets/many_to_many_raw_id.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        if self.rel.model in self.admin_site._registry:\n            # The related object is registered with the same AdminSite\n            context['widget']['attrs']['class'] = 'vManyToManyRawIdAdminField'\n        return context\n\n    def url_parameters(self):\n        return self.base_url_parameters()\n\n    def label_and_url_for_value(self, value):\n        return '', ''\n\n    def value_from_datadict(self, data, files, name):\n        value = data.get(name)\n        if value:\n            return value.split(',')\n\n    def format_value(self, value):\n        return ','.join(str(v) for v in value) if value else ''\n\n\nclass RelatedFieldWidgetWrapper(forms.Widget):\n    \"\"\"\n    This class is a wrapper to a given widget to add the add icon for the\n    admin interface.\n    \"\"\"\n    template_name = 'admin/widgets/related_widget_wrapper.html'\n\n    def __init__(self, widget, rel, admin_site, can_add_related=None,\n                 can_change_related=False, can_delete_related=False,\n                 can_view_related=False):\n        self.needs_multipart_form = widget.needs_multipart_form\n        self.attrs = widget.attrs\n        self.choices = widget.choices\n        self.widget = widget\n        self.rel = rel\n        # Backwards compatible check for whether a user can add related\n        # objects.\n        if can_add_related is None:\n            can_add_related = rel.model in admin_site._registry\n        self.can_add_related = can_add_related\n        # XXX: The UX does not support multiple selected values.\n        multiple = getattr(widget, 'allow_multiple_selected', False)\n        self.can_change_related = not multiple and can_change_related\n        # XXX: The deletion UX can be confusing when dealing with cascading deletion.\n        cascade = getattr(rel, 'on_delete', None) is CASCADE\n        self.can_delete_related = not multiple and not cascade and can_delete_related\n        self.can_view_related = not multiple and can_view_related\n        # so we can check if the related object is registered with this AdminSite\n        self.admin_site = admin_site\n\n    def __deepcopy__(self, memo):\n        obj = copy.copy(self)\n        obj.widget = copy.deepcopy(self.widget, memo)\n        obj.attrs = self.widget.attrs\n        memo[id(self)] = obj\n        return obj\n\n    @property\n    def is_hidden(self):\n        return self.widget.is_hidden\n\n    @property\n    def media(self):\n        return self.widget.media\n\n    def get_related_url(self, info, action, *args):\n        return reverse(\"admin:%s_%s_%s\" % (info + (action,)),\n                       current_app=self.admin_site.name, args=args)\n\n    def get_context(self, name, value, attrs):\n        from django.contrib.admin.views.main import IS_POPUP_VAR, TO_FIELD_VAR\n        rel_opts = self.rel.model._meta\n        info = (rel_opts.app_label, rel_opts.model_name)\n        self.widget.choices = self.choices\n        url_params = '&'.join(\"%s=%s\" % param for param in [\n            (TO_FIELD_VAR, self.rel.get_related_field().name),\n            (IS_POPUP_VAR, 1),\n        ])\n        context = {\n            'rendered_widget': self.widget.render(name, value, attrs),\n            'is_hidden': self.is_hidden,\n            'name': name,\n            'url_params': url_params,\n            'model': rel_opts.verbose_name,\n            'can_add_related': self.can_add_related,\n            'can_change_related': self.can_change_related,\n            'can_delete_related': self.can_delete_related,\n            'can_view_related': self.can_view_related,\n        }\n        if self.can_add_related:\n            context['add_related_url'] = self.get_related_url(info, 'add')\n        if self.can_delete_related:\n            context['delete_related_template_url'] = self.get_related_url(info, 'delete', '__fk__')\n        if self.can_view_related or self.can_change_related:\n            context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__')\n        return context\n\n    def value_from_datadict(self, data, files, name):\n        return self.widget.value_from_datadict(data, files, name)\n\n    def value_omitted_from_data(self, data, files, name):\n        return self.widget.value_omitted_from_data(data, files, name)\n\n    def id_for_label(self, id_):\n        return self.widget.id_for_label(id_)\n\n\nclass AdminTextareaWidget(forms.Textarea):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vLargeTextField', **(attrs or {})})\n\n\nclass AdminTextInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminEmailInputWidget(forms.EmailInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vTextField', **(attrs or {})})\n\n\nclass AdminURLFieldWidget(forms.URLInput):\n    template_name = 'admin/widgets/url.html'\n\n    def __init__(self, attrs=None, validator_class=URLValidator):\n        super().__init__(attrs={'class': 'vURLField', **(attrs or {})})\n        self.validator = validator_class()\n\n    def get_context(self, name, value, attrs):\n        try:\n            self.validator(value if value else '')\n            url_valid = True\n        except ValidationError:\n            url_valid = False\n        context = super().get_context(name, value, attrs)\n        context['current_label'] = _('Currently:')\n        context['change_label'] = _('Change:')\n        context['widget']['href'] = smart_urlquote(context['widget']['value']) if value else ''\n        context['url_valid'] = url_valid\n        return context\n\n\nclass AdminIntegerFieldWidget(forms.NumberInput):\n    class_name = 'vIntegerField'\n\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': self.class_name, **(attrs or {})})\n\n\nclass AdminBigIntegerFieldWidget(AdminIntegerFieldWidget):\n    class_name = 'vBigIntegerField'\n\n\nclass AdminUUIDInputWidget(forms.TextInput):\n    def __init__(self, attrs=None):\n        super().__init__(attrs={'class': 'vUUIDField', **(attrs or {})})\n\n\n# Mapping of lowercase language codes [returned by Django's get_language()] to\n# language codes supported by select2.\n# See django/contrib/admin/static/admin/js/vendor/select2/i18n/*\nSELECT2_TRANSLATIONS = {x.lower(): x for x in [\n    'ar', 'az', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et',\n    'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'id', 'is',\n    'it', 'ja', 'km', 'ko', 'lt', 'lv', 'mk', 'ms', 'nb', 'nl', 'pl',\n    'pt-BR', 'pt', 'ro', 'ru', 'sk', 'sr-Cyrl', 'sr', 'sv', 'th',\n    'tr', 'uk', 'vi',\n]}\nSELECT2_TRANSLATIONS.update({'zh-hans': 'zh-CN', 'zh-hant': 'zh-TW'})\n\n\nclass AutocompleteMixin:\n    \"\"\"\n    Select widget mixin that loads options from AutocompleteJsonView via AJAX.\n\n    Renders the necessary data attributes for select2 and adds the static form\n    media.\n    \"\"\"\n    url_name = '%s:%s_%s_autocomplete'\n\n    def __init__(self, rel, admin_site, attrs=None, choices=(), using=None):\n        self.rel = rel\n        self.admin_site = admin_site\n        self.db = using\n        self.choices = choices\n        self.attrs = {} if attrs is None else attrs.copy()\n\n    def get_url(self):\n        model = self.rel.model\n        return reverse(self.url_name % (self.admin_site.name, model._meta.app_label, model._meta.model_name))\n\n    def build_attrs(self, base_attrs, extra_attrs=None):\n        \"\"\"\n        Set select2's AJAX attributes.\n\n        Attributes can be set using the html5 data attribute.\n        Nested attributes require a double dash as per\n        https://select2.org/configuration/data-attributes#nested-subkey-options\n        \"\"\"\n        attrs = super().build_attrs(base_attrs, extra_attrs=extra_attrs)\n        attrs.setdefault('class', '')\n        attrs.update({\n            'data-ajax--cache': 'true',\n            'data-ajax--type': 'GET',\n            'data-ajax--url': self.get_url(),\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': json.dumps(not self.is_required),\n            'data-placeholder': '',  # Allows clearing of the input.\n            'class': attrs['class'] + (' ' if attrs['class'] else '') + 'admin-autocomplete',\n        })\n        return attrs\n\n    def optgroups(self, name, value, attr=None):\n        \"\"\"Return selected options based on the ModelChoiceIterator.\"\"\"\n        default = (None, [], 0)\n        groups = [default]\n        has_selected = False\n        selected_choices = {\n            str(v) for v in value\n            if str(v) not in self.choices.field.empty_values\n        }\n        if not self.is_required and not self.allow_multiple_selected:\n            default[1].append(self.create_option(name, '', '', False, 0))\n        choices = (\n            (obj.pk, self.choices.field.label_from_instance(obj))\n            for obj in self.choices.queryset.using(self.db).filter(pk__in=selected_choices)\n        )\n        for option_value, option_label in choices:\n            selected = (\n                str(option_value) in value and\n                (has_selected is False or self.allow_multiple_selected)\n            )\n            has_selected |= selected\n            index = len(default[1])\n            subgroup = default[1]\n            subgroup.append(self.create_option(name, option_value, option_label, selected_choices, index))\n        return groups\n\n    @property\n    def media(self):\n        extra = '' if settings.DEBUG else '.min'\n        i18n_name = SELECT2_TRANSLATIONS.get(get_language())\n        i18n_file = ('admin/js/vendor/select2/i18n/%s.js' % i18n_name,) if i18n_name else ()\n        return forms.Media(\n            js=(\n                'admin/js/vendor/jquery/jquery%s.js' % extra,\n                'admin/js/vendor/select2/select2.full%s.js' % extra,\n            ) + i18n_file + (\n                'admin/js/jquery.init.js',\n                'admin/js/autocomplete.js',\n            ),\n            css={\n                'screen': (\n                    'admin/css/vendor/select2/select2%s.css' % extra,\n                    'admin/css/autocomplete.css',\n                ),\n            },\n        )\n\n\nclass AutocompleteSelect(AutocompleteMixin, forms.Select):\n    pass\n\n\nclass AutocompleteSelectMultiple(AutocompleteMixin, forms.SelectMultiple):\n    pass\n"
  },
  {
    "patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 9c0496342d..88b35fc435 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -27,7 +27,20 @@ def format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n     # sign\n     sign = ''\n     if isinstance(number, Decimal):\n-        str_number = '{:f}'.format(number)\n+        # Format values with more than 200 digits (an arbitrary cutoff) using\n+        # scientific notation to avoid high memory usage in {:f}'.format().\n+        _, digits, exponent = number.as_tuple()\n+        if abs(exponent) + len(digits) > 200:\n+            number = '{:e}'.format(number)\n+            coefficient, exponent = number.split('e')\n+            # Format the coefficient.\n+            coefficient = format(\n+                coefficient, decimal_sep, decimal_pos, grouping,\n+                thousand_sep, force_grouping, use_l10n,\n+            )\n+            return '{}e{}'.format(coefficient, exponent)\n+        else:\n+            str_number = '{:f}'.format(number)\n     else:\n         str_number = str(number)\n     if str_number[0] == '-':\n",
    "commit_message": "Fixed CVE-2019-6975 -- Fixed memory exhaustion in utils.numberformat.format().\n\nThanks Sjoerd Job Postmus for the report and initial patch.\nThanks Michael Manfre, Tim Graham, and Florian Apolloner for review.\n\n",
    "code_before": "from decimal import Decimal\n\nfrom django.conf import settings\nfrom django.utils.safestring import mark_safe\n\n\ndef format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n           force_grouping=False, use_l10n=None):\n    \"\"\"\n    Get a number (as a number or string), and return it as a string,\n    using formats defined as arguments:\n\n    * decimal_sep: Decimal separator symbol (for example \".\")\n    * decimal_pos: Number of decimal positions\n    * grouping: Number of digits in every group limited by thousand separator.\n        For non-uniform digit grouping, it can be a sequence with the number\n        of digit group sizes following the format used by the Python locale\n        module in locale.localeconv() LC_NUMERIC grouping (e.g. (3, 2, 0)).\n    * thousand_sep: Thousand separator symbol (for example \",\")\n    \"\"\"\n    use_grouping = (use_l10n or (use_l10n is None and settings.USE_L10N)) and settings.USE_THOUSAND_SEPARATOR\n    use_grouping = use_grouping or force_grouping\n    use_grouping = use_grouping and grouping != 0\n    # Make the common case fast\n    if isinstance(number, int) and not use_grouping and not decimal_pos:\n        return mark_safe(number)\n    # sign\n    sign = ''\n    if isinstance(number, Decimal):\n        str_number = '{:f}'.format(number)\n    else:\n        str_number = str(number)\n    if str_number[0] == '-':\n        sign = '-'\n        str_number = str_number[1:]\n    # decimal part\n    if '.' in str_number:\n        int_part, dec_part = str_number.split('.')\n        if decimal_pos is not None:\n            dec_part = dec_part[:decimal_pos]\n    else:\n        int_part, dec_part = str_number, ''\n    if decimal_pos is not None:\n        dec_part = dec_part + ('0' * (decimal_pos - len(dec_part)))\n    dec_part = dec_part and decimal_sep + dec_part\n    # grouping\n    if use_grouping:\n        try:\n            # if grouping is a sequence\n            intervals = list(grouping)\n        except TypeError:\n            # grouping is a single value\n            intervals = [grouping, 0]\n        active_interval = intervals.pop(0)\n        int_part_gd = ''\n        cnt = 0\n        for digit in int_part[::-1]:\n            if cnt and cnt == active_interval:\n                if intervals:\n                    active_interval = intervals.pop(0) or active_interval\n                int_part_gd += thousand_sep[::-1]\n                cnt = 0\n            int_part_gd += digit\n            cnt += 1\n        int_part = int_part_gd[::-1]\n    return sign + int_part + dec_part\n",
    "code_after": "from decimal import Decimal\n\nfrom django.conf import settings\nfrom django.utils.safestring import mark_safe\n\n\ndef format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n           force_grouping=False, use_l10n=None):\n    \"\"\"\n    Get a number (as a number or string), and return it as a string,\n    using formats defined as arguments:\n\n    * decimal_sep: Decimal separator symbol (for example \".\")\n    * decimal_pos: Number of decimal positions\n    * grouping: Number of digits in every group limited by thousand separator.\n        For non-uniform digit grouping, it can be a sequence with the number\n        of digit group sizes following the format used by the Python locale\n        module in locale.localeconv() LC_NUMERIC grouping (e.g. (3, 2, 0)).\n    * thousand_sep: Thousand separator symbol (for example \",\")\n    \"\"\"\n    use_grouping = (use_l10n or (use_l10n is None and settings.USE_L10N)) and settings.USE_THOUSAND_SEPARATOR\n    use_grouping = use_grouping or force_grouping\n    use_grouping = use_grouping and grouping != 0\n    # Make the common case fast\n    if isinstance(number, int) and not use_grouping and not decimal_pos:\n        return mark_safe(number)\n    # sign\n    sign = ''\n    if isinstance(number, Decimal):\n        # Format values with more than 200 digits (an arbitrary cutoff) using\n        # scientific notation to avoid high memory usage in {:f}'.format().\n        _, digits, exponent = number.as_tuple()\n        if abs(exponent) + len(digits) > 200:\n            number = '{:e}'.format(number)\n            coefficient, exponent = number.split('e')\n            # Format the coefficient.\n            coefficient = format(\n                coefficient, decimal_sep, decimal_pos, grouping,\n                thousand_sep, force_grouping, use_l10n,\n            )\n            return '{}e{}'.format(coefficient, exponent)\n        else:\n            str_number = '{:f}'.format(number)\n    else:\n        str_number = str(number)\n    if str_number[0] == '-':\n        sign = '-'\n        str_number = str_number[1:]\n    # decimal part\n    if '.' in str_number:\n        int_part, dec_part = str_number.split('.')\n        if decimal_pos is not None:\n            dec_part = dec_part[:decimal_pos]\n    else:\n        int_part, dec_part = str_number, ''\n    if decimal_pos is not None:\n        dec_part = dec_part + ('0' * (decimal_pos - len(dec_part)))\n    dec_part = dec_part and decimal_sep + dec_part\n    # grouping\n    if use_grouping:\n        try:\n            # if grouping is a sequence\n            intervals = list(grouping)\n        except TypeError:\n            # grouping is a single value\n            intervals = [grouping, 0]\n        active_interval = intervals.pop(0)\n        int_part_gd = ''\n        cnt = 0\n        for digit in int_part[::-1]:\n            if cnt and cnt == active_interval:\n                if intervals:\n                    active_interval = intervals.pop(0) or active_interval\n                int_part_gd += thousand_sep[::-1]\n                cnt = 0\n            int_part_gd += digit\n            cnt += 1\n        int_part = int_part_gd[::-1]\n    return sign + int_part + dec_part\n"
  },
  {
    "patch": "diff --git a/django/views/defaults.py b/django/views/defaults.py\nindex dee081ec3d..6c394490ab 100644\n--- a/django/views/defaults.py\n+++ b/django/views/defaults.py\n@@ -1,3 +1,5 @@\n+from urllib.parse import quote\n+\n from django.http import (\n     HttpResponseBadRequest, HttpResponseForbidden, HttpResponseNotFound,\n     HttpResponseServerError,\n@@ -22,7 +24,8 @@ def page_not_found(request, exception, template_name=ERROR_404_TEMPLATE_NAME):\n     Templates: :template:`404.html`\n     Context:\n         request_path\n-            The path of the requested URL (e.g., '/app/pages/bad_page/')\n+            The path of the requested URL (e.g., '/app/pages/bad_page/'). It's\n+            quoted to prevent a content injection attack.\n         exception\n             The message from the exception which triggered the 404 (if one was\n             supplied), or the exception class name\n@@ -38,7 +41,7 @@ def page_not_found(request, exception, template_name=ERROR_404_TEMPLATE_NAME):\n         if isinstance(message, str):\n             exception_repr = message\n     context = {\n-        'request_path': request.path,\n+        'request_path': quote(request.path),\n         'exception': exception_repr,\n     }\n     try:\n@@ -51,7 +54,7 @@ def page_not_found(request, exception, template_name=ERROR_404_TEMPLATE_NAME):\n             raise\n         template = Engine().from_string(\n             '<h1>Not Found</h1>'\n-            '<p>The requested URL {{ request_path }} was not found on this server.</p>')\n+            '<p>The requested resource was not found on this server.</p>')\n         body = template.render(Context(context))\n         content_type = 'text/html'\n     return HttpResponseNotFound(body, content_type=content_type)\n",
    "commit_message": "Fixed #30070, CVE-2019-3498 -- Fixed content spoofing possiblity in the default 404 page.\n\nCo-Authored-By: Tim Graham <timograham@gmail.com>\n",
    "code_before": "from django.http import (\n    HttpResponseBadRequest, HttpResponseForbidden, HttpResponseNotFound,\n    HttpResponseServerError,\n)\nfrom django.template import Context, Engine, TemplateDoesNotExist, loader\nfrom django.views.decorators.csrf import requires_csrf_token\n\nERROR_404_TEMPLATE_NAME = '404.html'\nERROR_403_TEMPLATE_NAME = '403.html'\nERROR_400_TEMPLATE_NAME = '400.html'\nERROR_500_TEMPLATE_NAME = '500.html'\n\n\n# This can be called when CsrfViewMiddleware.process_view has not run,\n# therefore need @requires_csrf_token in case the template needs\n# {% csrf_token %}.\n@requires_csrf_token\ndef page_not_found(request, exception, template_name=ERROR_404_TEMPLATE_NAME):\n    \"\"\"\n    Default 404 handler.\n\n    Templates: :template:`404.html`\n    Context:\n        request_path\n            The path of the requested URL (e.g., '/app/pages/bad_page/')\n        exception\n            The message from the exception which triggered the 404 (if one was\n            supplied), or the exception class name\n    \"\"\"\n    exception_repr = exception.__class__.__name__\n    # Try to get an \"interesting\" exception message, if any (and not the ugly\n    # Resolver404 dictionary)\n    try:\n        message = exception.args[0]\n    except (AttributeError, IndexError):\n        pass\n    else:\n        if isinstance(message, str):\n            exception_repr = message\n    context = {\n        'request_path': request.path,\n        'exception': exception_repr,\n    }\n    try:\n        template = loader.get_template(template_name)\n        body = template.render(context, request)\n        content_type = None             # Django will use DEFAULT_CONTENT_TYPE\n    except TemplateDoesNotExist:\n        if template_name != ERROR_404_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        template = Engine().from_string(\n            '<h1>Not Found</h1>'\n            '<p>The requested URL {{ request_path }} was not found on this server.</p>')\n        body = template.render(Context(context))\n        content_type = 'text/html'\n    return HttpResponseNotFound(body, content_type=content_type)\n\n\n@requires_csrf_token\ndef server_error(request, template_name=ERROR_500_TEMPLATE_NAME):\n    \"\"\"\n    500 error handler.\n\n    Templates: :template:`500.html`\n    Context: None\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_500_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseServerError('<h1>Server Error (500)</h1>', content_type='text/html')\n    return HttpResponseServerError(template.render())\n\n\n@requires_csrf_token\ndef bad_request(request, exception, template_name=ERROR_400_TEMPLATE_NAME):\n    \"\"\"\n    400 error handler.\n\n    Templates: :template:`400.html`\n    Context: None\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_400_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseBadRequest('<h1>Bad Request (400)</h1>', content_type='text/html')\n    # No exception content is passed to the template, to not disclose any sensitive information.\n    return HttpResponseBadRequest(template.render())\n\n\n# This can be called when CsrfViewMiddleware.process_view has not run,\n# therefore need @requires_csrf_token in case the template needs\n# {% csrf_token %}.\n@requires_csrf_token\ndef permission_denied(request, exception, template_name=ERROR_403_TEMPLATE_NAME):\n    \"\"\"\n    Permission denied (403) handler.\n\n    Templates: :template:`403.html`\n    Context: None\n\n    If the template does not exist, an Http403 response containing the text\n    \"403 Forbidden\" (as per RFC 7231) will be returned.\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_403_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseForbidden('<h1>403 Forbidden</h1>', content_type='text/html')\n    return HttpResponseForbidden(\n        template.render(request=request, context={'exception': str(exception)})\n    )\n",
    "code_after": "from urllib.parse import quote\n\nfrom django.http import (\n    HttpResponseBadRequest, HttpResponseForbidden, HttpResponseNotFound,\n    HttpResponseServerError,\n)\nfrom django.template import Context, Engine, TemplateDoesNotExist, loader\nfrom django.views.decorators.csrf import requires_csrf_token\n\nERROR_404_TEMPLATE_NAME = '404.html'\nERROR_403_TEMPLATE_NAME = '403.html'\nERROR_400_TEMPLATE_NAME = '400.html'\nERROR_500_TEMPLATE_NAME = '500.html'\n\n\n# This can be called when CsrfViewMiddleware.process_view has not run,\n# therefore need @requires_csrf_token in case the template needs\n# {% csrf_token %}.\n@requires_csrf_token\ndef page_not_found(request, exception, template_name=ERROR_404_TEMPLATE_NAME):\n    \"\"\"\n    Default 404 handler.\n\n    Templates: :template:`404.html`\n    Context:\n        request_path\n            The path of the requested URL (e.g., '/app/pages/bad_page/'). It's\n            quoted to prevent a content injection attack.\n        exception\n            The message from the exception which triggered the 404 (if one was\n            supplied), or the exception class name\n    \"\"\"\n    exception_repr = exception.__class__.__name__\n    # Try to get an \"interesting\" exception message, if any (and not the ugly\n    # Resolver404 dictionary)\n    try:\n        message = exception.args[0]\n    except (AttributeError, IndexError):\n        pass\n    else:\n        if isinstance(message, str):\n            exception_repr = message\n    context = {\n        'request_path': quote(request.path),\n        'exception': exception_repr,\n    }\n    try:\n        template = loader.get_template(template_name)\n        body = template.render(context, request)\n        content_type = None             # Django will use DEFAULT_CONTENT_TYPE\n    except TemplateDoesNotExist:\n        if template_name != ERROR_404_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        template = Engine().from_string(\n            '<h1>Not Found</h1>'\n            '<p>The requested resource was not found on this server.</p>')\n        body = template.render(Context(context))\n        content_type = 'text/html'\n    return HttpResponseNotFound(body, content_type=content_type)\n\n\n@requires_csrf_token\ndef server_error(request, template_name=ERROR_500_TEMPLATE_NAME):\n    \"\"\"\n    500 error handler.\n\n    Templates: :template:`500.html`\n    Context: None\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_500_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseServerError('<h1>Server Error (500)</h1>', content_type='text/html')\n    return HttpResponseServerError(template.render())\n\n\n@requires_csrf_token\ndef bad_request(request, exception, template_name=ERROR_400_TEMPLATE_NAME):\n    \"\"\"\n    400 error handler.\n\n    Templates: :template:`400.html`\n    Context: None\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_400_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseBadRequest('<h1>Bad Request (400)</h1>', content_type='text/html')\n    # No exception content is passed to the template, to not disclose any sensitive information.\n    return HttpResponseBadRequest(template.render())\n\n\n# This can be called when CsrfViewMiddleware.process_view has not run,\n# therefore need @requires_csrf_token in case the template needs\n# {% csrf_token %}.\n@requires_csrf_token\ndef permission_denied(request, exception, template_name=ERROR_403_TEMPLATE_NAME):\n    \"\"\"\n    Permission denied (403) handler.\n\n    Templates: :template:`403.html`\n    Context: None\n\n    If the template does not exist, an Http403 response containing the text\n    \"403 Forbidden\" (as per RFC 7231) will be returned.\n    \"\"\"\n    try:\n        template = loader.get_template(template_name)\n    except TemplateDoesNotExist:\n        if template_name != ERROR_403_TEMPLATE_NAME:\n            # Reraise if it's a missing custom template.\n            raise\n        return HttpResponseForbidden('<h1>403 Forbidden</h1>', content_type='text/html')\n    return HttpResponseForbidden(\n        template.render(request=request, context={'exception': str(exception)})\n    )\n"
  },
  {
    "patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex e69f1e16c8..746a67ee00 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -20,7 +20,7 @@ def capfirst(x):\n # Set up regular expressions\n re_words = re.compile(r'<.*?>|((?:\\w[-\\w]*|&.*?;)+)', re.S)\n re_chars = re.compile(r'<.*?>|(.)', re.S)\n-re_tag = re.compile(r'<(/)?([^ ]+?)(?:(\\s*/)| .*?)?>', re.S)\n+re_tag = re.compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\n re_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\n re_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n \n",
    "commit_message": "Fixed CVE-2018-7537 -- Fixed catastrophic backtracking in django.utils.text.Truncator.\n\nThanks James Davis for suggesting the fix.\n\n",
    "code_before": "import html.entities\nimport re\nimport unicodedata\nfrom gzip import GzipFile\nfrom io import BytesIO\n\nfrom django.utils.functional import (\n    SimpleLazyObject, keep_lazy, keep_lazy_text, lazy,\n)\nfrom django.utils.safestring import SafeText, mark_safe\nfrom django.utils.translation import gettext as _, gettext_lazy, pgettext\n\n\n@keep_lazy_text\ndef capfirst(x):\n    \"\"\"Capitalize the first letter of a string.\"\"\"\n    return x and str(x)[0].upper() + str(x)[1:]\n\n\n# Set up regular expressions\nre_words = re.compile(r'<.*?>|((?:\\w[-\\w]*|&.*?;)+)', re.S)\nre_chars = re.compile(r'<.*?>|(.)', re.S)\nre_tag = re.compile(r'<(/)?([^ ]+?)(?:(\\s*/)| .*?)?>', re.S)\nre_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\nre_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n\n\n@keep_lazy_text\ndef wrap(text, width):\n    \"\"\"\n    A word-wrap function that preserves existing line breaks. Expects that\n    existing line breaks are posix newlines.\n\n    Preserve all white space except added line breaks consume the space on\n    which they break the line.\n\n    Don't wrap long words, thus the output text may have lines longer than\n    ``width``.\n    \"\"\"\n    def _generator():\n        for line in text.splitlines(True):  # True keeps trailing linebreaks\n            max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            while len(line) > max_width:\n                space = line[:max_width + 1].rfind(' ') + 1\n                if space == 0:\n                    space = line.find(' ') + 1\n                    if space == 0:\n                        yield line\n                        line = ''\n                        break\n                yield '%s\\n' % line[:space - 1]\n                line = line[space:]\n                max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            if line:\n                yield line\n    return ''.join(_generator())\n\n\nclass Truncator(SimpleLazyObject):\n    \"\"\"\n    An object used to truncate text, either by characters or words.\n    \"\"\"\n    def __init__(self, text):\n        super().__init__(lambda: str(text))\n\n    def add_truncation_text(self, text, truncate=None):\n        if truncate is None:\n            truncate = pgettext(\n                'String to return when truncating text',\n                '%(truncated_text)s...')\n        if '%(truncated_text)s' in truncate:\n            return truncate % {'truncated_text': text}\n        # The truncation text didn't contain the %(truncated_text)s string\n        # replacement argument so just append it to the text.\n        if text.endswith(truncate):\n            # But don't append the truncation text if the current text already\n            # ends in this.\n            return text\n        return '%s%s' % (text, truncate)\n\n    def chars(self, num, truncate=None, html=False):\n        \"\"\"\n        Return the text truncated to be no longer than the specified number\n        of characters.\n\n        `truncate` specifies what should be used to notify that the string has\n        been truncated, defaulting to a translatable string of an ellipsis\n        (...).\n        \"\"\"\n        self._setup()\n        length = int(num)\n        text = unicodedata.normalize('NFC', self._wrapped)\n\n        # Calculate the length to truncate to (max length - end_text length)\n        truncate_len = length\n        for char in self.add_truncation_text('', truncate):\n            if not unicodedata.combining(char):\n                truncate_len -= 1\n                if truncate_len == 0:\n                    break\n        if html:\n            return self._truncate_html(length, truncate, text, truncate_len, False)\n        return self._text_chars(length, truncate, text, truncate_len)\n\n    def _text_chars(self, length, truncate, text, truncate_len):\n        \"\"\"Truncate a string after a certain number of chars.\"\"\"\n        s_len = 0\n        end_index = None\n        for i, char in enumerate(text):\n            if unicodedata.combining(char):\n                # Don't consider combining characters\n                # as adding to the string length\n                continue\n            s_len += 1\n            if end_index is None and s_len > truncate_len:\n                end_index = i\n            if s_len > length:\n                # Return the truncated string\n                return self.add_truncation_text(text[:end_index or 0],\n                                                truncate)\n\n        # Return the original string since no truncation was necessary\n        return text\n\n    def words(self, num, truncate=None, html=False):\n        \"\"\"\n        Truncate a string after a certain number of words. `truncate` specifies\n        what should be used to notify that the string has been truncated,\n        defaulting to ellipsis (...).\n        \"\"\"\n        self._setup()\n        length = int(num)\n        if html:\n            return self._truncate_html(length, truncate, self._wrapped, length, True)\n        return self._text_words(length, truncate)\n\n    def _text_words(self, length, truncate):\n        \"\"\"\n        Truncate a string after a certain number of words.\n\n        Strip newlines in the string.\n        \"\"\"\n        words = self._wrapped.split()\n        if len(words) > length:\n            words = words[:length]\n            return self.add_truncation_text(' '.join(words), truncate)\n        return ' '.join(words)\n\n    def _truncate_html(self, length, truncate, text, truncate_len, words):\n        \"\"\"\n        Truncate HTML to a certain number of chars (not counting tags and\n        comments), or, if words is True, then to a certain number of words.\n        Close opened tags if they were correctly closed in the given HTML.\n\n        Preserve newlines in the HTML.\n        \"\"\"\n        if words and length <= 0:\n            return ''\n\n        html4_singlets = (\n            'br', 'col', 'link', 'base', 'img',\n            'param', 'area', 'hr', 'input'\n        )\n\n        # Count non-HTML chars/words and keep note of open tags\n        pos = 0\n        end_text_pos = 0\n        current_len = 0\n        open_tags = []\n\n        regex = re_words if words else re_chars\n\n        while current_len <= length:\n            m = regex.search(text, pos)\n            if not m:\n                # Checked through whole string\n                break\n            pos = m.end(0)\n            if m.group(1):\n                # It's an actual non-HTML word or char\n                current_len += 1\n                if current_len == truncate_len:\n                    end_text_pos = pos\n                continue\n            # Check for tag\n            tag = re_tag.match(m.group(0))\n            if not tag or current_len >= truncate_len:\n                # Don't worry about non tags or tags after our truncate point\n                continue\n            closing_tag, tagname, self_closing = tag.groups()\n            # Element names are always case-insensitive\n            tagname = tagname.lower()\n            if self_closing or tagname in html4_singlets:\n                pass\n            elif closing_tag:\n                # Check for match in open tags list\n                try:\n                    i = open_tags.index(tagname)\n                except ValueError:\n                    pass\n                else:\n                    # SGML: An end tag closes, back to the matching start tag,\n                    # all unclosed intervening start tags with omitted end tags\n                    open_tags = open_tags[i + 1:]\n            else:\n                # Add it to the start of the open tags list\n                open_tags.insert(0, tagname)\n\n        if current_len <= length:\n            return text\n        out = text[:end_text_pos]\n        truncate_text = self.add_truncation_text('', truncate)\n        if truncate_text:\n            out += truncate_text\n        # Close any tags still open\n        for tag in open_tags:\n            out += '</%s>' % tag\n        # Return string\n        return out\n\n\n@keep_lazy_text\ndef get_valid_filename(s):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)\n\n\n@keep_lazy_text\ndef get_text_list(list_, last_word=gettext_lazy('or')):\n    \"\"\"\n    >>> get_text_list(['a', 'b', 'c', 'd'])\n    'a, b, c or d'\n    >>> get_text_list(['a', 'b', 'c'], 'and')\n    'a, b and c'\n    >>> get_text_list(['a', 'b'], 'and')\n    'a and b'\n    >>> get_text_list(['a'])\n    'a'\n    >>> get_text_list([])\n    ''\n    \"\"\"\n    if not list_:\n        return ''\n    if len(list_) == 1:\n        return str(list_[0])\n    return '%s %s %s' % (\n        # Translators: This string is used as a separator between list elements\n        _(', ').join(str(i) for i in list_[:-1]), str(last_word), str(list_[-1])\n    )\n\n\n@keep_lazy_text\ndef normalize_newlines(text):\n    \"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"\n    return re_newlines.sub('\\n', str(text))\n\n\n@keep_lazy_text\ndef phone2numeric(phone):\n    \"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"\n    char2number = {\n        'a': '2', 'b': '2', 'c': '2', 'd': '3', 'e': '3', 'f': '3', 'g': '4',\n        'h': '4', 'i': '4', 'j': '5', 'k': '5', 'l': '5', 'm': '6', 'n': '6',\n        'o': '6', 'p': '7', 'q': '7', 'r': '7', 's': '7', 't': '8', 'u': '8',\n        'v': '8', 'w': '9', 'x': '9', 'y': '9', 'z': '9',\n    }\n    return ''.join(char2number.get(c, c) for c in phone.lower())\n\n\n# From http://www.xhaus.com/alan/python/httpcomp.html#gzip\n# Used with permission.\ndef compress_string(s):\n    zbuf = BytesIO()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n        zfile.write(s)\n    return zbuf.getvalue()\n\n\nclass StreamingBuffer:\n    def __init__(self):\n        self.vals = []\n\n    def write(self, val):\n        self.vals.append(val)\n\n    def read(self):\n        if not self.vals:\n            return b''\n        ret = b''.join(self.vals)\n        self.vals = []\n        return ret\n\n    def flush(self):\n        return\n\n    def close(self):\n        return\n\n\n# Like compress_string, but for iterators of strings.\ndef compress_sequence(sequence):\n    buf = StreamingBuffer()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=buf, mtime=0) as zfile:\n        # Output headers...\n        yield buf.read()\n        for item in sequence:\n            zfile.write(item)\n            data = buf.read()\n            if data:\n                yield data\n    yield buf.read()\n\n\n# Expression to match some_token and some_token=\"with spaces\" (and similarly\n# for single-quoted strings).\nsmart_split_re = re.compile(r\"\"\"\n    ((?:\n        [^\\s'\"]*\n        (?:\n            (?:\"(?:[^\"\\\\]|\\\\.)*\" | '(?:[^'\\\\]|\\\\.)*')\n            [^\\s'\"]*\n        )+\n    ) | \\S+)\n\"\"\", re.VERBOSE)\n\n\ndef smart_split(text):\n    r\"\"\"\n    Generator that splits a string by spaces, leaving quoted phrases together.\n    Supports both single and double quotes, and supports escaping quotes with\n    backslashes. In the output, strings will keep their initial and trailing\n    quote marks and escaped quotes will remain escaped (the results can then\n    be further processed with unescape_string_literal()).\n\n    >>> list(smart_split(r'This is \"a person\\'s\" test.'))\n    ['This', 'is', '\"a person\\\\\\'s\"', 'test.']\n    >>> list(smart_split(r\"Another 'person\\'s' test.\"))\n    ['Another', \"'person\\\\'s'\", 'test.']\n    >>> list(smart_split(r'A \"\\\"funky\\\" style\" test.'))\n    ['A', '\"\\\\\"funky\\\\\" style\"', 'test.']\n    \"\"\"\n    for bit in smart_split_re.finditer(str(text)):\n        yield bit.group(0)\n\n\ndef _replace_entity(match):\n    text = match.group(1)\n    if text[0] == '#':\n        text = text[1:]\n        try:\n            if text[0] in 'xX':\n                c = int(text[1:], 16)\n            else:\n                c = int(text)\n            return chr(c)\n        except ValueError:\n            return match.group(0)\n    else:\n        try:\n            return chr(html.entities.name2codepoint[text])\n        except (ValueError, KeyError):\n            return match.group(0)\n\n\n_entity_re = re.compile(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\")\n\n\n@keep_lazy_text\ndef unescape_entities(text):\n    return _entity_re.sub(_replace_entity, str(text))\n\n\n@keep_lazy_text\ndef unescape_string_literal(s):\n    r\"\"\"\n    Convert quoted string literals to unquoted strings with escaped quotes and\n    backslashes unquoted::\n\n        >>> unescape_string_literal('\"abc\"')\n        'abc'\n        >>> unescape_string_literal(\"'abc'\")\n        'abc'\n        >>> unescape_string_literal('\"a \\\"bc\\\"\"')\n        'a \"bc\"'\n        >>> unescape_string_literal(\"'\\'ab\\' c'\")\n        \"'ab' c\"\n    \"\"\"\n    if s[0] not in \"\\\"'\" or s[-1] != s[0]:\n        raise ValueError(\"Not a string literal: %r\" % s)\n    quote = s[0]\n    return s[1:-1].replace(r'\\%s' % quote, quote).replace(r'\\\\', '\\\\')\n\n\n@keep_lazy(str, SafeText)\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces to hyphens.\n    Remove characters that aren't alphanumerics, underscores, or hyphens.\n    Convert to lowercase. Also strip leading and trailing whitespace.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return mark_safe(re.sub(r'[-\\s]+', '-', value))\n\n\ndef camel_case_to_spaces(value):\n    \"\"\"\n    Split CamelCase and convert to lower case. Strip surrounding whitespace.\n    \"\"\"\n    return re_camel_case.sub(r' \\1', value).strip().lower()\n\n\ndef _format_lazy(format_string, *args, **kwargs):\n    \"\"\"\n    Apply str.format() on 'format_string' where format_string, args,\n    and/or kwargs might be lazy.\n    \"\"\"\n    return format_string.format(*args, **kwargs)\n\n\nformat_lazy = lazy(_format_lazy, str)\n",
    "code_after": "import html.entities\nimport re\nimport unicodedata\nfrom gzip import GzipFile\nfrom io import BytesIO\n\nfrom django.utils.functional import (\n    SimpleLazyObject, keep_lazy, keep_lazy_text, lazy,\n)\nfrom django.utils.safestring import SafeText, mark_safe\nfrom django.utils.translation import gettext as _, gettext_lazy, pgettext\n\n\n@keep_lazy_text\ndef capfirst(x):\n    \"\"\"Capitalize the first letter of a string.\"\"\"\n    return x and str(x)[0].upper() + str(x)[1:]\n\n\n# Set up regular expressions\nre_words = re.compile(r'<.*?>|((?:\\w[-\\w]*|&.*?;)+)', re.S)\nre_chars = re.compile(r'<.*?>|(.)', re.S)\nre_tag = re.compile(r'<(/)?(\\S+?)(?:(\\s*/)|\\s.*?)?>', re.S)\nre_newlines = re.compile(r'\\r\\n|\\r')  # Used in normalize_newlines\nre_camel_case = re.compile(r'(((?<=[a-z])[A-Z])|([A-Z](?![A-Z]|$)))')\n\n\n@keep_lazy_text\ndef wrap(text, width):\n    \"\"\"\n    A word-wrap function that preserves existing line breaks. Expects that\n    existing line breaks are posix newlines.\n\n    Preserve all white space except added line breaks consume the space on\n    which they break the line.\n\n    Don't wrap long words, thus the output text may have lines longer than\n    ``width``.\n    \"\"\"\n    def _generator():\n        for line in text.splitlines(True):  # True keeps trailing linebreaks\n            max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            while len(line) > max_width:\n                space = line[:max_width + 1].rfind(' ') + 1\n                if space == 0:\n                    space = line.find(' ') + 1\n                    if space == 0:\n                        yield line\n                        line = ''\n                        break\n                yield '%s\\n' % line[:space - 1]\n                line = line[space:]\n                max_width = min((line.endswith('\\n') and width + 1 or width), width)\n            if line:\n                yield line\n    return ''.join(_generator())\n\n\nclass Truncator(SimpleLazyObject):\n    \"\"\"\n    An object used to truncate text, either by characters or words.\n    \"\"\"\n    def __init__(self, text):\n        super().__init__(lambda: str(text))\n\n    def add_truncation_text(self, text, truncate=None):\n        if truncate is None:\n            truncate = pgettext(\n                'String to return when truncating text',\n                '%(truncated_text)s...')\n        if '%(truncated_text)s' in truncate:\n            return truncate % {'truncated_text': text}\n        # The truncation text didn't contain the %(truncated_text)s string\n        # replacement argument so just append it to the text.\n        if text.endswith(truncate):\n            # But don't append the truncation text if the current text already\n            # ends in this.\n            return text\n        return '%s%s' % (text, truncate)\n\n    def chars(self, num, truncate=None, html=False):\n        \"\"\"\n        Return the text truncated to be no longer than the specified number\n        of characters.\n\n        `truncate` specifies what should be used to notify that the string has\n        been truncated, defaulting to a translatable string of an ellipsis\n        (...).\n        \"\"\"\n        self._setup()\n        length = int(num)\n        text = unicodedata.normalize('NFC', self._wrapped)\n\n        # Calculate the length to truncate to (max length - end_text length)\n        truncate_len = length\n        for char in self.add_truncation_text('', truncate):\n            if not unicodedata.combining(char):\n                truncate_len -= 1\n                if truncate_len == 0:\n                    break\n        if html:\n            return self._truncate_html(length, truncate, text, truncate_len, False)\n        return self._text_chars(length, truncate, text, truncate_len)\n\n    def _text_chars(self, length, truncate, text, truncate_len):\n        \"\"\"Truncate a string after a certain number of chars.\"\"\"\n        s_len = 0\n        end_index = None\n        for i, char in enumerate(text):\n            if unicodedata.combining(char):\n                # Don't consider combining characters\n                # as adding to the string length\n                continue\n            s_len += 1\n            if end_index is None and s_len > truncate_len:\n                end_index = i\n            if s_len > length:\n                # Return the truncated string\n                return self.add_truncation_text(text[:end_index or 0],\n                                                truncate)\n\n        # Return the original string since no truncation was necessary\n        return text\n\n    def words(self, num, truncate=None, html=False):\n        \"\"\"\n        Truncate a string after a certain number of words. `truncate` specifies\n        what should be used to notify that the string has been truncated,\n        defaulting to ellipsis (...).\n        \"\"\"\n        self._setup()\n        length = int(num)\n        if html:\n            return self._truncate_html(length, truncate, self._wrapped, length, True)\n        return self._text_words(length, truncate)\n\n    def _text_words(self, length, truncate):\n        \"\"\"\n        Truncate a string after a certain number of words.\n\n        Strip newlines in the string.\n        \"\"\"\n        words = self._wrapped.split()\n        if len(words) > length:\n            words = words[:length]\n            return self.add_truncation_text(' '.join(words), truncate)\n        return ' '.join(words)\n\n    def _truncate_html(self, length, truncate, text, truncate_len, words):\n        \"\"\"\n        Truncate HTML to a certain number of chars (not counting tags and\n        comments), or, if words is True, then to a certain number of words.\n        Close opened tags if they were correctly closed in the given HTML.\n\n        Preserve newlines in the HTML.\n        \"\"\"\n        if words and length <= 0:\n            return ''\n\n        html4_singlets = (\n            'br', 'col', 'link', 'base', 'img',\n            'param', 'area', 'hr', 'input'\n        )\n\n        # Count non-HTML chars/words and keep note of open tags\n        pos = 0\n        end_text_pos = 0\n        current_len = 0\n        open_tags = []\n\n        regex = re_words if words else re_chars\n\n        while current_len <= length:\n            m = regex.search(text, pos)\n            if not m:\n                # Checked through whole string\n                break\n            pos = m.end(0)\n            if m.group(1):\n                # It's an actual non-HTML word or char\n                current_len += 1\n                if current_len == truncate_len:\n                    end_text_pos = pos\n                continue\n            # Check for tag\n            tag = re_tag.match(m.group(0))\n            if not tag or current_len >= truncate_len:\n                # Don't worry about non tags or tags after our truncate point\n                continue\n            closing_tag, tagname, self_closing = tag.groups()\n            # Element names are always case-insensitive\n            tagname = tagname.lower()\n            if self_closing or tagname in html4_singlets:\n                pass\n            elif closing_tag:\n                # Check for match in open tags list\n                try:\n                    i = open_tags.index(tagname)\n                except ValueError:\n                    pass\n                else:\n                    # SGML: An end tag closes, back to the matching start tag,\n                    # all unclosed intervening start tags with omitted end tags\n                    open_tags = open_tags[i + 1:]\n            else:\n                # Add it to the start of the open tags list\n                open_tags.insert(0, tagname)\n\n        if current_len <= length:\n            return text\n        out = text[:end_text_pos]\n        truncate_text = self.add_truncation_text('', truncate)\n        if truncate_text:\n            out += truncate_text\n        # Close any tags still open\n        for tag in open_tags:\n            out += '</%s>' % tag\n        # Return string\n        return out\n\n\n@keep_lazy_text\ndef get_valid_filename(s):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)\n\n\n@keep_lazy_text\ndef get_text_list(list_, last_word=gettext_lazy('or')):\n    \"\"\"\n    >>> get_text_list(['a', 'b', 'c', 'd'])\n    'a, b, c or d'\n    >>> get_text_list(['a', 'b', 'c'], 'and')\n    'a, b and c'\n    >>> get_text_list(['a', 'b'], 'and')\n    'a and b'\n    >>> get_text_list(['a'])\n    'a'\n    >>> get_text_list([])\n    ''\n    \"\"\"\n    if not list_:\n        return ''\n    if len(list_) == 1:\n        return str(list_[0])\n    return '%s %s %s' % (\n        # Translators: This string is used as a separator between list elements\n        _(', ').join(str(i) for i in list_[:-1]), str(last_word), str(list_[-1])\n    )\n\n\n@keep_lazy_text\ndef normalize_newlines(text):\n    \"\"\"Normalize CRLF and CR newlines to just LF.\"\"\"\n    return re_newlines.sub('\\n', str(text))\n\n\n@keep_lazy_text\ndef phone2numeric(phone):\n    \"\"\"Convert a phone number with letters into its numeric equivalent.\"\"\"\n    char2number = {\n        'a': '2', 'b': '2', 'c': '2', 'd': '3', 'e': '3', 'f': '3', 'g': '4',\n        'h': '4', 'i': '4', 'j': '5', 'k': '5', 'l': '5', 'm': '6', 'n': '6',\n        'o': '6', 'p': '7', 'q': '7', 'r': '7', 's': '7', 't': '8', 'u': '8',\n        'v': '8', 'w': '9', 'x': '9', 'y': '9', 'z': '9',\n    }\n    return ''.join(char2number.get(c, c) for c in phone.lower())\n\n\n# From http://www.xhaus.com/alan/python/httpcomp.html#gzip\n# Used with permission.\ndef compress_string(s):\n    zbuf = BytesIO()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, mtime=0) as zfile:\n        zfile.write(s)\n    return zbuf.getvalue()\n\n\nclass StreamingBuffer:\n    def __init__(self):\n        self.vals = []\n\n    def write(self, val):\n        self.vals.append(val)\n\n    def read(self):\n        if not self.vals:\n            return b''\n        ret = b''.join(self.vals)\n        self.vals = []\n        return ret\n\n    def flush(self):\n        return\n\n    def close(self):\n        return\n\n\n# Like compress_string, but for iterators of strings.\ndef compress_sequence(sequence):\n    buf = StreamingBuffer()\n    with GzipFile(mode='wb', compresslevel=6, fileobj=buf, mtime=0) as zfile:\n        # Output headers...\n        yield buf.read()\n        for item in sequence:\n            zfile.write(item)\n            data = buf.read()\n            if data:\n                yield data\n    yield buf.read()\n\n\n# Expression to match some_token and some_token=\"with spaces\" (and similarly\n# for single-quoted strings).\nsmart_split_re = re.compile(r\"\"\"\n    ((?:\n        [^\\s'\"]*\n        (?:\n            (?:\"(?:[^\"\\\\]|\\\\.)*\" | '(?:[^'\\\\]|\\\\.)*')\n            [^\\s'\"]*\n        )+\n    ) | \\S+)\n\"\"\", re.VERBOSE)\n\n\ndef smart_split(text):\n    r\"\"\"\n    Generator that splits a string by spaces, leaving quoted phrases together.\n    Supports both single and double quotes, and supports escaping quotes with\n    backslashes. In the output, strings will keep their initial and trailing\n    quote marks and escaped quotes will remain escaped (the results can then\n    be further processed with unescape_string_literal()).\n\n    >>> list(smart_split(r'This is \"a person\\'s\" test.'))\n    ['This', 'is', '\"a person\\\\\\'s\"', 'test.']\n    >>> list(smart_split(r\"Another 'person\\'s' test.\"))\n    ['Another', \"'person\\\\'s'\", 'test.']\n    >>> list(smart_split(r'A \"\\\"funky\\\" style\" test.'))\n    ['A', '\"\\\\\"funky\\\\\" style\"', 'test.']\n    \"\"\"\n    for bit in smart_split_re.finditer(str(text)):\n        yield bit.group(0)\n\n\ndef _replace_entity(match):\n    text = match.group(1)\n    if text[0] == '#':\n        text = text[1:]\n        try:\n            if text[0] in 'xX':\n                c = int(text[1:], 16)\n            else:\n                c = int(text)\n            return chr(c)\n        except ValueError:\n            return match.group(0)\n    else:\n        try:\n            return chr(html.entities.name2codepoint[text])\n        except (ValueError, KeyError):\n            return match.group(0)\n\n\n_entity_re = re.compile(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\")\n\n\n@keep_lazy_text\ndef unescape_entities(text):\n    return _entity_re.sub(_replace_entity, str(text))\n\n\n@keep_lazy_text\ndef unescape_string_literal(s):\n    r\"\"\"\n    Convert quoted string literals to unquoted strings with escaped quotes and\n    backslashes unquoted::\n\n        >>> unescape_string_literal('\"abc\"')\n        'abc'\n        >>> unescape_string_literal(\"'abc'\")\n        'abc'\n        >>> unescape_string_literal('\"a \\\"bc\\\"\"')\n        'a \"bc\"'\n        >>> unescape_string_literal(\"'\\'ab\\' c'\")\n        \"'ab' c\"\n    \"\"\"\n    if s[0] not in \"\\\"'\" or s[-1] != s[0]:\n        raise ValueError(\"Not a string literal: %r\" % s)\n    quote = s[0]\n    return s[1:-1].replace(r'\\%s' % quote, quote).replace(r'\\\\', '\\\\')\n\n\n@keep_lazy(str, SafeText)\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces to hyphens.\n    Remove characters that aren't alphanumerics, underscores, or hyphens.\n    Convert to lowercase. Also strip leading and trailing whitespace.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n    return mark_safe(re.sub(r'[-\\s]+', '-', value))\n\n\ndef camel_case_to_spaces(value):\n    \"\"\"\n    Split CamelCase and convert to lower case. Strip surrounding whitespace.\n    \"\"\"\n    return re_camel_case.sub(r' \\1', value).strip().lower()\n\n\ndef _format_lazy(format_string, *args, **kwargs):\n    \"\"\"\n    Apply str.format() on 'format_string' where format_string, args,\n    and/or kwargs might be lazy.\n    \"\"\"\n    return format_string.format(*args, **kwargs)\n\n\nformat_lazy = lazy(_format_lazy, str)\n"
  },
  {
    "patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex ed105b2869..c5035e3b23 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -13,12 +13,7 @@ from django.utils.safestring import SafeData, SafeText, mark_safe\n from django.utils.text import normalize_newlines\n \n # Configuration for urlize() function.\n-TRAILING_PUNCTUATION_RE = re.compile(\n-    '^'           # Beginning of word\n-    '(.*?)'       # The URL in word\n-    '([.,:;!]+)'  # Allowed non-wrapping, trailing punctuation\n-    '$'           # End of word\n-)\n+TRAILING_PUNCTUATION_CHARS = '.,:;!'\n WRAPPING_PUNCTUATION = [('(', ')'), ('<', '>'), ('[', ']'), ('&lt;', '&gt;'), ('\"', '\"'), ('\\'', '\\'')]\n \n # List of possible strings used for bullets in bulleted lists.\n@@ -28,7 +23,6 @@ unencoded_ampersands_re = re.compile(r'&(?!(\\w+|#\\d+);)')\n word_split_re = re.compile(r'''([\\s<>\"']+)''')\n simple_url_re = re.compile(r'^https?://\\[?\\w', re.IGNORECASE)\n simple_url_2_re = re.compile(r'^www\\.|^(?!http)\\w[^@]+\\.(com|edu|gov|int|mil|net|org)($|/.*)$', re.IGNORECASE)\n-simple_email_re = re.compile(r'^\\S+@\\S+\\.\\S+$')\n \n _html_escapes = {\n     ord('&'): '&amp;',\n@@ -293,10 +287,10 @@ def urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n             trimmed_something = False\n \n             # Trim trailing punctuation.\n-            match = TRAILING_PUNCTUATION_RE.match(middle)\n-            if match:\n-                middle = match.group(1)\n-                trail = match.group(2) + trail\n+            stripped = middle.rstrip(TRAILING_PUNCTUATION_CHARS)\n+            if middle != stripped:\n+                trail = middle[len(stripped):] + trail\n+                middle = stripped\n                 trimmed_something = True\n \n             # Trim wrapping punctuation.\n@@ -313,6 +307,21 @@ def urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n                     trimmed_something = True\n         return lead, middle, trail\n \n+    def is_email_simple(value):\n+        \"\"\"Return True if value looks like an email address.\"\"\"\n+        # An @ must be in the middle of the value.\n+        if '@' not in value or value.startswith('@') or value.endswith('@'):\n+            return False\n+        try:\n+            p1, p2 = value.split('@')\n+        except ValueError:\n+            # value contains more than one @.\n+            return False\n+        # Dot must be in p2 (e.g. example.com)\n+        if '.' not in p2 or p2.startswith('.'):\n+            return False\n+        return True\n+\n     words = word_split_re.split(str(text))\n     for i, word in enumerate(words):\n         if '.' in word or '@' in word or ':' in word:\n@@ -332,7 +341,7 @@ def urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n             elif simple_url_2_re.match(middle):\n                 middle, middle_unescaped, trail = unescape(middle, trail)\n                 url = smart_urlquote('http://%s' % middle_unescaped)\n-            elif ':' not in middle and simple_email_re.match(middle):\n+            elif ':' not in middle and is_email_simple(middle):\n                 local, domain = middle.rsplit('@', 1)\n                 try:\n                     domain = domain.encode('idna').decode('ascii')\n",
    "commit_message": "Fixed CVE-2018-7536 -- Fixed catastrophic backtracking in urlize and urlizetrunc template filters.\n\nThanks Florian Apolloner for assisting with the patch.\n\n",
    "code_before": "\"\"\"HTML utilities suitable for global use.\"\"\"\n\nimport json\nimport re\nfrom html.parser import HTMLParser\nfrom urllib.parse import (\n    parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n)\n\nfrom django.utils.functional import Promise, keep_lazy, keep_lazy_text\nfrom django.utils.http import RFC3986_GENDELIMS, RFC3986_SUBDELIMS\nfrom django.utils.safestring import SafeData, SafeText, mark_safe\nfrom django.utils.text import normalize_newlines\n\n# Configuration for urlize() function.\nTRAILING_PUNCTUATION_RE = re.compile(\n    '^'           # Beginning of word\n    '(.*?)'       # The URL in word\n    '([.,:;!]+)'  # Allowed non-wrapping, trailing punctuation\n    '$'           # End of word\n)\nWRAPPING_PUNCTUATION = [('(', ')'), ('<', '>'), ('[', ']'), ('&lt;', '&gt;'), ('\"', '\"'), ('\\'', '\\'')]\n\n# List of possible strings used for bullets in bulleted lists.\nDOTS = ['&middot;', '*', '\\u2022', '&#149;', '&bull;', '&#8226;']\n\nunencoded_ampersands_re = re.compile(r'&(?!(\\w+|#\\d+);)')\nword_split_re = re.compile(r'''([\\s<>\"']+)''')\nsimple_url_re = re.compile(r'^https?://\\[?\\w', re.IGNORECASE)\nsimple_url_2_re = re.compile(r'^www\\.|^(?!http)\\w[^@]+\\.(com|edu|gov|int|mil|net|org)($|/.*)$', re.IGNORECASE)\nsimple_email_re = re.compile(r'^\\S+@\\S+\\.\\S+$')\n\n_html_escapes = {\n    ord('&'): '&amp;',\n    ord('<'): '&lt;',\n    ord('>'): '&gt;',\n    ord('\"'): '&quot;',\n    ord(\"'\"): '&#39;',\n}\n\n\n@keep_lazy(str, SafeText)\ndef escape(text):\n    \"\"\"\n    Return the given text with ampersands, quotes and angle brackets encoded\n    for use in HTML.\n\n    Always escape input, even if it's already escaped and marked as such.\n    This may result in double-escaping. If this is a concern, use\n    conditional_escape() instead.\n    \"\"\"\n    return mark_safe(str(text).translate(_html_escapes))\n\n\n_js_escapes = {\n    ord('\\\\'): '\\\\u005C',\n    ord('\\''): '\\\\u0027',\n    ord('\"'): '\\\\u0022',\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n    ord('='): '\\\\u003D',\n    ord('-'): '\\\\u002D',\n    ord(';'): '\\\\u003B',\n    ord('`'): '\\\\u0060',\n    ord('\\u2028'): '\\\\u2028',\n    ord('\\u2029'): '\\\\u2029'\n}\n\n# Escape every ASCII character with a value less than 32.\n_js_escapes.update((ord('%c' % z), '\\\\u%04X' % z) for z in range(32))\n\n\n@keep_lazy(str, SafeText)\ndef escapejs(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return mark_safe(str(value).translate(_js_escapes))\n\n\n_json_script_escapes = {\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n}\n\n\ndef json_script(value, element_id):\n    \"\"\"\n    Escape all the HTML/XML special characters with their unicode escapes, so\n    value is safe to be output anywhere except for inside a tag attribute. Wrap\n    the escaped JSON in a script tag.\n    \"\"\"\n    from django.core.serializers.json import DjangoJSONEncoder\n    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    return format_html(\n        '<script id=\"{}\" type=\"application/json\">{}</script>',\n        element_id, mark_safe(json_str)\n    )\n\n\ndef conditional_escape(text):\n    \"\"\"\n    Similar to escape(), except that it doesn't operate on pre-escaped strings.\n\n    This function relies on the __html__ convention used both by Django's\n    SafeData class and by third-party libraries like markupsafe.\n    \"\"\"\n    if isinstance(text, Promise):\n        text = str(text)\n    if hasattr(text, '__html__'):\n        return text.__html__()\n    else:\n        return escape(text)\n\n\ndef format_html(format_string, *args, **kwargs):\n    \"\"\"\n    Similar to str.format, but pass all arguments through conditional_escape(),\n    and call mark_safe() on the result. This function should be used instead\n    of str.format or % interpolation to build up small HTML fragments.\n    \"\"\"\n    args_safe = map(conditional_escape, args)\n    kwargs_safe = {k: conditional_escape(v) for (k, v) in kwargs.items()}\n    return mark_safe(format_string.format(*args_safe, **kwargs_safe))\n\n\ndef format_html_join(sep, format_string, args_generator):\n    \"\"\"\n    A wrapper of format_html, for the common case of a group of arguments that\n    need to be formatted using the same format string, and then joined using\n    'sep'. 'sep' is also passed through conditional_escape.\n\n    'args_generator' should be an iterator that returns the sequence of 'args'\n    that will be passed to format_html.\n\n    Example:\n\n      format_html_join('\\n', \"<li>{} {}</li>\", ((u.first_name, u.last_name)\n                                                  for u in users))\n    \"\"\"\n    return mark_safe(conditional_escape(sep).join(\n        format_html(format_string, *tuple(args))\n        for args in args_generator))\n\n\n@keep_lazy_text\ndef linebreaks(value, autoescape=False):\n    \"\"\"Convert newlines into <p> and <br>s.\"\"\"\n    value = normalize_newlines(value)\n    paras = re.split('\\n{2,}', str(value))\n    if autoescape:\n        paras = ['<p>%s</p>' % escape(p).replace('\\n', '<br>') for p in paras]\n    else:\n        paras = ['<p>%s</p>' % p.replace('\\n', '<br>') for p in paras]\n    return '\\n\\n'.join(paras)\n\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        super().__init__(convert_charrefs=False)\n        self.reset()\n        self.fed = []\n\n    def handle_data(self, d):\n        self.fed.append(d)\n\n    def handle_entityref(self, name):\n        self.fed.append('&%s;' % name)\n\n    def handle_charref(self, name):\n        self.fed.append('&#%s;' % name)\n\n    def get_data(self):\n        return ''.join(self.fed)\n\n\ndef _strip_once(value):\n    \"\"\"\n    Internal tag stripping utility used by strip_tags.\n    \"\"\"\n    s = MLStripper()\n    s.feed(value)\n    s.close()\n    return s.get_data()\n\n\n@keep_lazy_text\ndef strip_tags(value):\n    \"\"\"Return the given HTML with all tags stripped.\"\"\"\n    # Note: in typical case this loop executes _strip_once once. Loop condition\n    # is redundant, but helps to reduce number of executions of _strip_once.\n    value = str(value)\n    while '<' in value and '>' in value:\n        new_value = _strip_once(value)\n        if len(new_value) >= len(value):\n            # _strip_once was not able to detect more tags\n            break\n        value = new_value\n    return value\n\n\n@keep_lazy_text\ndef strip_spaces_between_tags(value):\n    \"\"\"Return the given HTML with spaces between tags removed.\"\"\"\n    return re.sub(r'>\\s+<', '><', str(value))\n\n\ndef smart_urlquote(url):\n    \"\"\"Quote a URL if it isn't already quoted.\"\"\"\n    def unquote_quote(segment):\n        segment = unquote(segment)\n        # Tilde is part of RFC3986 Unreserved Characters\n        # http://tools.ietf.org/html/rfc3986#section-2.3\n        # See also http://bugs.python.org/issue16285\n        return quote(segment, safe=RFC3986_SUBDELIMS + RFC3986_GENDELIMS + '~')\n\n    # Handle IDN before quoting.\n    try:\n        scheme, netloc, path, query, fragment = urlsplit(url)\n    except ValueError:\n        # invalid IPv6 URL (normally square brackets in hostname part).\n        return unquote_quote(url)\n\n    try:\n        netloc = netloc.encode('idna').decode('ascii')  # IDN -> ACE\n    except UnicodeError:  # invalid domain part\n        return unquote_quote(url)\n\n    if query:\n        # Separately unquoting key/value, so as to not mix querystring separators\n        # included in query values. See #22267.\n        query_parts = [(unquote(q[0]), unquote(q[1]))\n                       for q in parse_qsl(query, keep_blank_values=True)]\n        # urlencode will take care of quoting\n        query = urlencode(query_parts)\n\n    path = unquote_quote(path)\n    fragment = unquote_quote(fragment)\n\n    return urlunsplit((scheme, netloc, path, query, fragment))\n\n\n@keep_lazy_text\ndef urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n    \"\"\"\n    Convert any URLs in text into clickable links.\n\n    Works on http://, https://, www. links, and also on links ending in one of\n    the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).\n    Links can have trailing punctuation (periods, commas, close-parens) and\n    leading punctuation (opening parens) and it'll still do the right thing.\n\n    If trim_url_limit is not None, truncate the URLs in the link text longer\n    than this limit to trim_url_limit-3 characters and append an ellipsis.\n\n    If nofollow is True, give the links a rel=\"nofollow\" attribute.\n\n    If autoescape is True, autoescape the link text and URLs.\n    \"\"\"\n    safe_input = isinstance(text, SafeData)\n\n    def trim_url(x, limit=trim_url_limit):\n        if limit is None or len(x) <= limit:\n            return x\n        return '%s...' % x[:max(0, limit - 3)]\n\n    def unescape(text, trail):\n        \"\"\"\n        If input URL is HTML-escaped, unescape it so that it can be safely fed\n        to smart_urlquote. For example:\n        http://example.com?x=1&amp;y=&lt;2&gt; => http://example.com?x=1&y=<2>\n        \"\"\"\n        unescaped = (text + trail).replace(\n            '&amp;', '&').replace('&lt;', '<').replace(\n            '&gt;', '>').replace('&quot;', '\"').replace('&#39;', \"'\")\n        if trail and unescaped.endswith(trail):\n            # Remove trail for unescaped if it was not consumed by unescape\n            unescaped = unescaped[:-len(trail)]\n        elif trail == ';':\n            # Trail was consumed by unescape (as end-of-entity marker), move it to text\n            text += trail\n            trail = ''\n        return text, unescaped, trail\n\n    def trim_punctuation(lead, middle, trail):\n        \"\"\"\n        Trim trailing and wrapping punctuation from `middle`. Return the items\n        of the new state.\n        \"\"\"\n        # Continue trimming until middle remains unchanged.\n        trimmed_something = True\n        while trimmed_something:\n            trimmed_something = False\n\n            # Trim trailing punctuation.\n            match = TRAILING_PUNCTUATION_RE.match(middle)\n            if match:\n                middle = match.group(1)\n                trail = match.group(2) + trail\n                trimmed_something = True\n\n            # Trim wrapping punctuation.\n            for opening, closing in WRAPPING_PUNCTUATION:\n                if middle.startswith(opening):\n                    middle = middle[len(opening):]\n                    lead += opening\n                    trimmed_something = True\n                # Keep parentheses at the end only if they're balanced.\n                if (middle.endswith(closing) and\n                        middle.count(closing) == middle.count(opening) + 1):\n                    middle = middle[:-len(closing)]\n                    trail = closing + trail\n                    trimmed_something = True\n        return lead, middle, trail\n\n    words = word_split_re.split(str(text))\n    for i, word in enumerate(words):\n        if '.' in word or '@' in word or ':' in word:\n            # lead: Current punctuation trimmed from the beginning of the word.\n            # middle: Current state of the word.\n            # trail: Current punctuation trimmed from the end of the word.\n            lead, middle, trail = '', word, ''\n            # Deal with punctuation.\n            lead, middle, trail = trim_punctuation(lead, middle, trail)\n\n            # Make URL we want to point to.\n            url = None\n            nofollow_attr = ' rel=\"nofollow\"' if nofollow else ''\n            if simple_url_re.match(middle):\n                middle, middle_unescaped, trail = unescape(middle, trail)\n                url = smart_urlquote(middle_unescaped)\n            elif simple_url_2_re.match(middle):\n                middle, middle_unescaped, trail = unescape(middle, trail)\n                url = smart_urlquote('http://%s' % middle_unescaped)\n            elif ':' not in middle and simple_email_re.match(middle):\n                local, domain = middle.rsplit('@', 1)\n                try:\n                    domain = domain.encode('idna').decode('ascii')\n                except UnicodeError:\n                    continue\n                url = 'mailto:%s@%s' % (local, domain)\n                nofollow_attr = ''\n\n            # Make link.\n            if url:\n                trimmed = trim_url(middle)\n                if autoescape and not safe_input:\n                    lead, trail = escape(lead), escape(trail)\n                    trimmed = escape(trimmed)\n                middle = '<a href=\"%s\"%s>%s</a>' % (escape(url), nofollow_attr, trimmed)\n                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))\n            else:\n                if safe_input:\n                    words[i] = mark_safe(word)\n                elif autoescape:\n                    words[i] = escape(word)\n        elif safe_input:\n            words[i] = mark_safe(word)\n        elif autoescape:\n            words[i] = escape(word)\n    return ''.join(words)\n\n\ndef avoid_wrapping(value):\n    \"\"\"\n    Avoid text wrapping in the middle of a phrase by adding non-breaking\n    spaces where there previously were normal spaces.\n    \"\"\"\n    return value.replace(\" \", \"\\xa0\")\n\n\ndef html_safe(klass):\n    \"\"\"\n    A decorator that defines the __html__ method. This helps non-Django\n    templates to detect classes whose __str__ methods return SafeText.\n    \"\"\"\n    if '__html__' in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it defines \"\n            \"__html__().\" % klass.__name__\n        )\n    if '__str__' not in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it doesn't \"\n            \"define __str__().\" % klass.__name__\n        )\n    klass_str = klass.__str__\n    klass.__str__ = lambda self: mark_safe(klass_str(self))\n    klass.__html__ = lambda self: str(self)\n    return klass\n",
    "code_after": "\"\"\"HTML utilities suitable for global use.\"\"\"\n\nimport json\nimport re\nfrom html.parser import HTMLParser\nfrom urllib.parse import (\n    parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n)\n\nfrom django.utils.functional import Promise, keep_lazy, keep_lazy_text\nfrom django.utils.http import RFC3986_GENDELIMS, RFC3986_SUBDELIMS\nfrom django.utils.safestring import SafeData, SafeText, mark_safe\nfrom django.utils.text import normalize_newlines\n\n# Configuration for urlize() function.\nTRAILING_PUNCTUATION_CHARS = '.,:;!'\nWRAPPING_PUNCTUATION = [('(', ')'), ('<', '>'), ('[', ']'), ('&lt;', '&gt;'), ('\"', '\"'), ('\\'', '\\'')]\n\n# List of possible strings used for bullets in bulleted lists.\nDOTS = ['&middot;', '*', '\\u2022', '&#149;', '&bull;', '&#8226;']\n\nunencoded_ampersands_re = re.compile(r'&(?!(\\w+|#\\d+);)')\nword_split_re = re.compile(r'''([\\s<>\"']+)''')\nsimple_url_re = re.compile(r'^https?://\\[?\\w', re.IGNORECASE)\nsimple_url_2_re = re.compile(r'^www\\.|^(?!http)\\w[^@]+\\.(com|edu|gov|int|mil|net|org)($|/.*)$', re.IGNORECASE)\n\n_html_escapes = {\n    ord('&'): '&amp;',\n    ord('<'): '&lt;',\n    ord('>'): '&gt;',\n    ord('\"'): '&quot;',\n    ord(\"'\"): '&#39;',\n}\n\n\n@keep_lazy(str, SafeText)\ndef escape(text):\n    \"\"\"\n    Return the given text with ampersands, quotes and angle brackets encoded\n    for use in HTML.\n\n    Always escape input, even if it's already escaped and marked as such.\n    This may result in double-escaping. If this is a concern, use\n    conditional_escape() instead.\n    \"\"\"\n    return mark_safe(str(text).translate(_html_escapes))\n\n\n_js_escapes = {\n    ord('\\\\'): '\\\\u005C',\n    ord('\\''): '\\\\u0027',\n    ord('\"'): '\\\\u0022',\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n    ord('='): '\\\\u003D',\n    ord('-'): '\\\\u002D',\n    ord(';'): '\\\\u003B',\n    ord('`'): '\\\\u0060',\n    ord('\\u2028'): '\\\\u2028',\n    ord('\\u2029'): '\\\\u2029'\n}\n\n# Escape every ASCII character with a value less than 32.\n_js_escapes.update((ord('%c' % z), '\\\\u%04X' % z) for z in range(32))\n\n\n@keep_lazy(str, SafeText)\ndef escapejs(value):\n    \"\"\"Hex encode characters for use in JavaScript strings.\"\"\"\n    return mark_safe(str(value).translate(_js_escapes))\n\n\n_json_script_escapes = {\n    ord('>'): '\\\\u003E',\n    ord('<'): '\\\\u003C',\n    ord('&'): '\\\\u0026',\n}\n\n\ndef json_script(value, element_id):\n    \"\"\"\n    Escape all the HTML/XML special characters with their unicode escapes, so\n    value is safe to be output anywhere except for inside a tag attribute. Wrap\n    the escaped JSON in a script tag.\n    \"\"\"\n    from django.core.serializers.json import DjangoJSONEncoder\n    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    return format_html(\n        '<script id=\"{}\" type=\"application/json\">{}</script>',\n        element_id, mark_safe(json_str)\n    )\n\n\ndef conditional_escape(text):\n    \"\"\"\n    Similar to escape(), except that it doesn't operate on pre-escaped strings.\n\n    This function relies on the __html__ convention used both by Django's\n    SafeData class and by third-party libraries like markupsafe.\n    \"\"\"\n    if isinstance(text, Promise):\n        text = str(text)\n    if hasattr(text, '__html__'):\n        return text.__html__()\n    else:\n        return escape(text)\n\n\ndef format_html(format_string, *args, **kwargs):\n    \"\"\"\n    Similar to str.format, but pass all arguments through conditional_escape(),\n    and call mark_safe() on the result. This function should be used instead\n    of str.format or % interpolation to build up small HTML fragments.\n    \"\"\"\n    args_safe = map(conditional_escape, args)\n    kwargs_safe = {k: conditional_escape(v) for (k, v) in kwargs.items()}\n    return mark_safe(format_string.format(*args_safe, **kwargs_safe))\n\n\ndef format_html_join(sep, format_string, args_generator):\n    \"\"\"\n    A wrapper of format_html, for the common case of a group of arguments that\n    need to be formatted using the same format string, and then joined using\n    'sep'. 'sep' is also passed through conditional_escape.\n\n    'args_generator' should be an iterator that returns the sequence of 'args'\n    that will be passed to format_html.\n\n    Example:\n\n      format_html_join('\\n', \"<li>{} {}</li>\", ((u.first_name, u.last_name)\n                                                  for u in users))\n    \"\"\"\n    return mark_safe(conditional_escape(sep).join(\n        format_html(format_string, *tuple(args))\n        for args in args_generator))\n\n\n@keep_lazy_text\ndef linebreaks(value, autoescape=False):\n    \"\"\"Convert newlines into <p> and <br>s.\"\"\"\n    value = normalize_newlines(value)\n    paras = re.split('\\n{2,}', str(value))\n    if autoescape:\n        paras = ['<p>%s</p>' % escape(p).replace('\\n', '<br>') for p in paras]\n    else:\n        paras = ['<p>%s</p>' % p.replace('\\n', '<br>') for p in paras]\n    return '\\n\\n'.join(paras)\n\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        super().__init__(convert_charrefs=False)\n        self.reset()\n        self.fed = []\n\n    def handle_data(self, d):\n        self.fed.append(d)\n\n    def handle_entityref(self, name):\n        self.fed.append('&%s;' % name)\n\n    def handle_charref(self, name):\n        self.fed.append('&#%s;' % name)\n\n    def get_data(self):\n        return ''.join(self.fed)\n\n\ndef _strip_once(value):\n    \"\"\"\n    Internal tag stripping utility used by strip_tags.\n    \"\"\"\n    s = MLStripper()\n    s.feed(value)\n    s.close()\n    return s.get_data()\n\n\n@keep_lazy_text\ndef strip_tags(value):\n    \"\"\"Return the given HTML with all tags stripped.\"\"\"\n    # Note: in typical case this loop executes _strip_once once. Loop condition\n    # is redundant, but helps to reduce number of executions of _strip_once.\n    value = str(value)\n    while '<' in value and '>' in value:\n        new_value = _strip_once(value)\n        if len(new_value) >= len(value):\n            # _strip_once was not able to detect more tags\n            break\n        value = new_value\n    return value\n\n\n@keep_lazy_text\ndef strip_spaces_between_tags(value):\n    \"\"\"Return the given HTML with spaces between tags removed.\"\"\"\n    return re.sub(r'>\\s+<', '><', str(value))\n\n\ndef smart_urlquote(url):\n    \"\"\"Quote a URL if it isn't already quoted.\"\"\"\n    def unquote_quote(segment):\n        segment = unquote(segment)\n        # Tilde is part of RFC3986 Unreserved Characters\n        # http://tools.ietf.org/html/rfc3986#section-2.3\n        # See also http://bugs.python.org/issue16285\n        return quote(segment, safe=RFC3986_SUBDELIMS + RFC3986_GENDELIMS + '~')\n\n    # Handle IDN before quoting.\n    try:\n        scheme, netloc, path, query, fragment = urlsplit(url)\n    except ValueError:\n        # invalid IPv6 URL (normally square brackets in hostname part).\n        return unquote_quote(url)\n\n    try:\n        netloc = netloc.encode('idna').decode('ascii')  # IDN -> ACE\n    except UnicodeError:  # invalid domain part\n        return unquote_quote(url)\n\n    if query:\n        # Separately unquoting key/value, so as to not mix querystring separators\n        # included in query values. See #22267.\n        query_parts = [(unquote(q[0]), unquote(q[1]))\n                       for q in parse_qsl(query, keep_blank_values=True)]\n        # urlencode will take care of quoting\n        query = urlencode(query_parts)\n\n    path = unquote_quote(path)\n    fragment = unquote_quote(fragment)\n\n    return urlunsplit((scheme, netloc, path, query, fragment))\n\n\n@keep_lazy_text\ndef urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n    \"\"\"\n    Convert any URLs in text into clickable links.\n\n    Works on http://, https://, www. links, and also on links ending in one of\n    the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).\n    Links can have trailing punctuation (periods, commas, close-parens) and\n    leading punctuation (opening parens) and it'll still do the right thing.\n\n    If trim_url_limit is not None, truncate the URLs in the link text longer\n    than this limit to trim_url_limit-3 characters and append an ellipsis.\n\n    If nofollow is True, give the links a rel=\"nofollow\" attribute.\n\n    If autoescape is True, autoescape the link text and URLs.\n    \"\"\"\n    safe_input = isinstance(text, SafeData)\n\n    def trim_url(x, limit=trim_url_limit):\n        if limit is None or len(x) <= limit:\n            return x\n        return '%s...' % x[:max(0, limit - 3)]\n\n    def unescape(text, trail):\n        \"\"\"\n        If input URL is HTML-escaped, unescape it so that it can be safely fed\n        to smart_urlquote. For example:\n        http://example.com?x=1&amp;y=&lt;2&gt; => http://example.com?x=1&y=<2>\n        \"\"\"\n        unescaped = (text + trail).replace(\n            '&amp;', '&').replace('&lt;', '<').replace(\n            '&gt;', '>').replace('&quot;', '\"').replace('&#39;', \"'\")\n        if trail and unescaped.endswith(trail):\n            # Remove trail for unescaped if it was not consumed by unescape\n            unescaped = unescaped[:-len(trail)]\n        elif trail == ';':\n            # Trail was consumed by unescape (as end-of-entity marker), move it to text\n            text += trail\n            trail = ''\n        return text, unescaped, trail\n\n    def trim_punctuation(lead, middle, trail):\n        \"\"\"\n        Trim trailing and wrapping punctuation from `middle`. Return the items\n        of the new state.\n        \"\"\"\n        # Continue trimming until middle remains unchanged.\n        trimmed_something = True\n        while trimmed_something:\n            trimmed_something = False\n\n            # Trim trailing punctuation.\n            stripped = middle.rstrip(TRAILING_PUNCTUATION_CHARS)\n            if middle != stripped:\n                trail = middle[len(stripped):] + trail\n                middle = stripped\n                trimmed_something = True\n\n            # Trim wrapping punctuation.\n            for opening, closing in WRAPPING_PUNCTUATION:\n                if middle.startswith(opening):\n                    middle = middle[len(opening):]\n                    lead += opening\n                    trimmed_something = True\n                # Keep parentheses at the end only if they're balanced.\n                if (middle.endswith(closing) and\n                        middle.count(closing) == middle.count(opening) + 1):\n                    middle = middle[:-len(closing)]\n                    trail = closing + trail\n                    trimmed_something = True\n        return lead, middle, trail\n\n    def is_email_simple(value):\n        \"\"\"Return True if value looks like an email address.\"\"\"\n        # An @ must be in the middle of the value.\n        if '@' not in value or value.startswith('@') or value.endswith('@'):\n            return False\n        try:\n            p1, p2 = value.split('@')\n        except ValueError:\n            # value contains more than one @.\n            return False\n        # Dot must be in p2 (e.g. example.com)\n        if '.' not in p2 or p2.startswith('.'):\n            return False\n        return True\n\n    words = word_split_re.split(str(text))\n    for i, word in enumerate(words):\n        if '.' in word or '@' in word or ':' in word:\n            # lead: Current punctuation trimmed from the beginning of the word.\n            # middle: Current state of the word.\n            # trail: Current punctuation trimmed from the end of the word.\n            lead, middle, trail = '', word, ''\n            # Deal with punctuation.\n            lead, middle, trail = trim_punctuation(lead, middle, trail)\n\n            # Make URL we want to point to.\n            url = None\n            nofollow_attr = ' rel=\"nofollow\"' if nofollow else ''\n            if simple_url_re.match(middle):\n                middle, middle_unescaped, trail = unescape(middle, trail)\n                url = smart_urlquote(middle_unescaped)\n            elif simple_url_2_re.match(middle):\n                middle, middle_unescaped, trail = unescape(middle, trail)\n                url = smart_urlquote('http://%s' % middle_unescaped)\n            elif ':' not in middle and is_email_simple(middle):\n                local, domain = middle.rsplit('@', 1)\n                try:\n                    domain = domain.encode('idna').decode('ascii')\n                except UnicodeError:\n                    continue\n                url = 'mailto:%s@%s' % (local, domain)\n                nofollow_attr = ''\n\n            # Make link.\n            if url:\n                trimmed = trim_url(middle)\n                if autoescape and not safe_input:\n                    lead, trail = escape(lead), escape(trail)\n                    trimmed = escape(trimmed)\n                middle = '<a href=\"%s\"%s>%s</a>' % (escape(url), nofollow_attr, trimmed)\n                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))\n            else:\n                if safe_input:\n                    words[i] = mark_safe(word)\n                elif autoescape:\n                    words[i] = escape(word)\n        elif safe_input:\n            words[i] = mark_safe(word)\n        elif autoescape:\n            words[i] = escape(word)\n    return ''.join(words)\n\n\ndef avoid_wrapping(value):\n    \"\"\"\n    Avoid text wrapping in the middle of a phrase by adding non-breaking\n    spaces where there previously were normal spaces.\n    \"\"\"\n    return value.replace(\" \", \"\\xa0\")\n\n\ndef html_safe(klass):\n    \"\"\"\n    A decorator that defines the __html__ method. This helps non-Django\n    templates to detect classes whose __str__ methods return SafeText.\n    \"\"\"\n    if '__html__' in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it defines \"\n            \"__html__().\" % klass.__name__\n        )\n    if '__str__' not in klass.__dict__:\n        raise ValueError(\n            \"can't apply @html_safe to %s because it doesn't \"\n            \"define __str__().\" % klass.__name__\n        )\n    klass_str = klass.__str__\n    klass.__str__ = lambda self: mark_safe(klass_str(self))\n    klass.__html__ = lambda self: str(self)\n    return klass\n"
  },
  {
    "patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex dfceccb2ec..2f67dc15ec 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -191,15 +191,6 @@ class AuthenticationForm(forms.Form):\n         if username is not None and password:\n             self.user_cache = authenticate(self.request, username=username, password=password)\n             if self.user_cache is None:\n-                # An authentication backend may reject inactive users. Check\n-                # if the user exists and is inactive, and raise the 'inactive'\n-                # error if so.\n-                try:\n-                    self.user_cache = UserModel._default_manager.get_by_natural_key(username)\n-                except UserModel.DoesNotExist:\n-                    pass\n-                else:\n-                    self.confirm_login_allowed(self.user_cache)\n                 raise self.get_invalid_login_error()\n             else:\n                 self.confirm_login_allowed(self.user_cache)\n",
    "commit_message": "Fixed CVE-2018-6188 -- Fixed information leakage in AuthenticationForm.\n\nReverted 359370a8b8ca0efe99b1d4630b291ec060b69225 (refs #28645).\n\nThis is a security fix.\n\n",
    "code_before": "import unicodedata\n\nfrom django import forms\nfrom django.contrib.auth import (\n    authenticate, get_user_model, password_validation,\n)\nfrom django.contrib.auth.hashers import (\n    UNUSABLE_PASSWORD_PREFIX, identify_hasher,\n)\nfrom django.contrib.auth.tokens import default_token_generator\nfrom django.contrib.sites.shortcuts import get_current_site\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.template import loader\nfrom django.utils.encoding import force_bytes\nfrom django.utils.http import urlsafe_base64_encode\nfrom django.utils.text import capfirst\nfrom django.utils.translation import gettext, gettext_lazy as _\n\nUserModel = get_user_model()\n\n\nclass ReadOnlyPasswordHashWidget(forms.Widget):\n    template_name = 'auth/widgets/read_only_password_hash.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        summary = []\n        if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n            summary.append({'label': gettext(\"No password set.\")})\n        else:\n            try:\n                hasher = identify_hasher(value)\n            except ValueError:\n                summary.append({'label': gettext(\"Invalid password format or unknown hashing algorithm.\")})\n            else:\n                for key, value_ in hasher.safe_summary(value).items():\n                    summary.append({'label': gettext(key), 'value': value_})\n        context['summary'] = summary\n        return context\n\n\nclass ReadOnlyPasswordHashField(forms.Field):\n    widget = ReadOnlyPasswordHashWidget\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault(\"required\", False)\n        super().__init__(*args, **kwargs)\n\n    def bound_data(self, data, initial):\n        # Always return initial because the widget doesn't\n        # render an input field.\n        return initial\n\n    def has_changed(self, initial, data):\n        return False\n\n\nclass UsernameField(forms.CharField):\n    def to_python(self, value):\n        return unicodedata.normalize('NFKC', super().to_python(value))\n\n\nclass UserCreationForm(forms.ModelForm):\n    \"\"\"\n    A form that creates a user, with no privileges, from the given username and\n    password.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password confirmation\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    class Meta:\n        model = UserModel\n        fields = (UserModel.USERNAME_FIELD,)\n        field_classes = {UserModel.USERNAME_FIELD: UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if self._meta.model.USERNAME_FIELD in self.fields:\n            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs.update({'autofocus': True})\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get(\"password1\")\n        password2 = self.cleaned_data.get(\"password2\")\n        if password1 and password2 and password1 != password2:\n            raise forms.ValidationError(\n                self.error_messages['password_mismatch'],\n                code='password_mismatch',\n            )\n        return password2\n\n    def _post_clean(self):\n        super()._post_clean()\n        # Validate the password after self.instance is updated with form data\n        # by super().\n        password = self.cleaned_data.get('password2')\n        if password:\n            try:\n                password_validation.validate_password(password, self.instance)\n            except forms.ValidationError as error:\n                self.add_error('password2', error)\n\n    def save(self, commit=True):\n        user = super().save(commit=False)\n        user.set_password(self.cleaned_data[\"password1\"])\n        if commit:\n            user.save()\n        return user\n\n\nclass UserChangeForm(forms.ModelForm):\n    password = ReadOnlyPasswordHashField(\n        label=_(\"Password\"),\n        help_text=_(\n            \"Raw passwords are not stored, so there is no way to see this \"\n            \"user's password, but you can change the password using \"\n            \"<a href=\\\"{}\\\">this form</a>.\"\n        ),\n    )\n\n    class Meta:\n        model = UserModel\n        fields = '__all__'\n        field_classes = {UserModel.USERNAME_FIELD: UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.fields['password'].help_text = self.fields['password'].help_text.format('../password/')\n        f = self.fields.get('user_permissions')\n        if f is not None:\n            f.queryset = f.queryset.select_related('content_type')\n\n    def clean_password(self):\n        # Regardless of what the user provides, return the initial value.\n        # This is done here, rather than on the field, because the\n        # field does not have access to the initial value\n        return self.initial[\"password\"]\n\n\nclass AuthenticationForm(forms.Form):\n    \"\"\"\n    Base class for authenticating users. Extend this to get a form that accepts\n    username/password logins.\n    \"\"\"\n    username = UsernameField(widget=forms.TextInput(attrs={'autofocus': True}))\n    password = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput,\n    )\n\n    error_messages = {\n        'invalid_login': _(\n            \"Please enter a correct %(username)s and password. Note that both \"\n            \"fields may be case-sensitive.\"\n        ),\n        'inactive': _(\"This account is inactive.\"),\n    }\n\n    def __init__(self, request=None, *args, **kwargs):\n        \"\"\"\n        The 'request' parameter is set for custom auth use by subclasses.\n        The form data comes in via the standard 'data' kwarg.\n        \"\"\"\n        self.request = request\n        self.user_cache = None\n        super().__init__(*args, **kwargs)\n\n        # Set the max length and label for the \"username\" field.\n        self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n        self.fields['username'].max_length = self.username_field.max_length or 254\n        if self.fields['username'].label is None:\n            self.fields['username'].label = capfirst(self.username_field.verbose_name)\n\n    def clean(self):\n        username = self.cleaned_data.get('username')\n        password = self.cleaned_data.get('password')\n\n        if username is not None and password:\n            self.user_cache = authenticate(self.request, username=username, password=password)\n            if self.user_cache is None:\n                # An authentication backend may reject inactive users. Check\n                # if the user exists and is inactive, and raise the 'inactive'\n                # error if so.\n                try:\n                    self.user_cache = UserModel._default_manager.get_by_natural_key(username)\n                except UserModel.DoesNotExist:\n                    pass\n                else:\n                    self.confirm_login_allowed(self.user_cache)\n                raise self.get_invalid_login_error()\n            else:\n                self.confirm_login_allowed(self.user_cache)\n\n        return self.cleaned_data\n\n    def confirm_login_allowed(self, user):\n        \"\"\"\n        Controls whether the given User may log in. This is a policy setting,\n        independent of end-user authentication. This default behavior is to\n        allow login by active users, and reject login by inactive users.\n\n        If the given user cannot log in, this method should raise a\n        ``forms.ValidationError``.\n\n        If the given user may log in, this method should return None.\n        \"\"\"\n        if not user.is_active:\n            raise forms.ValidationError(\n                self.error_messages['inactive'],\n                code='inactive',\n            )\n\n    def get_user_id(self):\n        if self.user_cache:\n            return self.user_cache.id\n        return None\n\n    def get_user(self):\n        return self.user_cache\n\n    def get_invalid_login_error(self):\n        return forms.ValidationError(\n            self.error_messages['invalid_login'],\n            code='invalid_login',\n            params={'username': self.username_field.verbose_name},\n        )\n\n\nclass PasswordResetForm(forms.Form):\n    email = forms.EmailField(label=_(\"Email\"), max_length=254)\n\n    def send_mail(self, subject_template_name, email_template_name,\n                  context, from_email, to_email, html_email_template_name=None):\n        \"\"\"\n        Send a django.core.mail.EmailMultiAlternatives to `to_email`.\n        \"\"\"\n        subject = loader.render_to_string(subject_template_name, context)\n        # Email subject *must not* contain newlines\n        subject = ''.join(subject.splitlines())\n        body = loader.render_to_string(email_template_name, context)\n\n        email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])\n        if html_email_template_name is not None:\n            html_email = loader.render_to_string(html_email_template_name, context)\n            email_message.attach_alternative(html_email, 'text/html')\n\n        email_message.send()\n\n    def get_users(self, email):\n        \"\"\"Given an email, return matching user(s) who should receive a reset.\n\n        This allows subclasses to more easily customize the default policies\n        that prevent inactive users and users with unusable passwords from\n        resetting their password.\n        \"\"\"\n        active_users = UserModel._default_manager.filter(**{\n            '%s__iexact' % UserModel.get_email_field_name(): email,\n            'is_active': True,\n        })\n        return (u for u in active_users if u.has_usable_password())\n\n    def save(self, domain_override=None,\n             subject_template_name='registration/password_reset_subject.txt',\n             email_template_name='registration/password_reset_email.html',\n             use_https=False, token_generator=default_token_generator,\n             from_email=None, request=None, html_email_template_name=None,\n             extra_email_context=None):\n        \"\"\"\n        Generate a one-use only link for resetting password and send it to the\n        user.\n        \"\"\"\n        email = self.cleaned_data[\"email\"]\n        for user in self.get_users(email):\n            if not domain_override:\n                current_site = get_current_site(request)\n                site_name = current_site.name\n                domain = current_site.domain\n            else:\n                site_name = domain = domain_override\n            context = {\n                'email': email,\n                'domain': domain,\n                'site_name': site_name,\n                'uid': urlsafe_base64_encode(force_bytes(user.pk)).decode(),\n                'user': user,\n                'token': token_generator.make_token(user),\n                'protocol': 'https' if use_https else 'http',\n                **(extra_email_context or {}),\n            }\n            self.send_mail(\n                subject_template_name, email_template_name, context, from_email,\n                email, html_email_template_name=html_email_template_name,\n            )\n\n\nclass SetPasswordForm(forms.Form):\n    \"\"\"\n    A form that lets a user change set their password without entering the old\n    password\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    new_password1 = forms.CharField(\n        label=_(\"New password\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    new_password2 = forms.CharField(\n        label=_(\"New password confirmation\"),\n        strip=False,\n        widget=forms.PasswordInput,\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_new_password2(self):\n        password1 = self.cleaned_data.get('new_password1')\n        password2 = self.cleaned_data.get('new_password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        password = self.cleaned_data[\"new_password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n\nclass PasswordChangeForm(SetPasswordForm):\n    \"\"\"\n    A form that lets a user change their password by entering their old\n    password.\n    \"\"\"\n    error_messages = {\n        **SetPasswordForm.error_messages,\n        'password_incorrect': _(\"Your old password was entered incorrectly. Please enter it again.\"),\n    }\n    old_password = forms.CharField(\n        label=_(\"Old password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autofocus': True}),\n    )\n\n    field_order = ['old_password', 'new_password1', 'new_password2']\n\n    def clean_old_password(self):\n        \"\"\"\n        Validate that the old_password field is correct.\n        \"\"\"\n        old_password = self.cleaned_data[\"old_password\"]\n        if not self.user.check_password(old_password):\n            raise forms.ValidationError(\n                self.error_messages['password_incorrect'],\n                code='password_incorrect',\n            )\n        return old_password\n\n\nclass AdminPasswordChangeForm(forms.Form):\n    \"\"\"\n    A form used to change the password of a user in the admin interface.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    required_css_class = 'required'\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        widget=forms.PasswordInput(attrs={'autofocus': True}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password (again)\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get('password1')\n        password2 = self.cleaned_data.get('password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        \"\"\"Save the new password.\"\"\"\n        password = self.cleaned_data[\"password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        for name in self.fields:\n            if name not in data:\n                return []\n        return ['password']\n",
    "code_after": "import unicodedata\n\nfrom django import forms\nfrom django.contrib.auth import (\n    authenticate, get_user_model, password_validation,\n)\nfrom django.contrib.auth.hashers import (\n    UNUSABLE_PASSWORD_PREFIX, identify_hasher,\n)\nfrom django.contrib.auth.tokens import default_token_generator\nfrom django.contrib.sites.shortcuts import get_current_site\nfrom django.core.mail import EmailMultiAlternatives\nfrom django.template import loader\nfrom django.utils.encoding import force_bytes\nfrom django.utils.http import urlsafe_base64_encode\nfrom django.utils.text import capfirst\nfrom django.utils.translation import gettext, gettext_lazy as _\n\nUserModel = get_user_model()\n\n\nclass ReadOnlyPasswordHashWidget(forms.Widget):\n    template_name = 'auth/widgets/read_only_password_hash.html'\n\n    def get_context(self, name, value, attrs):\n        context = super().get_context(name, value, attrs)\n        summary = []\n        if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n            summary.append({'label': gettext(\"No password set.\")})\n        else:\n            try:\n                hasher = identify_hasher(value)\n            except ValueError:\n                summary.append({'label': gettext(\"Invalid password format or unknown hashing algorithm.\")})\n            else:\n                for key, value_ in hasher.safe_summary(value).items():\n                    summary.append({'label': gettext(key), 'value': value_})\n        context['summary'] = summary\n        return context\n\n\nclass ReadOnlyPasswordHashField(forms.Field):\n    widget = ReadOnlyPasswordHashWidget\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault(\"required\", False)\n        super().__init__(*args, **kwargs)\n\n    def bound_data(self, data, initial):\n        # Always return initial because the widget doesn't\n        # render an input field.\n        return initial\n\n    def has_changed(self, initial, data):\n        return False\n\n\nclass UsernameField(forms.CharField):\n    def to_python(self, value):\n        return unicodedata.normalize('NFKC', super().to_python(value))\n\n\nclass UserCreationForm(forms.ModelForm):\n    \"\"\"\n    A form that creates a user, with no privileges, from the given username and\n    password.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password confirmation\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    class Meta:\n        model = UserModel\n        fields = (UserModel.USERNAME_FIELD,)\n        field_classes = {UserModel.USERNAME_FIELD: UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if self._meta.model.USERNAME_FIELD in self.fields:\n            self.fields[self._meta.model.USERNAME_FIELD].widget.attrs.update({'autofocus': True})\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get(\"password1\")\n        password2 = self.cleaned_data.get(\"password2\")\n        if password1 and password2 and password1 != password2:\n            raise forms.ValidationError(\n                self.error_messages['password_mismatch'],\n                code='password_mismatch',\n            )\n        return password2\n\n    def _post_clean(self):\n        super()._post_clean()\n        # Validate the password after self.instance is updated with form data\n        # by super().\n        password = self.cleaned_data.get('password2')\n        if password:\n            try:\n                password_validation.validate_password(password, self.instance)\n            except forms.ValidationError as error:\n                self.add_error('password2', error)\n\n    def save(self, commit=True):\n        user = super().save(commit=False)\n        user.set_password(self.cleaned_data[\"password1\"])\n        if commit:\n            user.save()\n        return user\n\n\nclass UserChangeForm(forms.ModelForm):\n    password = ReadOnlyPasswordHashField(\n        label=_(\"Password\"),\n        help_text=_(\n            \"Raw passwords are not stored, so there is no way to see this \"\n            \"user's password, but you can change the password using \"\n            \"<a href=\\\"{}\\\">this form</a>.\"\n        ),\n    )\n\n    class Meta:\n        model = UserModel\n        fields = '__all__'\n        field_classes = {UserModel.USERNAME_FIELD: UsernameField}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.fields['password'].help_text = self.fields['password'].help_text.format('../password/')\n        f = self.fields.get('user_permissions')\n        if f is not None:\n            f.queryset = f.queryset.select_related('content_type')\n\n    def clean_password(self):\n        # Regardless of what the user provides, return the initial value.\n        # This is done here, rather than on the field, because the\n        # field does not have access to the initial value\n        return self.initial[\"password\"]\n\n\nclass AuthenticationForm(forms.Form):\n    \"\"\"\n    Base class for authenticating users. Extend this to get a form that accepts\n    username/password logins.\n    \"\"\"\n    username = UsernameField(widget=forms.TextInput(attrs={'autofocus': True}))\n    password = forms.CharField(\n        label=_(\"Password\"),\n        strip=False,\n        widget=forms.PasswordInput,\n    )\n\n    error_messages = {\n        'invalid_login': _(\n            \"Please enter a correct %(username)s and password. Note that both \"\n            \"fields may be case-sensitive.\"\n        ),\n        'inactive': _(\"This account is inactive.\"),\n    }\n\n    def __init__(self, request=None, *args, **kwargs):\n        \"\"\"\n        The 'request' parameter is set for custom auth use by subclasses.\n        The form data comes in via the standard 'data' kwarg.\n        \"\"\"\n        self.request = request\n        self.user_cache = None\n        super().__init__(*args, **kwargs)\n\n        # Set the max length and label for the \"username\" field.\n        self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n        self.fields['username'].max_length = self.username_field.max_length or 254\n        if self.fields['username'].label is None:\n            self.fields['username'].label = capfirst(self.username_field.verbose_name)\n\n    def clean(self):\n        username = self.cleaned_data.get('username')\n        password = self.cleaned_data.get('password')\n\n        if username is not None and password:\n            self.user_cache = authenticate(self.request, username=username, password=password)\n            if self.user_cache is None:\n                raise self.get_invalid_login_error()\n            else:\n                self.confirm_login_allowed(self.user_cache)\n\n        return self.cleaned_data\n\n    def confirm_login_allowed(self, user):\n        \"\"\"\n        Controls whether the given User may log in. This is a policy setting,\n        independent of end-user authentication. This default behavior is to\n        allow login by active users, and reject login by inactive users.\n\n        If the given user cannot log in, this method should raise a\n        ``forms.ValidationError``.\n\n        If the given user may log in, this method should return None.\n        \"\"\"\n        if not user.is_active:\n            raise forms.ValidationError(\n                self.error_messages['inactive'],\n                code='inactive',\n            )\n\n    def get_user_id(self):\n        if self.user_cache:\n            return self.user_cache.id\n        return None\n\n    def get_user(self):\n        return self.user_cache\n\n    def get_invalid_login_error(self):\n        return forms.ValidationError(\n            self.error_messages['invalid_login'],\n            code='invalid_login',\n            params={'username': self.username_field.verbose_name},\n        )\n\n\nclass PasswordResetForm(forms.Form):\n    email = forms.EmailField(label=_(\"Email\"), max_length=254)\n\n    def send_mail(self, subject_template_name, email_template_name,\n                  context, from_email, to_email, html_email_template_name=None):\n        \"\"\"\n        Send a django.core.mail.EmailMultiAlternatives to `to_email`.\n        \"\"\"\n        subject = loader.render_to_string(subject_template_name, context)\n        # Email subject *must not* contain newlines\n        subject = ''.join(subject.splitlines())\n        body = loader.render_to_string(email_template_name, context)\n\n        email_message = EmailMultiAlternatives(subject, body, from_email, [to_email])\n        if html_email_template_name is not None:\n            html_email = loader.render_to_string(html_email_template_name, context)\n            email_message.attach_alternative(html_email, 'text/html')\n\n        email_message.send()\n\n    def get_users(self, email):\n        \"\"\"Given an email, return matching user(s) who should receive a reset.\n\n        This allows subclasses to more easily customize the default policies\n        that prevent inactive users and users with unusable passwords from\n        resetting their password.\n        \"\"\"\n        active_users = UserModel._default_manager.filter(**{\n            '%s__iexact' % UserModel.get_email_field_name(): email,\n            'is_active': True,\n        })\n        return (u for u in active_users if u.has_usable_password())\n\n    def save(self, domain_override=None,\n             subject_template_name='registration/password_reset_subject.txt',\n             email_template_name='registration/password_reset_email.html',\n             use_https=False, token_generator=default_token_generator,\n             from_email=None, request=None, html_email_template_name=None,\n             extra_email_context=None):\n        \"\"\"\n        Generate a one-use only link for resetting password and send it to the\n        user.\n        \"\"\"\n        email = self.cleaned_data[\"email\"]\n        for user in self.get_users(email):\n            if not domain_override:\n                current_site = get_current_site(request)\n                site_name = current_site.name\n                domain = current_site.domain\n            else:\n                site_name = domain = domain_override\n            context = {\n                'email': email,\n                'domain': domain,\n                'site_name': site_name,\n                'uid': urlsafe_base64_encode(force_bytes(user.pk)).decode(),\n                'user': user,\n                'token': token_generator.make_token(user),\n                'protocol': 'https' if use_https else 'http',\n                **(extra_email_context or {}),\n            }\n            self.send_mail(\n                subject_template_name, email_template_name, context, from_email,\n                email, html_email_template_name=html_email_template_name,\n            )\n\n\nclass SetPasswordForm(forms.Form):\n    \"\"\"\n    A form that lets a user change set their password without entering the old\n    password\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    new_password1 = forms.CharField(\n        label=_(\"New password\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    new_password2 = forms.CharField(\n        label=_(\"New password confirmation\"),\n        strip=False,\n        widget=forms.PasswordInput,\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_new_password2(self):\n        password1 = self.cleaned_data.get('new_password1')\n        password2 = self.cleaned_data.get('new_password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        password = self.cleaned_data[\"new_password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n\nclass PasswordChangeForm(SetPasswordForm):\n    \"\"\"\n    A form that lets a user change their password by entering their old\n    password.\n    \"\"\"\n    error_messages = {\n        **SetPasswordForm.error_messages,\n        'password_incorrect': _(\"Your old password was entered incorrectly. Please enter it again.\"),\n    }\n    old_password = forms.CharField(\n        label=_(\"Old password\"),\n        strip=False,\n        widget=forms.PasswordInput(attrs={'autofocus': True}),\n    )\n\n    field_order = ['old_password', 'new_password1', 'new_password2']\n\n    def clean_old_password(self):\n        \"\"\"\n        Validate that the old_password field is correct.\n        \"\"\"\n        old_password = self.cleaned_data[\"old_password\"]\n        if not self.user.check_password(old_password):\n            raise forms.ValidationError(\n                self.error_messages['password_incorrect'],\n                code='password_incorrect',\n            )\n        return old_password\n\n\nclass AdminPasswordChangeForm(forms.Form):\n    \"\"\"\n    A form used to change the password of a user in the admin interface.\n    \"\"\"\n    error_messages = {\n        'password_mismatch': _(\"The two password fields didn't match.\"),\n    }\n    required_css_class = 'required'\n    password1 = forms.CharField(\n        label=_(\"Password\"),\n        widget=forms.PasswordInput(attrs={'autofocus': True}),\n        strip=False,\n        help_text=password_validation.password_validators_help_text_html(),\n    )\n    password2 = forms.CharField(\n        label=_(\"Password (again)\"),\n        widget=forms.PasswordInput,\n        strip=False,\n        help_text=_(\"Enter the same password as before, for verification.\"),\n    )\n\n    def __init__(self, user, *args, **kwargs):\n        self.user = user\n        super().__init__(*args, **kwargs)\n\n    def clean_password2(self):\n        password1 = self.cleaned_data.get('password1')\n        password2 = self.cleaned_data.get('password2')\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                )\n        password_validation.validate_password(password2, self.user)\n        return password2\n\n    def save(self, commit=True):\n        \"\"\"Save the new password.\"\"\"\n        password = self.cleaned_data[\"password1\"]\n        self.user.set_password(password)\n        if commit:\n            self.user.save()\n        return self.user\n\n    @property\n    def changed_data(self):\n        data = super().changed_data\n        for name in self.fields:\n            if name not in data:\n                return []\n        return ['password']\n"
  },
  {
    "patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex fca137fd07..35cff6338f 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -8,7 +8,7 @@ from pathlib import Path\n from django.conf import settings\n from django.http import HttpResponse, HttpResponseNotFound\n from django.template import Context, Engine, TemplateDoesNotExist\n-from django.template.defaultfilters import force_escape, pprint\n+from django.template.defaultfilters import pprint\n from django.urls import Resolver404, resolve\n from django.utils import timezone\n from django.utils.datastructures import MultiValueDict\n@@ -271,7 +271,7 @@ class ExceptionReporter:\n                     # Trim large blobs of data\n                     if len(v) > 4096:\n                         v = '%s... <trimmed %d bytes string>' % (v[0:4096], len(v))\n-                    frame_vars.append((k, force_escape(v)))\n+                    frame_vars.append((k, v))\n                 frame['vars'] = frame_vars\n             frames[i] = frame\n \n",
    "commit_message": "Fixed CVE-2017-12794 -- Fixed XSS possibility in traceback section of technical 500 debug page.\n\nThis is a security fix.\n\n",
    "code_before": "import functools\nimport re\nimport sys\nimport types\nfrom contextlib import suppress\nfrom pathlib import Path\n\nfrom django.conf import settings\nfrom django.http import HttpResponse, HttpResponseNotFound\nfrom django.template import Context, Engine, TemplateDoesNotExist\nfrom django.template.defaultfilters import force_escape, pprint\nfrom django.urls import Resolver404, resolve\nfrom django.utils import timezone\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_text\nfrom django.utils.module_loading import import_string\nfrom django.utils.version import get_docs_version\n\n# Minimal Django templates engine to render the error templates\n# regardless of the project's TEMPLATES setting. Templates are\n# read directly from the filesystem so that the error handler\n# works even if the template loader is broken.\nDEBUG_ENGINE = Engine(\n    debug=True,\n    libraries={'i18n': 'django.templatetags.i18n'},\n)\n\nHIDDEN_SETTINGS = re.compile('API|TOKEN|KEY|SECRET|PASS|SIGNATURE', flags=re.IGNORECASE)\n\nCLEANSED_SUBSTITUTE = '********************'\n\nCURRENT_DIR = Path(__file__).parent\n\n\nclass CallableSettingWrapper:\n    \"\"\"\n    Object to wrap callable appearing in settings.\n    * Not to call in the debug page (#21345).\n    * Not to break the debug page if the callable forbidding to set attributes\n      (#23070).\n    \"\"\"\n    def __init__(self, callable_setting):\n        self._wrapped = callable_setting\n\n    def __repr__(self):\n        return repr(self._wrapped)\n\n\ndef cleanse_setting(key, value):\n    \"\"\"\n    Cleanse an individual setting key/value of sensitive content. If the value\n    is a dictionary, recursively cleanse the keys in that dictionary.\n    \"\"\"\n    try:\n        if HIDDEN_SETTINGS.search(key):\n            cleansed = CLEANSED_SUBSTITUTE\n        else:\n            if isinstance(value, dict):\n                cleansed = {k: cleanse_setting(k, v) for k, v in value.items()}\n            else:\n                cleansed = value\n    except TypeError:\n        # If the key isn't regex-able, just return as-is.\n        cleansed = value\n\n    if callable(cleansed):\n        # For fixing #21345 and #23070\n        cleansed = CallableSettingWrapper(cleansed)\n\n    return cleansed\n\n\ndef get_safe_settings():\n    \"\"\"\n    Return a dictionary of the settings module with values of sensitive\n    settings replaced with stars (*********).\n    \"\"\"\n    settings_dict = {}\n    for k in dir(settings):\n        if k.isupper():\n            settings_dict[k] = cleanse_setting(k, getattr(settings, k))\n    return settings_dict\n\n\ndef technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n    \"\"\"\n    Create a technical server error response. The last three arguments are\n    the values returned from sys.exc_info() and friends.\n    \"\"\"\n    reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n    if request.is_ajax():\n        text = reporter.get_traceback_text()\n        return HttpResponse(text, status=status_code, content_type='text/plain; charset=utf-8')\n    else:\n        html = reporter.get_traceback_html()\n        return HttpResponse(html, status=status_code, content_type='text/html')\n\n\n@functools.lru_cache()\ndef get_default_exception_reporter_filter():\n    # Instantiate the default filter for the first time and cache it.\n    return import_string(settings.DEFAULT_EXCEPTION_REPORTER_FILTER)()\n\n\ndef get_exception_reporter_filter(request):\n    default_filter = get_default_exception_reporter_filter()\n    return getattr(request, 'exception_reporter_filter', default_filter)\n\n\nclass ExceptionReporterFilter:\n    \"\"\"\n    Base for all exception reporter filter classes. All overridable hooks\n    contain lenient default behaviors.\n    \"\"\"\n\n    def get_post_parameters(self, request):\n        if request is None:\n            return {}\n        else:\n            return request.POST\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        return list(tb_frame.f_locals.items())\n\n\nclass SafeExceptionReporterFilter(ExceptionReporterFilter):\n    \"\"\"\n    Use annotations made by the sensitive_post_parameters and\n    sensitive_variables decorators to filter out sensitive information.\n    \"\"\"\n\n    def is_active(self, request):\n        \"\"\"\n        This filter is to add safety in production environments (i.e. DEBUG\n        is False). If DEBUG is True then your site is not safe anyway.\n        This hook is provided as a convenience to easily activate or\n        deactivate the filter on a per request basis.\n        \"\"\"\n        return settings.DEBUG is False\n\n    def get_cleansed_multivaluedict(self, request, multivaluedict):\n        \"\"\"\n        Replace the keys in a MultiValueDict marked as sensitive with stars.\n        This mitigates leaking sensitive POST parameters if something like\n        request.POST['nonexistent_key'] throws an exception (#21098).\n        \"\"\"\n        sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n        if self.is_active(request) and sensitive_post_parameters:\n            multivaluedict = multivaluedict.copy()\n            for param in sensitive_post_parameters:\n                if param in multivaluedict:\n                    multivaluedict[param] = CLEANSED_SUBSTITUTE\n        return multivaluedict\n\n    def get_post_parameters(self, request):\n        \"\"\"\n        Replace the values of POST parameters marked as sensitive with\n        stars (*********).\n        \"\"\"\n        if request is None:\n            return {}\n        else:\n            sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n            if self.is_active(request) and sensitive_post_parameters:\n                cleansed = request.POST.copy()\n                if sensitive_post_parameters == '__ALL__':\n                    # Cleanse all parameters.\n                    for k, v in cleansed.items():\n                        cleansed[k] = CLEANSED_SUBSTITUTE\n                    return cleansed\n                else:\n                    # Cleanse only the specified parameters.\n                    for param in sensitive_post_parameters:\n                        if param in cleansed:\n                            cleansed[param] = CLEANSED_SUBSTITUTE\n                    return cleansed\n            else:\n                return request.POST\n\n    def cleanse_special_types(self, request, value):\n        try:\n            # If value is lazy or a complex object of another kind, this check\n            # might raise an exception. isinstance checks that lazy\n            # MultiValueDicts will have a return value.\n            is_multivalue_dict = isinstance(value, MultiValueDict)\n        except Exception as e:\n            return '{!r} while evaluating {!r}'.format(e, value)\n\n        if is_multivalue_dict:\n            # Cleanse MultiValueDicts (request.POST is the one we usually care about)\n            value = self.get_cleansed_multivaluedict(request, value)\n        return value\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        \"\"\"\n        Replace the values of variables marked as sensitive with\n        stars (*********).\n        \"\"\"\n        # Loop through the frame's callers to see if the sensitive_variables\n        # decorator was used.\n        current_frame = tb_frame.f_back\n        sensitive_variables = None\n        while current_frame is not None:\n            if (current_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n                    'sensitive_variables_wrapper' in current_frame.f_locals):\n                # The sensitive_variables decorator was used, so we take note\n                # of the sensitive variables' names.\n                wrapper = current_frame.f_locals['sensitive_variables_wrapper']\n                sensitive_variables = getattr(wrapper, 'sensitive_variables', None)\n                break\n            current_frame = current_frame.f_back\n\n        cleansed = {}\n        if self.is_active(request) and sensitive_variables:\n            if sensitive_variables == '__ALL__':\n                # Cleanse all variables\n                for name, value in tb_frame.f_locals.items():\n                    cleansed[name] = CLEANSED_SUBSTITUTE\n            else:\n                # Cleanse specified variables\n                for name, value in tb_frame.f_locals.items():\n                    if name in sensitive_variables:\n                        value = CLEANSED_SUBSTITUTE\n                    else:\n                        value = self.cleanse_special_types(request, value)\n                    cleansed[name] = value\n        else:\n            # Potentially cleanse the request and any MultiValueDicts if they\n            # are one of the frame variables.\n            for name, value in tb_frame.f_locals.items():\n                cleansed[name] = self.cleanse_special_types(request, value)\n\n        if (tb_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n                'sensitive_variables_wrapper' in tb_frame.f_locals):\n            # For good measure, obfuscate the decorated function's arguments in\n            # the sensitive_variables decorator's frame, in case the variables\n            # associated with those arguments were meant to be obfuscated from\n            # the decorated function's frame.\n            cleansed['func_args'] = CLEANSED_SUBSTITUTE\n            cleansed['func_kwargs'] = CLEANSED_SUBSTITUTE\n\n        return cleansed.items()\n\n\nclass ExceptionReporter:\n    \"\"\"Organize and coordinate reporting on exceptions.\"\"\"\n    def __init__(self, request, exc_type, exc_value, tb, is_email=False):\n        self.request = request\n        self.filter = get_exception_reporter_filter(self.request)\n        self.exc_type = exc_type\n        self.exc_value = exc_value\n        self.tb = tb\n        self.is_email = is_email\n\n        self.template_info = getattr(self.exc_value, 'template_debug', None)\n        self.template_does_not_exist = False\n        self.postmortem = None\n\n    def get_traceback_data(self):\n        \"\"\"Return a dictionary containing traceback information.\"\"\"\n        if self.exc_type and issubclass(self.exc_type, TemplateDoesNotExist):\n            self.template_does_not_exist = True\n            self.postmortem = self.exc_value.chain or [self.exc_value]\n\n        frames = self.get_traceback_frames()\n        for i, frame in enumerate(frames):\n            if 'vars' in frame:\n                frame_vars = []\n                for k, v in frame['vars']:\n                    v = pprint(v)\n                    # Trim large blobs of data\n                    if len(v) > 4096:\n                        v = '%s... <trimmed %d bytes string>' % (v[0:4096], len(v))\n                    frame_vars.append((k, force_escape(v)))\n                frame['vars'] = frame_vars\n            frames[i] = frame\n\n        unicode_hint = ''\n        if self.exc_type and issubclass(self.exc_type, UnicodeError):\n            start = getattr(self.exc_value, 'start', None)\n            end = getattr(self.exc_value, 'end', None)\n            if start is not None and end is not None:\n                unicode_str = self.exc_value.args[1]\n                unicode_hint = force_text(\n                    unicode_str[max(start - 5, 0):min(end + 5, len(unicode_str))],\n                    'ascii', errors='replace'\n                )\n        from django import get_version\n\n        if self.request is None:\n            user_str = None\n        else:\n            try:\n                user_str = str(self.request.user)\n            except Exception:\n                # request.user may raise OperationalError if the database is\n                # unavailable, for example.\n                user_str = '[unable to retrieve the current user]'\n\n        c = {\n            'is_email': self.is_email,\n            'unicode_hint': unicode_hint,\n            'frames': frames,\n            'request': self.request,\n            'user_str': user_str,\n            'filtered_POST_items': list(self.filter.get_post_parameters(self.request).items()),\n            'settings': get_safe_settings(),\n            'sys_executable': sys.executable,\n            'sys_version_info': '%d.%d.%d' % sys.version_info[0:3],\n            'server_time': timezone.now(),\n            'django_version_info': get_version(),\n            'sys_path': sys.path,\n            'template_info': self.template_info,\n            'template_does_not_exist': self.template_does_not_exist,\n            'postmortem': self.postmortem,\n        }\n        if self.request is not None:\n            c['request_GET_items'] = self.request.GET.items()\n            c['request_FILES_items'] = self.request.FILES.items()\n            c['request_COOKIES_items'] = self.request.COOKIES.items()\n        # Check whether exception info is available\n        if self.exc_type:\n            c['exception_type'] = self.exc_type.__name__\n        if self.exc_value:\n            c['exception_value'] = str(self.exc_value)\n        if frames:\n            c['lastframe'] = frames[-1]\n        return c\n\n    def get_traceback_html(self):\n        \"\"\"Return HTML version of debug 500 HTTP error page.\"\"\"\n        with Path(CURRENT_DIR, 'templates', 'technical_500.html').open() as fh:\n            t = DEBUG_ENGINE.from_string(fh.read())\n        c = Context(self.get_traceback_data(), use_l10n=False)\n        return t.render(c)\n\n    def get_traceback_text(self):\n        \"\"\"Return plain text version of debug 500 HTTP error page.\"\"\"\n        with Path(CURRENT_DIR, 'templates', 'technical_500.txt').open() as fh:\n            t = DEBUG_ENGINE.from_string(fh.read())\n        c = Context(self.get_traceback_data(), autoescape=False, use_l10n=False)\n        return t.render(c)\n\n    def _get_lines_from_file(self, filename, lineno, context_lines, loader=None, module_name=None):\n        \"\"\"\n        Return context_lines before and after lineno from file.\n        Return (pre_context_lineno, pre_context, context_line, post_context).\n        \"\"\"\n        source = None\n        if loader is not None and hasattr(loader, \"get_source\"):\n            with suppress(ImportError):\n                source = loader.get_source(module_name)\n            if source is not None:\n                source = source.splitlines()\n        if source is None:\n            with suppress(OSError, IOError):\n                with open(filename, 'rb') as fp:\n                    source = fp.read().splitlines()\n        if source is None:\n            return None, [], None, []\n\n        # If we just read the source from a file, or if the loader did not\n        # apply tokenize.detect_encoding to decode the source into a\n        # string, then we should do that ourselves.\n        if isinstance(source[0], bytes):\n            encoding = 'ascii'\n            for line in source[:2]:\n                # File coding may be specified. Match pattern from PEP-263\n                # (http://www.python.org/dev/peps/pep-0263/)\n                match = re.search(br'coding[:=]\\s*([-\\w.]+)', line)\n                if match:\n                    encoding = match.group(1).decode('ascii')\n                    break\n            source = [str(sline, encoding, 'replace') for sline in source]\n\n        lower_bound = max(0, lineno - context_lines)\n        upper_bound = lineno + context_lines\n\n        pre_context = source[lower_bound:lineno]\n        context_line = source[lineno]\n        post_context = source[lineno + 1:upper_bound]\n\n        return lower_bound, pre_context, context_line, post_context\n\n    def get_traceback_frames(self):\n        def explicit_or_implicit_cause(exc_value):\n            explicit = getattr(exc_value, '__cause__', None)\n            implicit = getattr(exc_value, '__context__', None)\n            return explicit or implicit\n\n        # Get the exception and all its causes\n        exceptions = []\n        exc_value = self.exc_value\n        while exc_value:\n            exceptions.append(exc_value)\n            exc_value = explicit_or_implicit_cause(exc_value)\n\n        frames = []\n        # No exceptions were supplied to ExceptionReporter\n        if not exceptions:\n            return frames\n\n        # In case there's just one exception, take the traceback from self.tb\n        exc_value = exceptions.pop()\n        tb = self.tb if not exceptions else exc_value.__traceback__\n\n        while tb is not None:\n            # Support for __traceback_hide__ which is used by a few libraries\n            # to hide internal frames.\n            if tb.tb_frame.f_locals.get('__traceback_hide__'):\n                tb = tb.tb_next\n                continue\n            filename = tb.tb_frame.f_code.co_filename\n            function = tb.tb_frame.f_code.co_name\n            lineno = tb.tb_lineno - 1\n            loader = tb.tb_frame.f_globals.get('__loader__')\n            module_name = tb.tb_frame.f_globals.get('__name__') or ''\n            pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file(\n                filename, lineno, 7, loader, module_name,\n            )\n            if pre_context_lineno is None:\n                pre_context_lineno = lineno\n                pre_context = []\n                context_line = '<source code not available>'\n                post_context = []\n            frames.append({\n                'exc_cause': explicit_or_implicit_cause(exc_value),\n                'exc_cause_explicit': getattr(exc_value, '__cause__', True),\n                'tb': tb,\n                'type': 'django' if module_name.startswith('django.') else 'user',\n                'filename': filename,\n                'function': function,\n                'lineno': lineno + 1,\n                'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame),\n                'id': id(tb),\n                'pre_context': pre_context,\n                'context_line': context_line,\n                'post_context': post_context,\n                'pre_context_lineno': pre_context_lineno + 1,\n            })\n\n            # If the traceback for current exception is consumed, try the\n            # other exception.\n            if not tb.tb_next and exceptions:\n                exc_value = exceptions.pop()\n                tb = exc_value.__traceback__\n            else:\n                tb = tb.tb_next\n\n        return frames\n\n\ndef technical_404_response(request, exception):\n    \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n    else:\n        if (not tried or (                  # empty URLconf\n            request.path == '/' and\n            len(tried) == 1 and             # default URLconf\n            len(tried[0]) == 1 and\n            getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n        )):\n            return default_urlconf(request)\n\n    urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n    if isinstance(urlconf, types.ModuleType):\n        urlconf = urlconf.__name__\n\n    caller = ''\n    try:\n        resolver_match = resolve(request.path)\n    except Resolver404:\n        pass\n    else:\n        obj = resolver_match.func\n\n        if hasattr(obj, '__name__'):\n            caller = obj.__name__\n        elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n            caller = obj.__class__.__name__\n\n        if hasattr(obj, '__module__'):\n            module = obj.__module__\n            caller = '%s.%s' % (module, caller)\n\n    with Path(CURRENT_DIR, 'templates', 'technical_404.html').open() as fh:\n        t = DEBUG_ENGINE.from_string(fh.read())\n    c = Context({\n        'urlconf': urlconf,\n        'root_urlconf': settings.ROOT_URLCONF,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': str(exception),\n        'request': request,\n        'settings': get_safe_settings(),\n        'raising_view_name': caller,\n    })\n    return HttpResponseNotFound(t.render(c), content_type='text/html')\n\n\ndef default_urlconf(request):\n    \"\"\"Create an empty URLconf 404 error response.\"\"\"\n    with Path(CURRENT_DIR, 'templates', 'default_urlconf.html').open() as fh:\n        t = DEBUG_ENGINE.from_string(fh.read())\n    c = Context({\n        'version': get_docs_version(),\n    })\n\n    return HttpResponse(t.render(c), content_type='text/html')\n",
    "code_after": "import functools\nimport re\nimport sys\nimport types\nfrom contextlib import suppress\nfrom pathlib import Path\n\nfrom django.conf import settings\nfrom django.http import HttpResponse, HttpResponseNotFound\nfrom django.template import Context, Engine, TemplateDoesNotExist\nfrom django.template.defaultfilters import pprint\nfrom django.urls import Resolver404, resolve\nfrom django.utils import timezone\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_text\nfrom django.utils.module_loading import import_string\nfrom django.utils.version import get_docs_version\n\n# Minimal Django templates engine to render the error templates\n# regardless of the project's TEMPLATES setting. Templates are\n# read directly from the filesystem so that the error handler\n# works even if the template loader is broken.\nDEBUG_ENGINE = Engine(\n    debug=True,\n    libraries={'i18n': 'django.templatetags.i18n'},\n)\n\nHIDDEN_SETTINGS = re.compile('API|TOKEN|KEY|SECRET|PASS|SIGNATURE', flags=re.IGNORECASE)\n\nCLEANSED_SUBSTITUTE = '********************'\n\nCURRENT_DIR = Path(__file__).parent\n\n\nclass CallableSettingWrapper:\n    \"\"\"\n    Object to wrap callable appearing in settings.\n    * Not to call in the debug page (#21345).\n    * Not to break the debug page if the callable forbidding to set attributes\n      (#23070).\n    \"\"\"\n    def __init__(self, callable_setting):\n        self._wrapped = callable_setting\n\n    def __repr__(self):\n        return repr(self._wrapped)\n\n\ndef cleanse_setting(key, value):\n    \"\"\"\n    Cleanse an individual setting key/value of sensitive content. If the value\n    is a dictionary, recursively cleanse the keys in that dictionary.\n    \"\"\"\n    try:\n        if HIDDEN_SETTINGS.search(key):\n            cleansed = CLEANSED_SUBSTITUTE\n        else:\n            if isinstance(value, dict):\n                cleansed = {k: cleanse_setting(k, v) for k, v in value.items()}\n            else:\n                cleansed = value\n    except TypeError:\n        # If the key isn't regex-able, just return as-is.\n        cleansed = value\n\n    if callable(cleansed):\n        # For fixing #21345 and #23070\n        cleansed = CallableSettingWrapper(cleansed)\n\n    return cleansed\n\n\ndef get_safe_settings():\n    \"\"\"\n    Return a dictionary of the settings module with values of sensitive\n    settings replaced with stars (*********).\n    \"\"\"\n    settings_dict = {}\n    for k in dir(settings):\n        if k.isupper():\n            settings_dict[k] = cleanse_setting(k, getattr(settings, k))\n    return settings_dict\n\n\ndef technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n    \"\"\"\n    Create a technical server error response. The last three arguments are\n    the values returned from sys.exc_info() and friends.\n    \"\"\"\n    reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n    if request.is_ajax():\n        text = reporter.get_traceback_text()\n        return HttpResponse(text, status=status_code, content_type='text/plain; charset=utf-8')\n    else:\n        html = reporter.get_traceback_html()\n        return HttpResponse(html, status=status_code, content_type='text/html')\n\n\n@functools.lru_cache()\ndef get_default_exception_reporter_filter():\n    # Instantiate the default filter for the first time and cache it.\n    return import_string(settings.DEFAULT_EXCEPTION_REPORTER_FILTER)()\n\n\ndef get_exception_reporter_filter(request):\n    default_filter = get_default_exception_reporter_filter()\n    return getattr(request, 'exception_reporter_filter', default_filter)\n\n\nclass ExceptionReporterFilter:\n    \"\"\"\n    Base for all exception reporter filter classes. All overridable hooks\n    contain lenient default behaviors.\n    \"\"\"\n\n    def get_post_parameters(self, request):\n        if request is None:\n            return {}\n        else:\n            return request.POST\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        return list(tb_frame.f_locals.items())\n\n\nclass SafeExceptionReporterFilter(ExceptionReporterFilter):\n    \"\"\"\n    Use annotations made by the sensitive_post_parameters and\n    sensitive_variables decorators to filter out sensitive information.\n    \"\"\"\n\n    def is_active(self, request):\n        \"\"\"\n        This filter is to add safety in production environments (i.e. DEBUG\n        is False). If DEBUG is True then your site is not safe anyway.\n        This hook is provided as a convenience to easily activate or\n        deactivate the filter on a per request basis.\n        \"\"\"\n        return settings.DEBUG is False\n\n    def get_cleansed_multivaluedict(self, request, multivaluedict):\n        \"\"\"\n        Replace the keys in a MultiValueDict marked as sensitive with stars.\n        This mitigates leaking sensitive POST parameters if something like\n        request.POST['nonexistent_key'] throws an exception (#21098).\n        \"\"\"\n        sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n        if self.is_active(request) and sensitive_post_parameters:\n            multivaluedict = multivaluedict.copy()\n            for param in sensitive_post_parameters:\n                if param in multivaluedict:\n                    multivaluedict[param] = CLEANSED_SUBSTITUTE\n        return multivaluedict\n\n    def get_post_parameters(self, request):\n        \"\"\"\n        Replace the values of POST parameters marked as sensitive with\n        stars (*********).\n        \"\"\"\n        if request is None:\n            return {}\n        else:\n            sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n            if self.is_active(request) and sensitive_post_parameters:\n                cleansed = request.POST.copy()\n                if sensitive_post_parameters == '__ALL__':\n                    # Cleanse all parameters.\n                    for k, v in cleansed.items():\n                        cleansed[k] = CLEANSED_SUBSTITUTE\n                    return cleansed\n                else:\n                    # Cleanse only the specified parameters.\n                    for param in sensitive_post_parameters:\n                        if param in cleansed:\n                            cleansed[param] = CLEANSED_SUBSTITUTE\n                    return cleansed\n            else:\n                return request.POST\n\n    def cleanse_special_types(self, request, value):\n        try:\n            # If value is lazy or a complex object of another kind, this check\n            # might raise an exception. isinstance checks that lazy\n            # MultiValueDicts will have a return value.\n            is_multivalue_dict = isinstance(value, MultiValueDict)\n        except Exception as e:\n            return '{!r} while evaluating {!r}'.format(e, value)\n\n        if is_multivalue_dict:\n            # Cleanse MultiValueDicts (request.POST is the one we usually care about)\n            value = self.get_cleansed_multivaluedict(request, value)\n        return value\n\n    def get_traceback_frame_variables(self, request, tb_frame):\n        \"\"\"\n        Replace the values of variables marked as sensitive with\n        stars (*********).\n        \"\"\"\n        # Loop through the frame's callers to see if the sensitive_variables\n        # decorator was used.\n        current_frame = tb_frame.f_back\n        sensitive_variables = None\n        while current_frame is not None:\n            if (current_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n                    'sensitive_variables_wrapper' in current_frame.f_locals):\n                # The sensitive_variables decorator was used, so we take note\n                # of the sensitive variables' names.\n                wrapper = current_frame.f_locals['sensitive_variables_wrapper']\n                sensitive_variables = getattr(wrapper, 'sensitive_variables', None)\n                break\n            current_frame = current_frame.f_back\n\n        cleansed = {}\n        if self.is_active(request) and sensitive_variables:\n            if sensitive_variables == '__ALL__':\n                # Cleanse all variables\n                for name, value in tb_frame.f_locals.items():\n                    cleansed[name] = CLEANSED_SUBSTITUTE\n            else:\n                # Cleanse specified variables\n                for name, value in tb_frame.f_locals.items():\n                    if name in sensitive_variables:\n                        value = CLEANSED_SUBSTITUTE\n                    else:\n                        value = self.cleanse_special_types(request, value)\n                    cleansed[name] = value\n        else:\n            # Potentially cleanse the request and any MultiValueDicts if they\n            # are one of the frame variables.\n            for name, value in tb_frame.f_locals.items():\n                cleansed[name] = self.cleanse_special_types(request, value)\n\n        if (tb_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n                'sensitive_variables_wrapper' in tb_frame.f_locals):\n            # For good measure, obfuscate the decorated function's arguments in\n            # the sensitive_variables decorator's frame, in case the variables\n            # associated with those arguments were meant to be obfuscated from\n            # the decorated function's frame.\n            cleansed['func_args'] = CLEANSED_SUBSTITUTE\n            cleansed['func_kwargs'] = CLEANSED_SUBSTITUTE\n\n        return cleansed.items()\n\n\nclass ExceptionReporter:\n    \"\"\"Organize and coordinate reporting on exceptions.\"\"\"\n    def __init__(self, request, exc_type, exc_value, tb, is_email=False):\n        self.request = request\n        self.filter = get_exception_reporter_filter(self.request)\n        self.exc_type = exc_type\n        self.exc_value = exc_value\n        self.tb = tb\n        self.is_email = is_email\n\n        self.template_info = getattr(self.exc_value, 'template_debug', None)\n        self.template_does_not_exist = False\n        self.postmortem = None\n\n    def get_traceback_data(self):\n        \"\"\"Return a dictionary containing traceback information.\"\"\"\n        if self.exc_type and issubclass(self.exc_type, TemplateDoesNotExist):\n            self.template_does_not_exist = True\n            self.postmortem = self.exc_value.chain or [self.exc_value]\n\n        frames = self.get_traceback_frames()\n        for i, frame in enumerate(frames):\n            if 'vars' in frame:\n                frame_vars = []\n                for k, v in frame['vars']:\n                    v = pprint(v)\n                    # Trim large blobs of data\n                    if len(v) > 4096:\n                        v = '%s... <trimmed %d bytes string>' % (v[0:4096], len(v))\n                    frame_vars.append((k, v))\n                frame['vars'] = frame_vars\n            frames[i] = frame\n\n        unicode_hint = ''\n        if self.exc_type and issubclass(self.exc_type, UnicodeError):\n            start = getattr(self.exc_value, 'start', None)\n            end = getattr(self.exc_value, 'end', None)\n            if start is not None and end is not None:\n                unicode_str = self.exc_value.args[1]\n                unicode_hint = force_text(\n                    unicode_str[max(start - 5, 0):min(end + 5, len(unicode_str))],\n                    'ascii', errors='replace'\n                )\n        from django import get_version\n\n        if self.request is None:\n            user_str = None\n        else:\n            try:\n                user_str = str(self.request.user)\n            except Exception:\n                # request.user may raise OperationalError if the database is\n                # unavailable, for example.\n                user_str = '[unable to retrieve the current user]'\n\n        c = {\n            'is_email': self.is_email,\n            'unicode_hint': unicode_hint,\n            'frames': frames,\n            'request': self.request,\n            'user_str': user_str,\n            'filtered_POST_items': list(self.filter.get_post_parameters(self.request).items()),\n            'settings': get_safe_settings(),\n            'sys_executable': sys.executable,\n            'sys_version_info': '%d.%d.%d' % sys.version_info[0:3],\n            'server_time': timezone.now(),\n            'django_version_info': get_version(),\n            'sys_path': sys.path,\n            'template_info': self.template_info,\n            'template_does_not_exist': self.template_does_not_exist,\n            'postmortem': self.postmortem,\n        }\n        if self.request is not None:\n            c['request_GET_items'] = self.request.GET.items()\n            c['request_FILES_items'] = self.request.FILES.items()\n            c['request_COOKIES_items'] = self.request.COOKIES.items()\n        # Check whether exception info is available\n        if self.exc_type:\n            c['exception_type'] = self.exc_type.__name__\n        if self.exc_value:\n            c['exception_value'] = str(self.exc_value)\n        if frames:\n            c['lastframe'] = frames[-1]\n        return c\n\n    def get_traceback_html(self):\n        \"\"\"Return HTML version of debug 500 HTTP error page.\"\"\"\n        with Path(CURRENT_DIR, 'templates', 'technical_500.html').open() as fh:\n            t = DEBUG_ENGINE.from_string(fh.read())\n        c = Context(self.get_traceback_data(), use_l10n=False)\n        return t.render(c)\n\n    def get_traceback_text(self):\n        \"\"\"Return plain text version of debug 500 HTTP error page.\"\"\"\n        with Path(CURRENT_DIR, 'templates', 'technical_500.txt').open() as fh:\n            t = DEBUG_ENGINE.from_string(fh.read())\n        c = Context(self.get_traceback_data(), autoescape=False, use_l10n=False)\n        return t.render(c)\n\n    def _get_lines_from_file(self, filename, lineno, context_lines, loader=None, module_name=None):\n        \"\"\"\n        Return context_lines before and after lineno from file.\n        Return (pre_context_lineno, pre_context, context_line, post_context).\n        \"\"\"\n        source = None\n        if loader is not None and hasattr(loader, \"get_source\"):\n            with suppress(ImportError):\n                source = loader.get_source(module_name)\n            if source is not None:\n                source = source.splitlines()\n        if source is None:\n            with suppress(OSError, IOError):\n                with open(filename, 'rb') as fp:\n                    source = fp.read().splitlines()\n        if source is None:\n            return None, [], None, []\n\n        # If we just read the source from a file, or if the loader did not\n        # apply tokenize.detect_encoding to decode the source into a\n        # string, then we should do that ourselves.\n        if isinstance(source[0], bytes):\n            encoding = 'ascii'\n            for line in source[:2]:\n                # File coding may be specified. Match pattern from PEP-263\n                # (http://www.python.org/dev/peps/pep-0263/)\n                match = re.search(br'coding[:=]\\s*([-\\w.]+)', line)\n                if match:\n                    encoding = match.group(1).decode('ascii')\n                    break\n            source = [str(sline, encoding, 'replace') for sline in source]\n\n        lower_bound = max(0, lineno - context_lines)\n        upper_bound = lineno + context_lines\n\n        pre_context = source[lower_bound:lineno]\n        context_line = source[lineno]\n        post_context = source[lineno + 1:upper_bound]\n\n        return lower_bound, pre_context, context_line, post_context\n\n    def get_traceback_frames(self):\n        def explicit_or_implicit_cause(exc_value):\n            explicit = getattr(exc_value, '__cause__', None)\n            implicit = getattr(exc_value, '__context__', None)\n            return explicit or implicit\n\n        # Get the exception and all its causes\n        exceptions = []\n        exc_value = self.exc_value\n        while exc_value:\n            exceptions.append(exc_value)\n            exc_value = explicit_or_implicit_cause(exc_value)\n\n        frames = []\n        # No exceptions were supplied to ExceptionReporter\n        if not exceptions:\n            return frames\n\n        # In case there's just one exception, take the traceback from self.tb\n        exc_value = exceptions.pop()\n        tb = self.tb if not exceptions else exc_value.__traceback__\n\n        while tb is not None:\n            # Support for __traceback_hide__ which is used by a few libraries\n            # to hide internal frames.\n            if tb.tb_frame.f_locals.get('__traceback_hide__'):\n                tb = tb.tb_next\n                continue\n            filename = tb.tb_frame.f_code.co_filename\n            function = tb.tb_frame.f_code.co_name\n            lineno = tb.tb_lineno - 1\n            loader = tb.tb_frame.f_globals.get('__loader__')\n            module_name = tb.tb_frame.f_globals.get('__name__') or ''\n            pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file(\n                filename, lineno, 7, loader, module_name,\n            )\n            if pre_context_lineno is None:\n                pre_context_lineno = lineno\n                pre_context = []\n                context_line = '<source code not available>'\n                post_context = []\n            frames.append({\n                'exc_cause': explicit_or_implicit_cause(exc_value),\n                'exc_cause_explicit': getattr(exc_value, '__cause__', True),\n                'tb': tb,\n                'type': 'django' if module_name.startswith('django.') else 'user',\n                'filename': filename,\n                'function': function,\n                'lineno': lineno + 1,\n                'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame),\n                'id': id(tb),\n                'pre_context': pre_context,\n                'context_line': context_line,\n                'post_context': post_context,\n                'pre_context_lineno': pre_context_lineno + 1,\n            })\n\n            # If the traceback for current exception is consumed, try the\n            # other exception.\n            if not tb.tb_next and exceptions:\n                exc_value = exceptions.pop()\n                tb = exc_value.__traceback__\n            else:\n                tb = tb.tb_next\n\n        return frames\n\n\ndef technical_404_response(request, exception):\n    \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n    else:\n        if (not tried or (                  # empty URLconf\n            request.path == '/' and\n            len(tried) == 1 and             # default URLconf\n            len(tried[0]) == 1 and\n            getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n        )):\n            return default_urlconf(request)\n\n    urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n    if isinstance(urlconf, types.ModuleType):\n        urlconf = urlconf.__name__\n\n    caller = ''\n    try:\n        resolver_match = resolve(request.path)\n    except Resolver404:\n        pass\n    else:\n        obj = resolver_match.func\n\n        if hasattr(obj, '__name__'):\n            caller = obj.__name__\n        elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n            caller = obj.__class__.__name__\n\n        if hasattr(obj, '__module__'):\n            module = obj.__module__\n            caller = '%s.%s' % (module, caller)\n\n    with Path(CURRENT_DIR, 'templates', 'technical_404.html').open() as fh:\n        t = DEBUG_ENGINE.from_string(fh.read())\n    c = Context({\n        'urlconf': urlconf,\n        'root_urlconf': settings.ROOT_URLCONF,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': str(exception),\n        'request': request,\n        'settings': get_safe_settings(),\n        'raising_view_name': caller,\n    })\n    return HttpResponseNotFound(t.render(c), content_type='text/html')\n\n\ndef default_urlconf(request):\n    \"\"\"Create an empty URLconf 404 error response.\"\"\"\n    with Path(CURRENT_DIR, 'templates', 'default_urlconf.html').open() as fh:\n        t = DEBUG_ENGINE.from_string(fh.read())\n    c = Context({\n        'version': get_docs_version(),\n    })\n\n    return HttpResponse(t.render(c), content_type='text/html')\n"
  },
  {
    "patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex bd2daad4b2..1433df4ff0 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -7,8 +7,9 @@ import warnings\n from binascii import Error as BinasciiError\n from email.utils import formatdate\n from urllib.parse import (\n-    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,\n-    urlparse,\n+    ParseResult, SplitResult, _coerce_args, _splitnetloc, _splitparams, quote,\n+    quote_plus, scheme_chars, unquote, unquote_plus,\n+    urlencode as original_urlencode, uses_params,\n )\n \n from django.core.exceptions import TooManyFieldsSent\n@@ -293,12 +294,62 @@ def is_safe_url(url, host=None, allowed_hosts=None, require_https=False):\n             _is_safe_url(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https))\n \n \n+# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\n+def _urlparse(url, scheme='', allow_fragments=True):\n+    \"\"\"Parse a URL into 6 components:\n+    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n+    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n+    Note that we don't break the components up in smaller bits\n+    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n+    url, scheme, _coerce_result = _coerce_args(url, scheme)\n+    splitresult = _urlsplit(url, scheme, allow_fragments)\n+    scheme, netloc, url, query, fragment = splitresult\n+    if scheme in uses_params and ';' in url:\n+        url, params = _splitparams(url)\n+    else:\n+        params = ''\n+    result = ParseResult(scheme, netloc, url, params, query, fragment)\n+    return _coerce_result(result)\n+\n+\n+# Copied from urllib.parse.urlsplit() with\n+# https://github.com/python/cpython/pull/661 applied.\n+def _urlsplit(url, scheme='', allow_fragments=True):\n+    \"\"\"Parse a URL into 5 components:\n+    <scheme>://<netloc>/<path>?<query>#<fragment>\n+    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n+    Note that we don't break the components up in smaller bits\n+    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n+    url, scheme, _coerce_result = _coerce_args(url, scheme)\n+    allow_fragments = bool(allow_fragments)\n+    netloc = query = fragment = ''\n+    i = url.find(':')\n+    if i > 0:\n+        for c in url[:i]:\n+            if c not in scheme_chars:\n+                break\n+        else:\n+            scheme, url = url[:i].lower(), url[i + 1:]\n+\n+    if url[:2] == '//':\n+        netloc, url = _splitnetloc(url, 2)\n+        if (('[' in netloc and ']' not in netloc) or\n+                (']' in netloc and '[' not in netloc)):\n+            raise ValueError(\"Invalid IPv6 URL\")\n+    if allow_fragments and '#' in url:\n+        url, fragment = url.split('#', 1)\n+    if '?' in url:\n+        url, query = url.split('?', 1)\n+    v = SplitResult(scheme, netloc, url, query, fragment)\n+    return _coerce_result(v)\n+\n+\n def _is_safe_url(url, allowed_hosts, require_https=False):\n     # Chrome considers any URL with more than two slashes to be absolute, but\n     # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n     if url.startswith('///'):\n         return False\n-    url_info = urlparse(url)\n+    url_info = _urlparse(url)\n     # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n     # In that URL, example.com is not the hostname but, a path component. However,\n     # Chrome will still consider example.com to be the hostname, so we must not\n",
    "commit_message": "Fixed #27912, CVE-2017-7233 -- Fixed is_safe_url() with numeric URLs.\n\nThis is a security fix.\n\n",
    "code_before": "import base64\nimport calendar\nimport datetime\nimport re\nimport unicodedata\nimport warnings\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\nfrom urllib.parse import (\n    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,\n    urlparse,\n)\n\nfrom django.core.exceptions import TooManyFieldsSent\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.deprecation import RemovedInDjango21Warning\nfrom django.utils.encoding import force_bytes\nfrom django.utils.functional import keep_lazy_text\n\n# based on RFC 7232, Appendix C\nETAG_MATCH = re.compile(r'''\n    \\A(      # start of string and capture group\n    (?:W/)?  # optional weak indicator\n    \"        # opening quote\n    [^\"]*    # any sequence of non-quote characters\n    \"        # end quote\n    )\\Z      # end of string and capture group\n''', re.X)\n\nMONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n__D = r'(?P<day>\\d{2})'\n__D2 = r'(?P<day>[ \\d]\\d)'\n__M = r'(?P<mon>\\w{3})'\n__Y = r'(?P<year>\\d{4})'\n__Y2 = r'(?P<year>\\d{2})'\n__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\nRFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\nRFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\nASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = \":/?#[]@\"\nRFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n\nFIELDS_MATCH = re.compile('[&;]')\n\n\n@keep_lazy_text\ndef urlquote(url, safe='/'):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.quote() function.\n    (was used for unicode handling on Python 2)\n    \"\"\"\n    return quote(url, safe)\n\n\n@keep_lazy_text\ndef urlquote_plus(url, safe=''):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.quote_plus()\n    function. (was used for unicode handling on Python 2)\n    \"\"\"\n    return quote_plus(url, safe)\n\n\n@keep_lazy_text\ndef urlunquote(quoted_url):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.unquote() function.\n    (was used for unicode handling on Python 2)\n    \"\"\"\n    return unquote(quoted_url)\n\n\n@keep_lazy_text\ndef urlunquote_plus(quoted_url):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.unquote_plus()\n    function. (was used for unicode handling on Python 2)\n    \"\"\"\n    return unquote_plus(quoted_url)\n\n\ndef urlencode(query, doseq=False):\n    \"\"\"\n    A version of Python's urllib.parse.urlencode() function that can operate on\n    MultiValueDict and non-string values.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, 'items'):\n        query = query.items()\n    return original_urlencode(\n        [(k, [str(i) for i in v] if isinstance(v, (list, tuple)) else str(v))\n         for k, v in query],\n        doseq\n    )\n\n\ndef cookie_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to ensure compatibility with Netscape's cookie standard.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to match the RFC1123 date format as specified by HTTP\n    RFC7231 section 7.1.1.1.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        year = int(m.group('year'))\n        if year < 100:\n            if year < 70:\n                year += 2000\n            else:\n                year += 1900\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec)\n        return calendar.timegm(result.utctimetuple())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but return None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\ndef base36_to_int(s):\n    \"\"\"\n    Convert a base 36 string to an int. Raise ValueError if the input won't fit\n    into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is longer than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    return int(s, 36)\n\n\ndef int_to_base36(i):\n    \"\"\"Convert an integer to a base36 string.\"\"\"\n    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if i < 36:\n        return char_set[i]\n    b36 = ''\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encode a bytestring in base64 for use in URLs. Strip any trailing equal\n    signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decode a base64 encoded string. Add back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = force_bytes(s)\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parse a string of ETags given in an If-None-Match or If-Match header as\n    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags\n    should be matched.\n    \"\"\"\n    if etag_str.strip() == '*':\n        return ['*']\n    else:\n        # Parse each ETag individually, and return any that are valid.\n        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))\n        return [match.group(1) for match in etag_matches if match]\n\n\ndef quote_etag(etag_str):\n    \"\"\"\n    If the provided string is already a quoted ETag, return it. Otherwise, wrap\n    the string in quotes, making it a strong ETag.\n    \"\"\"\n    if ETAG_MATCH.match(etag_str):\n        return etag_str\n    else:\n        return '\"%s\"' % etag_str\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or\n        pattern == host\n    )\n\n\ndef is_safe_url(url, host=None, allowed_hosts=None, require_https=False):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always return ``False`` on an empty url.\n\n    If ``require_https`` is ``True``, only 'https' will be considered a valid\n    scheme, as opposed to 'http' and 'https' with the default, ``False``.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    if allowed_hosts is None:\n        allowed_hosts = set()\n    if host:\n        warnings.warn(\n            \"The host argument is deprecated, use allowed_hosts instead.\",\n            RemovedInDjango21Warning,\n            stacklevel=2,\n        )\n        # Avoid mutating the passed in allowed_hosts.\n        allowed_hosts = allowed_hosts | {host}\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return (_is_safe_url(url, allowed_hosts, require_https=require_https) and\n            _is_safe_url(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https))\n\n\ndef _is_safe_url(url, allowed_hosts, require_https=False):\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    scheme = url_info.scheme\n    # Consider URLs without a scheme (e.g. //example.com/p) to be http.\n    if not url_info.scheme and url_info.netloc:\n        scheme = 'http'\n    valid_schemes = ['https'] if require_https else ['http', 'https']\n    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and\n            (not scheme or scheme in valid_schemes))\n\n\ndef limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',\n                      errors='replace', fields_limit=None):\n    \"\"\"\n    Return a list of key/value tuples parsed from query string.\n\n    Copied from urlparse with an additional \"fields_limit\" argument.\n    Copyright (C) 2013 Python Software Foundation (see LICENSE.python).\n\n    Arguments:\n\n    qs: percent-encoded query string to be parsed\n\n    keep_blank_values: flag indicating whether blank values in\n        percent-encoded queries should be treated as blank strings. A\n        true value indicates that blanks should be retained as blank\n        strings. The default false value indicates that blank values\n        are to be ignored and treated as if they were  not included.\n\n    encoding and errors: specify how to decode percent-encoded sequences\n        into Unicode characters, as accepted by the bytes.decode() method.\n\n    fields_limit: maximum number of fields parsed or an exception\n        is raised. None means no limit and is the default.\n    \"\"\"\n    if fields_limit:\n        pairs = FIELDS_MATCH.split(qs, fields_limit)\n        if len(pairs) > fields_limit:\n            raise TooManyFieldsSent(\n                'The number of GET/POST parameters exceeded '\n                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n            )\n    else:\n        pairs = FIELDS_MATCH.split(qs)\n    r = []\n    for name_value in pairs:\n        if not name_value:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            r.append((name, value))\n    return r\n",
    "code_after": "import base64\nimport calendar\nimport datetime\nimport re\nimport unicodedata\nimport warnings\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\nfrom urllib.parse import (\n    ParseResult, SplitResult, _coerce_args, _splitnetloc, _splitparams, quote,\n    quote_plus, scheme_chars, unquote, unquote_plus,\n    urlencode as original_urlencode, uses_params,\n)\n\nfrom django.core.exceptions import TooManyFieldsSent\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.deprecation import RemovedInDjango21Warning\nfrom django.utils.encoding import force_bytes\nfrom django.utils.functional import keep_lazy_text\n\n# based on RFC 7232, Appendix C\nETAG_MATCH = re.compile(r'''\n    \\A(      # start of string and capture group\n    (?:W/)?  # optional weak indicator\n    \"        # opening quote\n    [^\"]*    # any sequence of non-quote characters\n    \"        # end quote\n    )\\Z      # end of string and capture group\n''', re.X)\n\nMONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n__D = r'(?P<day>\\d{2})'\n__D2 = r'(?P<day>[ \\d]\\d)'\n__M = r'(?P<mon>\\w{3})'\n__Y = r'(?P<year>\\d{4})'\n__Y2 = r'(?P<year>\\d{2})'\n__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\nRFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\nRFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\nASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = \":/?#[]@\"\nRFC3986_SUBDELIMS = \"!$&'()*+,;=\"\n\nFIELDS_MATCH = re.compile('[&;]')\n\n\n@keep_lazy_text\ndef urlquote(url, safe='/'):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.quote() function.\n    (was used for unicode handling on Python 2)\n    \"\"\"\n    return quote(url, safe)\n\n\n@keep_lazy_text\ndef urlquote_plus(url, safe=''):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.quote_plus()\n    function. (was used for unicode handling on Python 2)\n    \"\"\"\n    return quote_plus(url, safe)\n\n\n@keep_lazy_text\ndef urlunquote(quoted_url):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.unquote() function.\n    (was used for unicode handling on Python 2)\n    \"\"\"\n    return unquote(quoted_url)\n\n\n@keep_lazy_text\ndef urlunquote_plus(quoted_url):\n    \"\"\"\n    A legacy compatibility wrapper to Python's urllib.parse.unquote_plus()\n    function. (was used for unicode handling on Python 2)\n    \"\"\"\n    return unquote_plus(quoted_url)\n\n\ndef urlencode(query, doseq=False):\n    \"\"\"\n    A version of Python's urllib.parse.urlencode() function that can operate on\n    MultiValueDict and non-string values.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, 'items'):\n        query = query.items()\n    return original_urlencode(\n        [(k, [str(i) for i in v] if isinstance(v, (list, tuple)) else str(v))\n         for k, v in query],\n        doseq\n    )\n\n\ndef cookie_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to ensure compatibility with Netscape's cookie standard.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Format the time to match the RFC1123 date format as specified by HTTP\n    RFC7231 section 7.1.1.1.\n\n    `epoch_seconds` is a floating point number expressed in seconds since the\n    epoch, in UTC - such as that outputted by time.time(). If set to None, it\n    defaults to the current time.\n\n    Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        year = int(m.group('year'))\n        if year < 100:\n            if year < 70:\n                year += 2000\n            else:\n                year += 1900\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec)\n        return calendar.timegm(result.utctimetuple())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but return None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\ndef base36_to_int(s):\n    \"\"\"\n    Convert a base 36 string to an int. Raise ValueError if the input won't fit\n    into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is longer than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    return int(s, 36)\n\n\ndef int_to_base36(i):\n    \"\"\"Convert an integer to a base36 string.\"\"\"\n    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if i < 36:\n        return char_set[i]\n    b36 = ''\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encode a bytestring in base64 for use in URLs. Strip any trailing equal\n    signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decode a base64 encoded string. Add back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = force_bytes(s)\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parse a string of ETags given in an If-None-Match or If-Match header as\n    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags\n    should be matched.\n    \"\"\"\n    if etag_str.strip() == '*':\n        return ['*']\n    else:\n        # Parse each ETag individually, and return any that are valid.\n        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))\n        return [match.group(1) for match in etag_matches if match]\n\n\ndef quote_etag(etag_str):\n    \"\"\"\n    If the provided string is already a quoted ETag, return it. Otherwise, wrap\n    the string in quotes, making it a strong ETag.\n    \"\"\"\n    if ETAG_MATCH.match(etag_str):\n        return etag_str\n    else:\n        return '\"%s\"' % etag_str\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or\n        pattern == host\n    )\n\n\ndef is_safe_url(url, host=None, allowed_hosts=None, require_https=False):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always return ``False`` on an empty url.\n\n    If ``require_https`` is ``True``, only 'https' will be considered a valid\n    scheme, as opposed to 'http' and 'https' with the default, ``False``.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    if allowed_hosts is None:\n        allowed_hosts = set()\n    if host:\n        warnings.warn(\n            \"The host argument is deprecated, use allowed_hosts instead.\",\n            RemovedInDjango21Warning,\n            stacklevel=2,\n        )\n        # Avoid mutating the passed in allowed_hosts.\n        allowed_hosts = allowed_hosts | {host}\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return (_is_safe_url(url, allowed_hosts, require_https=require_https) and\n            _is_safe_url(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https))\n\n\n# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.\ndef _urlparse(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = _urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and ';' in url:\n        url, params = _splitparams(url)\n    else:\n        params = ''\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\n\n# Copied from urllib.parse.urlsplit() with\n# https://github.com/python/cpython/pull/661 applied.\ndef _urlsplit(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    allow_fragments = bool(allow_fragments)\n    netloc = query = fragment = ''\n    i = url.find(':')\n    if i > 0:\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            scheme, url = url[:i].lower(), url[i + 1:]\n\n    if url[:2] == '//':\n        netloc, url = _splitnetloc(url, 2)\n        if (('[' in netloc and ']' not in netloc) or\n                (']' in netloc and '[' not in netloc)):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and '#' in url:\n        url, fragment = url.split('#', 1)\n    if '?' in url:\n        url, query = url.split('?', 1)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    return _coerce_result(v)\n\n\ndef _is_safe_url(url, allowed_hosts, require_https=False):\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = _urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    scheme = url_info.scheme\n    # Consider URLs without a scheme (e.g. //example.com/p) to be http.\n    if not url_info.scheme and url_info.netloc:\n        scheme = 'http'\n    valid_schemes = ['https'] if require_https else ['http', 'https']\n    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and\n            (not scheme or scheme in valid_schemes))\n\n\ndef limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',\n                      errors='replace', fields_limit=None):\n    \"\"\"\n    Return a list of key/value tuples parsed from query string.\n\n    Copied from urlparse with an additional \"fields_limit\" argument.\n    Copyright (C) 2013 Python Software Foundation (see LICENSE.python).\n\n    Arguments:\n\n    qs: percent-encoded query string to be parsed\n\n    keep_blank_values: flag indicating whether blank values in\n        percent-encoded queries should be treated as blank strings. A\n        true value indicates that blanks should be retained as blank\n        strings. The default false value indicates that blank values\n        are to be ignored and treated as if they were  not included.\n\n    encoding and errors: specify how to decode percent-encoded sequences\n        into Unicode characters, as accepted by the bytes.decode() method.\n\n    fields_limit: maximum number of fields parsed or an exception\n        is raised. None means no limit and is the default.\n    \"\"\"\n    if fields_limit:\n        pairs = FIELDS_MATCH.split(qs, fields_limit)\n        if len(pairs) > fields_limit:\n            raise TooManyFieldsSent(\n                'The number of GET/POST parameters exceeded '\n                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n            )\n    else:\n        pairs = FIELDS_MATCH.split(qs)\n    r = []\n    for name_value in pairs:\n        if not name_value:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            r.append((name, value))\n    return r\n"
  },
  {
    "patch": "diff --git a/django/views/static.py b/django/views/static.py\nindex 03e8c34a1c..289d26ef55 100644\n--- a/django/views/static.py\n+++ b/django/views/static.py\n@@ -10,9 +10,9 @@ import stat\n \n from django.http import (\n     FileResponse, Http404, HttpResponse, HttpResponseNotModified,\n-    HttpResponseRedirect,\n )\n from django.template import Context, Engine, TemplateDoesNotExist, loader\n+from django.utils._os import safe_join\n from django.utils.http import http_date, parse_http_date\n from django.utils.translation import gettext as _, gettext_lazy\n \n@@ -33,25 +33,11 @@ def serve(request, path, document_root=None, show_indexes=False):\n     but if you'd like to override it, you can create a template called\n     ``static/directory_index.html``.\n     \"\"\"\n-    path = posixpath.normpath(path)\n-    path = path.lstrip('/')\n-    newpath = ''\n-    for part in path.split('/'):\n-        if not part:\n-            # Strip empty path components.\n-            continue\n-        drive, part = os.path.splitdrive(part)\n-        head, part = os.path.split(part)\n-        if part in (os.curdir, os.pardir):\n-            # Strip '.' and '..' in path.\n-            continue\n-        newpath = os.path.join(newpath, part).replace('\\\\', '/')\n-    if newpath and path != newpath:\n-        return HttpResponseRedirect(newpath)\n-    fullpath = os.path.join(document_root, newpath)\n+    path = posixpath.normpath(path).lstrip('/')\n+    fullpath = safe_join(document_root, path)\n     if os.path.isdir(fullpath):\n         if show_indexes:\n-            return directory_index(newpath, fullpath)\n+            return directory_index(path, fullpath)\n         raise Http404(_(\"Directory indexes are not allowed here.\"))\n     if not os.path.exists(fullpath):\n         raise Http404(_('\"%(path)s\" does not exist') % {'path': fullpath})\n",
    "commit_message": "Fixed CVE-2017-7234 -- Fixed open redirect vulnerability in views.static.serve().\n\nThis is a security fix.\n\n",
    "code_before": "\"\"\"\nViews and functions for serving static files. These are only to be used\nduring development, and SHOULD NOT be used in a production setting.\n\"\"\"\nimport mimetypes\nimport os\nimport posixpath\nimport re\nimport stat\n\nfrom django.http import (\n    FileResponse, Http404, HttpResponse, HttpResponseNotModified,\n    HttpResponseRedirect,\n)\nfrom django.template import Context, Engine, TemplateDoesNotExist, loader\nfrom django.utils.http import http_date, parse_http_date\nfrom django.utils.translation import gettext as _, gettext_lazy\n\n\ndef serve(request, path, document_root=None, show_indexes=False):\n    \"\"\"\n    Serve static files below a given point in the directory structure.\n\n    To use, put a URL pattern such as::\n\n        from django.views.static import serve\n\n        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})\n\n    in your URLconf. You must provide the ``document_root`` param. You may\n    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index\n    of the directory.  This index view will use the template hardcoded below,\n    but if you'd like to override it, you can create a template called\n    ``static/directory_index.html``.\n    \"\"\"\n    path = posixpath.normpath(path)\n    path = path.lstrip('/')\n    newpath = ''\n    for part in path.split('/'):\n        if not part:\n            # Strip empty path components.\n            continue\n        drive, part = os.path.splitdrive(part)\n        head, part = os.path.split(part)\n        if part in (os.curdir, os.pardir):\n            # Strip '.' and '..' in path.\n            continue\n        newpath = os.path.join(newpath, part).replace('\\\\', '/')\n    if newpath and path != newpath:\n        return HttpResponseRedirect(newpath)\n    fullpath = os.path.join(document_root, newpath)\n    if os.path.isdir(fullpath):\n        if show_indexes:\n            return directory_index(newpath, fullpath)\n        raise Http404(_(\"Directory indexes are not allowed here.\"))\n    if not os.path.exists(fullpath):\n        raise Http404(_('\"%(path)s\" does not exist') % {'path': fullpath})\n    # Respect the If-Modified-Since header.\n    statobj = os.stat(fullpath)\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj.st_mtime, statobj.st_size):\n        return HttpResponseNotModified()\n    content_type, encoding = mimetypes.guess_type(fullpath)\n    content_type = content_type or 'application/octet-stream'\n    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)\n    response[\"Last-Modified\"] = http_date(statobj.st_mtime)\n    if stat.S_ISREG(statobj.st_mode):\n        response[\"Content-Length\"] = statobj.st_size\n    if encoding:\n        response[\"Content-Encoding\"] = encoding\n    return response\n\n\nDEFAULT_DIRECTORY_INDEX_TEMPLATE = \"\"\"\n{% load i18n %}\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n    <meta http-equiv=\"Content-Language\" content=\"en-us\" />\n    <meta name=\"robots\" content=\"NONE,NOARCHIVE\" />\n    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>\n  </head>\n  <body>\n    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>\n    <ul>\n      {% if directory != \"/\" %}\n      <li><a href=\"../\">../</a></li>\n      {% endif %}\n      {% for f in file_list %}\n      <li><a href=\"{{ f|urlencode }}\">{{ f }}</a></li>\n      {% endfor %}\n    </ul>\n  </body>\n</html>\n\"\"\"\ntemplate_translatable = gettext_lazy(\"Index of %(directory)s\")\n\n\ndef directory_index(path, fullpath):\n    try:\n        t = loader.select_template([\n            'static/directory_index.html',\n            'static/directory_index',\n        ])\n    except TemplateDoesNotExist:\n        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)\n    files = []\n    for f in os.listdir(fullpath):\n        if not f.startswith('.'):\n            if os.path.isdir(os.path.join(fullpath, f)):\n                f += '/'\n            files.append(f)\n    c = Context({\n        'directory': path + '/',\n        'file_list': files,\n    })\n    return HttpResponse(t.render(c))\n\n\ndef was_modified_since(header=None, mtime=0, size=0):\n    \"\"\"\n    Was something modified since the user last downloaded it?\n\n    header\n      This is the value of the If-Modified-Since header.  If this is None,\n      I'll just return True.\n\n    mtime\n      This is the modification time of the item we're talking about.\n\n    size\n      This is the size of the item we're talking about.\n    \"\"\"\n    try:\n        if header is None:\n            raise ValueError\n        matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header,\n                           re.IGNORECASE)\n        header_mtime = parse_http_date(matches.group(1))\n        header_len = matches.group(3)\n        if header_len and int(header_len) != size:\n            raise ValueError\n        if int(mtime) > header_mtime:\n            raise ValueError\n    except (AttributeError, ValueError, OverflowError):\n        return True\n    return False\n",
    "code_after": "\"\"\"\nViews and functions for serving static files. These are only to be used\nduring development, and SHOULD NOT be used in a production setting.\n\"\"\"\nimport mimetypes\nimport os\nimport posixpath\nimport re\nimport stat\n\nfrom django.http import (\n    FileResponse, Http404, HttpResponse, HttpResponseNotModified,\n)\nfrom django.template import Context, Engine, TemplateDoesNotExist, loader\nfrom django.utils._os import safe_join\nfrom django.utils.http import http_date, parse_http_date\nfrom django.utils.translation import gettext as _, gettext_lazy\n\n\ndef serve(request, path, document_root=None, show_indexes=False):\n    \"\"\"\n    Serve static files below a given point in the directory structure.\n\n    To use, put a URL pattern such as::\n\n        from django.views.static import serve\n\n        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})\n\n    in your URLconf. You must provide the ``document_root`` param. You may\n    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index\n    of the directory.  This index view will use the template hardcoded below,\n    but if you'd like to override it, you can create a template called\n    ``static/directory_index.html``.\n    \"\"\"\n    path = posixpath.normpath(path).lstrip('/')\n    fullpath = safe_join(document_root, path)\n    if os.path.isdir(fullpath):\n        if show_indexes:\n            return directory_index(path, fullpath)\n        raise Http404(_(\"Directory indexes are not allowed here.\"))\n    if not os.path.exists(fullpath):\n        raise Http404(_('\"%(path)s\" does not exist') % {'path': fullpath})\n    # Respect the If-Modified-Since header.\n    statobj = os.stat(fullpath)\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj.st_mtime, statobj.st_size):\n        return HttpResponseNotModified()\n    content_type, encoding = mimetypes.guess_type(fullpath)\n    content_type = content_type or 'application/octet-stream'\n    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)\n    response[\"Last-Modified\"] = http_date(statobj.st_mtime)\n    if stat.S_ISREG(statobj.st_mode):\n        response[\"Content-Length\"] = statobj.st_size\n    if encoding:\n        response[\"Content-Encoding\"] = encoding\n    return response\n\n\nDEFAULT_DIRECTORY_INDEX_TEMPLATE = \"\"\"\n{% load i18n %}\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n    <meta http-equiv=\"Content-Language\" content=\"en-us\" />\n    <meta name=\"robots\" content=\"NONE,NOARCHIVE\" />\n    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>\n  </head>\n  <body>\n    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>\n    <ul>\n      {% if directory != \"/\" %}\n      <li><a href=\"../\">../</a></li>\n      {% endif %}\n      {% for f in file_list %}\n      <li><a href=\"{{ f|urlencode }}\">{{ f }}</a></li>\n      {% endfor %}\n    </ul>\n  </body>\n</html>\n\"\"\"\ntemplate_translatable = gettext_lazy(\"Index of %(directory)s\")\n\n\ndef directory_index(path, fullpath):\n    try:\n        t = loader.select_template([\n            'static/directory_index.html',\n            'static/directory_index',\n        ])\n    except TemplateDoesNotExist:\n        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)\n    files = []\n    for f in os.listdir(fullpath):\n        if not f.startswith('.'):\n            if os.path.isdir(os.path.join(fullpath, f)):\n                f += '/'\n            files.append(f)\n    c = Context({\n        'directory': path + '/',\n        'file_list': files,\n    })\n    return HttpResponse(t.render(c))\n\n\ndef was_modified_since(header=None, mtime=0, size=0):\n    \"\"\"\n    Was something modified since the user last downloaded it?\n\n    header\n      This is the value of the If-Modified-Since header.  If this is None,\n      I'll just return True.\n\n    mtime\n      This is the modification time of the item we're talking about.\n\n    size\n      This is the size of the item we're talking about.\n    \"\"\"\n    try:\n        if header is None:\n            raise ValueError\n        matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header,\n                           re.IGNORECASE)\n        header_mtime = parse_http_date(matches.group(1))\n        header_len = matches.group(3)\n        if header_len and int(header_len) != size:\n            raise ValueError\n        if int(mtime) > header_mtime:\n            raise ValueError\n    except (AttributeError, ValueError, OverflowError):\n        return True\n    return False\n"
  },
  {
    "patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 6846068c2f..73858c5abd 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -96,12 +96,13 @@ class HttpRequest(object):\n         \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n         host = self._get_raw_host()\n \n-        # There is no hostname validation when DEBUG=True\n-        if settings.DEBUG:\n-            return host\n+        # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n+        allowed_hosts = settings.ALLOWED_HOSTS\n+        if settings.DEBUG and not allowed_hosts:\n+            allowed_hosts = ['localhost', '127.0.0.1', '[::1]']\n \n         domain, port = split_domain_port(host)\n-        if domain and validate_host(domain, settings.ALLOWED_HOSTS):\n+        if domain and validate_host(domain, allowed_hosts):\n             return host\n         else:\n             msg = \"Invalid HTTP_HOST header: %r.\" % host\n",
    "commit_message": "Fixed CVE-2016-9014 -- Validated Host header when DEBUG=True.\n\nThis is a security fix.\n\n",
    "code_before": "from __future__ import unicode_literals\n\nimport copy\nimport re\nimport sys\nfrom io import BytesIO\nfrom itertools import chain\n\nfrom django.conf import settings\nfrom django.core import signing\nfrom django.core.exceptions import (\n    DisallowedHost, ImproperlyConfigured, RequestDataTooBig,\n)\nfrom django.core.files import uploadhandler\nfrom django.http.multipartparser import MultiPartParser, MultiPartParserError\nfrom django.utils import six\nfrom django.utils.datastructures import ImmutableList, MultiValueDict\nfrom django.utils.encoding import (\n    escape_uri_path, force_bytes, force_str, force_text, iri_to_uri,\n)\nfrom django.utils.http import is_same_domain, limited_parse_qsl\nfrom django.utils.six.moves.urllib.parse import (\n    quote, urlencode, urljoin, urlsplit,\n)\n\nRAISE_ERROR = object()\nhost_validation_re = re.compile(r\"^([a-z0-9.-]+|\\[[a-f0-9]*:[a-f0-9\\.:]+\\])(:\\d+)?$\")\n\n\nclass UnreadablePostError(IOError):\n    pass\n\n\nclass RawPostDataException(Exception):\n    \"\"\"\n    You cannot access raw_post_data from a request that has\n    multipart/* POST data if it has been accessed via POST,\n    FILES, etc..\n    \"\"\"\n    pass\n\n\nclass HttpRequest(object):\n    \"\"\"A basic HTTP request.\"\"\"\n\n    # The encoding used in GET/POST dicts. None means use default setting.\n    _encoding = None\n    _upload_handlers = []\n\n    def __init__(self):\n        # WARNING: The `WSGIRequest` subclass doesn't call `super`.\n        # Any variable assignment made here should also happen in\n        # `WSGIRequest.__init__()`.\n\n        self.GET = QueryDict(mutable=True)\n        self.POST = QueryDict(mutable=True)\n        self.COOKIES = {}\n        self.META = {}\n        self.FILES = MultiValueDict()\n\n        self.path = ''\n        self.path_info = ''\n        self.method = None\n        self.resolver_match = None\n        self._post_parse_error = False\n        self.content_type = None\n        self.content_params = None\n\n    def __repr__(self):\n        if self.method is None or not self.get_full_path():\n            return force_str('<%s>' % self.__class__.__name__)\n        return force_str(\n            '<%s: %s %r>' % (self.__class__.__name__, self.method, force_str(self.get_full_path()))\n        )\n\n    def _get_raw_host(self):\n        \"\"\"\n        Return the HTTP host using the environment or request headers. Skip\n        allowed hosts protection, so may return an insecure host.\n        \"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n                'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = self.get_port()\n            if server_port != ('443' if self.is_secure() else '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n\n    def get_host(self):\n        \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n        host = self._get_raw_host()\n\n        # There is no hostname validation when DEBUG=True\n        if settings.DEBUG:\n            return host\n\n        domain, port = split_domain_port(host)\n        if domain and validate_host(domain, settings.ALLOWED_HOSTS):\n            return host\n        else:\n            msg = \"Invalid HTTP_HOST header: %r.\" % host\n            if domain:\n                msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain\n            else:\n                msg += \" The domain name provided is not valid according to RFC 1034/1035.\"\n            raise DisallowedHost(msg)\n\n    def get_port(self):\n        \"\"\"Return the port number for the request as a string.\"\"\"\n        if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META:\n            port = self.META['HTTP_X_FORWARDED_PORT']\n        else:\n            port = self.META['SERVER_PORT']\n        return str(port)\n\n    def get_full_path(self, force_append_slash=False):\n        # RFC 3986 requires query string arguments to be in the ASCII range.\n        # Rather than crash if this doesn't happen, we encode defensively.\n        return '%s%s%s' % (\n            escape_uri_path(self.path),\n            '/' if force_append_slash and not self.path.endswith('/') else '',\n            ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else ''\n        )\n\n    def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n        \"\"\"\n        Attempts to return a signed cookie. If the signature fails or the\n        cookie has expired, raises an exception... unless you provide the\n        default argument in which case that value will be returned instead.\n        \"\"\"\n        try:\n            cookie_value = self.COOKIES[key]\n        except KeyError:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        try:\n            value = signing.get_cookie_signer(salt=key + salt).unsign(\n                cookie_value, max_age=max_age)\n        except signing.BadSignature:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        return value\n\n    def get_raw_uri(self):\n        \"\"\"\n        Return an absolute URI from variables available in this request. Skip\n        allowed hosts protection, so may return insecure URI.\n        \"\"\"\n        return '{scheme}://{host}{path}'.format(\n            scheme=self.scheme,\n            host=self._get_raw_host(),\n            path=self.get_full_path(),\n        )\n\n    def build_absolute_uri(self, location=None):\n        \"\"\"\n        Builds an absolute URI from the location and the variables available in\n        this request. If no ``location`` is specified, the absolute URI is\n        built on ``request.get_full_path()``. Anyway, if the location is\n        absolute, it is simply converted to an RFC 3987 compliant URI and\n        returned and if location is relative or is scheme-relative (i.e.,\n        ``//example.com/``), it is urljoined to a base URL constructed from the\n        request variables.\n        \"\"\"\n        if location is None:\n            # Make it an absolute url (but schemeless and domainless) for the\n            # edge case that the path starts with '//'.\n            location = '//%s' % self.get_full_path()\n        bits = urlsplit(location)\n        if not (bits.scheme and bits.netloc):\n            current_uri = '{scheme}://{host}{path}'.format(scheme=self.scheme,\n                                                           host=self.get_host(),\n                                                           path=self.path)\n            # Join the constructed URL with the provided location, which will\n            # allow the provided ``location`` to apply query strings to the\n            # base path as well as override the host, if it begins with //\n            location = urljoin(current_uri, location)\n        return iri_to_uri(location)\n\n    def _get_scheme(self):\n        \"\"\"\n        Hook for subclasses like WSGIRequest to implement. Returns 'http' by\n        default.\n        \"\"\"\n        return 'http'\n\n    @property\n    def scheme(self):\n        if settings.SECURE_PROXY_SSL_HEADER:\n            try:\n                header, value = settings.SECURE_PROXY_SSL_HEADER\n            except ValueError:\n                raise ImproperlyConfigured(\n                    'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n                )\n            if self.META.get(header) == value:\n                return 'https'\n        return self._get_scheme()\n\n    def is_secure(self):\n        return self.scheme == 'https'\n\n    def is_ajax(self):\n        return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n\n    @property\n    def encoding(self):\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, val):\n        \"\"\"\n        Sets the encoding used for GET/POST accesses. If the GET or POST\n        dictionary has already been created, it is removed and recreated on the\n        next access (so that it is decoded correctly).\n        \"\"\"\n        self._encoding = val\n        if hasattr(self, '_get'):\n            del self._get\n        if hasattr(self, '_post'):\n            del self._post\n\n    def _initialize_handlers(self):\n        self._upload_handlers = [uploadhandler.load_handler(handler, self)\n                                 for handler in settings.FILE_UPLOAD_HANDLERS]\n\n    @property\n    def upload_handlers(self):\n        if not self._upload_handlers:\n            # If there are no upload handlers defined, initialize them from settings.\n            self._initialize_handlers()\n        return self._upload_handlers\n\n    @upload_handlers.setter\n    def upload_handlers(self, upload_handlers):\n        if hasattr(self, '_files'):\n            raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n        self._upload_handlers = upload_handlers\n\n    def parse_file_upload(self, META, post_data):\n        \"\"\"Returns a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n        self.upload_handlers = ImmutableList(\n            self.upload_handlers,\n            warning=\"You cannot alter upload handlers after the upload has been processed.\"\n        )\n        parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n        return parser.parse()\n\n    @property\n    def body(self):\n        if not hasattr(self, '_body'):\n            if self._read_started:\n                raise RawPostDataException(\"You cannot access body after reading from request's data stream\")\n\n            # Limit the maximum request data size that will be handled in-memory.\n            if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                    int(self.META.get('CONTENT_LENGTH') or 0) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n            try:\n                self._body = self.read()\n            except IOError as e:\n                six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n            self._stream = BytesIO(self._body)\n        return self._body\n\n    def _mark_post_parse_error(self):\n        self._post = QueryDict()\n        self._files = MultiValueDict()\n        self._post_parse_error = True\n\n    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != 'POST':\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n            return\n        if self._read_started and not hasattr(self, '_body'):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == 'multipart/form-data':\n            if hasattr(self, '_body'):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                # Mark that an error occurred. This allows self.__repr__ to\n                # be explicit about it instead of simply representing an\n                # empty POST\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == 'application/x-www-form-urlencoded':\n            self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n        else:\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n\n    def close(self):\n        if hasattr(self, '_files'):\n            for f in chain.from_iterable(l[1] for l in self._files.lists()):\n                f.close()\n\n    # File-like and iterator interface.\n    #\n    # Expects self._stream to be set to an appropriate source of bytes by\n    # a corresponding request subclass (e.g. WSGIRequest).\n    # Also when request data has already been read by request.POST or\n    # request.body, self._stream points to a BytesIO instance\n    # containing that data.\n\n    def read(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.read(*args, **kwargs)\n        except IOError as e:\n            six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n\n    def readline(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.readline(*args, **kwargs)\n        except IOError as e:\n            six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n\n    def xreadlines(self):\n        while True:\n            buf = self.readline()\n            if not buf:\n                break\n            yield buf\n\n    __iter__ = xreadlines\n\n    def readlines(self):\n        return list(iter(self))\n\n\nclass QueryDict(MultiValueDict):\n    \"\"\"\n    A specialized MultiValueDict which represents a query string.\n\n    A QueryDict can be used to represent GET or POST data. It subclasses\n    MultiValueDict since keys in such data can be repeated, for instance\n    in the data from a form with a <select multiple> field.\n\n    By default QueryDicts are immutable, though the copy() method\n    will always return a mutable copy.\n\n    Both keys and values set on this class are converted from the given encoding\n    (DEFAULT_CHARSET by default) to unicode.\n    \"\"\"\n\n    # These are both reset in __init__, but is specified here at the class\n    # level so that unpickling will have valid values\n    _mutable = True\n    _encoding = None\n\n    def __init__(self, query_string=None, mutable=False, encoding=None):\n        super(QueryDict, self).__init__()\n        if not encoding:\n            encoding = settings.DEFAULT_CHARSET\n        self.encoding = encoding\n        query_string = query_string or ''\n        parse_qsl_kwargs = {\n            'keep_blank_values': True,\n            'fields_limit': settings.DATA_UPLOAD_MAX_NUMBER_FIELDS,\n            'encoding': encoding,\n        }\n        if six.PY3:\n            if isinstance(query_string, bytes):\n                # query_string normally contains URL-encoded data, a subset of ASCII.\n                try:\n                    query_string = query_string.decode(encoding)\n                except UnicodeDecodeError:\n                    # ... but some user agents are misbehaving :-(\n                    query_string = query_string.decode('iso-8859-1')\n            for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n                self.appendlist(key, value)\n        else:\n            for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n                try:\n                    value = value.decode(encoding)\n                except UnicodeDecodeError:\n                    value = value.decode('iso-8859-1')\n                self.appendlist(force_text(key, encoding, errors='replace'),\n                                value)\n        self._mutable = mutable\n\n    @classmethod\n    def fromkeys(cls, iterable, value='', mutable=False, encoding=None):\n        \"\"\"\n        Return a new QueryDict with keys (may be repeated) from an iterable and\n        values from value.\n        \"\"\"\n        q = cls('', mutable=True, encoding=encoding)\n        for key in iterable:\n            q.appendlist(key, value)\n        if not mutable:\n            q._mutable = False\n        return q\n\n    @property\n    def encoding(self):\n        if self._encoding is None:\n            self._encoding = settings.DEFAULT_CHARSET\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value):\n        self._encoding = value\n\n    def _assert_mutable(self):\n        if not self._mutable:\n            raise AttributeError(\"This QueryDict instance is immutable\")\n\n    def __setitem__(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super(QueryDict, self).__setitem__(key, value)\n\n    def __delitem__(self, key):\n        self._assert_mutable()\n        super(QueryDict, self).__delitem__(key)\n\n    def __copy__(self):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        for key, value in six.iterlists(self):\n            result.setlist(key, value)\n        return result\n\n    def __deepcopy__(self, memo):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        memo[id(self)] = result\n        for key, value in six.iterlists(self):\n            result.setlist(copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n        return result\n\n    def setlist(self, key, list_):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        list_ = [bytes_to_text(elt, self.encoding) for elt in list_]\n        super(QueryDict, self).setlist(key, list_)\n\n    def setlistdefault(self, key, default_list=None):\n        self._assert_mutable()\n        return super(QueryDict, self).setlistdefault(key, default_list)\n\n    def appendlist(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super(QueryDict, self).appendlist(key, value)\n\n    def pop(self, key, *args):\n        self._assert_mutable()\n        return super(QueryDict, self).pop(key, *args)\n\n    def popitem(self):\n        self._assert_mutable()\n        return super(QueryDict, self).popitem()\n\n    def clear(self):\n        self._assert_mutable()\n        super(QueryDict, self).clear()\n\n    def setdefault(self, key, default=None):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        default = bytes_to_text(default, self.encoding)\n        return super(QueryDict, self).setdefault(key, default)\n\n    def copy(self):\n        \"\"\"Returns a mutable copy of this object.\"\"\"\n        return self.__deepcopy__({})\n\n    def urlencode(self, safe=None):\n        \"\"\"\n        Returns an encoded string of all query string arguments.\n\n        :arg safe: Used to specify characters which do not require quoting, for\n            example::\n\n                >>> q = QueryDict(mutable=True)\n                >>> q['next'] = '/a&b/'\n                >>> q.urlencode()\n                'next=%2Fa%26b%2F'\n                >>> q.urlencode(safe='/')\n                'next=/a%26b/'\n        \"\"\"\n        output = []\n        if safe:\n            safe = force_bytes(safe, self.encoding)\n\n            def encode(k, v):\n                return '%s=%s' % ((quote(k, safe), quote(v, safe)))\n        else:\n            def encode(k, v):\n                return urlencode({k: v})\n        for k, list_ in self.lists():\n            k = force_bytes(k, self.encoding)\n            output.extend(encode(k, force_bytes(v, self.encoding))\n                          for v in list_)\n        return '&'.join(output)\n\n\n# It's neither necessary nor appropriate to use\n# django.utils.encoding.force_text for parsing URLs and form inputs. Thus,\n# this slightly more restricted function, used by QueryDict.\ndef bytes_to_text(s, encoding):\n    \"\"\"\n    Converts basestring objects to unicode, using the given encoding. Illegally\n    encoded input characters are replaced with Unicode \"unknown\" codepoint\n    (\\ufffd).\n\n    Returns any non-basestring objects without change.\n    \"\"\"\n    if isinstance(s, bytes):\n        return six.text_type(s, encoding, 'replace')\n    else:\n        return s\n\n\ndef split_domain_port(host):\n    \"\"\"\n    Return a (domain, port) tuple from a given host.\n\n    Returned domain is lower-cased. If the host is invalid, the domain will be\n    empty.\n    \"\"\"\n    host = host.lower()\n\n    if not host_validation_re.match(host):\n        return '', ''\n\n    if host[-1] == ']':\n        # It's an IPv6 address without a port.\n        return host, ''\n    bits = host.rsplit(':', 1)\n    if len(bits) == 2:\n        return tuple(bits)\n    return bits[0], ''\n\n\ndef validate_host(host, allowed_hosts):\n    \"\"\"\n    Validate the given host for this site.\n\n    Check that the host looks valid and matches a host or host pattern in the\n    given list of ``allowed_hosts``. Any pattern beginning with a period\n    matches a domain and all its subdomains (e.g. ``.example.com`` matches\n    ``example.com`` and any subdomain), ``*`` matches anything, and anything\n    else must match exactly.\n\n    Note: This function assumes that the given host is lower-cased and has\n    already had the port, if any, stripped off.\n\n    Return ``True`` for a valid host, ``False`` otherwise.\n    \"\"\"\n    host = host[:-1] if host.endswith('.') else host\n\n    for pattern in allowed_hosts:\n        if pattern == '*' or is_same_domain(host, pattern):\n            return True\n\n    return False\n",
    "code_after": "from __future__ import unicode_literals\n\nimport copy\nimport re\nimport sys\nfrom io import BytesIO\nfrom itertools import chain\n\nfrom django.conf import settings\nfrom django.core import signing\nfrom django.core.exceptions import (\n    DisallowedHost, ImproperlyConfigured, RequestDataTooBig,\n)\nfrom django.core.files import uploadhandler\nfrom django.http.multipartparser import MultiPartParser, MultiPartParserError\nfrom django.utils import six\nfrom django.utils.datastructures import ImmutableList, MultiValueDict\nfrom django.utils.encoding import (\n    escape_uri_path, force_bytes, force_str, force_text, iri_to_uri,\n)\nfrom django.utils.http import is_same_domain, limited_parse_qsl\nfrom django.utils.six.moves.urllib.parse import (\n    quote, urlencode, urljoin, urlsplit,\n)\n\nRAISE_ERROR = object()\nhost_validation_re = re.compile(r\"^([a-z0-9.-]+|\\[[a-f0-9]*:[a-f0-9\\.:]+\\])(:\\d+)?$\")\n\n\nclass UnreadablePostError(IOError):\n    pass\n\n\nclass RawPostDataException(Exception):\n    \"\"\"\n    You cannot access raw_post_data from a request that has\n    multipart/* POST data if it has been accessed via POST,\n    FILES, etc..\n    \"\"\"\n    pass\n\n\nclass HttpRequest(object):\n    \"\"\"A basic HTTP request.\"\"\"\n\n    # The encoding used in GET/POST dicts. None means use default setting.\n    _encoding = None\n    _upload_handlers = []\n\n    def __init__(self):\n        # WARNING: The `WSGIRequest` subclass doesn't call `super`.\n        # Any variable assignment made here should also happen in\n        # `WSGIRequest.__init__()`.\n\n        self.GET = QueryDict(mutable=True)\n        self.POST = QueryDict(mutable=True)\n        self.COOKIES = {}\n        self.META = {}\n        self.FILES = MultiValueDict()\n\n        self.path = ''\n        self.path_info = ''\n        self.method = None\n        self.resolver_match = None\n        self._post_parse_error = False\n        self.content_type = None\n        self.content_params = None\n\n    def __repr__(self):\n        if self.method is None or not self.get_full_path():\n            return force_str('<%s>' % self.__class__.__name__)\n        return force_str(\n            '<%s: %s %r>' % (self.__class__.__name__, self.method, force_str(self.get_full_path()))\n        )\n\n    def _get_raw_host(self):\n        \"\"\"\n        Return the HTTP host using the environment or request headers. Skip\n        allowed hosts protection, so may return an insecure host.\n        \"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n                'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = self.get_port()\n            if server_port != ('443' if self.is_secure() else '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n\n    def get_host(self):\n        \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n        host = self._get_raw_host()\n\n        # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n        allowed_hosts = settings.ALLOWED_HOSTS\n        if settings.DEBUG and not allowed_hosts:\n            allowed_hosts = ['localhost', '127.0.0.1', '[::1]']\n\n        domain, port = split_domain_port(host)\n        if domain and validate_host(domain, allowed_hosts):\n            return host\n        else:\n            msg = \"Invalid HTTP_HOST header: %r.\" % host\n            if domain:\n                msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain\n            else:\n                msg += \" The domain name provided is not valid according to RFC 1034/1035.\"\n            raise DisallowedHost(msg)\n\n    def get_port(self):\n        \"\"\"Return the port number for the request as a string.\"\"\"\n        if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META:\n            port = self.META['HTTP_X_FORWARDED_PORT']\n        else:\n            port = self.META['SERVER_PORT']\n        return str(port)\n\n    def get_full_path(self, force_append_slash=False):\n        # RFC 3986 requires query string arguments to be in the ASCII range.\n        # Rather than crash if this doesn't happen, we encode defensively.\n        return '%s%s%s' % (\n            escape_uri_path(self.path),\n            '/' if force_append_slash and not self.path.endswith('/') else '',\n            ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else ''\n        )\n\n    def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n        \"\"\"\n        Attempts to return a signed cookie. If the signature fails or the\n        cookie has expired, raises an exception... unless you provide the\n        default argument in which case that value will be returned instead.\n        \"\"\"\n        try:\n            cookie_value = self.COOKIES[key]\n        except KeyError:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        try:\n            value = signing.get_cookie_signer(salt=key + salt).unsign(\n                cookie_value, max_age=max_age)\n        except signing.BadSignature:\n            if default is not RAISE_ERROR:\n                return default\n            else:\n                raise\n        return value\n\n    def get_raw_uri(self):\n        \"\"\"\n        Return an absolute URI from variables available in this request. Skip\n        allowed hosts protection, so may return insecure URI.\n        \"\"\"\n        return '{scheme}://{host}{path}'.format(\n            scheme=self.scheme,\n            host=self._get_raw_host(),\n            path=self.get_full_path(),\n        )\n\n    def build_absolute_uri(self, location=None):\n        \"\"\"\n        Builds an absolute URI from the location and the variables available in\n        this request. If no ``location`` is specified, the absolute URI is\n        built on ``request.get_full_path()``. Anyway, if the location is\n        absolute, it is simply converted to an RFC 3987 compliant URI and\n        returned and if location is relative or is scheme-relative (i.e.,\n        ``//example.com/``), it is urljoined to a base URL constructed from the\n        request variables.\n        \"\"\"\n        if location is None:\n            # Make it an absolute url (but schemeless and domainless) for the\n            # edge case that the path starts with '//'.\n            location = '//%s' % self.get_full_path()\n        bits = urlsplit(location)\n        if not (bits.scheme and bits.netloc):\n            current_uri = '{scheme}://{host}{path}'.format(scheme=self.scheme,\n                                                           host=self.get_host(),\n                                                           path=self.path)\n            # Join the constructed URL with the provided location, which will\n            # allow the provided ``location`` to apply query strings to the\n            # base path as well as override the host, if it begins with //\n            location = urljoin(current_uri, location)\n        return iri_to_uri(location)\n\n    def _get_scheme(self):\n        \"\"\"\n        Hook for subclasses like WSGIRequest to implement. Returns 'http' by\n        default.\n        \"\"\"\n        return 'http'\n\n    @property\n    def scheme(self):\n        if settings.SECURE_PROXY_SSL_HEADER:\n            try:\n                header, value = settings.SECURE_PROXY_SSL_HEADER\n            except ValueError:\n                raise ImproperlyConfigured(\n                    'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n                )\n            if self.META.get(header) == value:\n                return 'https'\n        return self._get_scheme()\n\n    def is_secure(self):\n        return self.scheme == 'https'\n\n    def is_ajax(self):\n        return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n\n    @property\n    def encoding(self):\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, val):\n        \"\"\"\n        Sets the encoding used for GET/POST accesses. If the GET or POST\n        dictionary has already been created, it is removed and recreated on the\n        next access (so that it is decoded correctly).\n        \"\"\"\n        self._encoding = val\n        if hasattr(self, '_get'):\n            del self._get\n        if hasattr(self, '_post'):\n            del self._post\n\n    def _initialize_handlers(self):\n        self._upload_handlers = [uploadhandler.load_handler(handler, self)\n                                 for handler in settings.FILE_UPLOAD_HANDLERS]\n\n    @property\n    def upload_handlers(self):\n        if not self._upload_handlers:\n            # If there are no upload handlers defined, initialize them from settings.\n            self._initialize_handlers()\n        return self._upload_handlers\n\n    @upload_handlers.setter\n    def upload_handlers(self, upload_handlers):\n        if hasattr(self, '_files'):\n            raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n        self._upload_handlers = upload_handlers\n\n    def parse_file_upload(self, META, post_data):\n        \"\"\"Returns a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n        self.upload_handlers = ImmutableList(\n            self.upload_handlers,\n            warning=\"You cannot alter upload handlers after the upload has been processed.\"\n        )\n        parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n        return parser.parse()\n\n    @property\n    def body(self):\n        if not hasattr(self, '_body'):\n            if self._read_started:\n                raise RawPostDataException(\"You cannot access body after reading from request's data stream\")\n\n            # Limit the maximum request data size that will be handled in-memory.\n            if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                    int(self.META.get('CONTENT_LENGTH') or 0) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n            try:\n                self._body = self.read()\n            except IOError as e:\n                six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n            self._stream = BytesIO(self._body)\n        return self._body\n\n    def _mark_post_parse_error(self):\n        self._post = QueryDict()\n        self._files = MultiValueDict()\n        self._post_parse_error = True\n\n    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != 'POST':\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n            return\n        if self._read_started and not hasattr(self, '_body'):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == 'multipart/form-data':\n            if hasattr(self, '_body'):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                # Mark that an error occurred. This allows self.__repr__ to\n                # be explicit about it instead of simply representing an\n                # empty POST\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == 'application/x-www-form-urlencoded':\n            self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n        else:\n            self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n\n    def close(self):\n        if hasattr(self, '_files'):\n            for f in chain.from_iterable(l[1] for l in self._files.lists()):\n                f.close()\n\n    # File-like and iterator interface.\n    #\n    # Expects self._stream to be set to an appropriate source of bytes by\n    # a corresponding request subclass (e.g. WSGIRequest).\n    # Also when request data has already been read by request.POST or\n    # request.body, self._stream points to a BytesIO instance\n    # containing that data.\n\n    def read(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.read(*args, **kwargs)\n        except IOError as e:\n            six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n\n    def readline(self, *args, **kwargs):\n        self._read_started = True\n        try:\n            return self._stream.readline(*args, **kwargs)\n        except IOError as e:\n            six.reraise(UnreadablePostError, UnreadablePostError(*e.args), sys.exc_info()[2])\n\n    def xreadlines(self):\n        while True:\n            buf = self.readline()\n            if not buf:\n                break\n            yield buf\n\n    __iter__ = xreadlines\n\n    def readlines(self):\n        return list(iter(self))\n\n\nclass QueryDict(MultiValueDict):\n    \"\"\"\n    A specialized MultiValueDict which represents a query string.\n\n    A QueryDict can be used to represent GET or POST data. It subclasses\n    MultiValueDict since keys in such data can be repeated, for instance\n    in the data from a form with a <select multiple> field.\n\n    By default QueryDicts are immutable, though the copy() method\n    will always return a mutable copy.\n\n    Both keys and values set on this class are converted from the given encoding\n    (DEFAULT_CHARSET by default) to unicode.\n    \"\"\"\n\n    # These are both reset in __init__, but is specified here at the class\n    # level so that unpickling will have valid values\n    _mutable = True\n    _encoding = None\n\n    def __init__(self, query_string=None, mutable=False, encoding=None):\n        super(QueryDict, self).__init__()\n        if not encoding:\n            encoding = settings.DEFAULT_CHARSET\n        self.encoding = encoding\n        query_string = query_string or ''\n        parse_qsl_kwargs = {\n            'keep_blank_values': True,\n            'fields_limit': settings.DATA_UPLOAD_MAX_NUMBER_FIELDS,\n            'encoding': encoding,\n        }\n        if six.PY3:\n            if isinstance(query_string, bytes):\n                # query_string normally contains URL-encoded data, a subset of ASCII.\n                try:\n                    query_string = query_string.decode(encoding)\n                except UnicodeDecodeError:\n                    # ... but some user agents are misbehaving :-(\n                    query_string = query_string.decode('iso-8859-1')\n            for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n                self.appendlist(key, value)\n        else:\n            for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n                try:\n                    value = value.decode(encoding)\n                except UnicodeDecodeError:\n                    value = value.decode('iso-8859-1')\n                self.appendlist(force_text(key, encoding, errors='replace'),\n                                value)\n        self._mutable = mutable\n\n    @classmethod\n    def fromkeys(cls, iterable, value='', mutable=False, encoding=None):\n        \"\"\"\n        Return a new QueryDict with keys (may be repeated) from an iterable and\n        values from value.\n        \"\"\"\n        q = cls('', mutable=True, encoding=encoding)\n        for key in iterable:\n            q.appendlist(key, value)\n        if not mutable:\n            q._mutable = False\n        return q\n\n    @property\n    def encoding(self):\n        if self._encoding is None:\n            self._encoding = settings.DEFAULT_CHARSET\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value):\n        self._encoding = value\n\n    def _assert_mutable(self):\n        if not self._mutable:\n            raise AttributeError(\"This QueryDict instance is immutable\")\n\n    def __setitem__(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super(QueryDict, self).__setitem__(key, value)\n\n    def __delitem__(self, key):\n        self._assert_mutable()\n        super(QueryDict, self).__delitem__(key)\n\n    def __copy__(self):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        for key, value in six.iterlists(self):\n            result.setlist(key, value)\n        return result\n\n    def __deepcopy__(self, memo):\n        result = self.__class__('', mutable=True, encoding=self.encoding)\n        memo[id(self)] = result\n        for key, value in six.iterlists(self):\n            result.setlist(copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n        return result\n\n    def setlist(self, key, list_):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        list_ = [bytes_to_text(elt, self.encoding) for elt in list_]\n        super(QueryDict, self).setlist(key, list_)\n\n    def setlistdefault(self, key, default_list=None):\n        self._assert_mutable()\n        return super(QueryDict, self).setlistdefault(key, default_list)\n\n    def appendlist(self, key, value):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        value = bytes_to_text(value, self.encoding)\n        super(QueryDict, self).appendlist(key, value)\n\n    def pop(self, key, *args):\n        self._assert_mutable()\n        return super(QueryDict, self).pop(key, *args)\n\n    def popitem(self):\n        self._assert_mutable()\n        return super(QueryDict, self).popitem()\n\n    def clear(self):\n        self._assert_mutable()\n        super(QueryDict, self).clear()\n\n    def setdefault(self, key, default=None):\n        self._assert_mutable()\n        key = bytes_to_text(key, self.encoding)\n        default = bytes_to_text(default, self.encoding)\n        return super(QueryDict, self).setdefault(key, default)\n\n    def copy(self):\n        \"\"\"Returns a mutable copy of this object.\"\"\"\n        return self.__deepcopy__({})\n\n    def urlencode(self, safe=None):\n        \"\"\"\n        Returns an encoded string of all query string arguments.\n\n        :arg safe: Used to specify characters which do not require quoting, for\n            example::\n\n                >>> q = QueryDict(mutable=True)\n                >>> q['next'] = '/a&b/'\n                >>> q.urlencode()\n                'next=%2Fa%26b%2F'\n                >>> q.urlencode(safe='/')\n                'next=/a%26b/'\n        \"\"\"\n        output = []\n        if safe:\n            safe = force_bytes(safe, self.encoding)\n\n            def encode(k, v):\n                return '%s=%s' % ((quote(k, safe), quote(v, safe)))\n        else:\n            def encode(k, v):\n                return urlencode({k: v})\n        for k, list_ in self.lists():\n            k = force_bytes(k, self.encoding)\n            output.extend(encode(k, force_bytes(v, self.encoding))\n                          for v in list_)\n        return '&'.join(output)\n\n\n# It's neither necessary nor appropriate to use\n# django.utils.encoding.force_text for parsing URLs and form inputs. Thus,\n# this slightly more restricted function, used by QueryDict.\ndef bytes_to_text(s, encoding):\n    \"\"\"\n    Converts basestring objects to unicode, using the given encoding. Illegally\n    encoded input characters are replaced with Unicode \"unknown\" codepoint\n    (\\ufffd).\n\n    Returns any non-basestring objects without change.\n    \"\"\"\n    if isinstance(s, bytes):\n        return six.text_type(s, encoding, 'replace')\n    else:\n        return s\n\n\ndef split_domain_port(host):\n    \"\"\"\n    Return a (domain, port) tuple from a given host.\n\n    Returned domain is lower-cased. If the host is invalid, the domain will be\n    empty.\n    \"\"\"\n    host = host.lower()\n\n    if not host_validation_re.match(host):\n        return '', ''\n\n    if host[-1] == ']':\n        # It's an IPv6 address without a port.\n        return host, ''\n    bits = host.rsplit(':', 1)\n    if len(bits) == 2:\n        return tuple(bits)\n    return bits[0], ''\n\n\ndef validate_host(host, allowed_hosts):\n    \"\"\"\n    Validate the given host for this site.\n\n    Check that the host looks valid and matches a host or host pattern in the\n    given list of ``allowed_hosts``. Any pattern beginning with a period\n    matches a domain and all its subdomains (e.g. ``.example.com`` matches\n    ``example.com`` and any subdomain), ``*`` matches anything, and anything\n    else must match exactly.\n\n    Note: This function assumes that the given host is lower-cased and has\n    already had the port, if any, stripped off.\n\n    Return ``True`` for a valid host, ``False`` otherwise.\n    \"\"\"\n    host = host[:-1] if host.endswith('.') else host\n\n    for pattern in allowed_hosts:\n        if pattern == '*' or is_same_domain(host, pattern):\n            return True\n\n    return False\n"
  },
  {
    "patch": "diff --git a/django/db/backends/oracle/creation.py b/django/db/backends/oracle/creation.py\nindex 01b4056b4b..18653c39aa 100644\n--- a/django/db/backends/oracle/creation.py\n+++ b/django/db/backends/oracle/creation.py\n@@ -4,11 +4,11 @@ import time\n from django.conf import settings\n from django.db.backends.base.creation import BaseDatabaseCreation\n from django.db.utils import DatabaseError\n+from django.utils.crypto import get_random_string\n from django.utils.functional import cached_property\n from django.utils.six.moves import input\n \n TEST_DATABASE_PREFIX = 'test_'\n-PASSWORD = 'Im_a_lumberjack'\n \n \n class DatabaseCreation(BaseDatabaseCreation):\n@@ -223,7 +223,11 @@ class DatabaseCreation(BaseDatabaseCreation):\n         ]\n         # Ignore \"user already exists\" error when keepdb is on\n         acceptable_ora_err = 'ORA-01920' if keepdb else None\n-        self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n+        success = self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n+        # If the password was randomly generated, change the user accordingly.\n+        if not success and self._test_settings_get('PASSWORD') is None:\n+            set_password = \"ALTER USER %(user)s IDENTIFIED BY %(password)s\"\n+            self._execute_statements(cursor, [set_password], parameters, verbosity)\n         # Most test-suites can be run without the create-view privilege. But some need it.\n         extra = \"GRANT CREATE VIEW TO %(user)s\"\n         success = self._execute_allow_fail_statements(cursor, [extra], parameters, verbosity, 'ORA-01031')\n@@ -298,7 +302,7 @@ class DatabaseCreation(BaseDatabaseCreation):\n         \"\"\"\n         settings_dict = self.connection.settings_dict\n         val = settings_dict['TEST'].get(key, default)\n-        if val is None:\n+        if val is None and prefixed:\n             val = TEST_DATABASE_PREFIX + settings_dict[prefixed]\n         return val\n \n@@ -315,7 +319,11 @@ class DatabaseCreation(BaseDatabaseCreation):\n         return self._test_settings_get('USER', prefixed='USER')\n \n     def _test_database_passwd(self):\n-        return self._test_settings_get('PASSWORD', default=PASSWORD)\n+        password = self._test_settings_get('PASSWORD')\n+        if password is None and self._test_user_create():\n+            # Oracle passwords are limited to 30 chars and can't contain symbols.\n+            password = get_random_string(length=30)\n+        return password\n \n     def _test_database_tblspace(self):\n         return self._test_settings_get('TBLSPACE', prefixed='USER')\n",
    "commit_message": "Fixed CVE-2016-9013 -- Generated a random database user password when running tests on Oracle.\n\nThis is a security fix.\n\n",
    "code_before": "import sys\nimport time\n\nfrom django.conf import settings\nfrom django.db.backends.base.creation import BaseDatabaseCreation\nfrom django.db.utils import DatabaseError\nfrom django.utils.functional import cached_property\nfrom django.utils.six.moves import input\n\nTEST_DATABASE_PREFIX = 'test_'\nPASSWORD = 'Im_a_lumberjack'\n\n\nclass DatabaseCreation(BaseDatabaseCreation):\n\n    @cached_property\n    def _maindb_connection(self):\n        \"\"\"\n        This is analogous to other backends' `_nodb_connection` property,\n        which allows access to an \"administrative\" connection which can\n        be used to manage the test databases.\n        For Oracle, the only connection that can be used for that purpose\n        is the main (non-test) connection.\n        \"\"\"\n        settings_dict = settings.DATABASES[self.connection.alias]\n        user = settings_dict.get('SAVED_USER') or settings_dict['USER']\n        password = settings_dict.get('SAVED_PASSWORD') or settings_dict['PASSWORD']\n        settings_dict = settings_dict.copy()\n        settings_dict.update(USER=user, PASSWORD=password)\n        DatabaseWrapper = type(self.connection)\n        return DatabaseWrapper(settings_dict, alias=self.connection.alias)\n\n    def _create_test_db(self, verbosity=1, autoclobber=False, keepdb=False):\n        parameters = self._get_test_db_params()\n        cursor = self._maindb_connection.cursor()\n        if self._test_database_create():\n            try:\n                self._execute_test_db_creation(cursor, parameters, verbosity, keepdb)\n            except Exception as e:\n                # if we want to keep the db, then no need to do any of the below,\n                # just return and skip it all.\n                if keepdb:\n                    return\n                sys.stderr.write(\"Got an error creating the test database: %s\\n\" % e)\n                if not autoclobber:\n                    confirm = input(\n                        \"It appears the test database, %s, already exists. \"\n                        \"Type 'yes' to delete it, or 'no' to cancel: \" % parameters['user'])\n                if autoclobber or confirm == 'yes':\n                    if verbosity >= 1:\n                        print(\"Destroying old test database for alias '%s'...\" % self.connection.alias)\n                    try:\n                        self._execute_test_db_destruction(cursor, parameters, verbosity)\n                    except DatabaseError as e:\n                        if 'ORA-29857' in str(e):\n                            self._handle_objects_preventing_db_destruction(cursor, parameters,\n                                                                           verbosity, autoclobber)\n                        else:\n                            # Ran into a database error that isn't about leftover objects in the tablespace\n                            sys.stderr.write(\"Got an error destroying the old test database: %s\\n\" % e)\n                            sys.exit(2)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error destroying the old test database: %s\\n\" % e)\n                        sys.exit(2)\n                    try:\n                        self._execute_test_db_creation(cursor, parameters, verbosity, keepdb)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error recreating the test database: %s\\n\" % e)\n                        sys.exit(2)\n                else:\n                    print(\"Tests cancelled.\")\n                    sys.exit(1)\n\n        if self._test_user_create():\n            if verbosity >= 1:\n                print(\"Creating test user...\")\n            try:\n                self._create_test_user(cursor, parameters, verbosity, keepdb)\n            except Exception as e:\n                # If we want to keep the db, then we want to also keep the user.\n                if keepdb:\n                    return\n                sys.stderr.write(\"Got an error creating the test user: %s\\n\" % e)\n                if not autoclobber:\n                    confirm = input(\n                        \"It appears the test user, %s, already exists. Type \"\n                        \"'yes' to delete it, or 'no' to cancel: \" % parameters['user'])\n                if autoclobber or confirm == 'yes':\n                    try:\n                        if verbosity >= 1:\n                            print(\"Destroying old test user...\")\n                        self._destroy_test_user(cursor, parameters, verbosity)\n                        if verbosity >= 1:\n                            print(\"Creating test user...\")\n                        self._create_test_user(cursor, parameters, verbosity, keepdb)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error recreating the test user: %s\\n\" % e)\n                        sys.exit(2)\n                else:\n                    print(\"Tests cancelled.\")\n                    sys.exit(1)\n\n        self._maindb_connection.close()  # done with main user -- test user and tablespaces created\n        self._switch_to_test_user(parameters)\n        return self.connection.settings_dict['NAME']\n\n    def _switch_to_test_user(self, parameters):\n        \"\"\"\n        Oracle doesn't have the concept of separate databases under the same user.\n        Thus, we use a separate user (see _create_test_db). This method is used\n        to switch to that user. We will need the main user again for clean-up when\n        we end testing, so we keep its credentials in SAVED_USER/SAVED_PASSWORD\n        entries in the settings dict.\n        \"\"\"\n        real_settings = settings.DATABASES[self.connection.alias]\n        real_settings['SAVED_USER'] = self.connection.settings_dict['SAVED_USER'] = \\\n            self.connection.settings_dict['USER']\n        real_settings['SAVED_PASSWORD'] = self.connection.settings_dict['SAVED_PASSWORD'] = \\\n            self.connection.settings_dict['PASSWORD']\n        real_test_settings = real_settings['TEST']\n        test_settings = self.connection.settings_dict['TEST']\n        real_test_settings['USER'] = real_settings['USER'] = test_settings['USER'] = \\\n            self.connection.settings_dict['USER'] = parameters['user']\n        real_settings['PASSWORD'] = self.connection.settings_dict['PASSWORD'] = parameters['password']\n\n    def set_as_test_mirror(self, primary_settings_dict):\n        \"\"\"\n        Set this database up to be used in testing as a mirror of a primary database\n        whose settings are given\n        \"\"\"\n        self.connection.settings_dict['USER'] = primary_settings_dict['USER']\n        self.connection.settings_dict['PASSWORD'] = primary_settings_dict['PASSWORD']\n\n    def _handle_objects_preventing_db_destruction(self, cursor, parameters, verbosity, autoclobber):\n        # There are objects in the test tablespace which prevent dropping it\n        # The easy fix is to drop the test user -- but are we allowed to do so?\n        print(\"There are objects in the old test database which prevent its destruction.\")\n        print(\"If they belong to the test user, deleting the user will allow the test \"\n              \"database to be recreated.\")\n        print(\"Otherwise, you will need to find and remove each of these objects, \"\n              \"or use a different tablespace.\\n\")\n        if self._test_user_create():\n            if not autoclobber:\n                confirm = input(\"Type 'yes' to delete user %s: \" % parameters['user'])\n            if autoclobber or confirm == 'yes':\n                try:\n                    if verbosity >= 1:\n                        print(\"Destroying old test user...\")\n                    self._destroy_test_user(cursor, parameters, verbosity)\n                except Exception as e:\n                    sys.stderr.write(\"Got an error destroying the test user: %s\\n\" % e)\n                    sys.exit(2)\n                try:\n                    if verbosity >= 1:\n                        print(\"Destroying old test database for alias '%s'...\" % self.connection.alias)\n                    self._execute_test_db_destruction(cursor, parameters, verbosity)\n                except Exception as e:\n                    sys.stderr.write(\"Got an error destroying the test database: %s\\n\" % e)\n                    sys.exit(2)\n            else:\n                print(\"Tests cancelled -- test database cannot be recreated.\")\n                sys.exit(1)\n        else:\n            print(\"Django is configured to use pre-existing test user '%s',\"\n                  \" and will not attempt to delete it.\\n\" % parameters['user'])\n            print(\"Tests cancelled -- test database cannot be recreated.\")\n            sys.exit(1)\n\n    def _destroy_test_db(self, test_database_name, verbosity=1):\n        \"\"\"\n        Destroy a test database, prompting the user for confirmation if the\n        database already exists. Returns the name of the test database created.\n        \"\"\"\n        self.connection.settings_dict['USER'] = self.connection.settings_dict['SAVED_USER']\n        self.connection.settings_dict['PASSWORD'] = self.connection.settings_dict['SAVED_PASSWORD']\n        self.connection.close()\n        parameters = self._get_test_db_params()\n        cursor = self._maindb_connection.cursor()\n        time.sleep(1)  # To avoid \"database is being accessed by other users\" errors.\n        if self._test_user_create():\n            if verbosity >= 1:\n                print('Destroying test user...')\n            self._destroy_test_user(cursor, parameters, verbosity)\n        if self._test_database_create():\n            if verbosity >= 1:\n                print('Destroying test database tables...')\n            self._execute_test_db_destruction(cursor, parameters, verbosity)\n        self._maindb_connection.close()\n\n    def _execute_test_db_creation(self, cursor, parameters, verbosity, keepdb=False):\n        if verbosity >= 2:\n            print(\"_create_test_db(): dbname = %s\" % parameters['user'])\n        statements = [\n            \"\"\"CREATE TABLESPACE %(tblspace)s\n               DATAFILE '%(datafile)s' SIZE 20M\n               REUSE AUTOEXTEND ON NEXT 10M MAXSIZE %(maxsize)s\n            \"\"\",\n            \"\"\"CREATE TEMPORARY TABLESPACE %(tblspace_temp)s\n               TEMPFILE '%(datafile_tmp)s' SIZE 20M\n               REUSE AUTOEXTEND ON NEXT 10M MAXSIZE %(maxsize_tmp)s\n            \"\"\",\n        ]\n        # Ignore \"tablespace already exists\" error when keepdb is on.\n        acceptable_ora_err = 'ORA-01543' if keepdb else None\n        self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n\n    def _create_test_user(self, cursor, parameters, verbosity, keepdb=False):\n        if verbosity >= 2:\n            print(\"_create_test_user(): username = %s\" % parameters['user'])\n        statements = [\n            \"\"\"CREATE USER %(user)s\n               IDENTIFIED BY %(password)s\n               DEFAULT TABLESPACE %(tblspace)s\n               TEMPORARY TABLESPACE %(tblspace_temp)s\n               QUOTA UNLIMITED ON %(tblspace)s\n            \"\"\",\n            \"\"\"GRANT CREATE SESSION,\n                     CREATE TABLE,\n                     CREATE SEQUENCE,\n                     CREATE PROCEDURE,\n                     CREATE TRIGGER\n               TO %(user)s\"\"\",\n        ]\n        # Ignore \"user already exists\" error when keepdb is on\n        acceptable_ora_err = 'ORA-01920' if keepdb else None\n        self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n        # Most test-suites can be run without the create-view privilege. But some need it.\n        extra = \"GRANT CREATE VIEW TO %(user)s\"\n        success = self._execute_allow_fail_statements(cursor, [extra], parameters, verbosity, 'ORA-01031')\n        if not success and verbosity >= 2:\n            print(\"Failed to grant CREATE VIEW permission to test user. This may be ok.\")\n\n    def _execute_test_db_destruction(self, cursor, parameters, verbosity):\n        if verbosity >= 2:\n            print(\"_execute_test_db_destruction(): dbname=%s\" % parameters['user'])\n        statements = [\n            'DROP TABLESPACE %(tblspace)s INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS',\n            'DROP TABLESPACE %(tblspace_temp)s INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS',\n        ]\n        self._execute_statements(cursor, statements, parameters, verbosity)\n\n    def _destroy_test_user(self, cursor, parameters, verbosity):\n        if verbosity >= 2:\n            print(\"_destroy_test_user(): user=%s\" % parameters['user'])\n            print(\"Be patient.  This can take some time...\")\n        statements = [\n            'DROP USER %(user)s CASCADE',\n        ]\n        self._execute_statements(cursor, statements, parameters, verbosity)\n\n    def _execute_statements(self, cursor, statements, parameters, verbosity, allow_quiet_fail=False):\n        for template in statements:\n            stmt = template % parameters\n            if verbosity >= 2:\n                print(stmt)\n            try:\n                cursor.execute(stmt)\n            except Exception as err:\n                if (not allow_quiet_fail) or verbosity >= 2:\n                    sys.stderr.write(\"Failed (%s)\\n\" % (err))\n                raise\n\n    def _execute_allow_fail_statements(self, cursor, statements, parameters, verbosity, acceptable_ora_err):\n        \"\"\"\n        Execute statements which are allowed to fail silently if the Oracle\n        error code given by `acceptable_ora_err` is raised. Return True if the\n        statements execute without an exception, or False otherwise.\n        \"\"\"\n        try:\n            # Statement can fail when acceptable_ora_err is not None\n            allow_quiet_fail = acceptable_ora_err is not None and len(acceptable_ora_err) > 0\n            self._execute_statements(cursor, statements, parameters, verbosity, allow_quiet_fail=allow_quiet_fail)\n            return True\n        except DatabaseError as err:\n            description = str(err)\n            if acceptable_ora_err is None or acceptable_ora_err not in description:\n                raise\n            return False\n\n    def _get_test_db_params(self):\n        return {\n            'dbname': self._test_database_name(),\n            'user': self._test_database_user(),\n            'password': self._test_database_passwd(),\n            'tblspace': self._test_database_tblspace(),\n            'tblspace_temp': self._test_database_tblspace_tmp(),\n            'datafile': self._test_database_tblspace_datafile(),\n            'datafile_tmp': self._test_database_tblspace_tmp_datafile(),\n            'maxsize': self._test_database_tblspace_size(),\n            'maxsize_tmp': self._test_database_tblspace_tmp_size(),\n        }\n\n    def _test_settings_get(self, key, default=None, prefixed=None):\n        \"\"\"\n        Return a value from the test settings dict,\n        or a given default,\n        or a prefixed entry from the main settings dict\n        \"\"\"\n        settings_dict = self.connection.settings_dict\n        val = settings_dict['TEST'].get(key, default)\n        if val is None:\n            val = TEST_DATABASE_PREFIX + settings_dict[prefixed]\n        return val\n\n    def _test_database_name(self):\n        return self._test_settings_get('NAME', prefixed='NAME')\n\n    def _test_database_create(self):\n        return self._test_settings_get('CREATE_DB', default=True)\n\n    def _test_user_create(self):\n        return self._test_settings_get('CREATE_USER', default=True)\n\n    def _test_database_user(self):\n        return self._test_settings_get('USER', prefixed='USER')\n\n    def _test_database_passwd(self):\n        return self._test_settings_get('PASSWORD', default=PASSWORD)\n\n    def _test_database_tblspace(self):\n        return self._test_settings_get('TBLSPACE', prefixed='USER')\n\n    def _test_database_tblspace_tmp(self):\n        settings_dict = self.connection.settings_dict\n        return settings_dict['TEST'].get('TBLSPACE_TMP',\n                                         TEST_DATABASE_PREFIX + settings_dict['USER'] + '_temp')\n\n    def _test_database_tblspace_datafile(self):\n        tblspace = '%s.dbf' % self._test_database_tblspace()\n        return self._test_settings_get('DATAFILE', default=tblspace)\n\n    def _test_database_tblspace_tmp_datafile(self):\n        tblspace = '%s.dbf' % self._test_database_tblspace_tmp()\n        return self._test_settings_get('DATAFILE_TMP', default=tblspace)\n\n    def _test_database_tblspace_size(self):\n        return self._test_settings_get('DATAFILE_MAXSIZE', default='500M')\n\n    def _test_database_tblspace_tmp_size(self):\n        return self._test_settings_get('DATAFILE_TMP_MAXSIZE', default='500M')\n\n    def _get_test_db_name(self):\n        \"\"\"\n        We need to return the 'production' DB name to get the test DB creation\n        machinery to work. This isn't a great deal in this case because DB\n        names as handled by Django haven't real counterparts in Oracle.\n        \"\"\"\n        return self.connection.settings_dict['NAME']\n\n    def test_db_signature(self):\n        settings_dict = self.connection.settings_dict\n        return (\n            settings_dict['HOST'],\n            settings_dict['PORT'],\n            settings_dict['ENGINE'],\n            settings_dict['NAME'],\n            self._test_database_user(),\n        )\n",
    "code_after": "import sys\nimport time\n\nfrom django.conf import settings\nfrom django.db.backends.base.creation import BaseDatabaseCreation\nfrom django.db.utils import DatabaseError\nfrom django.utils.crypto import get_random_string\nfrom django.utils.functional import cached_property\nfrom django.utils.six.moves import input\n\nTEST_DATABASE_PREFIX = 'test_'\n\n\nclass DatabaseCreation(BaseDatabaseCreation):\n\n    @cached_property\n    def _maindb_connection(self):\n        \"\"\"\n        This is analogous to other backends' `_nodb_connection` property,\n        which allows access to an \"administrative\" connection which can\n        be used to manage the test databases.\n        For Oracle, the only connection that can be used for that purpose\n        is the main (non-test) connection.\n        \"\"\"\n        settings_dict = settings.DATABASES[self.connection.alias]\n        user = settings_dict.get('SAVED_USER') or settings_dict['USER']\n        password = settings_dict.get('SAVED_PASSWORD') or settings_dict['PASSWORD']\n        settings_dict = settings_dict.copy()\n        settings_dict.update(USER=user, PASSWORD=password)\n        DatabaseWrapper = type(self.connection)\n        return DatabaseWrapper(settings_dict, alias=self.connection.alias)\n\n    def _create_test_db(self, verbosity=1, autoclobber=False, keepdb=False):\n        parameters = self._get_test_db_params()\n        cursor = self._maindb_connection.cursor()\n        if self._test_database_create():\n            try:\n                self._execute_test_db_creation(cursor, parameters, verbosity, keepdb)\n            except Exception as e:\n                # if we want to keep the db, then no need to do any of the below,\n                # just return and skip it all.\n                if keepdb:\n                    return\n                sys.stderr.write(\"Got an error creating the test database: %s\\n\" % e)\n                if not autoclobber:\n                    confirm = input(\n                        \"It appears the test database, %s, already exists. \"\n                        \"Type 'yes' to delete it, or 'no' to cancel: \" % parameters['user'])\n                if autoclobber or confirm == 'yes':\n                    if verbosity >= 1:\n                        print(\"Destroying old test database for alias '%s'...\" % self.connection.alias)\n                    try:\n                        self._execute_test_db_destruction(cursor, parameters, verbosity)\n                    except DatabaseError as e:\n                        if 'ORA-29857' in str(e):\n                            self._handle_objects_preventing_db_destruction(cursor, parameters,\n                                                                           verbosity, autoclobber)\n                        else:\n                            # Ran into a database error that isn't about leftover objects in the tablespace\n                            sys.stderr.write(\"Got an error destroying the old test database: %s\\n\" % e)\n                            sys.exit(2)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error destroying the old test database: %s\\n\" % e)\n                        sys.exit(2)\n                    try:\n                        self._execute_test_db_creation(cursor, parameters, verbosity, keepdb)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error recreating the test database: %s\\n\" % e)\n                        sys.exit(2)\n                else:\n                    print(\"Tests cancelled.\")\n                    sys.exit(1)\n\n        if self._test_user_create():\n            if verbosity >= 1:\n                print(\"Creating test user...\")\n            try:\n                self._create_test_user(cursor, parameters, verbosity, keepdb)\n            except Exception as e:\n                # If we want to keep the db, then we want to also keep the user.\n                if keepdb:\n                    return\n                sys.stderr.write(\"Got an error creating the test user: %s\\n\" % e)\n                if not autoclobber:\n                    confirm = input(\n                        \"It appears the test user, %s, already exists. Type \"\n                        \"'yes' to delete it, or 'no' to cancel: \" % parameters['user'])\n                if autoclobber or confirm == 'yes':\n                    try:\n                        if verbosity >= 1:\n                            print(\"Destroying old test user...\")\n                        self._destroy_test_user(cursor, parameters, verbosity)\n                        if verbosity >= 1:\n                            print(\"Creating test user...\")\n                        self._create_test_user(cursor, parameters, verbosity, keepdb)\n                    except Exception as e:\n                        sys.stderr.write(\"Got an error recreating the test user: %s\\n\" % e)\n                        sys.exit(2)\n                else:\n                    print(\"Tests cancelled.\")\n                    sys.exit(1)\n\n        self._maindb_connection.close()  # done with main user -- test user and tablespaces created\n        self._switch_to_test_user(parameters)\n        return self.connection.settings_dict['NAME']\n\n    def _switch_to_test_user(self, parameters):\n        \"\"\"\n        Oracle doesn't have the concept of separate databases under the same user.\n        Thus, we use a separate user (see _create_test_db). This method is used\n        to switch to that user. We will need the main user again for clean-up when\n        we end testing, so we keep its credentials in SAVED_USER/SAVED_PASSWORD\n        entries in the settings dict.\n        \"\"\"\n        real_settings = settings.DATABASES[self.connection.alias]\n        real_settings['SAVED_USER'] = self.connection.settings_dict['SAVED_USER'] = \\\n            self.connection.settings_dict['USER']\n        real_settings['SAVED_PASSWORD'] = self.connection.settings_dict['SAVED_PASSWORD'] = \\\n            self.connection.settings_dict['PASSWORD']\n        real_test_settings = real_settings['TEST']\n        test_settings = self.connection.settings_dict['TEST']\n        real_test_settings['USER'] = real_settings['USER'] = test_settings['USER'] = \\\n            self.connection.settings_dict['USER'] = parameters['user']\n        real_settings['PASSWORD'] = self.connection.settings_dict['PASSWORD'] = parameters['password']\n\n    def set_as_test_mirror(self, primary_settings_dict):\n        \"\"\"\n        Set this database up to be used in testing as a mirror of a primary database\n        whose settings are given\n        \"\"\"\n        self.connection.settings_dict['USER'] = primary_settings_dict['USER']\n        self.connection.settings_dict['PASSWORD'] = primary_settings_dict['PASSWORD']\n\n    def _handle_objects_preventing_db_destruction(self, cursor, parameters, verbosity, autoclobber):\n        # There are objects in the test tablespace which prevent dropping it\n        # The easy fix is to drop the test user -- but are we allowed to do so?\n        print(\"There are objects in the old test database which prevent its destruction.\")\n        print(\"If they belong to the test user, deleting the user will allow the test \"\n              \"database to be recreated.\")\n        print(\"Otherwise, you will need to find and remove each of these objects, \"\n              \"or use a different tablespace.\\n\")\n        if self._test_user_create():\n            if not autoclobber:\n                confirm = input(\"Type 'yes' to delete user %s: \" % parameters['user'])\n            if autoclobber or confirm == 'yes':\n                try:\n                    if verbosity >= 1:\n                        print(\"Destroying old test user...\")\n                    self._destroy_test_user(cursor, parameters, verbosity)\n                except Exception as e:\n                    sys.stderr.write(\"Got an error destroying the test user: %s\\n\" % e)\n                    sys.exit(2)\n                try:\n                    if verbosity >= 1:\n                        print(\"Destroying old test database for alias '%s'...\" % self.connection.alias)\n                    self._execute_test_db_destruction(cursor, parameters, verbosity)\n                except Exception as e:\n                    sys.stderr.write(\"Got an error destroying the test database: %s\\n\" % e)\n                    sys.exit(2)\n            else:\n                print(\"Tests cancelled -- test database cannot be recreated.\")\n                sys.exit(1)\n        else:\n            print(\"Django is configured to use pre-existing test user '%s',\"\n                  \" and will not attempt to delete it.\\n\" % parameters['user'])\n            print(\"Tests cancelled -- test database cannot be recreated.\")\n            sys.exit(1)\n\n    def _destroy_test_db(self, test_database_name, verbosity=1):\n        \"\"\"\n        Destroy a test database, prompting the user for confirmation if the\n        database already exists. Returns the name of the test database created.\n        \"\"\"\n        self.connection.settings_dict['USER'] = self.connection.settings_dict['SAVED_USER']\n        self.connection.settings_dict['PASSWORD'] = self.connection.settings_dict['SAVED_PASSWORD']\n        self.connection.close()\n        parameters = self._get_test_db_params()\n        cursor = self._maindb_connection.cursor()\n        time.sleep(1)  # To avoid \"database is being accessed by other users\" errors.\n        if self._test_user_create():\n            if verbosity >= 1:\n                print('Destroying test user...')\n            self._destroy_test_user(cursor, parameters, verbosity)\n        if self._test_database_create():\n            if verbosity >= 1:\n                print('Destroying test database tables...')\n            self._execute_test_db_destruction(cursor, parameters, verbosity)\n        self._maindb_connection.close()\n\n    def _execute_test_db_creation(self, cursor, parameters, verbosity, keepdb=False):\n        if verbosity >= 2:\n            print(\"_create_test_db(): dbname = %s\" % parameters['user'])\n        statements = [\n            \"\"\"CREATE TABLESPACE %(tblspace)s\n               DATAFILE '%(datafile)s' SIZE 20M\n               REUSE AUTOEXTEND ON NEXT 10M MAXSIZE %(maxsize)s\n            \"\"\",\n            \"\"\"CREATE TEMPORARY TABLESPACE %(tblspace_temp)s\n               TEMPFILE '%(datafile_tmp)s' SIZE 20M\n               REUSE AUTOEXTEND ON NEXT 10M MAXSIZE %(maxsize_tmp)s\n            \"\"\",\n        ]\n        # Ignore \"tablespace already exists\" error when keepdb is on.\n        acceptable_ora_err = 'ORA-01543' if keepdb else None\n        self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n\n    def _create_test_user(self, cursor, parameters, verbosity, keepdb=False):\n        if verbosity >= 2:\n            print(\"_create_test_user(): username = %s\" % parameters['user'])\n        statements = [\n            \"\"\"CREATE USER %(user)s\n               IDENTIFIED BY %(password)s\n               DEFAULT TABLESPACE %(tblspace)s\n               TEMPORARY TABLESPACE %(tblspace_temp)s\n               QUOTA UNLIMITED ON %(tblspace)s\n            \"\"\",\n            \"\"\"GRANT CREATE SESSION,\n                     CREATE TABLE,\n                     CREATE SEQUENCE,\n                     CREATE PROCEDURE,\n                     CREATE TRIGGER\n               TO %(user)s\"\"\",\n        ]\n        # Ignore \"user already exists\" error when keepdb is on\n        acceptable_ora_err = 'ORA-01920' if keepdb else None\n        success = self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)\n        # If the password was randomly generated, change the user accordingly.\n        if not success and self._test_settings_get('PASSWORD') is None:\n            set_password = \"ALTER USER %(user)s IDENTIFIED BY %(password)s\"\n            self._execute_statements(cursor, [set_password], parameters, verbosity)\n        # Most test-suites can be run without the create-view privilege. But some need it.\n        extra = \"GRANT CREATE VIEW TO %(user)s\"\n        success = self._execute_allow_fail_statements(cursor, [extra], parameters, verbosity, 'ORA-01031')\n        if not success and verbosity >= 2:\n            print(\"Failed to grant CREATE VIEW permission to test user. This may be ok.\")\n\n    def _execute_test_db_destruction(self, cursor, parameters, verbosity):\n        if verbosity >= 2:\n            print(\"_execute_test_db_destruction(): dbname=%s\" % parameters['user'])\n        statements = [\n            'DROP TABLESPACE %(tblspace)s INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS',\n            'DROP TABLESPACE %(tblspace_temp)s INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS',\n        ]\n        self._execute_statements(cursor, statements, parameters, verbosity)\n\n    def _destroy_test_user(self, cursor, parameters, verbosity):\n        if verbosity >= 2:\n            print(\"_destroy_test_user(): user=%s\" % parameters['user'])\n            print(\"Be patient.  This can take some time...\")\n        statements = [\n            'DROP USER %(user)s CASCADE',\n        ]\n        self._execute_statements(cursor, statements, parameters, verbosity)\n\n    def _execute_statements(self, cursor, statements, parameters, verbosity, allow_quiet_fail=False):\n        for template in statements:\n            stmt = template % parameters\n            if verbosity >= 2:\n                print(stmt)\n            try:\n                cursor.execute(stmt)\n            except Exception as err:\n                if (not allow_quiet_fail) or verbosity >= 2:\n                    sys.stderr.write(\"Failed (%s)\\n\" % (err))\n                raise\n\n    def _execute_allow_fail_statements(self, cursor, statements, parameters, verbosity, acceptable_ora_err):\n        \"\"\"\n        Execute statements which are allowed to fail silently if the Oracle\n        error code given by `acceptable_ora_err` is raised. Return True if the\n        statements execute without an exception, or False otherwise.\n        \"\"\"\n        try:\n            # Statement can fail when acceptable_ora_err is not None\n            allow_quiet_fail = acceptable_ora_err is not None and len(acceptable_ora_err) > 0\n            self._execute_statements(cursor, statements, parameters, verbosity, allow_quiet_fail=allow_quiet_fail)\n            return True\n        except DatabaseError as err:\n            description = str(err)\n            if acceptable_ora_err is None or acceptable_ora_err not in description:\n                raise\n            return False\n\n    def _get_test_db_params(self):\n        return {\n            'dbname': self._test_database_name(),\n            'user': self._test_database_user(),\n            'password': self._test_database_passwd(),\n            'tblspace': self._test_database_tblspace(),\n            'tblspace_temp': self._test_database_tblspace_tmp(),\n            'datafile': self._test_database_tblspace_datafile(),\n            'datafile_tmp': self._test_database_tblspace_tmp_datafile(),\n            'maxsize': self._test_database_tblspace_size(),\n            'maxsize_tmp': self._test_database_tblspace_tmp_size(),\n        }\n\n    def _test_settings_get(self, key, default=None, prefixed=None):\n        \"\"\"\n        Return a value from the test settings dict,\n        or a given default,\n        or a prefixed entry from the main settings dict\n        \"\"\"\n        settings_dict = self.connection.settings_dict\n        val = settings_dict['TEST'].get(key, default)\n        if val is None and prefixed:\n            val = TEST_DATABASE_PREFIX + settings_dict[prefixed]\n        return val\n\n    def _test_database_name(self):\n        return self._test_settings_get('NAME', prefixed='NAME')\n\n    def _test_database_create(self):\n        return self._test_settings_get('CREATE_DB', default=True)\n\n    def _test_user_create(self):\n        return self._test_settings_get('CREATE_USER', default=True)\n\n    def _test_database_user(self):\n        return self._test_settings_get('USER', prefixed='USER')\n\n    def _test_database_passwd(self):\n        password = self._test_settings_get('PASSWORD')\n        if password is None and self._test_user_create():\n            # Oracle passwords are limited to 30 chars and can't contain symbols.\n            password = get_random_string(length=30)\n        return password\n\n    def _test_database_tblspace(self):\n        return self._test_settings_get('TBLSPACE', prefixed='USER')\n\n    def _test_database_tblspace_tmp(self):\n        settings_dict = self.connection.settings_dict\n        return settings_dict['TEST'].get('TBLSPACE_TMP',\n                                         TEST_DATABASE_PREFIX + settings_dict['USER'] + '_temp')\n\n    def _test_database_tblspace_datafile(self):\n        tblspace = '%s.dbf' % self._test_database_tblspace()\n        return self._test_settings_get('DATAFILE', default=tblspace)\n\n    def _test_database_tblspace_tmp_datafile(self):\n        tblspace = '%s.dbf' % self._test_database_tblspace_tmp()\n        return self._test_settings_get('DATAFILE_TMP', default=tblspace)\n\n    def _test_database_tblspace_size(self):\n        return self._test_settings_get('DATAFILE_MAXSIZE', default='500M')\n\n    def _test_database_tblspace_tmp_size(self):\n        return self._test_settings_get('DATAFILE_TMP_MAXSIZE', default='500M')\n\n    def _get_test_db_name(self):\n        \"\"\"\n        We need to return the 'production' DB name to get the test DB creation\n        machinery to work. This isn't a great deal in this case because DB\n        names as handled by Django haven't real counterparts in Oracle.\n        \"\"\"\n        return self.connection.settings_dict['NAME']\n\n    def test_db_signature(self):\n        settings_dict = self.connection.settings_dict\n        return (\n            settings_dict['HOST'],\n            settings_dict['PORT'],\n            settings_dict['ENGINE'],\n            settings_dict['NAME'],\n            self._test_database_user(),\n        )\n"
  },
  {
    "patch": "diff --git a/django/contrib/auth/hashers.py b/django/contrib/auth/hashers.py\nindex 5136110fa1..ad0045267c 100644\n--- a/django/contrib/auth/hashers.py\n+++ b/django/contrib/auth/hashers.py\n@@ -4,6 +4,7 @@ import base64\n import binascii\n import hashlib\n import importlib\n+import warnings\n from collections import OrderedDict\n \n from django.conf import settings\n@@ -46,10 +47,17 @@ def check_password(password, encoded, setter=None, preferred='default'):\n     preferred = get_hasher(preferred)\n     hasher = identify_hasher(encoded)\n \n-    must_update = hasher.algorithm != preferred.algorithm\n-    if not must_update:\n-        must_update = preferred.must_update(encoded)\n+    hasher_changed = hasher.algorithm != preferred.algorithm\n+    must_update = hasher_changed or preferred.must_update(encoded)\n     is_correct = hasher.verify(password, encoded)\n+\n+    # If the hasher didn't change (we don't protect against enumeration if it\n+    # does) and the password should get updated, try to close the timing gap\n+    # between the work factor of the current encoded password and the default\n+    # work factor.\n+    if not is_correct and not hasher_changed and must_update:\n+        hasher.harden_runtime(password, encoded)\n+\n     if setter and is_correct and must_update:\n         setter(password)\n     return is_correct\n@@ -216,6 +224,19 @@ class BasePasswordHasher(object):\n     def must_update(self, encoded):\n         return False\n \n+    def harden_runtime(self, password, encoded):\n+        \"\"\"\n+        Bridge the runtime gap between the work factor supplied in `encoded`\n+        and the work factor suggested by this hasher.\n+\n+        Taking PBKDF2 as an example, if `encoded` contains 20000 iterations and\n+        `self.iterations` is 30000, this method should run password through\n+        another 10000 iterations of PBKDF2. Similar approaches should exist\n+        for any hasher that has a work factor. If not, this method should be\n+        defined as a no-op to silence the warning.\n+        \"\"\"\n+        warnings.warn('subclasses of BasePasswordHasher should provide a harden_runtime() method')\n+\n \n class PBKDF2PasswordHasher(BasePasswordHasher):\n     \"\"\"\n@@ -258,6 +279,12 @@ class PBKDF2PasswordHasher(BasePasswordHasher):\n         algorithm, iterations, salt, hash = encoded.split('$', 3)\n         return int(iterations) != self.iterations\n \n+    def harden_runtime(self, password, encoded):\n+        algorithm, iterations, salt, hash = encoded.split('$', 3)\n+        extra_iterations = self.iterations - int(iterations)\n+        if extra_iterations > 0:\n+            self.encode(password, salt, extra_iterations)\n+\n \n class PBKDF2SHA1PasswordHasher(PBKDF2PasswordHasher):\n     \"\"\"\n@@ -305,23 +332,8 @@ class BCryptSHA256PasswordHasher(BasePasswordHasher):\n     def verify(self, password, encoded):\n         algorithm, data = encoded.split('$', 1)\n         assert algorithm == self.algorithm\n-        bcrypt = self._load_library()\n-\n-        # Hash the password prior to using bcrypt to prevent password\n-        # truncation as described in #20138.\n-        if self.digest is not None:\n-            # Use binascii.hexlify() because a hex encoded bytestring is\n-            # Unicode on Python 3.\n-            password = binascii.hexlify(self.digest(force_bytes(password)).digest())\n-        else:\n-            password = force_bytes(password)\n-\n-        # Ensure that our data is a bytestring\n-        data = force_bytes(data)\n-        # force_bytes() necessary for py-bcrypt compatibility\n-        hashpw = force_bytes(bcrypt.hashpw(password, data))\n-\n-        return constant_time_compare(data, hashpw)\n+        encoded_2 = self.encode(password, force_bytes(data))\n+        return constant_time_compare(encoded, encoded_2)\n \n     def safe_summary(self, encoded):\n         algorithm, empty, algostr, work_factor, data = encoded.split('$', 4)\n@@ -338,6 +350,16 @@ class BCryptSHA256PasswordHasher(BasePasswordHasher):\n         algorithm, empty, algostr, rounds, data = encoded.split('$', 4)\n         return int(rounds) != self.rounds\n \n+    def harden_runtime(self, password, encoded):\n+        _, data = encoded.split('$', 1)\n+        salt = data[:29]  # Length of the salt in bcrypt.\n+        rounds = data.split('$')[2]\n+        # work factor is logarithmic, adding one doubles the load.\n+        diff = 2**(self.rounds - int(rounds)) - 1\n+        while diff > 0:\n+            self.encode(password, force_bytes(salt))\n+            diff -= 1\n+\n \n class BCryptPasswordHasher(BCryptSHA256PasswordHasher):\n     \"\"\"\n@@ -385,6 +407,9 @@ class SHA1PasswordHasher(BasePasswordHasher):\n             (_('hash'), mask_hash(hash)),\n         ])\n \n+    def harden_runtime(self, password, encoded):\n+        pass\n+\n \n class MD5PasswordHasher(BasePasswordHasher):\n     \"\"\"\n@@ -413,6 +438,9 @@ class MD5PasswordHasher(BasePasswordHasher):\n             (_('hash'), mask_hash(hash)),\n         ])\n \n+    def harden_runtime(self, password, encoded):\n+        pass\n+\n \n class UnsaltedSHA1PasswordHasher(BasePasswordHasher):\n     \"\"\"\n@@ -445,6 +473,9 @@ class UnsaltedSHA1PasswordHasher(BasePasswordHasher):\n             (_('hash'), mask_hash(hash)),\n         ])\n \n+    def harden_runtime(self, password, encoded):\n+        pass\n+\n \n class UnsaltedMD5PasswordHasher(BasePasswordHasher):\n     \"\"\"\n@@ -478,6 +509,9 @@ class UnsaltedMD5PasswordHasher(BasePasswordHasher):\n             (_('hash'), mask_hash(encoded, show=3)),\n         ])\n \n+    def harden_runtime(self, password, encoded):\n+        pass\n+\n \n class CryptPasswordHasher(BasePasswordHasher):\n     \"\"\"\n@@ -512,3 +546,6 @@ class CryptPasswordHasher(BasePasswordHasher):\n             (_('salt'), salt),\n             (_('hash'), mask_hash(data, show=3)),\n         ])\n+\n+    def harden_runtime(self, password, encoded):\n+        pass\n",
    "commit_message": "Fixed CVE-2016-2513 -- Fixed user enumeration timing attack during login.\n\nThis is a security fix.\n\n",
    "code_before": "from __future__ import unicode_literals\n\nimport base64\nimport binascii\nimport hashlib\nimport importlib\nfrom collections import OrderedDict\n\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.signals import setting_changed\nfrom django.dispatch import receiver\nfrom django.utils import lru_cache\nfrom django.utils.crypto import (\n    constant_time_compare, get_random_string, pbkdf2,\n)\nfrom django.utils.encoding import force_bytes, force_str, force_text\nfrom django.utils.module_loading import import_string\nfrom django.utils.translation import ugettext_noop as _\n\nUNUSABLE_PASSWORD_PREFIX = '!'  # This will never be a valid encoded hash\nUNUSABLE_PASSWORD_SUFFIX_LENGTH = 40  # number of random chars to add after UNUSABLE_PASSWORD_PREFIX\n\n\ndef is_password_usable(encoded):\n    if encoded is None or encoded.startswith(UNUSABLE_PASSWORD_PREFIX):\n        return False\n    try:\n        identify_hasher(encoded)\n    except ValueError:\n        return False\n    return True\n\n\ndef check_password(password, encoded, setter=None, preferred='default'):\n    \"\"\"\n    Returns a boolean of whether the raw password matches the three\n    part encoded digest.\n\n    If setter is specified, it'll be called when you need to\n    regenerate the password.\n    \"\"\"\n    if password is None or not is_password_usable(encoded):\n        return False\n\n    preferred = get_hasher(preferred)\n    hasher = identify_hasher(encoded)\n\n    must_update = hasher.algorithm != preferred.algorithm\n    if not must_update:\n        must_update = preferred.must_update(encoded)\n    is_correct = hasher.verify(password, encoded)\n    if setter and is_correct and must_update:\n        setter(password)\n    return is_correct\n\n\ndef make_password(password, salt=None, hasher='default'):\n    \"\"\"\n    Turn a plain-text password into a hash for database storage\n\n    Same as encode() but generates a new random salt.\n    If password is None then a concatenation of\n    UNUSABLE_PASSWORD_PREFIX and a random string will be returned\n    which disallows logins. Additional random string reduces chances\n    of gaining access to staff or superuser accounts.\n    See ticket #20079 for more info.\n    \"\"\"\n    if password is None:\n        return UNUSABLE_PASSWORD_PREFIX + get_random_string(UNUSABLE_PASSWORD_SUFFIX_LENGTH)\n    hasher = get_hasher(hasher)\n\n    if not salt:\n        salt = hasher.salt()\n\n    return hasher.encode(password, salt)\n\n\n@lru_cache.lru_cache()\ndef get_hashers():\n    hashers = []\n    for hasher_path in settings.PASSWORD_HASHERS:\n        hasher_cls = import_string(hasher_path)\n        hasher = hasher_cls()\n        if not getattr(hasher, 'algorithm'):\n            raise ImproperlyConfigured(\"hasher doesn't specify an \"\n                                       \"algorithm name: %s\" % hasher_path)\n        hashers.append(hasher)\n    return hashers\n\n\n@lru_cache.lru_cache()\ndef get_hashers_by_algorithm():\n    return {hasher.algorithm: hasher for hasher in get_hashers()}\n\n\n@receiver(setting_changed)\ndef reset_hashers(**kwargs):\n    if kwargs['setting'] == 'PASSWORD_HASHERS':\n        get_hashers.cache_clear()\n        get_hashers_by_algorithm.cache_clear()\n\n\ndef get_hasher(algorithm='default'):\n    \"\"\"\n    Returns an instance of a loaded password hasher.\n\n    If algorithm is 'default', the default hasher will be returned.\n    This function will also lazy import hashers specified in your\n    settings file if needed.\n    \"\"\"\n    if hasattr(algorithm, 'algorithm'):\n        return algorithm\n\n    elif algorithm == 'default':\n        return get_hashers()[0]\n\n    else:\n        hashers = get_hashers_by_algorithm()\n        try:\n            return hashers[algorithm]\n        except KeyError:\n            raise ValueError(\"Unknown password hashing algorithm '%s'. \"\n                             \"Did you specify it in the PASSWORD_HASHERS \"\n                             \"setting?\" % algorithm)\n\n\ndef identify_hasher(encoded):\n    \"\"\"\n    Returns an instance of a loaded password hasher.\n\n    Identifies hasher algorithm by examining encoded hash, and calls\n    get_hasher() to return hasher. Raises ValueError if\n    algorithm cannot be identified, or if hasher is not loaded.\n    \"\"\"\n    # Ancient versions of Django created plain MD5 passwords and accepted\n    # MD5 passwords with an empty salt.\n    if ((len(encoded) == 32 and '$' not in encoded) or\n            (len(encoded) == 37 and encoded.startswith('md5$$'))):\n        algorithm = 'unsalted_md5'\n    # Ancient versions of Django accepted SHA1 passwords with an empty salt.\n    elif len(encoded) == 46 and encoded.startswith('sha1$$'):\n        algorithm = 'unsalted_sha1'\n    else:\n        algorithm = encoded.split('$', 1)[0]\n    return get_hasher(algorithm)\n\n\ndef mask_hash(hash, show=6, char=\"*\"):\n    \"\"\"\n    Returns the given hash, with only the first ``show`` number shown. The\n    rest are masked with ``char`` for security reasons.\n    \"\"\"\n    masked = hash[:show]\n    masked += char * len(hash[show:])\n    return masked\n\n\nclass BasePasswordHasher(object):\n    \"\"\"\n    Abstract base class for password hashers\n\n    When creating your own hasher, you need to override algorithm,\n    verify(), encode() and safe_summary().\n\n    PasswordHasher objects are immutable.\n    \"\"\"\n    algorithm = None\n    library = None\n\n    def _load_library(self):\n        if self.library is not None:\n            if isinstance(self.library, (tuple, list)):\n                name, mod_path = self.library\n            else:\n                mod_path = self.library\n            try:\n                module = importlib.import_module(mod_path)\n            except ImportError as e:\n                raise ValueError(\"Couldn't load %r algorithm library: %s\" %\n                                 (self.__class__.__name__, e))\n            return module\n        raise ValueError(\"Hasher %r doesn't specify a library attribute\" %\n                         self.__class__.__name__)\n\n    def salt(self):\n        \"\"\"\n        Generates a cryptographically secure nonce salt in ASCII\n        \"\"\"\n        return get_random_string()\n\n    def verify(self, password, encoded):\n        \"\"\"\n        Checks if the given password is correct\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide a verify() method')\n\n    def encode(self, password, salt):\n        \"\"\"\n        Creates an encoded database value\n\n        The result is normally formatted as \"algorithm$salt$hash\" and\n        must be fewer than 128 characters.\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide an encode() method')\n\n    def safe_summary(self, encoded):\n        \"\"\"\n        Returns a summary of safe values\n\n        The result is a dictionary and will be used where the password field\n        must be displayed to construct a safe representation of the password.\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide a safe_summary() method')\n\n    def must_update(self, encoded):\n        return False\n\n\nclass PBKDF2PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Secure password hashing using the PBKDF2 algorithm (recommended)\n\n    Configured to use PBKDF2 + HMAC + SHA256.\n    The result is a 64 byte binary string.  Iterations may be changed\n    safely but you must rename the algorithm if you change SHA256.\n    \"\"\"\n    algorithm = \"pbkdf2_sha256\"\n    iterations = 30000\n    digest = hashlib.sha256\n\n    def encode(self, password, salt, iterations=None):\n        assert password is not None\n        assert salt and '$' not in salt\n        if not iterations:\n            iterations = self.iterations\n        hash = pbkdf2(password, salt, iterations, digest=self.digest)\n        hash = base64.b64encode(hash).decode('ascii').strip()\n        return \"%s$%d$%s$%s\" % (self.algorithm, iterations, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt, int(iterations))\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('iterations'), iterations),\n            (_('salt'), mask_hash(salt)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n    def must_update(self, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        return int(iterations) != self.iterations\n\n\nclass PBKDF2SHA1PasswordHasher(PBKDF2PasswordHasher):\n    \"\"\"\n    Alternate PBKDF2 hasher which uses SHA1, the default PRF\n    recommended by PKCS #5. This is compatible with other\n    implementations of PBKDF2, such as openssl's\n    PKCS5_PBKDF2_HMAC_SHA1().\n    \"\"\"\n    algorithm = \"pbkdf2_sha1\"\n    digest = hashlib.sha1\n\n\nclass BCryptSHA256PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Secure password hashing using the bcrypt algorithm (recommended)\n\n    This is considered by many to be the most secure algorithm but you\n    must first install the bcrypt library.  Please be warned that\n    this library depends on native C code and might cause portability\n    issues.\n    \"\"\"\n    algorithm = \"bcrypt_sha256\"\n    digest = hashlib.sha256\n    library = (\"bcrypt\", \"bcrypt\")\n    rounds = 12\n\n    def salt(self):\n        bcrypt = self._load_library()\n        return bcrypt.gensalt(self.rounds)\n\n    def encode(self, password, salt):\n        bcrypt = self._load_library()\n        # Hash the password prior to using bcrypt to prevent password\n        # truncation as described in #20138.\n        if self.digest is not None:\n            # Use binascii.hexlify() because a hex encoded bytestring is\n            # Unicode on Python 3.\n            password = binascii.hexlify(self.digest(force_bytes(password)).digest())\n        else:\n            password = force_bytes(password)\n\n        data = bcrypt.hashpw(password, salt)\n        return \"%s$%s\" % (self.algorithm, force_text(data))\n\n    def verify(self, password, encoded):\n        algorithm, data = encoded.split('$', 1)\n        assert algorithm == self.algorithm\n        bcrypt = self._load_library()\n\n        # Hash the password prior to using bcrypt to prevent password\n        # truncation as described in #20138.\n        if self.digest is not None:\n            # Use binascii.hexlify() because a hex encoded bytestring is\n            # Unicode on Python 3.\n            password = binascii.hexlify(self.digest(force_bytes(password)).digest())\n        else:\n            password = force_bytes(password)\n\n        # Ensure that our data is a bytestring\n        data = force_bytes(data)\n        # force_bytes() necessary for py-bcrypt compatibility\n        hashpw = force_bytes(bcrypt.hashpw(password, data))\n\n        return constant_time_compare(data, hashpw)\n\n    def safe_summary(self, encoded):\n        algorithm, empty, algostr, work_factor, data = encoded.split('$', 4)\n        assert algorithm == self.algorithm\n        salt, checksum = data[:22], data[22:]\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('work factor'), work_factor),\n            (_('salt'), mask_hash(salt)),\n            (_('checksum'), mask_hash(checksum)),\n        ])\n\n    def must_update(self, encoded):\n        algorithm, empty, algostr, rounds, data = encoded.split('$', 4)\n        return int(rounds) != self.rounds\n\n\nclass BCryptPasswordHasher(BCryptSHA256PasswordHasher):\n    \"\"\"\n    Secure password hashing using the bcrypt algorithm\n\n    This is considered by many to be the most secure algorithm but you\n    must first install the bcrypt library.  Please be warned that\n    this library depends on native C code and might cause portability\n    issues.\n\n    This hasher does not first hash the password which means it is subject to\n    the 72 character bcrypt password truncation, most use cases should prefer\n    the BCryptSHA256PasswordHasher.\n\n    See: https://code.djangoproject.com/ticket/20138\n    \"\"\"\n    algorithm = \"bcrypt\"\n    digest = None\n\n\nclass SHA1PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    The SHA1 password hashing algorithm (not recommended)\n    \"\"\"\n    algorithm = \"sha1\"\n\n    def encode(self, password, salt):\n        assert password is not None\n        assert salt and '$' not in salt\n        hash = hashlib.sha1(force_bytes(salt + password)).hexdigest()\n        return \"%s$%s$%s\" % (self.algorithm, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt)\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), mask_hash(salt, show=2)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n\nclass MD5PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    The Salted MD5 password hashing algorithm (not recommended)\n    \"\"\"\n    algorithm = \"md5\"\n\n    def encode(self, password, salt):\n        assert password is not None\n        assert salt and '$' not in salt\n        hash = hashlib.md5(force_bytes(salt + password)).hexdigest()\n        return \"%s$%s$%s\" % (self.algorithm, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt)\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), mask_hash(salt, show=2)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n\nclass UnsaltedSHA1PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Very insecure algorithm that you should *never* use; stores SHA1 hashes\n    with an empty salt.\n\n    This class is implemented because Django used to accept such password\n    hashes. Some older Django installs still have these values lingering\n    around so we need to handle and upgrade them properly.\n    \"\"\"\n    algorithm = \"unsalted_sha1\"\n\n    def salt(self):\n        return ''\n\n    def encode(self, password, salt):\n        assert salt == ''\n        hash = hashlib.sha1(force_bytes(password)).hexdigest()\n        return 'sha1$$%s' % hash\n\n    def verify(self, password, encoded):\n        encoded_2 = self.encode(password, '')\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        assert encoded.startswith('sha1$$')\n        hash = encoded[6:]\n        return OrderedDict([\n            (_('algorithm'), self.algorithm),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n\nclass UnsaltedMD5PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Incredibly insecure algorithm that you should *never* use; stores unsalted\n    MD5 hashes without the algorithm prefix, also accepts MD5 hashes with an\n    empty salt.\n\n    This class is implemented because Django used to store passwords this way\n    and to accept such password hashes. Some older Django installs still have\n    these values lingering around so we need to handle and upgrade them\n    properly.\n    \"\"\"\n    algorithm = \"unsalted_md5\"\n\n    def salt(self):\n        return ''\n\n    def encode(self, password, salt):\n        assert salt == ''\n        return hashlib.md5(force_bytes(password)).hexdigest()\n\n    def verify(self, password, encoded):\n        if len(encoded) == 37 and encoded.startswith('md5$$'):\n            encoded = encoded[5:]\n        encoded_2 = self.encode(password, '')\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        return OrderedDict([\n            (_('algorithm'), self.algorithm),\n            (_('hash'), mask_hash(encoded, show=3)),\n        ])\n\n\nclass CryptPasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Password hashing using UNIX crypt (not recommended)\n\n    The crypt module is not supported on all platforms.\n    \"\"\"\n    algorithm = \"crypt\"\n    library = \"crypt\"\n\n    def salt(self):\n        return get_random_string(2)\n\n    def encode(self, password, salt):\n        crypt = self._load_library()\n        assert len(salt) == 2\n        data = crypt.crypt(force_str(password), salt)\n        # we don't need to store the salt, but Django used to do this\n        return \"%s$%s$%s\" % (self.algorithm, '', data)\n\n    def verify(self, password, encoded):\n        crypt = self._load_library()\n        algorithm, salt, data = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return constant_time_compare(data, crypt.crypt(force_str(password), data))\n\n    def safe_summary(self, encoded):\n        algorithm, salt, data = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), salt),\n            (_('hash'), mask_hash(data, show=3)),\n        ])\n",
    "code_after": "from __future__ import unicode_literals\n\nimport base64\nimport binascii\nimport hashlib\nimport importlib\nimport warnings\nfrom collections import OrderedDict\n\nfrom django.conf import settings\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.core.signals import setting_changed\nfrom django.dispatch import receiver\nfrom django.utils import lru_cache\nfrom django.utils.crypto import (\n    constant_time_compare, get_random_string, pbkdf2,\n)\nfrom django.utils.encoding import force_bytes, force_str, force_text\nfrom django.utils.module_loading import import_string\nfrom django.utils.translation import ugettext_noop as _\n\nUNUSABLE_PASSWORD_PREFIX = '!'  # This will never be a valid encoded hash\nUNUSABLE_PASSWORD_SUFFIX_LENGTH = 40  # number of random chars to add after UNUSABLE_PASSWORD_PREFIX\n\n\ndef is_password_usable(encoded):\n    if encoded is None or encoded.startswith(UNUSABLE_PASSWORD_PREFIX):\n        return False\n    try:\n        identify_hasher(encoded)\n    except ValueError:\n        return False\n    return True\n\n\ndef check_password(password, encoded, setter=None, preferred='default'):\n    \"\"\"\n    Returns a boolean of whether the raw password matches the three\n    part encoded digest.\n\n    If setter is specified, it'll be called when you need to\n    regenerate the password.\n    \"\"\"\n    if password is None or not is_password_usable(encoded):\n        return False\n\n    preferred = get_hasher(preferred)\n    hasher = identify_hasher(encoded)\n\n    hasher_changed = hasher.algorithm != preferred.algorithm\n    must_update = hasher_changed or preferred.must_update(encoded)\n    is_correct = hasher.verify(password, encoded)\n\n    # If the hasher didn't change (we don't protect against enumeration if it\n    # does) and the password should get updated, try to close the timing gap\n    # between the work factor of the current encoded password and the default\n    # work factor.\n    if not is_correct and not hasher_changed and must_update:\n        hasher.harden_runtime(password, encoded)\n\n    if setter and is_correct and must_update:\n        setter(password)\n    return is_correct\n\n\ndef make_password(password, salt=None, hasher='default'):\n    \"\"\"\n    Turn a plain-text password into a hash for database storage\n\n    Same as encode() but generates a new random salt.\n    If password is None then a concatenation of\n    UNUSABLE_PASSWORD_PREFIX and a random string will be returned\n    which disallows logins. Additional random string reduces chances\n    of gaining access to staff or superuser accounts.\n    See ticket #20079 for more info.\n    \"\"\"\n    if password is None:\n        return UNUSABLE_PASSWORD_PREFIX + get_random_string(UNUSABLE_PASSWORD_SUFFIX_LENGTH)\n    hasher = get_hasher(hasher)\n\n    if not salt:\n        salt = hasher.salt()\n\n    return hasher.encode(password, salt)\n\n\n@lru_cache.lru_cache()\ndef get_hashers():\n    hashers = []\n    for hasher_path in settings.PASSWORD_HASHERS:\n        hasher_cls = import_string(hasher_path)\n        hasher = hasher_cls()\n        if not getattr(hasher, 'algorithm'):\n            raise ImproperlyConfigured(\"hasher doesn't specify an \"\n                                       \"algorithm name: %s\" % hasher_path)\n        hashers.append(hasher)\n    return hashers\n\n\n@lru_cache.lru_cache()\ndef get_hashers_by_algorithm():\n    return {hasher.algorithm: hasher for hasher in get_hashers()}\n\n\n@receiver(setting_changed)\ndef reset_hashers(**kwargs):\n    if kwargs['setting'] == 'PASSWORD_HASHERS':\n        get_hashers.cache_clear()\n        get_hashers_by_algorithm.cache_clear()\n\n\ndef get_hasher(algorithm='default'):\n    \"\"\"\n    Returns an instance of a loaded password hasher.\n\n    If algorithm is 'default', the default hasher will be returned.\n    This function will also lazy import hashers specified in your\n    settings file if needed.\n    \"\"\"\n    if hasattr(algorithm, 'algorithm'):\n        return algorithm\n\n    elif algorithm == 'default':\n        return get_hashers()[0]\n\n    else:\n        hashers = get_hashers_by_algorithm()\n        try:\n            return hashers[algorithm]\n        except KeyError:\n            raise ValueError(\"Unknown password hashing algorithm '%s'. \"\n                             \"Did you specify it in the PASSWORD_HASHERS \"\n                             \"setting?\" % algorithm)\n\n\ndef identify_hasher(encoded):\n    \"\"\"\n    Returns an instance of a loaded password hasher.\n\n    Identifies hasher algorithm by examining encoded hash, and calls\n    get_hasher() to return hasher. Raises ValueError if\n    algorithm cannot be identified, or if hasher is not loaded.\n    \"\"\"\n    # Ancient versions of Django created plain MD5 passwords and accepted\n    # MD5 passwords with an empty salt.\n    if ((len(encoded) == 32 and '$' not in encoded) or\n            (len(encoded) == 37 and encoded.startswith('md5$$'))):\n        algorithm = 'unsalted_md5'\n    # Ancient versions of Django accepted SHA1 passwords with an empty salt.\n    elif len(encoded) == 46 and encoded.startswith('sha1$$'):\n        algorithm = 'unsalted_sha1'\n    else:\n        algorithm = encoded.split('$', 1)[0]\n    return get_hasher(algorithm)\n\n\ndef mask_hash(hash, show=6, char=\"*\"):\n    \"\"\"\n    Returns the given hash, with only the first ``show`` number shown. The\n    rest are masked with ``char`` for security reasons.\n    \"\"\"\n    masked = hash[:show]\n    masked += char * len(hash[show:])\n    return masked\n\n\nclass BasePasswordHasher(object):\n    \"\"\"\n    Abstract base class for password hashers\n\n    When creating your own hasher, you need to override algorithm,\n    verify(), encode() and safe_summary().\n\n    PasswordHasher objects are immutable.\n    \"\"\"\n    algorithm = None\n    library = None\n\n    def _load_library(self):\n        if self.library is not None:\n            if isinstance(self.library, (tuple, list)):\n                name, mod_path = self.library\n            else:\n                mod_path = self.library\n            try:\n                module = importlib.import_module(mod_path)\n            except ImportError as e:\n                raise ValueError(\"Couldn't load %r algorithm library: %s\" %\n                                 (self.__class__.__name__, e))\n            return module\n        raise ValueError(\"Hasher %r doesn't specify a library attribute\" %\n                         self.__class__.__name__)\n\n    def salt(self):\n        \"\"\"\n        Generates a cryptographically secure nonce salt in ASCII\n        \"\"\"\n        return get_random_string()\n\n    def verify(self, password, encoded):\n        \"\"\"\n        Checks if the given password is correct\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide a verify() method')\n\n    def encode(self, password, salt):\n        \"\"\"\n        Creates an encoded database value\n\n        The result is normally formatted as \"algorithm$salt$hash\" and\n        must be fewer than 128 characters.\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide an encode() method')\n\n    def safe_summary(self, encoded):\n        \"\"\"\n        Returns a summary of safe values\n\n        The result is a dictionary and will be used where the password field\n        must be displayed to construct a safe representation of the password.\n        \"\"\"\n        raise NotImplementedError('subclasses of BasePasswordHasher must provide a safe_summary() method')\n\n    def must_update(self, encoded):\n        return False\n\n    def harden_runtime(self, password, encoded):\n        \"\"\"\n        Bridge the runtime gap between the work factor supplied in `encoded`\n        and the work factor suggested by this hasher.\n\n        Taking PBKDF2 as an example, if `encoded` contains 20000 iterations and\n        `self.iterations` is 30000, this method should run password through\n        another 10000 iterations of PBKDF2. Similar approaches should exist\n        for any hasher that has a work factor. If not, this method should be\n        defined as a no-op to silence the warning.\n        \"\"\"\n        warnings.warn('subclasses of BasePasswordHasher should provide a harden_runtime() method')\n\n\nclass PBKDF2PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Secure password hashing using the PBKDF2 algorithm (recommended)\n\n    Configured to use PBKDF2 + HMAC + SHA256.\n    The result is a 64 byte binary string.  Iterations may be changed\n    safely but you must rename the algorithm if you change SHA256.\n    \"\"\"\n    algorithm = \"pbkdf2_sha256\"\n    iterations = 30000\n    digest = hashlib.sha256\n\n    def encode(self, password, salt, iterations=None):\n        assert password is not None\n        assert salt and '$' not in salt\n        if not iterations:\n            iterations = self.iterations\n        hash = pbkdf2(password, salt, iterations, digest=self.digest)\n        hash = base64.b64encode(hash).decode('ascii').strip()\n        return \"%s$%d$%s$%s\" % (self.algorithm, iterations, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt, int(iterations))\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('iterations'), iterations),\n            (_('salt'), mask_hash(salt)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n    def must_update(self, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        return int(iterations) != self.iterations\n\n    def harden_runtime(self, password, encoded):\n        algorithm, iterations, salt, hash = encoded.split('$', 3)\n        extra_iterations = self.iterations - int(iterations)\n        if extra_iterations > 0:\n            self.encode(password, salt, extra_iterations)\n\n\nclass PBKDF2SHA1PasswordHasher(PBKDF2PasswordHasher):\n    \"\"\"\n    Alternate PBKDF2 hasher which uses SHA1, the default PRF\n    recommended by PKCS #5. This is compatible with other\n    implementations of PBKDF2, such as openssl's\n    PKCS5_PBKDF2_HMAC_SHA1().\n    \"\"\"\n    algorithm = \"pbkdf2_sha1\"\n    digest = hashlib.sha1\n\n\nclass BCryptSHA256PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Secure password hashing using the bcrypt algorithm (recommended)\n\n    This is considered by many to be the most secure algorithm but you\n    must first install the bcrypt library.  Please be warned that\n    this library depends on native C code and might cause portability\n    issues.\n    \"\"\"\n    algorithm = \"bcrypt_sha256\"\n    digest = hashlib.sha256\n    library = (\"bcrypt\", \"bcrypt\")\n    rounds = 12\n\n    def salt(self):\n        bcrypt = self._load_library()\n        return bcrypt.gensalt(self.rounds)\n\n    def encode(self, password, salt):\n        bcrypt = self._load_library()\n        # Hash the password prior to using bcrypt to prevent password\n        # truncation as described in #20138.\n        if self.digest is not None:\n            # Use binascii.hexlify() because a hex encoded bytestring is\n            # Unicode on Python 3.\n            password = binascii.hexlify(self.digest(force_bytes(password)).digest())\n        else:\n            password = force_bytes(password)\n\n        data = bcrypt.hashpw(password, salt)\n        return \"%s$%s\" % (self.algorithm, force_text(data))\n\n    def verify(self, password, encoded):\n        algorithm, data = encoded.split('$', 1)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, force_bytes(data))\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, empty, algostr, work_factor, data = encoded.split('$', 4)\n        assert algorithm == self.algorithm\n        salt, checksum = data[:22], data[22:]\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('work factor'), work_factor),\n            (_('salt'), mask_hash(salt)),\n            (_('checksum'), mask_hash(checksum)),\n        ])\n\n    def must_update(self, encoded):\n        algorithm, empty, algostr, rounds, data = encoded.split('$', 4)\n        return int(rounds) != self.rounds\n\n    def harden_runtime(self, password, encoded):\n        _, data = encoded.split('$', 1)\n        salt = data[:29]  # Length of the salt in bcrypt.\n        rounds = data.split('$')[2]\n        # work factor is logarithmic, adding one doubles the load.\n        diff = 2**(self.rounds - int(rounds)) - 1\n        while diff > 0:\n            self.encode(password, force_bytes(salt))\n            diff -= 1\n\n\nclass BCryptPasswordHasher(BCryptSHA256PasswordHasher):\n    \"\"\"\n    Secure password hashing using the bcrypt algorithm\n\n    This is considered by many to be the most secure algorithm but you\n    must first install the bcrypt library.  Please be warned that\n    this library depends on native C code and might cause portability\n    issues.\n\n    This hasher does not first hash the password which means it is subject to\n    the 72 character bcrypt password truncation, most use cases should prefer\n    the BCryptSHA256PasswordHasher.\n\n    See: https://code.djangoproject.com/ticket/20138\n    \"\"\"\n    algorithm = \"bcrypt\"\n    digest = None\n\n\nclass SHA1PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    The SHA1 password hashing algorithm (not recommended)\n    \"\"\"\n    algorithm = \"sha1\"\n\n    def encode(self, password, salt):\n        assert password is not None\n        assert salt and '$' not in salt\n        hash = hashlib.sha1(force_bytes(salt + password)).hexdigest()\n        return \"%s$%s$%s\" % (self.algorithm, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt)\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), mask_hash(salt, show=2)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n    def harden_runtime(self, password, encoded):\n        pass\n\n\nclass MD5PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    The Salted MD5 password hashing algorithm (not recommended)\n    \"\"\"\n    algorithm = \"md5\"\n\n    def encode(self, password, salt):\n        assert password is not None\n        assert salt and '$' not in salt\n        hash = hashlib.md5(force_bytes(salt + password)).hexdigest()\n        return \"%s$%s$%s\" % (self.algorithm, salt, hash)\n\n    def verify(self, password, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        encoded_2 = self.encode(password, salt)\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        algorithm, salt, hash = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), mask_hash(salt, show=2)),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n    def harden_runtime(self, password, encoded):\n        pass\n\n\nclass UnsaltedSHA1PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Very insecure algorithm that you should *never* use; stores SHA1 hashes\n    with an empty salt.\n\n    This class is implemented because Django used to accept such password\n    hashes. Some older Django installs still have these values lingering\n    around so we need to handle and upgrade them properly.\n    \"\"\"\n    algorithm = \"unsalted_sha1\"\n\n    def salt(self):\n        return ''\n\n    def encode(self, password, salt):\n        assert salt == ''\n        hash = hashlib.sha1(force_bytes(password)).hexdigest()\n        return 'sha1$$%s' % hash\n\n    def verify(self, password, encoded):\n        encoded_2 = self.encode(password, '')\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        assert encoded.startswith('sha1$$')\n        hash = encoded[6:]\n        return OrderedDict([\n            (_('algorithm'), self.algorithm),\n            (_('hash'), mask_hash(hash)),\n        ])\n\n    def harden_runtime(self, password, encoded):\n        pass\n\n\nclass UnsaltedMD5PasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Incredibly insecure algorithm that you should *never* use; stores unsalted\n    MD5 hashes without the algorithm prefix, also accepts MD5 hashes with an\n    empty salt.\n\n    This class is implemented because Django used to store passwords this way\n    and to accept such password hashes. Some older Django installs still have\n    these values lingering around so we need to handle and upgrade them\n    properly.\n    \"\"\"\n    algorithm = \"unsalted_md5\"\n\n    def salt(self):\n        return ''\n\n    def encode(self, password, salt):\n        assert salt == ''\n        return hashlib.md5(force_bytes(password)).hexdigest()\n\n    def verify(self, password, encoded):\n        if len(encoded) == 37 and encoded.startswith('md5$$'):\n            encoded = encoded[5:]\n        encoded_2 = self.encode(password, '')\n        return constant_time_compare(encoded, encoded_2)\n\n    def safe_summary(self, encoded):\n        return OrderedDict([\n            (_('algorithm'), self.algorithm),\n            (_('hash'), mask_hash(encoded, show=3)),\n        ])\n\n    def harden_runtime(self, password, encoded):\n        pass\n\n\nclass CryptPasswordHasher(BasePasswordHasher):\n    \"\"\"\n    Password hashing using UNIX crypt (not recommended)\n\n    The crypt module is not supported on all platforms.\n    \"\"\"\n    algorithm = \"crypt\"\n    library = \"crypt\"\n\n    def salt(self):\n        return get_random_string(2)\n\n    def encode(self, password, salt):\n        crypt = self._load_library()\n        assert len(salt) == 2\n        data = crypt.crypt(force_str(password), salt)\n        # we don't need to store the salt, but Django used to do this\n        return \"%s$%s$%s\" % (self.algorithm, '', data)\n\n    def verify(self, password, encoded):\n        crypt = self._load_library()\n        algorithm, salt, data = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return constant_time_compare(data, crypt.crypt(force_str(password), data))\n\n    def safe_summary(self, encoded):\n        algorithm, salt, data = encoded.split('$', 2)\n        assert algorithm == self.algorithm\n        return OrderedDict([\n            (_('algorithm'), algorithm),\n            (_('salt'), salt),\n            (_('hash'), mask_hash(data, show=3)),\n        ])\n\n    def harden_runtime(self, password, encoded):\n        pass\n"
  },
  {
    "patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 2dce7d3add..6e782bd576 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -290,8 +290,12 @@ def is_safe_url(url, host=None):\n         url = url.strip()\n     if not url:\n         return False\n-    # Chrome treats \\ completely as /\n-    url = url.replace('\\\\', '/')\n+    # Chrome treats \\ completely as / in paths but it could be part of some\n+    # basic auth credentials so we need to check both URLs.\n+    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)\n+\n+\n+def _is_safe_url(url, host):\n     # Chrome considers any URL with more than two slashes to be absolute, but\n     # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n     if url.startswith('///'):\n",
    "commit_message": "Fixed CVE-2016-2512 -- Prevented spoofing is_safe_url() with basic auth.\n\nThis is a security fix.\n\n",
    "code_before": "from __future__ import unicode_literals\n\nimport base64\nimport calendar\nimport datetime\nimport re\nimport sys\nimport unicodedata\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\n\nfrom django.utils import six\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_bytes, force_str, force_text\nfrom django.utils.functional import keep_lazy_text\nfrom django.utils.six.moves.urllib.parse import (\n    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,\n    urlparse,\n)\n\nETAG_MATCH = re.compile(r'(?:W/)?\"((?:\\\\.|[^\"])*)\"')\n\nMONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n__D = r'(?P<day>\\d{2})'\n__D2 = r'(?P<day>[ \\d]\\d)'\n__M = r'(?P<mon>\\w{3})'\n__Y = r'(?P<year>\\d{4})'\n__Y2 = r'(?P<year>\\d{2})'\n__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\nRFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\nRFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\nASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = str(\":/?#[]@\")\nRFC3986_SUBDELIMS = str(\"!$&'()*+,;=\")\n\nPROTOCOL_TO_PORT = {\n    'http': 80,\n    'https': 443,\n}\n\n\n@keep_lazy_text\ndef urlquote(url, safe='/'):\n    \"\"\"\n    A version of Python's urllib.quote() function that can operate on unicode\n    strings. The url is first UTF-8 encoded before quoting. The returned string\n    can safely be used as part of an argument to a subsequent iri_to_uri() call\n    without double-quoting occurring.\n    \"\"\"\n    return force_text(quote(force_str(url), force_str(safe)))\n\n\n@keep_lazy_text\ndef urlquote_plus(url, safe=''):\n    \"\"\"\n    A version of Python's urllib.quote_plus() function that can operate on\n    unicode strings. The url is first UTF-8 encoded before quoting. The\n    returned string can safely be used as part of an argument to a subsequent\n    iri_to_uri() call without double-quoting occurring.\n    \"\"\"\n    return force_text(quote_plus(force_str(url), force_str(safe)))\n\n\n@keep_lazy_text\ndef urlunquote(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote() function that can operate on\n    the result of django.utils.http.urlquote().\n    \"\"\"\n    return force_text(unquote(force_str(quoted_url)))\n\n\n@keep_lazy_text\ndef urlunquote_plus(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote_plus() function that can operate on\n    the result of django.utils.http.urlquote_plus().\n    \"\"\"\n    return force_text(unquote_plus(force_str(quoted_url)))\n\n\ndef urlencode(query, doseq=0):\n    \"\"\"\n    A version of Python's urllib.urlencode() function that can operate on\n    unicode strings. The parameters are first cast to UTF-8 encoded strings and\n    then encoded as per normal.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, 'items'):\n        query = query.items()\n    return original_urlencode(\n        [(force_str(k),\n         [force_str(i) for i in v] if isinstance(v, (list, tuple)) else force_str(v))\n            for k, v in query],\n        doseq)\n\n\ndef cookie_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to ensure compatibility with Netscape's cookie standard.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to match the RFC1123 date format as specified by HTTP\n    RFC2616 section 3.3.1.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parses a date format as specified by HTTP RFC2616 section 3.3.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Returns an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately\n    # RFC2616 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        year = int(m.group('year'))\n        if year < 100:\n            if year < 70:\n                year += 2000\n            else:\n                year += 1900\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec)\n        return calendar.timegm(result.utctimetuple())\n    except Exception:\n        six.reraise(ValueError, ValueError(\"%r is not a valid date\" % date), sys.exc_info()[2])\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but returns None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\ndef base36_to_int(s):\n    \"\"\"\n    Converts a base 36 string to an ``int``. Raises ``ValueError` if the\n    input won't fit into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is long than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    value = int(s, 36)\n    # ... then do a final check that the value will fit into an int to avoid\n    # returning a long (#15067). The long type was removed in Python 3.\n    if six.PY2 and value > sys.maxint:\n        raise ValueError(\"Base36 input too large\")\n    return value\n\n\ndef int_to_base36(i):\n    \"\"\"\n    Converts an integer to a base36 string\n    \"\"\"\n    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if six.PY2:\n        if not isinstance(i, six.integer_types):\n            raise TypeError(\"Non-integer base36 conversion input.\")\n        if i > sys.maxint:\n            raise ValueError(\"Base36 conversion input too large.\")\n    if i < 36:\n        return char_set[i]\n    b36 = ''\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encodes a bytestring in base64 for use in URLs, stripping any trailing\n    equal signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decodes a base64 encoded string, adding back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = force_bytes(s)\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parses a string with one or several etags passed in If-None-Match and\n    If-Match headers by the rules in RFC 2616. Returns a list of etags\n    without surrounding double quotes (\") and unescaped from \\<CHAR>.\n    \"\"\"\n    etags = ETAG_MATCH.findall(etag_str)\n    if not etags:\n        # etag_str has wrong format, treat it as an opaque string then\n        return [etag_str]\n    etags = [e.encode('ascii').decode('unicode_escape') for e in etags]\n    return etags\n\n\ndef quote_etag(etag):\n    \"\"\"\n    Wraps a string in double quotes escaping contents as necessary.\n    \"\"\"\n    return '\"%s\"' % etag.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n\n\ndef unquote_etag(etag):\n    \"\"\"\n    Unquote an ETag string; i.e. revert quote_etag().\n    \"\"\"\n    return etag.strip('\"').replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\') if etag else etag\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or\n        pattern == host\n    )\n\n\ndef is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as /\n    url = url.replace('\\\\', '/')\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    return ((not url_info.netloc or url_info.netloc == host) and\n            (not url_info.scheme or url_info.scheme in ['http', 'https']))\n",
    "code_after": "from __future__ import unicode_literals\n\nimport base64\nimport calendar\nimport datetime\nimport re\nimport sys\nimport unicodedata\nfrom binascii import Error as BinasciiError\nfrom email.utils import formatdate\n\nfrom django.utils import six\nfrom django.utils.datastructures import MultiValueDict\nfrom django.utils.encoding import force_bytes, force_str, force_text\nfrom django.utils.functional import keep_lazy_text\nfrom django.utils.six.moves.urllib.parse import (\n    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,\n    urlparse,\n)\n\nETAG_MATCH = re.compile(r'(?:W/)?\"((?:\\\\.|[^\"])*)\"')\n\nMONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()\n__D = r'(?P<day>\\d{2})'\n__D2 = r'(?P<day>[ \\d]\\d)'\n__M = r'(?P<mon>\\w{3})'\n__Y = r'(?P<year>\\d{4})'\n__Y2 = r'(?P<year>\\d{2})'\n__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'\nRFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))\nRFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))\nASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))\n\nRFC3986_GENDELIMS = str(\":/?#[]@\")\nRFC3986_SUBDELIMS = str(\"!$&'()*+,;=\")\n\nPROTOCOL_TO_PORT = {\n    'http': 80,\n    'https': 443,\n}\n\n\n@keep_lazy_text\ndef urlquote(url, safe='/'):\n    \"\"\"\n    A version of Python's urllib.quote() function that can operate on unicode\n    strings. The url is first UTF-8 encoded before quoting. The returned string\n    can safely be used as part of an argument to a subsequent iri_to_uri() call\n    without double-quoting occurring.\n    \"\"\"\n    return force_text(quote(force_str(url), force_str(safe)))\n\n\n@keep_lazy_text\ndef urlquote_plus(url, safe=''):\n    \"\"\"\n    A version of Python's urllib.quote_plus() function that can operate on\n    unicode strings. The url is first UTF-8 encoded before quoting. The\n    returned string can safely be used as part of an argument to a subsequent\n    iri_to_uri() call without double-quoting occurring.\n    \"\"\"\n    return force_text(quote_plus(force_str(url), force_str(safe)))\n\n\n@keep_lazy_text\ndef urlunquote(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote() function that can operate on\n    the result of django.utils.http.urlquote().\n    \"\"\"\n    return force_text(unquote(force_str(quoted_url)))\n\n\n@keep_lazy_text\ndef urlunquote_plus(quoted_url):\n    \"\"\"\n    A wrapper for Python's urllib.unquote_plus() function that can operate on\n    the result of django.utils.http.urlquote_plus().\n    \"\"\"\n    return force_text(unquote_plus(force_str(quoted_url)))\n\n\ndef urlencode(query, doseq=0):\n    \"\"\"\n    A version of Python's urllib.urlencode() function that can operate on\n    unicode strings. The parameters are first cast to UTF-8 encoded strings and\n    then encoded as per normal.\n    \"\"\"\n    if isinstance(query, MultiValueDict):\n        query = query.lists()\n    elif hasattr(query, 'items'):\n        query = query.items()\n    return original_urlencode(\n        [(force_str(k),\n         [force_str(i) for i in v] if isinstance(v, (list, tuple)) else force_str(v))\n            for k, v in query],\n        doseq)\n\n\ndef cookie_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to ensure compatibility with Netscape's cookie standard.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.\n    \"\"\"\n    rfcdate = formatdate(epoch_seconds)\n    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])\n\n\ndef http_date(epoch_seconds=None):\n    \"\"\"\n    Formats the time to match the RFC1123 date format as specified by HTTP\n    RFC2616 section 3.3.1.\n\n    Accepts a floating point number expressed in seconds since the epoch, in\n    UTC - such as that outputted by time.time(). If set to None, defaults to\n    the current time.\n\n    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.\n    \"\"\"\n    return formatdate(epoch_seconds, usegmt=True)\n\n\ndef parse_http_date(date):\n    \"\"\"\n    Parses a date format as specified by HTTP RFC2616 section 3.3.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Returns an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately\n    # RFC2616 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        year = int(m.group('year'))\n        if year < 100:\n            if year < 70:\n                year += 2000\n            else:\n                year += 1900\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec)\n        return calendar.timegm(result.utctimetuple())\n    except Exception:\n        six.reraise(ValueError, ValueError(\"%r is not a valid date\" % date), sys.exc_info()[2])\n\n\ndef parse_http_date_safe(date):\n    \"\"\"\n    Same as parse_http_date, but returns None if the input is invalid.\n    \"\"\"\n    try:\n        return parse_http_date(date)\n    except Exception:\n        pass\n\n\n# Base 36 functions: useful for generating compact URLs\n\ndef base36_to_int(s):\n    \"\"\"\n    Converts a base 36 string to an ``int``. Raises ``ValueError` if the\n    input won't fit into an int.\n    \"\"\"\n    # To prevent overconsumption of server resources, reject any\n    # base36 string that is long than 13 base36 digits (13 digits\n    # is sufficient to base36-encode any 64-bit integer)\n    if len(s) > 13:\n        raise ValueError(\"Base36 input too large\")\n    value = int(s, 36)\n    # ... then do a final check that the value will fit into an int to avoid\n    # returning a long (#15067). The long type was removed in Python 3.\n    if six.PY2 and value > sys.maxint:\n        raise ValueError(\"Base36 input too large\")\n    return value\n\n\ndef int_to_base36(i):\n    \"\"\"\n    Converts an integer to a base36 string\n    \"\"\"\n    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'\n    if i < 0:\n        raise ValueError(\"Negative base36 conversion input.\")\n    if six.PY2:\n        if not isinstance(i, six.integer_types):\n            raise TypeError(\"Non-integer base36 conversion input.\")\n        if i > sys.maxint:\n            raise ValueError(\"Base36 conversion input too large.\")\n    if i < 36:\n        return char_set[i]\n    b36 = ''\n    while i != 0:\n        i, n = divmod(i, 36)\n        b36 = char_set[n] + b36\n    return b36\n\n\ndef urlsafe_base64_encode(s):\n    \"\"\"\n    Encodes a bytestring in base64 for use in URLs, stripping any trailing\n    equal signs.\n    \"\"\"\n    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')\n\n\ndef urlsafe_base64_decode(s):\n    \"\"\"\n    Decodes a base64 encoded string, adding back any trailing equal signs that\n    might have been stripped.\n    \"\"\"\n    s = force_bytes(s)\n    try:\n        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))\n    except (LookupError, BinasciiError) as e:\n        raise ValueError(e)\n\n\ndef parse_etags(etag_str):\n    \"\"\"\n    Parses a string with one or several etags passed in If-None-Match and\n    If-Match headers by the rules in RFC 2616. Returns a list of etags\n    without surrounding double quotes (\") and unescaped from \\<CHAR>.\n    \"\"\"\n    etags = ETAG_MATCH.findall(etag_str)\n    if not etags:\n        # etag_str has wrong format, treat it as an opaque string then\n        return [etag_str]\n    etags = [e.encode('ascii').decode('unicode_escape') for e in etags]\n    return etags\n\n\ndef quote_etag(etag):\n    \"\"\"\n    Wraps a string in double quotes escaping contents as necessary.\n    \"\"\"\n    return '\"%s\"' % etag.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n\n\ndef unquote_etag(etag):\n    \"\"\"\n    Unquote an ETag string; i.e. revert quote_etag().\n    \"\"\"\n    return etag.strip('\"').replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\') if etag else etag\n\n\ndef is_same_domain(host, pattern):\n    \"\"\"\n    Return ``True`` if the host is either an exact match or a match\n    to the wildcard pattern.\n\n    Any pattern beginning with a period matches a domain and all of its\n    subdomains. (e.g. ``.example.com`` matches ``example.com`` and\n    ``foo.example.com``). Anything else is an exact string match.\n    \"\"\"\n    if not pattern:\n        return False\n\n    pattern = pattern.lower()\n    return (\n        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or\n        pattern == host\n    )\n\n\ndef is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)\n\n\ndef _is_safe_url(url, host):\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    return ((not url_info.netloc or url_info.netloc == host) and\n            (not url_info.scheme or url_info.scheme in ['http', 'https']))\n"
  }
]
